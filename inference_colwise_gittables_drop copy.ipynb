{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/zhihao/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/zhihao/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "from time import time\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from collections import defaultdict\n",
    "\n",
    "# import pytrec_eval\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss, BCEWithLogitsLoss\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, BertConfig, AutoTokenizer\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from accelerate import Accelerator\n",
    "from copy import deepcopy\n",
    "\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "from watchog.dataset import (\n",
    "    # collate_fn,\n",
    "    TURLColTypeTablewiseDataset,\n",
    "    TURLRelExtTablewiseDataset,\n",
    "    SatoCVTablewiseDataset,\n",
    "    ColPoplTablewiseDataset\n",
    ")\n",
    "\n",
    "from watchog.dataset import TableDataset, SupCLTableDataset, SemtableCVTablewiseDataset, GittablesColwiseDataset, GittablesTablewiseDataset\n",
    "from watchog.model import BertMultiPairPooler, BertForMultiOutputClassification, BertForMultiOutputClassificationColPopl, Verifier\n",
    "from watchog.model import SupCLforTable, UnsupCLforTable, lm_mp\n",
    "from watchog.utils import load_checkpoint, f1_score_multilabel, collate_fn, get_col_pred, ColPoplEvaluator\n",
    "from watchog.utils import task_num_class_dict\n",
    "from accelerate import DistributedDataParallelKwargs\n",
    "import wandb\n",
    "\n",
    "from argparse import Namespace\n",
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import re\n",
    "import transformers\n",
    "from torch.utils import data\n",
    "from torch.nn.utils import rnn\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from typing import List\n",
    "from functools import reduce\n",
    "import operator\n",
    "\n",
    "from itertools import chain\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args={\"wandb\": false, \"model\": \"Watchog\", \"unlabeled_train_only\": false, \"context_encoding_type\": \"v0\", \"pool_version\": \"v0.2\", \"random_sample\": false, \"comment\": \"debug\", \"shortcut_name\": \"bert-base-uncased\", \"max_length\": 64, \"adaptive_max_length\": false, \"max_num_col\": 8, \"batch_size\": 3, \"epoch\": 1, \"random_seed\": 4649, \"train_n_seed_cols\": -1, \"num_classes\": 101, \"multi_gpu\": false, \"fp16\": false, \"warmup\": 0.0, \"lr\": 5e-05, \"task\": \"gt-semtab22-dbpedia-all0\", \"colpair\": false, \"metadata\": false, \"from_scratch\": false, \"cl_tag\": \"wikitables/simclr/bert_100000_10_32_256_5e-05_sample_row4,sample_row4_tfidf_entity_column_0.05_0_last.pt\", \"dropout_prob\": 0.5, \"eval_test\": true, \"small_tag\": \"semi1\", \"data_path\": \"/data/zhihao/TU/\", \"pretrained_ckpt_path\": \"/data/zhihao/TU/Watchog/model/\"}\n",
      "gt-semtab22-dbpedia-all0/wikitables-simclr-bert_100000_10_32_256_5e-05_sample_row4,sample_row4_tfidf_entity_column_0.05_0_last.pt_bert-base-uncased-poolsemi1-max_colsv0.2-rand8-bsFalse-ml3-ne64-do10.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "/tmp/ipykernel_1200793/4069850021.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(ckpt_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(augment_op='sample_row4,sample_row4', batch_size=32, data_path='/data/zhihao/TU/TURL/', fp16=True, gpus='0', lm='bert', logdir='/data/zhihao/TU/Watchog/model/', lr=5e-05, max_len=256, mode='simclr', model='Watchog', n_epochs=10, pretrain_data='wikitables', pretrained_model_path='', projector=768, run_id=0, sample_meth='tfidf_entity', save_model=10, single_column=False, size=100000, table_order='column', temperature=0.05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "    device = torch.device(2)\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--wandb\", type=bool, default=False)\n",
    "    parser.add_argument(\"--model\", type=str, default=\"Watchog\")\n",
    "    parser.add_argument(\"--unlabeled_train_only\", type=bool, default=False)\n",
    "    parser.add_argument(\"--context_encoding_type\", type=str, default=\"v0\")\n",
    "    parser.add_argument(\"--pool_version\", type=str, default=\"v0.2\")\n",
    "    parser.add_argument(\"--random_sample\", type=bool, default=False)\n",
    "    parser.add_argument(\"--comment\", type=str, default=\"debug\", help=\"to distinguish the runs\")\n",
    "    parser.add_argument(\n",
    "        \"--shortcut_name\",\n",
    "        default=\"bert-base-uncased\",\n",
    "        type=str,\n",
    "        help=\"Huggingface model shortcut name \",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--max_length\",\n",
    "        default=64,\n",
    "        type=int,\n",
    "        help=\n",
    "        \"The maximum total input sequence length after tokenization. Sequences longer \"\n",
    "        \"than this will be truncated, sequences shorter will be padded.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--adaptive_max_length\",\n",
    "        default=False,\n",
    "        type=bool,\n",
    "    )    \n",
    "    parser.add_argument(\n",
    "        \"--max_num_col\",\n",
    "        default=8,\n",
    "        type=int,\n",
    "    )   \n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--batch_size\",\n",
    "        default=3,\n",
    "        type=int,\n",
    "        help=\"Batch size\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--epoch\",\n",
    "        default=1,\n",
    "        type=int,\n",
    "        help=\"Number of epochs for training\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--random_seed\",\n",
    "        default=4649,\n",
    "        type=int,\n",
    "        help=\"Random seed\",\n",
    "    )\n",
    "    \n",
    "    parser.add_argument(\n",
    "        \"--train_n_seed_cols\",\n",
    "        default=-1,\n",
    "        type=int,\n",
    "        help=\"number of seeding columns in training\",\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--num_classes\",\n",
    "        default=78,\n",
    "        type=int,\n",
    "        help=\"Number of classes\",\n",
    "    )\n",
    "    parser.add_argument(\"--multi_gpu\",\n",
    "                        action=\"store_true\",\n",
    "                        default=False,\n",
    "                        help=\"Use multiple GPU\")\n",
    "    parser.add_argument(\"--fp16\",\n",
    "                        action=\"store_true\",\n",
    "                        default=False,\n",
    "                        help=\"Use FP16\")\n",
    "    parser.add_argument(\"--warmup\",\n",
    "                        type=float,\n",
    "                        default=0.,\n",
    "                        help=\"Warmup ratio\")\n",
    "    parser.add_argument(\"--lr\", type=float, default=5e-5, help=\"Learning rate\")\n",
    "    parser.add_argument(\"--task\",\n",
    "                        type=str,\n",
    "                        default='gt-semtab22-dbpedia-all0',\n",
    "                        choices=[\n",
    "                            \"sato0\", \"sato1\", \"sato2\", \"sato3\", \"sato4\",\n",
    "                            \"msato0\", \"msato1\", \"msato2\", \"msato3\", \"msato4\",\n",
    "                            \"gt-dbpedia0\", \"gt-dbpedia1\", \"gt-dbpedia2\", \"gt-dbpedia3\", \"gt-dbpedia4\",\n",
    "                            \"gt-dbpedia-all0\", \"gt-dbpedia-all1\", \"gt-dbpedia-all2\", \"gt-dbpedia-all3\", \"gt-dbpedia-all4\",\n",
    "                            \"gt-schema-all0\", \"gt-schema-all1\", \"gt-schema-all2\", \"gt-schema-all3\", \"gt-schema-all4\",\n",
    "                            \"gt-semtab22-dbpedia\", \"gt-semtab22-dbpedia0\", \"gt-semtab22-dbpedia1\", \"gt-semtab22-dbpedia2\", \"gt-semtab22-dbpedia3\", \"gt-semtab22-dbpedia4\",\n",
    "                            \"gt-semtab22-dbpedia-all\", \"gt-semtab22-dbpedia-all0\", \"gt-semtab22-dbpedia-all1\", \"gt-semtab22-dbpedia-all2\", \"gt-semtab22-dbpedia-all3\", \"gt-semtab22-dbpedia-all4\",\n",
    "                            \"gt-semtab22-schema-class-all\", \"gt-semtab22-schema-property-all\",\n",
    "                            \"turl\", \"turl-re\", \"col-popl-1\", \"col-popl-2\", \"col-popl-3\", \"row-popl\",\n",
    "                            \"col-popl-turl-0\", \"col-popl-turl-1\", \"col-popl-turl-2\",\n",
    "                            \"col-popl-turl-mdonly-0\", \"col-popl-turl-mdonly-1\", \"col-popl-turl-mdonly-2\"\n",
    "                        ],\n",
    "                        help=\"Task names}\")\n",
    "    parser.add_argument(\"--colpair\",\n",
    "                        action=\"store_true\",\n",
    "                        help=\"Use column pair embedding\")\n",
    "    parser.add_argument(\"--metadata\",\n",
    "                        action=\"store_true\",\n",
    "                        help=\"Use column header metadata\")\n",
    "    parser.add_argument(\"--from_scratch\",\n",
    "                        action=\"store_true\",\n",
    "                        help=\"Training from scratch\")\n",
    "    parser.add_argument(\"--cl_tag\",\n",
    "                        type=str,\n",
    "                        default=\"wikitables/simclr/bert_100000_10_32_256_5e-05_sample_row4,sample_row4_tfidf_entity_column_0.05_0_last.pt\",\n",
    "                        help=\"path to the pre-trained file\")\n",
    "    parser.add_argument(\"--dropout_prob\",\n",
    "                        type=float,\n",
    "                        default=0.5)\n",
    "    parser.add_argument(\"--eval_test\",\n",
    "                        action=\"store_true\",\n",
    "                        help=\"evaluate on testset and do not save the model file\")\n",
    "    parser.add_argument(\"--small_tag\",\n",
    "                        type=str,\n",
    "                        default=\"semi1\",\n",
    "                        help=\"e.g., by_table_t5_v1\")\n",
    "    parser.add_argument(\"--data_path\",\n",
    "                        type=str,\n",
    "                        default=\"/data/zhihao/TU/\")\n",
    "    parser.add_argument(\"--pretrained_ckpt_path\",\n",
    "                        type=str,\n",
    "                        default=\"/data/zhihao/TU/Watchog/model/\")    \n",
    "\n",
    "    args = parser.parse_args([])\n",
    "    task = args.task\n",
    "    if args.small_tag != \"\":\n",
    "        args.eval_test = True\n",
    "    \n",
    "    args.num_classes = task_num_class_dict[task]\n",
    "    if args.colpair:\n",
    "        assert \"turl-re\" == task, \"colpair can be only used for Relation Extraction\"\n",
    "    if args.metadata:\n",
    "        assert \"turl-re\" == task or \"turl\" == task, \"metadata can be only used for TURL datasets\"\n",
    "    if \"col-popl\":\n",
    "        # metrics = {\n",
    "        #     \"accuracy\": CategoricalAccuracy(tie_break=True),\n",
    "        # }\n",
    "        if args.train_n_seed_cols != -1:\n",
    "            if \"col-popl\" in task:\n",
    "                assert args.train_n_seed_cols == int(task[-1]),  \"# of seed columns must match\"\n",
    "\n",
    "    print(\"args={}\".format(json.dumps(vars(args))))\n",
    "\n",
    "    max_length = args.max_length\n",
    "    batch_size = args.batch_size\n",
    "    num_train_epochs = args.epoch\n",
    "\n",
    "    shortcut_name = args.shortcut_name\n",
    "\n",
    "    if args.colpair and args.metadata:\n",
    "        taskname = \"{}-colpair-metadata\".format(task)\n",
    "    elif args.colpair:\n",
    "        taskname = \"{}-colpair\".format(task)\n",
    "    elif args.metadata:\n",
    "        taskname = \"{}-metadata\".format(task)\n",
    "    elif args.train_n_seed_cols == -1 and 'popl' in task:\n",
    "        taskname = \"{}-mix\".format(task)\n",
    "    else:\n",
    "        taskname = \"\".join(task)\n",
    "    cv = int(task[-1])\n",
    "\n",
    "    if args.from_scratch:\n",
    "        if \"gt\" in task:\n",
    "            tag_name = \"{}/{}-{}-{}-pool{}-max_cols{}-rand{}-bs{}-ml{}-ne{}-do{}{}\".format(\n",
    "                taskname,  \"{}-fromscratch\".format(shortcut_name), args.small_tag, args.comment, args.pool_version, args.max_num_col, args.random_sample,\n",
    "                batch_size, max_length, num_train_epochs, args.dropout_prob, \n",
    "                '-rs{}'.format(args.random_seed) if args.random_seed != 4649 else '')\n",
    "        else:\n",
    "            tag_name = \"{}/{}-{}-{}-bs{}-ml{}-ne{}-do{}{}\".format(\n",
    "                taskname,  \"{}-fromscratch\".format(shortcut_name), args.small_tag, args.comment, \n",
    "                batch_size, max_length, num_train_epochs, args.dropout_prob, \n",
    "                '-rs{}'.format(args.random_seed) if args.random_seed != 4649 else '')\n",
    "        \n",
    "    else:\n",
    "        if \"gt\" in task:\n",
    "            tag_name = \"{}/{}_{}-pool{}-max_cols{}-rand{}-bs{}-ml{}-ne{}-do{}{}\".format(\n",
    "                taskname, args.cl_tag.replace('/', '-'),  shortcut_name, args.small_tag, args.pool_version, args.max_num_col, args.random_sample,\n",
    "                batch_size, max_length, num_train_epochs, args.dropout_prob,\n",
    "                '-rs{}'.format(args.random_seed) if args.random_seed != 4649 else '')\n",
    "        else:\n",
    "            tag_name = \"{}/{}_{}-{}-bs{}-ml{}-ne{}-do{}{}\".format(\n",
    "                taskname, args.cl_tag.replace('/', '-'),  shortcut_name, args.small_tag,\n",
    "                batch_size, max_length, num_train_epochs, args.dropout_prob,\n",
    "                '-rs{}'.format(args.random_seed) if args.random_seed != 4649 else '')\n",
    "\n",
    "    # if args.eval_test:\n",
    "    #     if args.small_tag != '':\n",
    "    #         tag_name = tag_name.replace('outputs', 'small_outputs')\n",
    "    #         tag_name += '-' + args.small_tag\n",
    "    print(tag_name)\n",
    "    file_path = os.path.join(args.data_path, \"Watchog\", \"outputs\", tag_name)\n",
    "\n",
    "    dirpath = os.path.dirname(file_path)\n",
    "    if not os.path.exists(dirpath):\n",
    "        print(\"{} not exists. Created\".format(dirpath))\n",
    "        os.makedirs(dirpath)\n",
    "    \n",
    "    if args.fp16:\n",
    "        torch.backends.cuda.matmul.allow_fp16_reduced_precision_reduction = True\n",
    "        \n",
    "      \n",
    "        \n",
    "    # accelerator = Accelerator(mixed_precision=\"no\" if not args.fp16 else \"fp16\")   \n",
    "    ddp_kwargs = DistributedDataParallelKwargs(find_unused_parameters=True)\n",
    "    accelerator = Accelerator(mixed_precision=\"no\" if not args.fp16 else \"fp16\", kwargs_handlers=[ddp_kwargs])\n",
    "\n",
    "    device = torch.device(1)\n",
    "    ckpt_path = os.path.join(args.pretrained_ckpt_path, args.cl_tag)\n",
    "    # ckpt_path = '/efs/checkpoints/{}.pt'.format(args.cl_tag)\n",
    "    ckpt = torch.load(ckpt_path, map_location=device)\n",
    "    ckpt_hp = ckpt['hp']\n",
    "    print(ckpt_hp)\n",
    " \n",
    "    setattr(ckpt_hp, 'batch_size', args.batch_size)\n",
    "    setattr(ckpt_hp, 'hidden_dropout_prob', args.dropout_prob)\n",
    "    setattr(ckpt_hp, 'shortcut_name', args.shortcut_name)\n",
    "    setattr(ckpt_hp, 'num_labels', args.num_classes)\n",
    "    \n",
    "    \n",
    "    \n",
    "    tokenizer = BertTokenizer.from_pretrained(shortcut_name)\n",
    "    padder = collate_fn(tokenizer.pad_token_id)\n",
    "    if task == \"turl-re\" and args.colpair:\n",
    "        model = BertForMultiOutputClassification(ckpt_hp, device=device, lm=ckpt['hp'].lm, col_pair='Pair')\n",
    "    elif \"col-popl\" in task:\n",
    "        model = BertForMultiOutputClassificationColPopl(ckpt_hp, device=device, lm=ckpt['hp'].lm, n_seed_cols=int(task[i][-1]), cls_for_md=\"md\" in task)\n",
    "    else:\n",
    "        model = BertForMultiOutputClassification(ckpt_hp, device=device, lm=ckpt['hp'].lm, version=\"v0\", use_attention_mask=True)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1200793/307592194.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_state_dict = torch.load(\"/data/zhihao/TU/Watchog/outputs/gt-semtab22-dbpedia-all0/bert-base-uncased-fromscratch-semi1-Repeat@5-AttnMask-UnlabelValid-max-unlabeled@8-poolv0-unlabeled8-randFalse-bs16-ml128-ne50-do0.1_best_f1_macro.pt\", map_location=device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best_state_dict = torch.load(\"/data/zhihao/TU/Watchog/outputs/gt-semtab22-dbpedia-all0/bert-base-uncased-fromscratch-semi1-AttnMask-max-unlabeled@8-poolv0-unlabeled8-randFalse-bs16-ml128-ne50-do0.1_best_f1_micro.pt\", map_location=device)\n",
    "best_state_dict = torch.load(\"/data/zhihao/TU/Watchog/outputs/gt-semtab22-dbpedia-all0/bert-base-uncased-fromscratch-semi1-Repeat@5-AttnMask-UnlabelValid-max-unlabeled@8-poolv0-unlabeled8-randFalse-bs16-ml128-ne50-do0.1_best_f1_macro.pt\", map_location=device)\n",
    "model.load_state_dict(best_state_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GittablesTablewiseIterateDataset(data.Dataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            cv: int,\n",
    "            split: str,\n",
    "            src: str,  # train or test\n",
    "            tokenizer: AutoTokenizer,\n",
    "            max_length: int = 256,\n",
    "            gt_only: bool = False,\n",
    "            device: torch.device = None,\n",
    "            base_dirpath: str = \"/data/zhihao/TU/GitTables/semtab_gittables/2022\",\n",
    "            base_tag: str = '', # blank, comma\n",
    "            small_tag: str = \"\",\n",
    "            train_ratio: float = 1.0,\n",
    "            max_unlabeled=8,\n",
    "            random_sample=False, # TODO\n",
    "            train_only=False): # TODO\n",
    "        if device is None:\n",
    "            device = torch.device('cpu')\n",
    "        basename = small_tag+ \"_cv_{}.csv\"\n",
    "    \n",
    "        if split in [\"train\", \"valid\"]:\n",
    "            df_list = []\n",
    "            for i in range(5):\n",
    "                if i == cv:\n",
    "                    continue\n",
    "                filepath = os.path.join(base_dirpath, basename.format(i))\n",
    "                df_list.append(pd.read_csv(filepath))\n",
    "                print(split, i)\n",
    "            df = pd.concat(df_list, axis=0)\n",
    "        else:\n",
    "            # test\n",
    "            filepath = os.path.join(base_dirpath, basename.format(cv))\n",
    "            df = pd.read_csv(filepath)\n",
    "            print(split)\n",
    "\n",
    "\n",
    "        if gt_only:\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "        if train_only and split != \"train\":\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "\n",
    "        \n",
    "        data_list = []\n",
    "        \n",
    "        df['class_id'] = df['class_id'].astype(int)\n",
    "        df.drop(df[(df['data'].isna()) & (df['class_id'] == -1)].index, inplace=True)\n",
    "        df['col_idx'] = df['col_idx'].astype(int)\n",
    "        df['data'] = df['data'].astype(str)\n",
    "        \n",
    "        num_tables = len(df.groupby(\"table_id\"))\n",
    "        valid_index = int(num_tables * 0.8)\n",
    "        num_train = int(train_ratio * num_tables * 0.8)        \n",
    "        \n",
    "        # df.drop(df[(df['data'] == '') & (df['class_id'] == -1)].index, inplace=True)\n",
    "        total_num_cols = 0\n",
    "        for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "            if (split == \"train\") and ((i >= num_train) or (i >= valid_index)):\n",
    "                break\n",
    "            if split == \"valid\" and i < valid_index:\n",
    "                continue\n",
    "            #     break\n",
    "            labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "            unlabeled_columns = group_df[group_df['class_id'] == -1]\n",
    "            num_unlabeled = min(max(max_unlabeled-len(labeled_columns), 0), len(unlabeled_columns)) if max_unlabeled > 0 else len(unlabeled_columns)\n",
    "            unlabeled_columns = unlabeled_columns.sample(num_unlabeled) if random_sample else unlabeled_columns[0:num_unlabeled]\n",
    "            # group_df = pd.concat([group_df[group_df['class_id'] > -1], unlabeled_columns.sample(min(10-len(labeled_columns), len(unlabeled_columns)))])\n",
    "            # group_df = pd.concat([group_df[group_df['class_id'] > -1], unlabeled_columns[0:min(max(10-len(labeled_columns), 0), len(unlabeled_columns))]])\n",
    "            group_df = pd.concat([group_df[group_df['class_id'] > -1], unlabeled_columns]) # TODO\n",
    "            group_df.sort_values(by=['col_idx'], inplace=True)\n",
    "\n",
    "            if max_length <= 128:\n",
    "                cur_maxlen = min(max_length, 512 // len(list(group_df[\"class_id\"].values)) - 1)\n",
    "            else:\n",
    "                cur_maxlen = max(1, max_length // len(list(group_df[\"class_id\"].values)) - 1)\n",
    "                \n",
    "            token_ids_list = group_df[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=cur_maxlen, truncation=True)).tolist(\n",
    "                )\n",
    "            token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                                token_ids_list)).to(device)\n",
    "            for col_i in range(len(token_ids_list)):\n",
    "                if group_df[\"class_id\"].values[col_i] == -1:\n",
    "                    continue\n",
    "                target_col_mask = []\n",
    "                cls_index_value = 0\n",
    "                context_id = 1\n",
    "                for col_j in range(len(token_ids_list)):\n",
    "                    if col_j == col_i:\n",
    "                        target_col_mask += [0] * len(token_ids_list[col_j])\n",
    "                    else:\n",
    "                        target_col_mask += [context_id] * len(token_ids_list[col_j])\n",
    "                        context_id += 1\n",
    "                    if col_j < col_i:\n",
    "                        cls_index_value += len(token_ids_list[col_j])\n",
    "                cls_index_list = [cls_index_value] \n",
    "                for cls_index in cls_index_list:\n",
    "                    assert token_ids[\n",
    "                        cls_index] == tokenizer.cls_token_id, \"cls_indexes validation\"\n",
    "                cls_indexes = torch.LongTensor(cls_index_list).to(device)\n",
    "                class_ids = torch.LongTensor(\n",
    "                    [group_df[\"class_id\"].values[col_i]]).to(device)\n",
    "                target_col_mask = torch.LongTensor(target_col_mask).to(device)\n",
    "                data_list.append(\n",
    "                    [index,\n",
    "                    len(group_df), token_ids, class_ids, cls_indexes, target_col_mask])                \n",
    "        print(split, len(data_list))\n",
    "        self.table_df = pd.DataFrame(data_list,\n",
    "                                     columns=[\n",
    "                                         \"table_id\", \"num_col\", \"data_tensor\",\n",
    "                                         \"label_tensor\", \"cls_indexes\", \"target_col_mask\"\n",
    "                                     ])\n",
    "        \"\"\"\n",
    "        # NOTE: msato contains a small portion of single-col tables. keep it to be consistent.  \n",
    "        if multicol_only:\n",
    "            # Check\n",
    "            num_all_tables = len(self.table_df)\n",
    "            self.table_df = self.table_df[self.table_df[\"num_col\"] > 1]\n",
    "            assert len(self.table_df) == num_all_tables\n",
    "        \"\"\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.table_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"data\": self.table_df.iloc[idx][\"data_tensor\"],\n",
    "            \"label\": self.table_df.iloc[idx][\"label_tensor\"],\n",
    "            \"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"],\n",
    "            \"target_col_mask\": self.table_df.iloc[idx][\"target_col_mask\"],\n",
    "        }\n",
    "        #\"idx\": torch.LongTensor([idx])}\n",
    "        #\"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(pad_token_id, data_only=True):\n",
    "    '''padder for input batch'''\n",
    "\n",
    "    def padder(samples):    \n",
    "        data = torch.nn.utils.rnn.pad_sequence(\n",
    "            [sample[\"data\"] for sample in samples], padding_value=pad_token_id)\n",
    "        if not data_only:\n",
    "            label = torch.nn.utils.rnn.pad_sequence(\n",
    "                [sample[\"label\"] for sample in samples], padding_value=-1)\n",
    "        else:\n",
    "            label = torch.cat([sample[\"label\"] for sample in samples])\n",
    "        batch = {\"data\": data, \"label\": label}\n",
    "        if \"idx\" in samples[0]:\n",
    "            batch[\"idx\"] = [sample[\"idx\"] for sample in samples]\n",
    "        if \"cls_indexes\" in samples[0]:\n",
    "            cls_indexes = torch.nn.utils.rnn.pad_sequence(\n",
    "                [sample[\"cls_indexes\"] for sample in samples], padding_value=0)\n",
    "            batch[\"cls_indexes\"] = cls_indexes\n",
    "        if \"target_col_mask\" in samples[0]:\n",
    "            target_col_mask = torch.nn.utils.rnn.pad_sequence(\n",
    "                [sample[\"target_col_mask\"] for sample in samples], padding_value=-1)\n",
    "            batch[\"target_col_mask\"] = target_col_mask\n",
    "        if \"table_embedding\" in samples[0]:\n",
    "            table_embeddings = [sample[\"table_embedding\"] for sample in samples]\n",
    "            batch[\"table_embedding\"] = torch.stack(table_embeddings, dim=0)\n",
    "        return batch\n",
    "        \n",
    "    return padder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "test 1085\n"
     ]
    }
   ],
   "source": [
    "src = None\n",
    "test_dataset_iter = GittablesTablewiseIterateDataset(cv=cv,\n",
    "                            split=\"test\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only='all' not in task,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\")\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "test_dataloader_iter = DataLoader(test_dataset_iter,\n",
    "                                batch_size=1,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 1\n",
      "train 2\n",
      "train 3\n",
      "train 4\n",
      "train 3463\n"
     ]
    }
   ],
   "source": [
    "train_dataset_iter = GittablesTablewiseIterateDataset(cv=cv,\n",
    "                            split=\"train\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only='all' not in task,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\")\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "train_dataloader_iter = DataLoader(train_dataset_iter,\n",
    "                                batch_size=1,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid 1\n",
      "valid 2\n",
      "valid 3\n",
      "valid 4\n",
      "valid 885\n"
     ]
    }
   ],
   "source": [
    "src = None\n",
    "valid_dataset_iter = GittablesTablewiseIterateDataset(cv=cv,\n",
    "                            split=\"valid\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only='all' not in task,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\")\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "valid_dataloader_iter = DataLoader(valid_dataset_iter,\n",
    "                                batch_size=1,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_micro_f1=0.5355, ts_macro_f1=0.2745\n",
      "ts_micro_f1=0.5351, ts_macro_f1=0.2745\n",
      "ts_micro_f1=1.0000, ts_macro_f1=1.0000\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    labels_test.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "    num_cols.append(batch[\"target_col_mask\"].max().item())\n",
    "    ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "labels_test = torch.cat(labels_test, dim=0)\n",
    "logits_test = torch.stack(logits_test, dim=0)\n",
    "preds_test = torch.argmax(logits_test, dim=1)\n",
    "num_cols = torch.tensor(num_cols)\n",
    "ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "mask = num_cols > 0\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "full_f1_init = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=None)\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach()[mask].numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach()[~mask].numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.82129278, 0.7003367 , 0.49019608, 0.41463415, 0.5       ,\n",
       "       0.57777778, 0.54545455, 0.5       , 0.31578947, 0.81081081,\n",
       "       0.21621622, 0.20689655, 0.84848485, 0.1875    , 0.64285714,\n",
       "       0.86666667, 0.10526316, 0.5       , 0.21428571, 0.92307692,\n",
       "       0.46153846, 0.56      , 0.28571429, 0.42105263, 0.31578947,\n",
       "       0.33333333, 0.26666667, 0.        , 0.14285714, 0.5       ,\n",
       "       0.36363636, 0.        , 0.        , 0.35294118, 0.44444444,\n",
       "       0.42857143, 0.26666667, 0.2       , 0.25      , 0.2       ,\n",
       "       0.        , 0.28571429, 0.30769231, 0.22222222, 0.        ,\n",
       "       0.        , 0.33333333, 0.        , 0.33333333, 0.33333333,\n",
       "       0.28571429, 0.        , 0.5       , 0.25      , 0.66666667,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 1.        , 0.        , 0.66666667, 0.        ,\n",
       "       0.        , 0.        , 0.5       , 0.33333333, 0.33333333,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.28571429, 0.33333333, 0.66666667, 0.28571429, 0.        ,\n",
       "       0.        , 0.        , 0.4       , 0.        , 0.22222222,\n",
       "       0.5       , 0.        , 0.5       , 1.        , 0.        ,\n",
       "       0.        , 0.33333333, 0.        , 0.        , 0.66666667,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_f1_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_micro_f1=0.5503, ts_macro_f1=0.3178\n",
      "ts_micro_f1=0.5493, ts_macro_f1=0.3178\n",
      "ts_micro_f1=1.0000, ts_macro_f1=1.0000\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(valid_dataloader_iter):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    labels_test.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "    num_cols.append(batch[\"target_col_mask\"].max().item())\n",
    "    ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "labels_test = torch.cat(labels_test, dim=0)\n",
    "logits_test = torch.stack(logits_test, dim=0)\n",
    "preds_test = torch.argmax(logits_test, dim=1)\n",
    "num_cols = torch.tensor(num_cols)\n",
    "ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "mask = num_cols > 0\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach()[mask].numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach()[~mask].numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_freq = torch.zeros(args.num_classes)\n",
    "for batch_idx, batch in enumerate(train_dataloader_iter):\n",
    "    class_freq[batch[\"label\"].item()] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def reweight_logits(logits, class_weights):\n",
    "#     # Reweight the logits by multiplying with class weights\n",
    "#     reweighted_logits = logits * torch.sqrt(class_weights)\n",
    "    \n",
    "#     # Apply softmax to the reweighted logits\n",
    "#     reweighted_probs = F.softmax(reweighted_logits, dim=-1)\n",
    "    \n",
    "#     return reweighted_probs\n",
    "def reweight_logits(logits, class_weights):\n",
    "    # Step 1: Apply exp(logits)\n",
    "    exp_logits = torch.exp(logits)\n",
    "    \n",
    "    # Step 2: Multiply by class weights\n",
    "    # reweighted_exp = exp_logits * torch.sqrt(class_weights)\n",
    "    reweighted_exp = exp_logits * class_weights\n",
    "    # Step 3: Normalize to get valid probabilities (like softmax)\n",
    "    reweighted_probs = reweighted_exp / reweighted_exp.sum(dim=-1, keepdim=True)\n",
    "    \n",
    "    return reweighted_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Threshold: 0.9****************************\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# brute force perumate, find uncertain init prediction, weighted msp\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "idx_list = []\n",
    "uncertain_init_mask = []\n",
    "uncertain_target_mask = []\n",
    "correct_init_mask = []\n",
    "correct_target_mask = []\n",
    "correct_permutation_mask = []\n",
    "correct_permutation_confident_mask = []\n",
    "correct_permutation_confident_scores = []\n",
    "correct_msp_mask = []\n",
    "init_target_mask = []\n",
    "ood_score_init_list = []\n",
    "ood_score_target_list = []\n",
    "ood_score_final_list = []\n",
    "msp_predicts = []\n",
    "max_col_length = 3\n",
    "\n",
    "alpha = 0\n",
    "# class_weights = (1.0 / class_freq) ** alpha\n",
    "# debias_threshold = 1.0\n",
    "# # Normalize the weights\n",
    "# class_weights /= class_weights.sum()\n",
    "for threshold in [0.9]:\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    log = defaultdict(list)\n",
    "    num_cols = []\n",
    "    corrected = 0\n",
    "    total_mistakes = 0\n",
    "\n",
    "    for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "        target_col_mask = batch[\"target_col_mask\"].T\n",
    "        if 1 in target_col_mask:\n",
    "            idx_list.append(batch_idx)\n",
    "\n",
    "            cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "            logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "            # logits = reweight_logits(logits.detach().cpu(), class_weights)\n",
    "            logits = F.softmax(logits, dim=-1)\n",
    "            num_cols.append(batch[\"target_col_mask\"].max().item())         \n",
    "            ood_score_init = logits.max().item()\n",
    "            ood_score_init_list.append(ood_score_init)\n",
    "            uncertain_init_mask.append(ood_score_init < threshold)\n",
    "            predict_init = logits.argmax().item()\n",
    "            correct_init_mask.append(predict_init == batch[\"label\"].item())\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            \n",
    "            correct_permutation = False\n",
    "            correct_permutation_ood_score = 0.0\n",
    "            correct_permutation_confident = False\n",
    "            ood_score_max = max_msp = 0\n",
    "            max_msp_debiased = 0\n",
    "            debias_class = []\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            assert -1 not in col_idx_set\n",
    "            for r in range(len(col_idx_set)-1, len(col_idx_set)//2, -1):\n",
    "                for subset in itertools.combinations(col_idx_set, r):\n",
    "                    if 0 not in subset and r != 1:\n",
    "                        continue\n",
    "                    for x in itertools.permutations(subset):\n",
    "                        if not is_sublist(x, init_permutation_i):\n",
    "                            continue\n",
    "                        new_batch_data = []\n",
    "                        for col_i in x:\n",
    "                            if col_i == 0:\n",
    "                                if len(new_batch_data) == 0:\n",
    "                                    cls_indexes_value = 0\n",
    "                                else:\n",
    "                                    cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                            new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                        if 0 not in x:\n",
    "                            cls_indexes_value = 0\n",
    "                        new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                        cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                        logits_temp = model(new_batch_data, cls_indexes=cls_indexes,)\n",
    "                        logits_temp = F.softmax(logits_temp, dim=-1)\n",
    "                        # logits_temp = reweight_logits(logits_temp.detach().cpu(), class_weights)\n",
    "                        msp_temp = logits_temp.max().item()\n",
    "                        predict_temp = logits_temp.argmax().item()\n",
    "                        # if 0 not in x and msp_temp > debias_threshold and (predict_temp!=predict_target or predict_temp!=predict_init):\n",
    "                        #     debias_class.append(predict_temp)\n",
    "                        #     continue\n",
    "                        # print(x, msp_temp, predict_temp)\n",
    "                        # if msp_temp > max_msp and 0 in x and predict_temp not in debias_class:\n",
    "                        if msp_temp > max_msp and 0 in x:\n",
    "                            max_msp = msp_temp\n",
    "                            msp_predict = predict_temp\n",
    "                        if predict_temp == batch[\"label\"].item():\n",
    "                            correct_permutation = True\n",
    "                            if msp_temp > correct_permutation_ood_score:\n",
    "                                correct_permutation_ood_score = msp_temp\n",
    "            msp_predicts.append(msp_predict)\n",
    "            ood_score_final_list.append(max_msp)\n",
    "            correct_permutation_mask.append(correct_permutation)\n",
    "            correct_permutation_confident_scores.append(correct_permutation_ood_score)\n",
    "            correct_msp_mask.append(msp_predict == batch[\"label\"].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3888413/4104837288.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  idx_list = torch.tensor(idx_list).reshape(-1)\n",
      "/tmp/ipykernel_3888413/4104837288.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  uncertain_init_mask = torch.tensor(uncertain_init_mask).reshape(-1)\n",
      "/tmp/ipykernel_3888413/4104837288.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  uncertain_target_mask = torch.tensor(uncertain_target_mask).reshape(-1)\n",
      "/tmp/ipykernel_3888413/4104837288.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  correct_init_mask = torch.tensor(correct_init_mask).reshape(-1)\n",
      "/tmp/ipykernel_3888413/4104837288.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  correct_target_mask = torch.tensor(correct_target_mask).reshape(-1)\n",
      "/tmp/ipykernel_3888413/4104837288.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  correct_permutation_mask = torch.tensor(correct_permutation_mask).reshape(-1)\n",
      "/tmp/ipykernel_3888413/4104837288.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  correct_permutation_confident_scores = torch.tensor(correct_permutation_confident_scores).reshape(-1)\n",
      "/tmp/ipykernel_3888413/4104837288.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  correct_msp_mask = torch.tensor(correct_msp_mask).reshape(-1)\n",
      "/tmp/ipykernel_3888413/4104837288.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  init_target_mask = torch.tensor(init_target_mask).reshape(-1)\n",
      "/tmp/ipykernel_3888413/4104837288.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ood_score_init_list = torch.tensor(ood_score_init_list).reshape(-1)\n",
      "/tmp/ipykernel_3888413/4104837288.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ood_score_target_list = torch.tensor(ood_score_target_list).reshape(-1)\n",
      "/tmp/ipykernel_3888413/4104837288.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ood_score_final_list = torch.tensor(ood_score_final_list).reshape(-1)\n",
      "/tmp/ipykernel_3888413/4104837288.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  msp_predicts = torch.tensor(msp_predicts).reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1084 0 1084 0 1084\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# idx_list = torch.tensor(idx_list).reshape(-1)\n",
    "# uncertain_init_mask = torch.tensor(uncertain_init_mask).reshape(-1)\n",
    "# uncertain_target_mask = torch.tensor(uncertain_target_mask).reshape(-1)\n",
    "# correct_init_mask = torch.tensor(correct_init_mask).reshape(-1)\n",
    "# correct_target_mask = torch.tensor(correct_target_mask).reshape(-1)\n",
    "# correct_permutation_mask = torch.tensor(correct_permutation_mask).reshape(-1)\n",
    "# correct_permutation_confident_scores = torch.tensor(correct_permutation_confident_scores).reshape(-1)\n",
    "# correct_msp_mask = torch.tensor(correct_msp_mask).reshape(-1)\n",
    "# init_target_mask = torch.tensor(init_target_mask).reshape(-1)\n",
    "# ood_score_init_list = torch.tensor(ood_score_init_list).reshape(-1)\n",
    "# ood_score_target_list = torch.tensor(ood_score_target_list).reshape(-1)\n",
    "# ood_score_final_list = torch.tensor(ood_score_final_list).reshape(-1)\n",
    "# msp_predicts = torch.tensor(msp_predicts).reshape(-1)\n",
    "# print(len(idx_list), len(init_target_mask), len(correct_init_mask), len(correct_target_mask), len(correct_permutation_mask))\n",
    "# torch.save({\"idx_list\": idx_list, \"uncertain_init_mask\": uncertain_init_mask, \"uncertain_target_mask\": uncertain_target_mask, \"correct_init_mask\": correct_init_mask, \"correct_target_mask\": correct_target_mask, \"correct_permutation_mask\": correct_permutation_mask, \"correct_msp_mask\": correct_msp_mask, \"init_target_mask\": init_target_mask, \"ood_score_init_list\": ood_score_init_list, \"ood_score_target_list\": ood_score_target_list, \"ood_score_final_list\": ood_score_final_list}, f\"./results/brute_force_permutation_alpha@{alpha}_drop.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Max Column Length: 2****************************\n",
      "ts_micro_f1=0.7558, ts_macro_f1=0.5195\n",
      "ts_micro_f1=0.7555, ts_macro_f1=0.5195\n",
      "ts_micro_f1=1.0000, ts_macro_f1=1.0000\n",
      "Time: 397.4999978542328\n"
     ]
    }
   ],
   "source": [
    "# Cheat brute force perumate\n",
    "\n",
    "import itertools\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "for max_col_length in [2]:\n",
    "    start = time.time()\n",
    "    print(f\"*********************Max Column Length: {max_col_length}****************************\")\n",
    "    model.load_state_dict(best_state_dict, strict=False)\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    log = defaultdict(list)\n",
    "    num_cols = []\n",
    "    threshold = 0.8\n",
    "    corrected = 0\n",
    "    total_mistakes = 0\n",
    "    init_permutation = defaultdict(list)\n",
    "    corrected_permutation = defaultdict(list)\n",
    "    init_logits = defaultdict(list)\n",
    "    corrected_logits = defaultdict(list)\n",
    "    MSP_permutation = defaultdict(list)\n",
    "    MSP_logits = defaultdict(list)\n",
    "    MSP_corrected = 0\n",
    "    Entropy_permutation = defaultdict(list)\n",
    "    Entropy_logits = defaultdict(list)\n",
    "    Entropy_corrected = 0\n",
    "    for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "        cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "        target_col_mask = batch[\"target_col_mask\"].T\n",
    "        logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "        num_cols.append(batch[\"target_col_mask\"].max().item())\n",
    "        if 1 in target_col_mask and logits.argmax().item() != batch[\"label\"].item():\n",
    "            total_mistakes += 1\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            successs = False\n",
    "            assert -1 not in col_idx_set\n",
    "            for r in range(len(init_permutation_i)-1, 0, -1): # not \n",
    "                for x in itertools.combinations(init_permutation_i, r):\n",
    "                    if 0 not in x:\n",
    "                        continue\n",
    "                    new_batch_data = []\n",
    "                    for col_i in x:\n",
    "                        if col_i == 0:\n",
    "                            if len(new_batch_data) == 0:\n",
    "                                cls_indexes_value = 0\n",
    "                            else:\n",
    "                                cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                        new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                    new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                    cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                    logits_temp = model(new_batch_data, cls_indexes=cls_indexes,)\n",
    "                    if logits_temp.argmax().item() == batch[\"label\"].item():\n",
    "                        logits = logits_temp.clone()\n",
    "                        successs = True\n",
    "                        corrected_permutation[batch_idx].append(x)\n",
    "                        corrected_logits[batch_idx].append(logits_temp.clone().detach().cpu())\n",
    "                        break\n",
    "                if successs:\n",
    "                    break          \n",
    "            if successs:\n",
    "                corrected += 1\n",
    "        labels_test.append(batch[\"label\"].cpu())\n",
    "        logits_test.append(logits.detach().cpu())\n",
    "    labels_test = torch.cat(labels_test, dim=0)\n",
    "    logits_test = torch.stack(logits_test, dim=0)\n",
    "    preds_test = torch.argmax(logits_test, dim=1)\n",
    "    num_cols = torch.tensor(num_cols)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix, f1_score\n",
    "    mask = num_cols > 0\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach().numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach()[mask].numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach()[~mask].numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "    print(f\"Time: {time.time()-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Max Column Length: 2****************************\n",
      "ts_micro_f1=0.6083, ts_macro_f1=0.3279\n",
      "ts_micro_f1=0.6079, ts_macro_f1=0.3279\n",
      "ts_micro_f1=1.0000, ts_macro_f1=1.0000\n",
      "Time: 29.16684079170227\n"
     ]
    }
   ],
   "source": [
    "# Cheat brute force perumate\n",
    "\n",
    "import itertools\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "for max_col_length in [2]:\n",
    "    start = time.time()\n",
    "    print(f\"*********************Max Column Length: {max_col_length}****************************\")\n",
    "    model.load_state_dict(best_state_dict, strict=False)\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    log = defaultdict(list)\n",
    "    num_cols = []\n",
    "    threshold = 0.8\n",
    "    corrected = 0\n",
    "    total_mistakes = 0\n",
    "    init_permutation = defaultdict(list)\n",
    "    corrected_permutation = defaultdict(list)\n",
    "    init_logits = defaultdict(list)\n",
    "    corrected_logits = defaultdict(list)\n",
    "    MSP_permutation = defaultdict(list)\n",
    "    MSP_logits = defaultdict(list)\n",
    "    MSP_corrected = 0\n",
    "    Entropy_permutation = defaultdict(list)\n",
    "    Entropy_logits = defaultdict(list)\n",
    "    Entropy_corrected = 0\n",
    "    for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "        cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "        target_col_mask = batch[\"target_col_mask\"].T\n",
    "        logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "        num_cols.append(batch[\"target_col_mask\"].max().item())\n",
    "        if 1 in target_col_mask and logits.argmax().item() != batch[\"label\"].item():\n",
    "            total_mistakes += 1\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            successs = False\n",
    "            assert -1 not in col_idx_set\n",
    "            for r in range(len(init_permutation_i)-1, len(init_permutation_i)-2, -1): # not \n",
    "                for x in itertools.combinations(init_permutation_i, r):\n",
    "                    if 0 not in x:\n",
    "                        continue\n",
    "                    new_batch_data = []\n",
    "                    for col_i in x:\n",
    "                        if col_i == 0:\n",
    "                            if len(new_batch_data) == 0:\n",
    "                                cls_indexes_value = 0\n",
    "                            else:\n",
    "                                cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                        new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                    new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                    cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                    logits_temp = model(new_batch_data, cls_indexes=cls_indexes,)\n",
    "                    if logits_temp.argmax().item() == batch[\"label\"].item():\n",
    "                        logits = logits_temp.clone()\n",
    "                        successs = True\n",
    "                        corrected_permutation[batch_idx].append(x)\n",
    "                        corrected_logits[batch_idx].append(logits_temp.clone().detach().cpu())\n",
    "                        break\n",
    "                if successs:\n",
    "                    break          \n",
    "            if successs:\n",
    "                corrected += 1\n",
    "        labels_test.append(batch[\"label\"].cpu())\n",
    "        logits_test.append(logits.detach().cpu())\n",
    "    labels_test = torch.cat(labels_test, dim=0)\n",
    "    logits_test = torch.stack(logits_test, dim=0)\n",
    "    preds_test = torch.argmax(logits_test, dim=1)\n",
    "    num_cols = torch.tensor(num_cols)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix, f1_score\n",
    "    mask = num_cols > 0\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach().numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach()[mask].numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach()[~mask].numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "    print(f\"Time: {time.time()-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Threshold: 0.9****************************\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# brute force perumate, find uncertain init prediction, weighted msp\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "idx_list = []\n",
    "uncertain_init_mask = []\n",
    "uncertain_target_mask = []\n",
    "correct_init_mask = []\n",
    "correct_target_mask = []\n",
    "correct_permutation_mask = []\n",
    "correct_permutation_confident_mask = []\n",
    "correct_permutation_confident_scores = []\n",
    "correct_msp_mask = []\n",
    "init_target_mask = []\n",
    "ood_score_init_list = []\n",
    "ood_score_target_list = []\n",
    "ood_score_final_list = []\n",
    "msp_predicts = []\n",
    "max_col_length = 3\n",
    "\n",
    "alpha = 0.25\n",
    "class_weights = (1.0 / class_freq) ** alpha\n",
    "debias_threshold = 1.0\n",
    "# Normalize the weights\n",
    "class_weights /= class_weights.sum()\n",
    "for threshold in [0.9]:\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    log = defaultdict(list)\n",
    "    num_cols = []\n",
    "    corrected = 0\n",
    "    total_mistakes = 0\n",
    "\n",
    "    for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "        target_col_mask = batch[\"target_col_mask\"].T\n",
    "        if 1 in target_col_mask:\n",
    "            idx_list.append(batch_idx)\n",
    "\n",
    "            cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "            logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "            logits = reweight_logits(logits.detach().cpu(), class_weights)\n",
    "            num_cols.append(batch[\"target_col_mask\"].max().item())         \n",
    "            ood_score_init = logits.max().item()\n",
    "            ood_score_init_list.append(ood_score_init)\n",
    "            uncertain_init_mask.append(ood_score_init < threshold)\n",
    "            predict_init = logits.argmax().item()\n",
    "            correct_init_mask.append(predict_init == batch[\"label\"].item())\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            \n",
    "            correct_permutation = False\n",
    "            correct_permutation_ood_score = 0.0\n",
    "            correct_permutation_confident = False\n",
    "            ood_score_max = max_msp = 0\n",
    "            max_msp_debiased = 0\n",
    "            debias_class = []\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            assert -1 not in col_idx_set\n",
    "            for r in range(len(col_idx_set)-1, len(col_idx_set)//2, -1):\n",
    "                for subset in itertools.combinations(col_idx_set, r):\n",
    "                    if 0 not in subset and r != 1:\n",
    "                        continue\n",
    "                    for x in itertools.permutations(subset):\n",
    "                        if not is_sublist(x, init_permutation_i):\n",
    "                            continue\n",
    "                        new_batch_data = []\n",
    "                        for col_i in x:\n",
    "                            if col_i == 0:\n",
    "                                if len(new_batch_data) == 0:\n",
    "                                    cls_indexes_value = 0\n",
    "                                else:\n",
    "                                    cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                            new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                        if 0 not in x:\n",
    "                            cls_indexes_value = 0\n",
    "                        new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                        cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                        logits_temp = model(new_batch_data, cls_indexes=cls_indexes,)\n",
    "                        logits_temp = reweight_logits(logits_temp.detach().cpu(), class_weights)\n",
    "                        msp_temp = logits_temp.max().item()\n",
    "                        predict_temp = logits_temp.argmax().item()\n",
    "                        # if 0 not in x and msp_temp > debias_threshold and (predict_temp!=predict_target or predict_temp!=predict_init):\n",
    "                        #     debias_class.append(predict_temp)\n",
    "                        #     continue\n",
    "                        # print(x, msp_temp, predict_temp)\n",
    "                        # if msp_temp > max_msp and 0 in x and predict_temp not in debias_class:\n",
    "                        if msp_temp > max_msp and 0 in x:\n",
    "                            max_msp = msp_temp\n",
    "                            msp_predict = predict_temp\n",
    "                        if predict_temp == batch[\"label\"].item():\n",
    "                            correct_permutation = True\n",
    "                            if msp_temp > correct_permutation_ood_score:\n",
    "                                correct_permutation_ood_score = msp_temp\n",
    "            msp_predicts.append(msp_predict)\n",
    "            ood_score_final_list.append(max_msp)\n",
    "            correct_permutation_mask.append(correct_permutation)\n",
    "            correct_permutation_confident_scores.append(correct_permutation_ood_score)\n",
    "            correct_msp_mask.append(msp_predict == batch[\"label\"].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1084 0 1084 0 1084\n"
     ]
    }
   ],
   "source": [
    "\n",
    "idx_list = torch.tensor(idx_list).reshape(-1)\n",
    "uncertain_init_mask = torch.tensor(uncertain_init_mask).reshape(-1)\n",
    "uncertain_target_mask = torch.tensor(uncertain_target_mask).reshape(-1)\n",
    "correct_init_mask = torch.tensor(correct_init_mask).reshape(-1)\n",
    "correct_target_mask = torch.tensor(correct_target_mask).reshape(-1)\n",
    "correct_permutation_mask = torch.tensor(correct_permutation_mask).reshape(-1)\n",
    "correct_permutation_confident_scores = torch.tensor(correct_permutation_confident_scores).reshape(-1)\n",
    "correct_msp_mask = torch.tensor(correct_msp_mask).reshape(-1)\n",
    "init_target_mask = torch.tensor(init_target_mask).reshape(-1)\n",
    "ood_score_init_list = torch.tensor(ood_score_init_list).reshape(-1)\n",
    "ood_score_target_list = torch.tensor(ood_score_target_list).reshape(-1)\n",
    "ood_score_final_list = torch.tensor(ood_score_final_list).reshape(-1)\n",
    "msp_predicts = torch.tensor(msp_predicts).reshape(-1)\n",
    "print(len(idx_list), len(init_target_mask), len(correct_init_mask), len(correct_target_mask), len(correct_permutation_mask))\n",
    "torch.save({\"idx_list\": idx_list, \"uncertain_init_mask\": uncertain_init_mask, \"uncertain_target_mask\": uncertain_target_mask, \"correct_init_mask\": correct_init_mask, \"correct_target_mask\": correct_target_mask, \"correct_permutation_mask\": correct_permutation_mask, \"correct_msp_mask\": correct_msp_mask, \"init_target_mask\": init_target_mask, \"ood_score_init_list\": ood_score_init_list, \"ood_score_target_list\": ood_score_target_list, \"ood_score_final_list\": ood_score_final_list}, f\"./results/brute_force_permutation_alpha@{alpha}_drop.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Threshold: 0.8****************************\n",
      "Init\n",
      "528 758 0.6965699208443272\n",
      "48 326 0.147239263803681\n",
      "MSP\n",
      "503 758 0.6635883905013192\n",
      "59 326 0.18098159509202455\n",
      "MSP & Init\n",
      "482\n",
      "549 758 0.7242744063324539\n",
      "85 326 0.2607361963190184\n",
      "Permutation\n",
      "609 758 0.8034300791556728\n",
      "141 326 0.4325153374233129\n",
      "Permutation Confident\n",
      "567 758 0.7480211081794196\n",
      "81 326 0.24846625766871167\n",
      "*********************Threshold: 0.9****************************\n",
      "Init\n",
      "505 688 0.7340116279069767\n",
      "71 396 0.17929292929292928\n",
      "MSP\n",
      "482 688 0.7005813953488372\n",
      "80 396 0.20202020202020202\n",
      "MSP & Init\n",
      "466\n",
      "521 688 0.7572674418604651\n",
      "113 396 0.28535353535353536\n",
      "Permutation\n",
      "564 688 0.8197674418604651\n",
      "186 396 0.4696969696969697\n",
      "Permutation Confident\n",
      "531 688 0.7718023255813954\n",
      "100 396 0.25252525252525254\n",
      "*********************Threshold: 0.99****************************\n",
      "Init\n",
      "431 515 0.8368932038834952\n",
      "145 569 0.2548330404217926\n",
      "MSP\n",
      "413 515 0.8019417475728156\n",
      "149 569 0.2618629173989455\n",
      "MSP & Init\n",
      "410\n",
      "434 515 0.8427184466019417\n",
      "200 569 0.351493848857645\n",
      "Permutation\n",
      "446 515 0.8660194174757282\n",
      "304 569 0.5342706502636204\n",
      "Permutation Confident\n",
      "433 515 0.8407766990291262\n",
      "104 569 0.1827768014059754\n"
     ]
    }
   ],
   "source": [
    "# weighted, only uncertain init\n",
    "\n",
    "for threshold in [0.8, 0.9, 0.99]:\n",
    "    correct_permutation_confident_mask = correct_permutation_confident_scores>threshold\n",
    "    uncertain_init_mask = ood_score_init_list < threshold\n",
    "    uncertain_target_mask = ood_score_target_list < threshold\n",
    "    condition_mask = ~uncertain_init_mask\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    print(\"Init\")\n",
    "    # init prediction\n",
    "    print((condition_mask&correct_init_mask).sum().item(), \n",
    "        (condition_mask).sum().item(), \n",
    "        (condition_mask&correct_init_mask).sum().item()/(condition_mask).sum().item())\n",
    "    # init prediction\n",
    "    print((~condition_mask&correct_init_mask).sum().item(), \n",
    "        (~condition_mask).sum().item(), \n",
    "       (~condition_mask&correct_init_mask).sum().item()/(~condition_mask).sum().item())\n",
    "    print(\"MSP\")\n",
    "    # msp prediction\n",
    "    print((condition_mask&correct_msp_mask).sum().item(), \n",
    "        (condition_mask).sum().item(), \n",
    "        (condition_mask&correct_msp_mask).sum().item()/(condition_mask).sum().item())\n",
    "    # msp prediction\n",
    "    print((~condition_mask&correct_msp_mask).sum().item(), \n",
    "        (~condition_mask).sum().item(), \n",
    "        (~condition_mask&correct_msp_mask).sum().item()/(~condition_mask).sum().item())\n",
    "    print(\"MSP & Init\")\n",
    "    print(((condition_mask&correct_init_mask)&(condition_mask&correct_msp_mask)).sum().item())\n",
    "    # print(((~(init_target_mask&(~uncertain_init_mask & ~uncertain_target_mask))& correct_msp_mask)&(~(init_target_mask&(~uncertain_init_mask & ~uncertain_target_mask))& correct_init_mask)).sum().item())\n",
    "    print(((condition_mask&correct_init_mask)|(condition_mask&correct_msp_mask)).sum().item(),\n",
    "          (condition_mask).sum().item(), \n",
    "          ((condition_mask&correct_init_mask)|(condition_mask&correct_msp_mask)).sum().item()/(condition_mask).sum().item())\n",
    "    print(((~condition_mask&correct_init_mask)|(~condition_mask&correct_msp_mask)).sum().item(),\n",
    "          (~condition_mask).sum().item(), \n",
    "          ((~condition_mask&correct_init_mask)|(~condition_mask&correct_msp_mask)).sum().item()/(~condition_mask).sum().item())\n",
    "    print(\"Permutation\")\n",
    "    print((condition_mask&correct_permutation_mask).sum().item(), \n",
    "        (condition_mask).sum().item(), \n",
    "        (condition_mask&correct_permutation_mask).sum().item()/(condition_mask).sum().item())\n",
    "    print((~condition_mask&correct_permutation_mask).sum().item(), \n",
    "         (~condition_mask).sum().item(), \n",
    "        (~condition_mask&correct_permutation_mask).sum().item()/(~condition_mask).sum().item())\n",
    "    print(\"Permutation Confident\")\n",
    "    print((condition_mask&correct_permutation_confident_mask).sum().item(), \n",
    "        (condition_mask).sum().item(), \n",
    "        (condition_mask&correct_permutation_confident_mask).sum().item()/(condition_mask).sum().item())\n",
    "    print((~condition_mask&correct_permutation_confident_mask).sum().item(),\n",
    "            (~condition_mask).sum().item(), \n",
    "            (~condition_mask&correct_permutation_confident_mask).sum().item()/(~condition_mask).sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Threshold: 0.82****************************\n",
      "Init\n",
      "524 742 0.706199460916442\n",
      "52 342 0.15204678362573099\n",
      "MSP\n",
      "497 742 0.6698113207547169\n",
      "65 342 0.19005847953216373\n",
      "MSP & Init\n",
      "479\n",
      "542 742 0.7304582210242587\n",
      "92 342 0.26900584795321636\n",
      "Permutation\n",
      "599 742 0.807277628032345\n",
      "151 342 0.4415204678362573\n",
      "Permutation Confident\n",
      "558 742 0.7520215633423181\n",
      "88 342 0.2573099415204678\n"
     ]
    }
   ],
   "source": [
    "# weighted, only uncertain init\n",
    "\n",
    "for threshold in [0.82]:\n",
    "    correct_permutation_confident_mask = correct_permutation_confident_scores>threshold\n",
    "    uncertain_init_mask = ood_score_init_list < threshold\n",
    "    uncertain_target_mask = ood_score_target_list < threshold\n",
    "    condition_mask = ~uncertain_init_mask\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    print(\"Init\")\n",
    "    # init prediction\n",
    "    print((condition_mask&correct_init_mask).sum().item(), \n",
    "        (condition_mask).sum().item(), \n",
    "        (condition_mask&correct_init_mask).sum().item()/(condition_mask).sum().item())\n",
    "    # init prediction\n",
    "    print((~condition_mask&correct_init_mask).sum().item(), \n",
    "        (~condition_mask).sum().item(), \n",
    "       (~condition_mask&correct_init_mask).sum().item()/(~condition_mask).sum().item())\n",
    "    print(\"MSP\")\n",
    "    # msp prediction\n",
    "    print((condition_mask&correct_msp_mask).sum().item(), \n",
    "        (condition_mask).sum().item(), \n",
    "        (condition_mask&correct_msp_mask).sum().item()/(condition_mask).sum().item())\n",
    "    # msp prediction\n",
    "    print((~condition_mask&correct_msp_mask).sum().item(), \n",
    "        (~condition_mask).sum().item(), \n",
    "        (~condition_mask&correct_msp_mask).sum().item()/(~condition_mask).sum().item())\n",
    "    print(\"MSP & Init\")\n",
    "    print(((condition_mask&correct_init_mask)&(condition_mask&correct_msp_mask)).sum().item())\n",
    "    # print(((~(init_target_mask&(~uncertain_init_mask & ~uncertain_target_mask))& correct_msp_mask)&(~(init_target_mask&(~uncertain_init_mask & ~uncertain_target_mask))& correct_init_mask)).sum().item())\n",
    "    print(((condition_mask&correct_init_mask)|(condition_mask&correct_msp_mask)).sum().item(),\n",
    "          (condition_mask).sum().item(), \n",
    "          ((condition_mask&correct_init_mask)|(condition_mask&correct_msp_mask)).sum().item()/(condition_mask).sum().item())\n",
    "    print(((~condition_mask&correct_init_mask)|(~condition_mask&correct_msp_mask)).sum().item(),\n",
    "          (~condition_mask).sum().item(), \n",
    "          ((~condition_mask&correct_init_mask)|(~condition_mask&correct_msp_mask)).sum().item()/(~condition_mask).sum().item())\n",
    "    print(\"Permutation\")\n",
    "    print((condition_mask&correct_permutation_mask).sum().item(), \n",
    "        (condition_mask).sum().item(), \n",
    "        (condition_mask&correct_permutation_mask).sum().item()/(condition_mask).sum().item())\n",
    "    print((~condition_mask&correct_permutation_mask).sum().item(), \n",
    "         (~condition_mask).sum().item(), \n",
    "        (~condition_mask&correct_permutation_mask).sum().item()/(~condition_mask).sum().item())\n",
    "    print(\"Permutation Confident\")\n",
    "    print((condition_mask&correct_permutation_confident_mask).sum().item(), \n",
    "        (condition_mask).sum().item(), \n",
    "        (condition_mask&correct_permutation_confident_mask).sum().item()/(condition_mask).sum().item())\n",
    "    print((~condition_mask&correct_permutation_confident_mask).sum().item(),\n",
    "            (~condition_mask).sum().item(), \n",
    "            (~condition_mask&correct_permutation_confident_mask).sum().item()/(~condition_mask).sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both correct tensor(25) tensor(0.6187) tensor(0.9433)\n",
      "MSP correct  tensor(40) tensor(0.5216) tensor(0.9643)\n",
      "Init correct tensor(27) tensor(0.5349) tensor(0.9423)\n",
      "Permutation correct tensor(13) tensor(0.5649) tensor(0.9761)\n"
     ]
    }
   ],
   "source": [
    "# MSP is wrong, but init is correct\n",
    "target_col_idx_msp_init = idx_list[~condition_mask&correct_msp_mask&correct_init_mask]\n",
    "target_col_idx_msp =  idx_list[~condition_mask&correct_msp_mask&~correct_init_mask]\n",
    "target_col_idx_init =  idx_list[~condition_mask&~correct_msp_mask&correct_init_mask]\n",
    "target_col_idx_permutation = idx_list[~condition_mask&correct_permutation_confident_mask&~correct_msp_mask&~correct_init_mask]\n",
    "target_col_idx_permutation_msp =  idx_list[~condition_mask&correct_permutation_confident_mask&~correct_msp_mask]\n",
    "target_col_idx_permutation_init =  idx_list[~condition_mask&correct_permutation_confident_mask&~correct_init_mask]\n",
    "\n",
    "print(\"Both correct\", (~condition_mask&correct_msp_mask&correct_init_mask).sum(), \n",
    "      ood_score_init_list[~condition_mask&correct_msp_mask&correct_init_mask].mean(), \n",
    "      # ood_score_target_list[~condition_mask&correct_msp_mask&correct_init_mask].mean(),\n",
    "      ood_score_final_list[~condition_mask&correct_msp_mask&correct_init_mask].mean())\n",
    "print(\"MSP correct \", (~condition_mask&correct_msp_mask&~correct_init_mask).sum(), \n",
    "      ood_score_init_list[~condition_mask&correct_msp_mask&~correct_init_mask].mean(),\n",
    "      #   ood_score_target_list[~condition_mask&correct_msp_mask&~correct_init_mask].mean(),\n",
    "        ood_score_final_list[~condition_mask&correct_msp_mask&~correct_init_mask].mean())\n",
    "print(\"Init correct\", (~condition_mask&~correct_msp_mask&correct_init_mask).sum(), \n",
    "      ood_score_init_list[~condition_mask&~correct_msp_mask&correct_init_mask].mean(),\n",
    "      #   ood_score_target_list[~condition_mask&~correct_msp_mask&correct_init_mask].mean(),\n",
    "        ood_score_final_list[~condition_mask&~correct_msp_mask&correct_init_mask].mean())\n",
    "print(\"Permutation correct\",(~condition_mask&correct_permutation_confident_mask&~correct_msp_mask&~correct_init_mask).sum(), \n",
    "      ood_score_init_list[~condition_mask&correct_permutation_confident_mask&~correct_msp_mask&~correct_init_mask].mean(),\n",
    "      #   ood_score_target_list[~condition_mask&correct_permutation_confident_mask&~correct_msp_mask&~correct_init_mask].mean(),\n",
    "        ood_score_final_list[~condition_mask&correct_permutation_confident_mask&~correct_msp_mask&~correct_init_mask].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  21,   52,   59,  118,  138,  154,  246,  265,  273,  275,  286,  287,\n",
       "         296,  325,  372,  419,  433,  568,  610,  643,  743,  808,  894,  929,\n",
       "         989, 1042, 1075])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_col_idx_permutation_msp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "7 [1, 2, 3, 4, 5, 6, 7, 0]\n",
      "********************************************************\n",
      "(1, 2, 3, 4, 5, 6, 0) tensor(0.6651) tensor(23)\n",
      "(1, 2, 3, 4, 5, 7, 0) tensor(0.3092) tensor(23)\n",
      "(1, 2, 3, 4, 6, 7, 0) tensor(0.4810) tensor(23)\n",
      "(1, 2, 3, 5, 6, 7, 0) tensor(0.2688) tensor(23)\n",
      "(1, 2, 4, 5, 6, 7, 0) tensor(0.2278) tensor(37)\n",
      "(1, 3, 4, 5, 6, 7, 0) tensor(0.1427) tensor(0)\n",
      "(2, 3, 4, 5, 6, 7, 0) tensor(0.3503) tensor(23)\n",
      "(1, 2, 3, 4, 5, 0) tensor(0.5194) tensor(23)\n",
      "(1, 2, 3, 4, 6, 0) tensor(0.7849) tensor(23)\n",
      "(1, 2, 3, 4, 7, 0) tensor(0.8610) tensor(23)\n",
      "(1, 2, 3, 5, 6, 0) tensor(0.4876) tensor(23)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3888413/152469504.py:38: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3697.)\n",
      "  target_col_mask = batch[\"target_col_mask\"].T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 3, 5, 7, 0) tensor(0.5947) tensor(23)\n",
      "(1, 2, 3, 6, 7, 0) tensor(0.8060) tensor(23)\n",
      "(1, 2, 4, 5, 6, 0) tensor(0.5498) tensor(34)\n",
      "(1, 2, 4, 5, 7, 0) tensor(0.8120) tensor(34)\n",
      "(1, 2, 4, 6, 7, 0) tensor(0.7552) tensor(34)\n",
      "(1, 2, 5, 6, 7, 0) tensor(0.3124) tensor(23)\n",
      "(1, 3, 4, 5, 6, 0) tensor(0.2555) tensor(23)\n",
      "(1, 3, 4, 5, 7, 0) tensor(0.3216) tensor(0)\n",
      "(1, 3, 4, 6, 7, 0) tensor(0.5315) tensor(0)\n",
      "(1, 3, 5, 6, 7, 0) tensor(0.4935) tensor(0)\n",
      "(1, 4, 5, 6, 7, 0) tensor(0.9806) tensor(0)\n",
      "(2, 3, 4, 5, 6, 0) tensor(0.2808) tensor(58)\n",
      "(2, 3, 4, 5, 7, 0) tensor(0.5887) tensor(23)\n",
      "(2, 3, 4, 6, 7, 0) tensor(0.7600) tensor(23)\n",
      "(2, 3, 5, 6, 7, 0) tensor(0.4811) tensor(23)\n",
      "(2, 4, 5, 6, 7, 0) tensor(0.4818) tensor(34)\n",
      "(3, 4, 5, 6, 7, 0) tensor(0.4339) tensor(43)\n",
      "(1, 2, 3, 4, 0) tensor(0.4082) tensor(23)\n",
      "(1, 2, 3, 5, 0) tensor(0.3759) tensor(58)\n",
      "(1, 2, 3, 6, 0) tensor(0.3691) tensor(23)\n",
      "(1, 2, 3, 7, 0) tensor(0.4590) tensor(23)\n",
      "(1, 2, 4, 5, 0) tensor(0.5800) tensor(34)\n",
      "(1, 2, 4, 6, 0) tensor(0.6279) tensor(34)\n",
      "(1, 2, 4, 7, 0) tensor(0.9516) tensor(34)\n",
      "(1, 2, 5, 6, 0) tensor(0.1263) tensor(34)\n",
      "(1, 2, 5, 7, 0) tensor(0.8446) tensor(34)\n",
      "(1, 2, 6, 7, 0) tensor(0.8761) tensor(34)\n",
      "(1, 3, 4, 5, 0) tensor(0.1679) tensor(23)\n",
      "(1, 3, 4, 6, 0) tensor(0.2394) tensor(0)\n",
      "(1, 3, 4, 7, 0) tensor(0.2182) tensor(43)\n",
      "(1, 3, 5, 6, 0) tensor(0.2751) tensor(0)\n",
      "(1, 3, 5, 7, 0) tensor(0.1049) tensor(23)\n",
      "(1, 3, 6, 7, 0) tensor(0.2515) tensor(43)\n",
      "(1, 4, 5, 6, 0) tensor(0.9962) tensor(0)\n",
      "(1, 4, 5, 7, 0) tensor(0.2923) tensor(0)\n",
      "(1, 4, 6, 7, 0) tensor(0.6230) tensor(0)\n",
      "(1, 5, 6, 7, 0) tensor(0.9986) tensor(0)\n",
      "(2, 3, 4, 5, 0) tensor(0.3924) tensor(23)\n",
      "(2, 3, 4, 6, 0) tensor(0.6938) tensor(23)\n",
      "(2, 3, 4, 7, 0) tensor(0.5539) tensor(23)\n",
      "(2, 3, 5, 6, 0) tensor(0.2649) tensor(27)\n",
      "(2, 3, 5, 7, 0) tensor(0.3043) tensor(23)\n",
      "(2, 3, 6, 7, 0) tensor(0.4006) tensor(23)\n",
      "(2, 4, 5, 6, 0) tensor(0.8024) tensor(34)\n",
      "(2, 4, 5, 7, 0) tensor(0.1661) tensor(34)\n",
      "(2, 4, 6, 7, 0) tensor(0.2791) tensor(34)\n",
      "(2, 5, 6, 7, 0) tensor(0.2626) tensor(3)\n",
      "(3, 4, 5, 6, 0) tensor(0.5505) tensor(0)\n",
      "(3, 4, 5, 7, 0) tensor(0.5359) tensor(0)\n",
      "(3, 4, 6, 7, 0) tensor(0.4521) tensor(0)\n",
      "(3, 5, 6, 7, 0) tensor(0.5652) tensor(0)\n",
      "(4, 5, 6, 7, 0) tensor(0.9993) tensor(0)\n",
      "********************************************************\n",
      "(4, 5, 6, 7, 0) tensor(0.9993) tensor(0)\n"
     ]
    }
   ],
   "source": [
    "# use target as head, the MSP context\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "log = defaultdict(list)\n",
    "num_cols = []\n",
    "threshold = 0.8\n",
    "corrected = 0\n",
    "total_mistakes = 0\n",
    "init_permutation = defaultdict(list)\n",
    "corrected_permutation = defaultdict(list)\n",
    "init_logits = defaultdict(list)\n",
    "corrected_logits = defaultdict(list)\n",
    "max_col_length = 3\n",
    "msp_threshold = 0.9\n",
    "\n",
    "\n",
    "alpha = 0.25\n",
    "\n",
    "class_weights = (1.0 / class_freq) ** alpha\n",
    "\n",
    "# Normalize the weights\n",
    "class_weights /= class_weights.sum()\n",
    "\n",
    "for batch_idx, batch in enumerate(test_dataset_iter):\n",
    "    if batch_idx == 19:\n",
    "        break\n",
    "cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "target_col_mask = batch[\"target_col_mask\"].T\n",
    "col_idx_set = target_col_mask.unique().tolist()\n",
    "init_permutation_i = get_permutation(target_col_mask)\n",
    "successs = False\n",
    "# logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,).detach().cpu()\n",
    "# logits = reweight_logits(logits, class_weights)\n",
    "# logits_init = logits.clone()\n",
    "# num_cols.append(batch[\"target_col_mask\"].max().item())\n",
    "\n",
    "\n",
    "# col_idx_set = target_col_mask.unique().tolist()\n",
    "# successs = False\n",
    "# init_permutation_i = get_permutation(target_col_mask)\n",
    "# init_permutation[batch_idx].append(get_permutation(target_col_mask))\n",
    "# init_logits[batch_idx].append(logits_init.detach().cpu())     \n",
    "# init_msp = logits_init.max().item()\n",
    "# print(batch[\"label\"].item())\n",
    "# print(get_permutation(target_col_mask), init_msp, init_logits[batch_idx][0].argmax().item()) \n",
    "print(batch[\"label\"].item())  \n",
    "print(batch[\"target_col_mask\"].max().item(), get_permutation(target_col_mask))\n",
    "print(\"********************************************************\")\n",
    "assert -1 not in col_idx_set\n",
    "max_msp = 0 \n",
    "# for r in range(1, min(len(col_idx_set), max_col_length) + 1):\n",
    "enough = False\n",
    "# for r in range(len(col_idx_set)-1, 0, -1):\n",
    "for r in range(len(col_idx_set)-1, len(col_idx_set)//2, -1):\n",
    "    for subset in itertools.combinations(col_idx_set, r):\n",
    "        if 0 not in subset and r != 1:\n",
    "            continue\n",
    "        for x in itertools.permutations(subset):\n",
    "            if not is_sublist(x, init_permutation_i):\n",
    "                continue\n",
    "            new_batch_data = []\n",
    "            for col_i in x:\n",
    "                if col_i == 0:\n",
    "                    if len(new_batch_data) == 0:\n",
    "                        cls_indexes_value = 0\n",
    "                    else:\n",
    "                        cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "            if 0 not in x:\n",
    "                cls_indexes_value = 0\n",
    "            new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "            cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "            logits_temp = model(new_batch_data, cls_indexes=cls_indexes,).detach().cpu()\n",
    "            logits_temp = reweight_logits(logits_temp, class_weights)\n",
    "            msp_temp = logits_temp.max()\n",
    "            predict_temp = logits_temp.argmax()\n",
    "            # msp_temp = F.softmax(logits_temp).max().item()\n",
    "            # predict_temp = F.softmax(logits_temp).argmax().item()\n",
    "\n",
    "            print(x, msp_temp,predict_temp)\n",
    "            if msp_temp > max_msp and 0 in x:\n",
    "                max_msp = msp_temp\n",
    "                best_msp_perm = x\n",
    "                msp_predict = predict_temp\n",
    "        \n",
    "print(\"********************************************************\")\n",
    "print(best_msp_perm, max_msp, msp_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************alpha: 0.25; uncertain: 0.8; debias: 1.0; msp: 0.8****************************\n",
      "ts_micro_f1=0.5419, ts_macro_f1=0.2608\n",
      "ts_micro_f1=0.5415, ts_macro_f1=0.2608\n",
      "ts_micro_f1=1.0000, ts_macro_f1=1.0000\n",
      "*********************alpha: 0.25; uncertain: 0.8; debias: 1.0; msp: 0.9****************************\n",
      "ts_micro_f1=0.5419, ts_macro_f1=0.2621\n",
      "ts_micro_f1=0.5415, ts_macro_f1=0.2621\n",
      "ts_micro_f1=1.0000, ts_macro_f1=1.0000\n",
      "*********************alpha: 0.25; uncertain: 0.8; debias: 1.0; msp: 0.99****************************\n",
      "ts_micro_f1=0.5382, ts_macro_f1=0.2664\n",
      "ts_micro_f1=0.5378, ts_macro_f1=0.2664\n",
      "ts_micro_f1=1.0000, ts_macro_f1=1.0000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# brute force perumate, early stop\n",
    "import itertools\n",
    "\n",
    "\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "\n",
    "max_col_length = 3\n",
    "for alpha in [0.25]:\n",
    "    class_weights = (1.0 / class_freq) ** alpha\n",
    "    # Normalize the weights\n",
    "    class_weights /= class_weights.sum()\n",
    "    for uncertainty_threshold in [ 0.8]:\n",
    "        for msp_threshold in [ 0.8, 0.9, 0.99]:\n",
    "            for debias_threshold in [1.0]:\n",
    "                print(f\"*********************alpha: {alpha}; uncertain: {uncertainty_threshold}; debias: {debias_threshold}; msp: {msp_threshold}****************************\")\n",
    "                ft_embs_test = []\n",
    "                labels_test = []\n",
    "                logits_test = []\n",
    "                log = defaultdict(list)\n",
    "                num_cols = []\n",
    "                corrected = 0\n",
    "                total_mistakes = 0\n",
    "\n",
    "                for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "                    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "                    target_col_mask = batch[\"target_col_mask\"].T\n",
    "                    logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "                    logits = reweight_logits(logits.detach().cpu(), class_weights) # Here !!!!!!!!!!\n",
    "                    msp_init = logits.max().item()\n",
    "                    num_cols.append(batch[\"target_col_mask\"].max().item())\n",
    "                    predict_init = logits.argmax().item()\n",
    "                    max_msp = 0\n",
    "                    \n",
    "                    if 1 in target_col_mask and msp_init < uncertainty_threshold:\n",
    "                        init_permutation_i = get_permutation(target_col_mask)\n",
    "                        col_idx_set = target_col_mask.unique().tolist()\n",
    "                        debias_classes = []\n",
    "                        early_stop = False\n",
    "                        assert -1 not in col_idx_set\n",
    "                        for r in range(len(col_idx_set)-1, len(col_idx_set)//2, -1):\n",
    "                            round_classes = set()\n",
    "                            for subset in itertools.combinations(col_idx_set, r):\n",
    "                                if 0 not in subset and r != 1:\n",
    "                                    continue\n",
    "                                for x in itertools.permutations(subset):\n",
    "                                    if not is_sublist(x, init_permutation_i):\n",
    "                                        continue\n",
    "                                    new_batch_data = []\n",
    "                                    for col_i in x:\n",
    "                                        if col_i == 0:\n",
    "                                            if len(new_batch_data) == 0:\n",
    "                                                cls_indexes_value = 0\n",
    "                                            else:\n",
    "                                                cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                                        new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                                    if 0 not in x:\n",
    "                                        cls_indexes_value = 0\n",
    "                                    new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                                    cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                                    logits_temp = model(new_batch_data, cls_indexes=cls_indexes,)\n",
    "                                    logits_temp = reweight_logits(logits_temp.detach().cpu(), class_weights)\n",
    "                                    msp_temp = logits_temp.max().item()\n",
    "                                    predict_temp = logits_temp.argmax().item()\n",
    "                                    round_classes.add(predict_temp)\n",
    "                                    # if len(x) == 1 and 0 in x:\n",
    "                                    #     predict_target = predict_temp\n",
    "                                    #     msp_target = msp_temp\n",
    "                                    # # print(x, msp_temp, predict_temp)\n",
    "                                    # if 0 not in x and msp_temp > debias_threshold and (predict_temp != predict_target):\n",
    "                                    #     debias_classes.append(predict_temp)\n",
    "                                    #     continue\n",
    "                                    if msp_temp > max_msp and 0 in x and predict_temp not in debias_classes:\n",
    "                                        max_msp = msp_temp\n",
    "                                        best_msp_perm = x\n",
    "                                        msp_predict = predict_temp\n",
    "                                        logits_msp = logits_temp.clone()\n",
    "                                        if max_msp > msp_threshold and 0 in x and len(round_classes) > 1: # make sure the classes in one round is not homogenous \n",
    "                                            early_stop = True\n",
    "                            if early_stop:\n",
    "                                break\n",
    "                    if max_msp > msp_threshold:\n",
    "                        logits = logits_msp.clone()\n",
    "                    labels_test.append(batch[\"label\"].cpu())\n",
    "                    logits_test.append(logits.detach().cpu())\n",
    "                labels_test = torch.cat(labels_test, dim=0)\n",
    "                logits_test = torch.stack(logits_test, dim=0)\n",
    "                preds_test = torch.argmax(logits_test, dim=1)\n",
    "                num_cols = torch.tensor(num_cols)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                from sklearn.metrics import confusion_matrix, f1_score\n",
    "                mask = num_cols > 0\n",
    "                ts_pred_list = logits_test.argmax(\n",
    "                                            1).cpu().detach().numpy().tolist()\n",
    "                ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"micro\")\n",
    "                ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"macro\")\n",
    "                print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "                ts_pred_list = logits_test.argmax(\n",
    "                                            1).cpu().detach()[mask].numpy().tolist()\n",
    "                ts_micro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"micro\")\n",
    "                ts_macro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"macro\")\n",
    "                print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "                ts_pred_list = logits_test.argmax(\n",
    "                                            1).cpu().detach()[~mask].numpy().tolist()\n",
    "                ts_micro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"micro\")\n",
    "                ts_macro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"macro\")\n",
    "                print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************alpha: 0.25; uncertain: 0.8; debias: 1.0; msp: 0.0****************************\n",
      "ts_micro_f1=0.5373, ts_macro_f1=0.2554\n",
      "ts_micro_f1=0.5369, ts_macro_f1=0.2554\n",
      "ts_micro_f1=1.0000, ts_macro_f1=1.0000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# brute force perumate, early stop\n",
    "import itertools\n",
    "\n",
    "\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "\n",
    "max_col_length = 3\n",
    "for alpha in [0.25]:\n",
    "    class_weights = (1.0 / class_freq) ** alpha\n",
    "    # Normalize the weights\n",
    "    class_weights /= class_weights.sum()\n",
    "    for uncertainty_threshold in [ 0.8]:\n",
    "        for msp_threshold in [0.0]:\n",
    "            for debias_threshold in [1.0]:\n",
    "                print(f\"*********************alpha: {alpha}; uncertain: {uncertainty_threshold}; debias: {debias_threshold}; msp: {msp_threshold}****************************\")\n",
    "                ft_embs_test = []\n",
    "                labels_test = []\n",
    "                logits_test = []\n",
    "                log = defaultdict(list)\n",
    "                num_cols = []\n",
    "                corrected = 0\n",
    "                total_mistakes = 0\n",
    "\n",
    "                for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "                    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "                    target_col_mask = batch[\"target_col_mask\"].T\n",
    "                    logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "                    logits = reweight_logits(logits.detach().cpu(), class_weights) # Here !!!!!!!!!!\n",
    "                    msp_init = logits.max().item()\n",
    "                    num_cols.append(batch[\"target_col_mask\"].max().item())\n",
    "                    predict_init = logits.argmax().item()\n",
    "                    max_msp = 0\n",
    "                    \n",
    "                    if 1 in target_col_mask and msp_init < uncertainty_threshold:\n",
    "                        init_permutation_i = get_permutation(target_col_mask)\n",
    "                        col_idx_set = target_col_mask.unique().tolist()\n",
    "                        debias_classes = []\n",
    "                        early_stop = False\n",
    "                        assert -1 not in col_idx_set\n",
    "                        for r in range(len(col_idx_set)-1, len(col_idx_set)//2, -1):\n",
    "                            round_classes = set()\n",
    "                            for subset in itertools.combinations(col_idx_set, r):\n",
    "                                if 0 not in subset and r != 1:\n",
    "                                    continue\n",
    "                                for x in itertools.permutations(subset):\n",
    "                                    if not is_sublist(x, init_permutation_i):\n",
    "                                        continue\n",
    "                                    new_batch_data = []\n",
    "                                    for col_i in x:\n",
    "                                        if col_i == 0:\n",
    "                                            if len(new_batch_data) == 0:\n",
    "                                                cls_indexes_value = 0\n",
    "                                            else:\n",
    "                                                cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                                        new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                                    if 0 not in x:\n",
    "                                        cls_indexes_value = 0\n",
    "                                    new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                                    cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                                    logits_temp = model(new_batch_data, cls_indexes=cls_indexes,)\n",
    "                                    logits_temp = reweight_logits(logits_temp.detach().cpu(), class_weights)\n",
    "                                    msp_temp = logits_temp.max().item()\n",
    "                                    predict_temp = logits_temp.argmax().item()\n",
    "                                    round_classes.add(predict_temp)\n",
    "                                    # if len(x) == 1 and 0 in x:\n",
    "                                    #     predict_target = predict_temp\n",
    "                                    #     msp_target = msp_temp\n",
    "                                    # # print(x, msp_temp, predict_temp)\n",
    "                                    # if 0 not in x and msp_temp > debias_threshold and (predict_temp != predict_target):\n",
    "                                    #     debias_classes.append(predict_temp)\n",
    "                                    #     continue\n",
    "                                    if msp_temp > max_msp and 0 in x and predict_temp not in debias_classes:\n",
    "                                        max_msp = msp_temp\n",
    "                                        best_msp_perm = x\n",
    "                                        msp_predict = predict_temp\n",
    "                                        logits_msp = logits_temp.clone()\n",
    "                                        if max_msp > msp_threshold and 0 in x and len(round_classes) > 1: # make sure the classes in one round is not homogenous \n",
    "                                            early_stop = True\n",
    "                            if early_stop:\n",
    "                                break\n",
    "                    if max_msp > msp_threshold:\n",
    "                        logits = logits_msp.clone()\n",
    "                    labels_test.append(batch[\"label\"].cpu())\n",
    "                    logits_test.append(logits.detach().cpu())\n",
    "                labels_test = torch.cat(labels_test, dim=0)\n",
    "                logits_test = torch.stack(logits_test, dim=0)\n",
    "                preds_test = torch.argmax(logits_test, dim=1)\n",
    "                num_cols = torch.tensor(num_cols)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                from sklearn.metrics import confusion_matrix, f1_score\n",
    "                mask = num_cols > 0\n",
    "                ts_pred_list = logits_test.argmax(\n",
    "                                            1).cpu().detach().numpy().tolist()\n",
    "                ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"micro\")\n",
    "                ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"macro\")\n",
    "                print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "                ts_pred_list = logits_test.argmax(\n",
    "                                            1).cpu().detach()[mask].numpy().tolist()\n",
    "                ts_micro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"micro\")\n",
    "                ts_macro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"macro\")\n",
    "                print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "                ts_pred_list = logits_test.argmax(\n",
    "                                            1).cpu().detach()[~mask].numpy().tolist()\n",
    "                ts_micro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"micro\")\n",
    "                ts_macro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"macro\")\n",
    "                print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************alpha: 0.25; uncertain: 0.85; debias: 1.0; msp: 0.9****************************\n",
      "ts_micro_f1=0.5447, ts_macro_f1=0.2636\n",
      "ts_micro_f1=0.5443, ts_macro_f1=0.2636\n",
      "ts_micro_f1=1.0000, ts_macro_f1=1.0000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# brute force perumate, early stop\n",
    "import itertools\n",
    "\n",
    "\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "\n",
    "max_col_length = 3\n",
    "for alpha in [0.25]:\n",
    "    class_weights = (1.0 / class_freq) ** alpha\n",
    "    # Normalize the weights\n",
    "    class_weights /= class_weights.sum()\n",
    "    for uncertainty_threshold in [ 0.85]:\n",
    "        for msp_threshold in [0.9]:\n",
    "            for debias_threshold in [1.0]:\n",
    "                print(f\"*********************alpha: {alpha}; uncertain: {uncertainty_threshold}; debias: {debias_threshold}; msp: {msp_threshold}****************************\")\n",
    "                ft_embs_test = []\n",
    "                labels_test = []\n",
    "                logits_test = []\n",
    "                log = defaultdict(list)\n",
    "                num_cols = []\n",
    "                corrected = 0\n",
    "                total_mistakes = 0\n",
    "\n",
    "                for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "                    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "                    target_col_mask = batch[\"target_col_mask\"].T\n",
    "                    logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "                    logits = reweight_logits(logits.detach().cpu(), class_weights) # Here !!!!!!!!!!\n",
    "                    msp_init = logits.max().item()\n",
    "                    num_cols.append(batch[\"target_col_mask\"].max().item())\n",
    "                    predict_init = logits.argmax().item()\n",
    "                    max_msp = 0\n",
    "                    \n",
    "                    if 1 in target_col_mask and msp_init < uncertainty_threshold:\n",
    "                        init_permutation_i = get_permutation(target_col_mask)\n",
    "                        col_idx_set = target_col_mask.unique().tolist()\n",
    "                        debias_classes = []\n",
    "                        early_stop = False\n",
    "                        assert -1 not in col_idx_set\n",
    "                        for r in range(len(col_idx_set)-1, len(col_idx_set)//2, -1):\n",
    "                            round_classes = set()\n",
    "                            for subset in itertools.combinations(col_idx_set, r):\n",
    "                                if 0 not in subset and r != 1:\n",
    "                                    continue\n",
    "                                for x in itertools.permutations(subset):\n",
    "                                    if not is_sublist(x, init_permutation_i):\n",
    "                                        continue\n",
    "                                    new_batch_data = []\n",
    "                                    for col_i in x:\n",
    "                                        if col_i == 0:\n",
    "                                            if len(new_batch_data) == 0:\n",
    "                                                cls_indexes_value = 0\n",
    "                                            else:\n",
    "                                                cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                                        new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                                    if 0 not in x:\n",
    "                                        cls_indexes_value = 0\n",
    "                                    new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                                    cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                                    logits_temp = model(new_batch_data, cls_indexes=cls_indexes,)\n",
    "                                    logits_temp = reweight_logits(logits_temp.detach().cpu(), class_weights)\n",
    "                                    msp_temp = logits_temp.max().item()\n",
    "                                    predict_temp = logits_temp.argmax().item()\n",
    "                                    round_classes.add(predict_temp)\n",
    "                                    # if len(x) == 1 and 0 in x:\n",
    "                                    #     predict_target = predict_temp\n",
    "                                    #     msp_target = msp_temp\n",
    "                                    # # print(x, msp_temp, predict_temp)\n",
    "                                    # if 0 not in x and msp_temp > debias_threshold and (predict_temp != predict_target):\n",
    "                                    #     debias_classes.append(predict_temp)\n",
    "                                    #     continue\n",
    "                                    if msp_temp > max_msp and 0 in x and predict_temp not in debias_classes:\n",
    "                                        max_msp = msp_temp\n",
    "                                        best_msp_perm = x\n",
    "                                        msp_predict = predict_temp\n",
    "                                        logits_msp = logits_temp.clone()\n",
    "                                        if max_msp > msp_threshold and 0 in x and len(round_classes) > 1: # make sure the classes in one round is not homogenous \n",
    "                                            early_stop = True\n",
    "                            if early_stop:\n",
    "                                break\n",
    "                    if max_msp > msp_threshold:\n",
    "                        logits = logits_msp.clone()\n",
    "                    labels_test.append(batch[\"label\"].cpu())\n",
    "                    logits_test.append(logits.detach().cpu())\n",
    "                labels_test = torch.cat(labels_test, dim=0)\n",
    "                logits_test = torch.stack(logits_test, dim=0)\n",
    "                preds_test = torch.argmax(logits_test, dim=1)\n",
    "                num_cols = torch.tensor(num_cols)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                from sklearn.metrics import confusion_matrix, f1_score\n",
    "                mask = num_cols > 0\n",
    "                ts_pred_list = logits_test.argmax(\n",
    "                                            1).cpu().detach().numpy().tolist()\n",
    "                ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"micro\")\n",
    "                ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"macro\")\n",
    "                print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "                ts_pred_list = logits_test.argmax(\n",
    "                                            1).cpu().detach()[mask].numpy().tolist()\n",
    "                ts_micro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"micro\")\n",
    "                ts_macro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"macro\")\n",
    "                print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "                ts_pred_list = logits_test.argmax(\n",
    "                                            1).cpu().detach()[~mask].numpy().tolist()\n",
    "                ts_micro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"micro\")\n",
    "                ts_macro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"macro\")\n",
    "                print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************alpha: 0.25; uncertain: 0.85; debias: 1.0; msp: 0.0****************************\n",
      "ts_micro_f1=0.5392, ts_macro_f1=0.2552\n",
      "ts_micro_f1=0.5387, ts_macro_f1=0.2552\n",
      "ts_micro_f1=1.0000, ts_macro_f1=1.0000\n",
      "*********************alpha: 0.25; uncertain: 0.85; debias: 1.0; msp: 0.8****************************\n",
      "ts_micro_f1=0.5456, ts_macro_f1=0.2609\n",
      "ts_micro_f1=0.5452, ts_macro_f1=0.2609\n",
      "ts_micro_f1=1.0000, ts_macro_f1=1.0000\n",
      "*********************alpha: 0.25; uncertain: 0.85; debias: 1.0; msp: 0.85****************************\n",
      "ts_micro_f1=0.5456, ts_macro_f1=0.2607\n",
      "ts_micro_f1=0.5452, ts_macro_f1=0.2607\n",
      "ts_micro_f1=1.0000, ts_macro_f1=1.0000\n",
      "*********************alpha: 0.25; uncertain: 0.85; debias: 1.0; msp: 0.9****************************\n",
      "ts_micro_f1=0.5456, ts_macro_f1=0.2627\n",
      "ts_micro_f1=0.5452, ts_macro_f1=0.2626\n",
      "ts_micro_f1=1.0000, ts_macro_f1=1.0000\n",
      "*********************alpha: 0.25; uncertain: 0.8; debias: 1.0; msp: 0.0****************************\n",
      "ts_micro_f1=0.5373, ts_macro_f1=0.2553\n",
      "ts_micro_f1=0.5369, ts_macro_f1=0.2553\n",
      "ts_micro_f1=1.0000, ts_macro_f1=1.0000\n",
      "*********************alpha: 0.25; uncertain: 0.8; debias: 1.0; msp: 0.8****************************\n",
      "ts_micro_f1=0.5438, ts_macro_f1=0.2610\n",
      "ts_micro_f1=0.5434, ts_macro_f1=0.2610\n",
      "ts_micro_f1=1.0000, ts_macro_f1=1.0000\n",
      "*********************alpha: 0.25; uncertain: 0.8; debias: 1.0; msp: 0.85****************************\n",
      "ts_micro_f1=0.5429, ts_macro_f1=0.2596\n",
      "ts_micro_f1=0.5424, ts_macro_f1=0.2596\n",
      "ts_micro_f1=1.0000, ts_macro_f1=1.0000\n",
      "*********************alpha: 0.25; uncertain: 0.8; debias: 1.0; msp: 0.9****************************\n",
      "ts_micro_f1=0.5429, ts_macro_f1=0.2612\n",
      "ts_micro_f1=0.5424, ts_macro_f1=0.2612\n",
      "ts_micro_f1=1.0000, ts_macro_f1=1.0000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# brute force perumate, early stop\n",
    "import itertools\n",
    "\n",
    "\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "\n",
    "max_col_length = 3\n",
    "for alpha in [0.25]:\n",
    "    class_weights = (1.0 / class_freq) ** alpha\n",
    "    # Normalize the weights\n",
    "    class_weights /= class_weights.sum()\n",
    "    for uncertainty_threshold in [ 0.85, 0.8]:\n",
    "        for msp_threshold in [0.0, 0.8, 0.85, 0.9]:\n",
    "            for debias_threshold in [1.0]:\n",
    "                print(f\"*********************alpha: {alpha}; uncertain: {uncertainty_threshold}; debias: {debias_threshold}; msp: {msp_threshold}****************************\")\n",
    "                ft_embs_test = []\n",
    "                labels_test = []\n",
    "                logits_test = []\n",
    "                log = defaultdict(list)\n",
    "                num_cols = []\n",
    "                corrected = 0\n",
    "                total_mistakes = 0\n",
    "\n",
    "                for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "                    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "                    target_col_mask = batch[\"target_col_mask\"].T\n",
    "                    logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "                    logits = reweight_logits(logits.detach().cpu(), class_weights) # Here !!!!!!!!!!\n",
    "                    msp_init = logits.max().item()\n",
    "                    num_cols.append(batch[\"target_col_mask\"].max().item())\n",
    "                    predict_init = logits.argmax().item()\n",
    "                    max_msp = 0\n",
    "                    \n",
    "                    if 1 in target_col_mask and msp_init < uncertainty_threshold:\n",
    "                        init_permutation_i = get_permutation(target_col_mask)\n",
    "                        col_idx_set = target_col_mask.unique().tolist()\n",
    "                        debias_classes = []\n",
    "                        early_stop = False\n",
    "                        assert -1 not in col_idx_set\n",
    "                        for r in range(len(col_idx_set)-1, len(col_idx_set)//2, -1):\n",
    "                            round_classes = set()\n",
    "                            for subset in itertools.combinations(col_idx_set, r):\n",
    "                                if 0 not in subset and r != 1:\n",
    "                                    continue\n",
    "                                for x in itertools.permutations(subset):\n",
    "                                    if not is_sublist(x, init_permutation_i):\n",
    "                                        continue\n",
    "                                    new_batch_data = []\n",
    "                                    for col_i in x:\n",
    "                                        if col_i == 0:\n",
    "                                            if len(new_batch_data) == 0:\n",
    "                                                cls_indexes_value = 0\n",
    "                                            else:\n",
    "                                                cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                                        new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                                    if 0 not in x:\n",
    "                                        cls_indexes_value = 0\n",
    "                                    new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                                    cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                                    logits_temp = model(new_batch_data, cls_indexes=cls_indexes,)\n",
    "                                    logits_temp = reweight_logits(logits_temp.detach().cpu(), class_weights)\n",
    "                                    msp_temp = logits_temp.max().item()\n",
    "                                    predict_temp = logits_temp.argmax().item()\n",
    "                                    round_classes.add(predict_temp)\n",
    "                                    # if len(x) == 1 and 0 in x:\n",
    "                                    #     predict_target = predict_temp\n",
    "                                    #     msp_target = msp_temp\n",
    "                                    # # print(x, msp_temp, predict_temp)\n",
    "                                    # if 0 not in x and msp_temp > debias_threshold and (predict_temp != predict_target):\n",
    "                                    #     debias_classes.append(predict_temp)\n",
    "                                    #     continue\n",
    "                                    if msp_temp > max_msp and 0 in x and predict_temp not in debias_classes:\n",
    "                                        max_msp = msp_temp\n",
    "                                        best_msp_perm = x\n",
    "                                        msp_predict = predict_temp\n",
    "                                        logits_msp = logits_temp.clone()\n",
    "                                        if max_msp > msp_threshold and 0 in x: # make sure the classes in one round is not homogenous \n",
    "                                            early_stop = True\n",
    "                            if early_stop:\n",
    "                                break\n",
    "                    if max_msp > msp_threshold:\n",
    "                        logits = logits_msp.clone()\n",
    "                    labels_test.append(batch[\"label\"].cpu())\n",
    "                    logits_test.append(logits.detach().cpu())\n",
    "                labels_test = torch.cat(labels_test, dim=0)\n",
    "                logits_test = torch.stack(logits_test, dim=0)\n",
    "                preds_test = torch.argmax(logits_test, dim=1)\n",
    "                num_cols = torch.tensor(num_cols)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                from sklearn.metrics import confusion_matrix, f1_score\n",
    "                mask = num_cols > 0\n",
    "                ts_pred_list = logits_test.argmax(\n",
    "                                            1).cpu().detach().numpy().tolist()\n",
    "                ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"micro\")\n",
    "                ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"macro\")\n",
    "                print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "                ts_pred_list = logits_test.argmax(\n",
    "                                            1).cpu().detach()[mask].numpy().tolist()\n",
    "                ts_micro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"micro\")\n",
    "                ts_macro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"macro\")\n",
    "                print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "                ts_pred_list = logits_test.argmax(\n",
    "                                            1).cpu().detach()[~mask].numpy().tolist()\n",
    "                ts_micro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"micro\")\n",
    "                ts_macro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"macro\")\n",
    "                print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *********************alpha: 0.25; uncertain: 0.85; debias: 1.0; msp: 0.9****************************\n",
    "# ts_micro_f1=0.5456, ts_macro_f1=0.2627\n",
    "# ts_micro_f1=0.5452, ts_macro_f1=0.2626\n",
    "# ts_micro_f1=1.0000, ts_macro_f1=1.0000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************alpha: 0.0; uncertain: 0.85; debias: 1.0; msp: 0.0****************************\n",
      "ts_micro_f1=0.5429, ts_macro_f1=0.2582\n",
      "ts_micro_f1=0.5424, ts_macro_f1=0.2582\n",
      "ts_micro_f1=1.0000, ts_macro_f1=1.0000\n",
      "*********************alpha: 0.0; uncertain: 0.85; debias: 1.0; msp: 0.8****************************\n",
      "ts_micro_f1=0.5484, ts_macro_f1=0.2633\n",
      "ts_micro_f1=0.5480, ts_macro_f1=0.2633\n",
      "ts_micro_f1=1.0000, ts_macro_f1=1.0000\n",
      "*********************alpha: 0.0; uncertain: 0.85; debias: 1.0; msp: 0.85****************************\n",
      "ts_micro_f1=0.5475, ts_macro_f1=0.2644\n",
      "ts_micro_f1=0.5470, ts_macro_f1=0.2644\n",
      "ts_micro_f1=1.0000, ts_macro_f1=1.0000\n",
      "*********************alpha: 0.0; uncertain: 0.85; debias: 1.0; msp: 0.9****************************\n",
      "ts_micro_f1=0.5456, ts_macro_f1=0.2667\n",
      "ts_micro_f1=0.5452, ts_macro_f1=0.2667\n",
      "ts_micro_f1=1.0000, ts_macro_f1=1.0000\n",
      "*********************alpha: 0.0; uncertain: 0.8; debias: 1.0; msp: 0.0****************************\n",
      "ts_micro_f1=0.5419, ts_macro_f1=0.2561\n",
      "ts_micro_f1=0.5415, ts_macro_f1=0.2561\n",
      "ts_micro_f1=1.0000, ts_macro_f1=1.0000\n",
      "*********************alpha: 0.0; uncertain: 0.8; debias: 1.0; msp: 0.8****************************\n",
      "ts_micro_f1=0.5475, ts_macro_f1=0.2611\n",
      "ts_micro_f1=0.5470, ts_macro_f1=0.2611\n",
      "ts_micro_f1=1.0000, ts_macro_f1=1.0000\n",
      "*********************alpha: 0.0; uncertain: 0.8; debias: 1.0; msp: 0.85****************************\n",
      "ts_micro_f1=0.5465, ts_macro_f1=0.2624\n",
      "ts_micro_f1=0.5461, ts_macro_f1=0.2624\n",
      "ts_micro_f1=1.0000, ts_macro_f1=1.0000\n",
      "*********************alpha: 0.0; uncertain: 0.8; debias: 1.0; msp: 0.9****************************\n",
      "ts_micro_f1=0.5447, ts_macro_f1=0.2642\n",
      "ts_micro_f1=0.5443, ts_macro_f1=0.2642\n",
      "ts_micro_f1=1.0000, ts_macro_f1=1.0000\n",
      "*********************alpha: 0.0; uncertain: 0.9; debias: 1.0; msp: 0.0****************************\n",
      "ts_micro_f1=0.5429, ts_macro_f1=0.2577\n",
      "ts_micro_f1=0.5424, ts_macro_f1=0.2577\n",
      "ts_micro_f1=1.0000, ts_macro_f1=1.0000\n",
      "*********************alpha: 0.0; uncertain: 0.9; debias: 1.0; msp: 0.8****************************\n",
      "ts_micro_f1=0.5493, ts_macro_f1=0.2627\n",
      "ts_micro_f1=0.5489, ts_macro_f1=0.2627\n",
      "ts_micro_f1=1.0000, ts_macro_f1=1.0000\n",
      "*********************alpha: 0.0; uncertain: 0.9; debias: 1.0; msp: 0.85****************************\n",
      "ts_micro_f1=0.5484, ts_macro_f1=0.2637\n",
      "ts_micro_f1=0.5480, ts_macro_f1=0.2637\n",
      "ts_micro_f1=1.0000, ts_macro_f1=1.0000\n",
      "*********************alpha: 0.0; uncertain: 0.9; debias: 1.0; msp: 0.9****************************\n",
      "ts_micro_f1=0.5465, ts_macro_f1=0.2657\n",
      "ts_micro_f1=0.5461, ts_macro_f1=0.2657\n",
      "ts_micro_f1=1.0000, ts_macro_f1=1.0000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# brute force perumate, early stop\n",
    "import itertools\n",
    "\n",
    "\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "\n",
    "max_col_length = 3\n",
    "for alpha in [0.0]:\n",
    "    # class_weights = (1.0 / class_freq) ** alpha\n",
    "    # # Normalize the weights\n",
    "    # class_weights /= class_weights.sum()\n",
    "    for uncertainty_threshold in [ 0.85, 0.8, 0.9]:\n",
    "        for msp_threshold in [0.0, 0.8, 0.85, 0.9]:\n",
    "            for debias_threshold in [1.0]:\n",
    "                print(f\"*********************alpha: {alpha}; uncertain: {uncertainty_threshold}; debias: {debias_threshold}; msp: {msp_threshold}****************************\")\n",
    "                ft_embs_test = []\n",
    "                labels_test = []\n",
    "                logits_test = []\n",
    "                log = defaultdict(list)\n",
    "                num_cols = []\n",
    "                corrected = 0\n",
    "                total_mistakes = 0\n",
    "\n",
    "                for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "                    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "                    target_col_mask = batch[\"target_col_mask\"].T\n",
    "                    logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "                    # logits = reweight_logits(logits.detach().cpu(), class_weights) # Here !!!!!!!!!!\n",
    "                    logits = F.softmax(logits, dim=-1)\n",
    "                    msp_init = logits.max().item()\n",
    "                    num_cols.append(batch[\"target_col_mask\"].max().item())\n",
    "                    predict_init = logits.argmax().item()\n",
    "                    max_msp = 0\n",
    "                    \n",
    "                    if 1 in target_col_mask and msp_init < uncertainty_threshold:\n",
    "                        init_permutation_i = get_permutation(target_col_mask)\n",
    "                        col_idx_set = target_col_mask.unique().tolist()\n",
    "                        debias_classes = []\n",
    "                        early_stop = False\n",
    "                        assert -1 not in col_idx_set\n",
    "                        for r in range(len(col_idx_set)-1, len(col_idx_set)//2, -1):\n",
    "                            round_classes = set()\n",
    "                            for subset in itertools.combinations(col_idx_set, r):\n",
    "                                if 0 not in subset and r != 1:\n",
    "                                    continue\n",
    "                                for x in itertools.permutations(subset):\n",
    "                                    if not is_sublist(x, init_permutation_i):\n",
    "                                        continue\n",
    "                                    new_batch_data = []\n",
    "                                    for col_i in x:\n",
    "                                        if col_i == 0:\n",
    "                                            if len(new_batch_data) == 0:\n",
    "                                                cls_indexes_value = 0\n",
    "                                            else:\n",
    "                                                cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                                        new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                                    if 0 not in x:\n",
    "                                        cls_indexes_value = 0\n",
    "                                    new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                                    cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                                    logits_temp = model(new_batch_data, cls_indexes=cls_indexes,)\n",
    "                                    # logits_temp = reweight_logits(logits_temp.detach().cpu(), class_weights)\n",
    "                                    logits_temp = F.softmax(logits_temp, dim=-1)\n",
    "                                    msp_temp = logits_temp.max().item()\n",
    "                                    predict_temp = logits_temp.argmax().item()\n",
    "                                    round_classes.add(predict_temp)\n",
    "                                    # if len(x) == 1 and 0 in x:\n",
    "                                    #     predict_target = predict_temp\n",
    "                                    #     msp_target = msp_temp\n",
    "                                    # # print(x, msp_temp, predict_temp)\n",
    "                                    # if 0 not in x and msp_temp > debias_threshold and (predict_temp != predict_target):\n",
    "                                    #     debias_classes.append(predict_temp)\n",
    "                                    #     continue\n",
    "                                    if msp_temp > max_msp and 0 in x and predict_temp not in debias_classes:\n",
    "                                        max_msp = msp_temp\n",
    "                                        best_msp_perm = x\n",
    "                                        msp_predict = predict_temp\n",
    "                                        logits_msp = logits_temp.clone()\n",
    "                                        if max_msp > msp_threshold and 0 in x: # make sure the classes in one round is not homogenous \n",
    "                                            early_stop = True\n",
    "                            if early_stop:\n",
    "                                break\n",
    "                    if max_msp > msp_threshold:\n",
    "                        logits = logits_msp.clone()\n",
    "                    labels_test.append(batch[\"label\"].cpu())\n",
    "                    logits_test.append(logits.detach().cpu())\n",
    "                labels_test = torch.cat(labels_test, dim=0)\n",
    "                logits_test = torch.stack(logits_test, dim=0)\n",
    "                preds_test = torch.argmax(logits_test, dim=1)\n",
    "                num_cols = torch.tensor(num_cols)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                from sklearn.metrics import confusion_matrix, f1_score\n",
    "                mask = num_cols > 0\n",
    "                ts_pred_list = logits_test.argmax(\n",
    "                                            1).cpu().detach().numpy().tolist()\n",
    "                ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"micro\")\n",
    "                ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"macro\")\n",
    "                print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "                ts_pred_list = logits_test.argmax(\n",
    "                                            1).cpu().detach()[mask].numpy().tolist()\n",
    "                ts_micro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"micro\")\n",
    "                ts_macro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"macro\")\n",
    "                print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "                ts_pred_list = logits_test.argmax(\n",
    "                                            1).cpu().detach()[~mask].numpy().tolist()\n",
    "                ts_micro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"micro\")\n",
    "                ts_macro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"macro\")\n",
    "                print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f5e60d93e20>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Threshold: 1.5****************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3888413/2143681938.py:31: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
      "/tmp/ipykernel_3888413/2143681938.py:61: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n"
     ]
    }
   ],
   "source": [
    "# brute force perumate in training TODO: restrict mamimus length of permutation\n",
    "import itertools\n",
    "import torch.nn.functional as F\n",
    "\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "for threshold in [1.5]:\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    log = defaultdict(list)\n",
    "    num_cols = []\n",
    "    corrected = 0\n",
    "    total_mistakes = 0\n",
    "    num_permutations = {}\n",
    "    init_permutation = {}\n",
    "    init_correctness = {}\n",
    "    score_init = {}\n",
    "    score_permutation = defaultdict(list)\n",
    "    permutation_correctness = defaultdict(list)\n",
    "    for batch_idx, batch in enumerate(train_dataloader_iter):\n",
    "        cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "        target_col_mask = batch[\"target_col_mask\"].T\n",
    "        logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "        score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
    "        label_i = batch[\"label\"].item()\n",
    "        predict_init = logits.argmax().item()\n",
    "        init_permutation_i = get_permutation(target_col_mask)\n",
    "        init_permutation[batch_idx] = init_permutation_i\n",
    "        if predict_init == label_i:\n",
    "            init_correctness[batch_idx] = True\n",
    "        else:\n",
    "            init_correctness[batch_idx] = False\n",
    "        num_permutations[batch_idx] = 0\n",
    "        if 1 in target_col_mask:\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            assert -1 not in col_idx_set\n",
    "            for r in range(len(init_permutation_i)-1, len(init_permutation_i)//2, -1): # not \n",
    "                for x in itertools.combinations(init_permutation_i, r):\n",
    "                    if 0 not in x:\n",
    "                        continue\n",
    "\n",
    "                    num_permutations[batch_idx] += 1\n",
    "                    new_batch_data = []\n",
    "                    for col_i in x:\n",
    "                        if col_i == 0:\n",
    "                            if len(new_batch_data) == 0:\n",
    "                                cls_indexes_value = 0\n",
    "                            else:\n",
    "                                cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                        new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                    new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                    cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                    logits_temp = model(new_batch_data, cls_indexes=cls_indexes,)\n",
    "                    ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n",
    "                    score_permutation[batch_idx].append(ood_score_temp)\n",
    "                    predict_temp = logits_temp.argmax().item()\n",
    "                    permutation_correctness[batch_idx].append(predict_temp == label_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhihao/jupyterprojects/jupyter/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/zhihao/jupyterprojects/jupyter/lib/python3.8/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "permutation_correctness_ratio = []\n",
    "score_permutation_avg = []\n",
    "for i in score_init:\n",
    "    permutation_correctness_ratio.append(np.mean(permutation_correctness[i]))\n",
    "    score_permutation_avg.append(np.mean(score_permutation[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(score_permutation_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8814620980217899 0.6078544614496102\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAD4CAYAAAAdIcpQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAARDklEQVR4nO3de7BdZX3G8e8DiLaVltDETIaLQRs7Up0ic0S8TMXSItCp0WopTJXIgOkoOLVeZrD+gaPjlE7VtnQsNmKG0FEQrZZYqTRFlGlHkKAWuUiJCJI0kiAUO2WqYn/9Y6/YbXLOeXeSfTk75/uZ2XPWetfaa/3es89Zz16XvXaqCkmS5nPQpAuQJC18hoUkqcmwkCQ1GRaSpCbDQpLUdMikCxiFpUuX1sqVKyddhiRNldtuu+3hqlo227QDMixWrlzJ5s2bJ12GJE2VJA/MNc3DUJKkJsNCktRkWEiSmgwLSVKTYSFJajIsJElNhoUkqcmwkCQ1GRaSpKYD8hPcknSgO2vN+Wx/+NE92lcsXcLVGy4f+voMC0maQtsffpQVq9++Z/u17x/J+jwMJUlqMiwkSU2GhSSpybCQJDUZFpKkJsNCktRkWEiSmgwLSVKTYSFJajIsJElNhoUkqcmwkCQ1GRaSpCbDQpLUNLKwSHJ0khuT3JXkziR/2LUfkWRTknu7n0u69iS5NMmWJLcnOaFvWWu6+e9NsmZUNUuSZjfKPYsngLdV1XHAScAFSY4DLgJuqKpVwA3dOMDpwKrusRa4DHrhAlwMvAA4Ebh4V8BIksZjZGFRVdur6qvd8H8BdwNHAquBDd1sG4BXdsOrgSur52bg8CQrgJcDm6rqkap6FNgEnDaquiVJexrLOYskK4HnAbcAy6tqezfpu8DybvhI4MG+p23t2uZqlySNycjDIslTgb8D3lJV3++fVlUF1JDWszbJ5iSbd+7cOYxFSpI6Iw2LJE+iFxQfq6pPd80PdYeX6H7u6Nq3AUf3Pf2orm2u9p9SVeuqaqaqZpYtWzbcjkjSIjfKq6ECfBS4u6o+2DdpI7DriqY1wLV97ed0V0WdBDzWHa66Hjg1yZLuxPapXZskaUwOGeGyXwy8DvhGkq93bX8MXAJck+Q84AHgzG7adcAZwBbgceBcgKp6JMl7gVu7+d5TVY+MsG5J0m5GFhZV9S9A5ph8yizzF3DBHMtaD6wfXnWSpL3hJ7glSU2GhSSpybCQJDUZFpKkJsNCktRkWEiSmgwLSVKTYSFJajIsJElNhoUkqcmwkCQ1GRaSpCbDQpLUZFhIkpoMC0lSk2EhSWoyLCRJTYaFJKnJsJAkNRkWkqQmw0KS1GRYSJKaDAtJUpNhIUlqMiwkSU2GhSSpybCQJDUZFpKkJsNCktRkWEiSmgwLSVKTYSFJajIsJElNhoUkqcmwkCQ1GRaSpCbDQpLUZFhIkppGFhZJ1ifZkeSOvrZ3J9mW5Ovd44y+ae9MsiXJPUle3td+Wte2JclFo6pXkjS3Ue5ZXAGcNkv7n1fV8d3jOoAkxwFnAb/SPeevkxyc5GDgQ8DpwHHA2d28kqQxOmRUC66qm5KsHHD21cDVVfUD4NtJtgAndtO2VNV9AEmu7ua9a9j1SpLmNolzFhcmub07TLWkazsSeLBvnq1d21zte0iyNsnmJJt37tw5iroladEad1hcBjwTOB7YDnxgWAuuqnVVNVNVM8uWLRvWYiVJjPAw1Gyq6qFdw0k+AvxDN7oNOLpv1qO6NuZplySNyVj3LJKs6Bt9FbDrSqmNwFlJnpzkWGAV8BXgVmBVkmOTHErvJPjGcdYsSRrhnkWSq4CTgaVJtgIXAycnOR4o4H7gDwCq6s4k19A7cf0EcEFV/bhbzoXA9cDBwPqqunNUNUuSZjfKq6HOnqX5o/PM/z7gfbO0XwdcN8TSJEl7yU9wS5KaDAtJUpNhIUlqMiwkSU2GhSSpybCQJDUZFpKkJsNCktRkWEiSmgwLSVKTYSFJajIsJElNhoUkqcmwkCQ1DRQWSV48SJsk6cA06J7FXw3YJkk6AM375UdJXgi8CFiW5K19k36e3jfXSZIWgdY35R0KPLWb77C+9u8DrxlVUZKkhWXesKiqLwFfSnJFVT0wppokSQvMoN/B/eQk64CV/c+pql8fRVGSpIVl0LD4JPBh4HLgx6MrR5K0EA0aFk9U1WUjrUSStGANeunsZ5O8KcmKJEfseoy0MknSgjHonsWa7uc7+toKeMZwy5EkLUQDhUVVHTvqQiRJC9dAYZHknNnaq+rK4ZYjSVqIBj0M9fy+4acApwBfBQwLSVoEBj0M9eb+8SSHA1ePoiBJ0sKzr7co/2/A8xiStEgMes7is/SufoLeDQSfDVwzqqIkSQvLoOcs3t83/ATwQFVtHUE9kqQFaKDDUN0NBb9J786zS4AfjrIoSdLCMug35Z0JfAX4XeBM4JYk3qJckhaJQQ9DvQt4flXtAEiyDPhn4FOjKkyStHAMejXUQbuCovO9vXiuJGnKDbpn8fkk1wNXdeO/B1w3mpIkSQtN6zu4fwlYXlXvSPI7wEu6SV8GPjbq4iRJC0Nrz+IvgHcCVNWngU8DJHluN+23R1ibJGmBaJ13WF5V39i9sWtbOd8Tk6xPsiPJHX1tRyTZlOTe7ueSrj1JLk2yJcntSU7oe86abv57k6yZbV2SpNFqhcXh80z7mcZzrwBO263tIuCGqloF3NCNA5wOrOoea4HLoBcuwMXAC4ATgYt3BYwkaXxaYbE5yRt2b0xyPnDbfE+sqpuAR3ZrXg1s6IY3AK/sa7+yem4GDk+yAng5sKmqHqmqR4FN7BlAkqQRa52zeAvwmSS/z/+HwwxwKPCqfVjf8qra3g1/F1jeDR8JPNg339auba72PSRZS2+vhGOOOWYfSpMkzWXesKiqh4AXJXkZ8Jyu+XNV9YX9XXFVVZJqzznw8tYB6wBmZmaGtlxJ0uDfZ3EjcOMQ1vdQkhVVtb07zLTrg37bgKP75juqa9sGnLxb+xeHUIckaS+M+1PYG4FdVzStAa7taz+nuyrqJOCx7nDV9cCpSZZ0J7ZP7dokSWM06Ce491qSq+jtFSxNspXeVU2XANckOQ94gN5NCaH3afAzgC3A48C5AFX1SJL3Ard2872nqnY/aS5JGrGRhUVVnT3HpFNmmbeAC+ZYznpg/RBLkyTtJW8GKElqMiwkSU2GhSSpybCQJDUZFpKkJsNCktRkWEiSmgwLSVKTYSFJajIsJElNhoUkqcmwkCQ1GRaSpCbDQpLUZFhIkpoMC0lSk2EhSWoyLCRJTYaFJKnJsJAkNRkWkqQmw0KS1GRYSJKaDAtJUpNhIUlqMiwkSU2GhSSpybCQJDUZFpKkJsNCktRkWEiSmgwLSVKTYSFJajIsJElNhoUkqcmwkCQ1GRaSpCbDQpLUNJGwSHJ/km8k+XqSzV3bEUk2Jbm3+7mka0+SS5NsSXJ7khMmUbMkLWaT3LN4WVUdX1Uz3fhFwA1VtQq4oRsHOB1Y1T3WApeNvVJJWuQW0mGo1cCGbngD8Mq+9iur52bg8CQrJlCfJC1akwqLAv4pyW1J1nZty6tqezf8XWB5N3wk8GDfc7d2bT8lydokm5Ns3rlz56jqlqRF6ZAJrfclVbUtydOATUm+2T+xqipJ7c0Cq2odsA5gZmZmr54rSZrfRPYsqmpb93MH8BngROChXYeXup87utm3AUf3Pf2ork2SNCZjD4skP5fksF3DwKnAHcBGYE032xrg2m54I3BOd1XUScBjfYerJEljMInDUMuBzyTZtf6PV9Xnk9wKXJPkPOAB4Mxu/uuAM4AtwOPAueMvWZIWt7GHRVXdB/zqLO3fA06Zpb2AC8ZQmiRpDgvp0llJ0gJlWEiSmgwLSVKTYSFJajIsJElNhoUkqcmwkCQ1GRaSpCbDQpLUZFhIkpoMC0lSk2EhSWoyLCRJTYaFJKnJsJAkNRkWkqQmw0KS1GRYSJKaDAtJUpNhIUlqMiwkSU2GhSSpybCQJDUZFpKkJsNCktRkWEiSmgwLSVKTYSFJajIsJElNhoUkqcmwkCQ1HTLpAiQtbGetOZ/tDz8667QH7vsWT3/GM/doX7F0CVdvuHzUpU2duX6X0/D7MiwkzWv7w4+yYvXbZ512x5+8YdZp2699/6jLmkpz/S6n4fdlWEjSEM23J3bPvd9ixZjrGRbDQpKGqLUnNq0MC0kHnGk+N9BvIe2lGBazOFD+0LQw+fc1esM8NzDJ12sh7aUYFrOY5pNQWvjG8fc13zvShRpKk9wot97Bn/z2y/ZoH+brdc/dd/PS33r1rOteKOc4piYskpwG/CVwMHB5VV0y4ZI0pRbDO/v53pF+8ZLzZt0wTbr/4wjR+TbKswUCzP0Ofpgb+B/VQbP2fSGd45iKsEhyMPAh4DeBrcCtSTZW1V2TrUwwno3vMNcxjkMU+1LbXBuf+ZY11/rn22DNtWGaK0T2ZeM3V1/m+lzGfOsZ5rKGuVGehg38ME1FWAAnAluq6j6AJFcDq4EFHxZ7u5Eb1+GDudazLx+y2tuN7770ca51zLWBg7n7srcbpday5npHurcb37k2Pq1lzbb+SW/85lvW3h6DH+aytO9SVZOuoSnJa4DTqur8bvx1wAuq6sK+edYCa7vRXwbu2Y9VLgUe3o/nT6PF1ufF1l+wz4vF/vT56VW1bLYJ07Jn0VRV64B1w1hWks1VNTOMZU2LxdbnxdZfsM+Lxaj6PC03EtwGHN03flTXJkkag2kJi1uBVUmOTXIocBawccI1SdKiMRWHoarqiSQXAtfTu3R2fVXdOcJVDuVw1pRZbH1ebP0F+7xYjKTPU3GCW5I0WdNyGEqSNEGGhSSpadGGRZLTktyTZEuSi2aZ/uQkn+im35Jk5QTKHKoB+vzWJHcluT3JDUmePok6h6nV5775Xp2kkkz9ZZaD9DnJmd1rfWeSj4+7xmEb4G/7mCQ3Jvla9/d9xiTqHJYk65PsSHLHHNOT5NLu93F7khP2e6VVtege9E6Sfwt4BnAo8G/AcbvN8ybgw93wWcAnJl33GPr8MuBnu+E3LoY+d/MdBtwE3AzMTLruMbzOq4CvAUu68adNuu4x9Hkd8MZu+Djg/knXvZ99/jXgBOCOOaafAfwjEOAk4Jb9Xedi3bP4ye1DquqHwK7bh/RbDWzohj8FnJIkY6xx2Jp9rqobq+rxbvRmep9nmWaDvM4A7wX+FPifcRY3IoP0+Q3Ah6rqUYCq2jHmGodtkD4X8PPd8C8A/zHG+oauqm4CHplnltXAldVzM3B4kv26ge1iDYsjgQf7xrd2bbPOU1VPAI8BvziW6kZjkD73O4/eO5Np1uxzt3t+dFV9bpyFjdAgr/OzgGcl+dckN3d3dJ5mg/T53cBrk2wFrgPePJ7SJmZv/9+bpuJzFhqvJK8FZoCXTrqWUUpyEPBB4PUTLmXcDqF3KOpkenuPNyV5blX95ySLGrGzgSuq6gNJXgj8bZLnVNX/TrqwabFY9ywGuX3IT+ZJcgi9XdfvjaW60RjolilJfgN4F/CKqvrBmGoblVafDwOeA3wxyf30ju1unPKT3IO8zluBjVX1o6r6NvDv9MJjWg3S5/OAawCq6svAU+jdcO9ANfRbJC3WsBjk9iEbgTXd8GuAL1R35mhKNfuc5HnA39ALimk/jg2NPlfVY1W1tKpWVtVKeudpXlFVmydT7lAM8rf99/T2KkiylN5hqfvGWOOwDdLn7wCnACR5Nr2w2DnWKsdrI3BOd1XUScBjVbV9fxa4KA9D1Ry3D0nyHmBzVW0EPkpvV3ULvRNJZ02u4v03YJ//DHgq8MnuXP53quoVEyt6Pw3Y5wPKgH2+Hjg1yV3Aj4F3VNXU7jUP2Oe3AR9J8kf0Tna/fprf/CW5il7gL+3Ow1wMPAmgqj5M77zMGcAW4HHg3P1e5xT/viRJY7JYD0NJkvaCYSFJajIsJElNhoUkqcmwkCQ1GRaSpCbDQpLU9H9/cX6tUSPsWwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(permutation_correctness_ratio)\n",
    "permutation_correctness_ratio = np.array(permutation_correctness_ratio)\n",
    "print(np.mean(permutation_correctness_ratio[~np.isnan(permutation_correctness_ratio)]), sum(permutation_correctness_ratio==1)/len(permutation_correctness_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permutation_correctness[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.873015873015873"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(permutation_correctness[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9998397827148438 True 15 [0, 1, 2, 3, 4, 5]\n",
      "0.9998408555984497 True\n",
      "0.9998300075531006 True\n",
      "0.9998401403427124 True\n",
      "0.9998437166213989 True\n",
      "0.9998289346694946 True\n",
      "0.9998310804367065 True\n",
      "0.9998443126678467 True\n",
      "0.9998371601104736 True\n",
      "0.999847412109375 True\n",
      "0.9998385906219482 True\n",
      "0.9998388290405273 True\n",
      "0.9998251795768738 True\n",
      "0.9998200535774231 True\n",
      "0.9998272061347961 True\n",
      "0.9998300075531006 True\n"
     ]
    }
   ],
   "source": [
    "for i in score_init:\n",
    "    print(score_init[i], init_correctness[i], num_permutations[i], init_permutation[i])\n",
    "    for score, correct in zip(score_permutation[i], permutation_correctness[i], ):\n",
    "        print(score, correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.9998397827148438 True 15 [0, 1, 2, 3, 4, 5]\n",
      "0.9998348991076151 1.0\n",
      "1 0.9995976090431213 True 15 [1, 0, 2, 3, 4, 5]\n",
      "0.9996114333470663 1.0\n",
      "2 0.999115526676178 True 2 [1, 0, 2]\n",
      "0.9991608262062073 1.0\n",
      "3 0.9965730905532837 True 63 [1, 2, 3, 4, 5, 6, 7, 0]\n",
      "0.9962718657084874 1.0\n",
      "4 0.9998373985290527 True 63 [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "0.9998213913705614 1.0\n",
      "5 0.9994794726371765 True 63 [1, 2, 0, 3, 4, 5, 6, 7]\n",
      "0.9994508624076843 1.0\n",
      "6 0.9974454641342163 True 63 [1, 2, 3, 4, 5, 0, 6, 7]\n",
      "0.9942260819768148 1.0\n",
      "7 0.9841338396072388 True 63 [1, 2, 3, 4, 5, 6, 0, 7]\n",
      "0.9567946072608705 1.0\n",
      "8 0.43239864706993103 False 3 [1, 2, 3, 0]\n",
      "0.5922626058260599 1.0\n",
      "9 0.9992141723632812 True 15 [1, 0, 2, 3, 4, 5]\n",
      "0.9992281198501587 1.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(i, score_init[i], init_correctness[i], num_permutations[i], init_permutation[i])\n",
    "    print(np.mean(score_permutation[i]), np.mean(permutation_correctness[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True, True]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permutation_correctness[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_valid = []\n",
    "for batch_idx, batch in enumerate(valid_dataloader_iter):\n",
    "    labels_valid.append(batch[\"label\"].cpu())\n",
    "labels_valid = torch.tensor(labels_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(labels_valid.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, batch in enumerate(valid_dataloader_iter):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 439])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"target_col_mask\"].T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Threshold: 1.5****************************\n"
     ]
    }
   ],
   "source": [
    "# brute force perumate in validation TODO: restrict mamimus length of permutation\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "import torch.nn.functional as F\n",
    "veri_data = defaultdict(list)\n",
    "veri_logits = defaultdict(list)\n",
    "veri_cls_indexes = defaultdict(list)\n",
    "veri_target_col_mask = defaultdict(list)\n",
    "veri_embs = defaultdict(list)\n",
    "veri_col_num = defaultdict(list)\n",
    "veri_label = defaultdict(list)\n",
    "veri_class = defaultdict(list)\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "for threshold in [1.5]:\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    log = defaultdict(list)\n",
    "    num_cols = []\n",
    "    corrected = 0\n",
    "    total_mistakes = 0\n",
    "    num_permutations = {}\n",
    "    init_permutation = {}\n",
    "    init_correctness = {}\n",
    "    score_init = {}\n",
    "    score_permutation = defaultdict(list)\n",
    "    permutation_correctness = defaultdict(list)\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(valid_dataloader_iter):\n",
    "            cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "            target_col_mask = batch[\"target_col_mask\"].T\n",
    "            logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "            label_i = batch[\"label\"].item()\n",
    "            predict_init = logits.argmax().item()\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            init_permutation[batch_idx] = deepcopy(init_permutation_i)\n",
    "            len_init = len(init_permutation_i)\n",
    "            if predict_init == label_i:\n",
    "                init_correctness[batch_idx] = True\n",
    "            else:\n",
    "                init_correctness[batch_idx] = False\n",
    "            num_permutations[batch_idx] = 0\n",
    "\n",
    "            num_cols.append(len(init_permutation_i))\n",
    "            labels_test.append(batch[\"label\"].cpu().item())\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "\n",
    "            init_permutation_i.remove(0)\n",
    "            assert -1 not in col_idx_set\n",
    "            for r in range(len_init-1, max(len_init//2, len_init-3), -1): # not \n",
    "                for subset in itertools.combinations(init_permutation_i, r):\n",
    "                    for pos in range(len_init):\n",
    "                        x = init_permutation_i[:pos] + [0] + init_permutation_i[pos:]\n",
    "                        num_permutations[batch_idx] += 1\n",
    "                        new_batch_data = []\n",
    "                        for col_i in x:\n",
    "                            if col_i == 0:\n",
    "                                if len(new_batch_data) == 0:\n",
    "                                    cls_indexes_value = 0\n",
    "                                else:\n",
    "                                    cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                            new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                        new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                        cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                        logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                        predict_temp = logits_temp.argmax().item()\n",
    "                        permutation_correctness[batch_idx].append(predict_temp == label_i)\n",
    "                        \n",
    "                        veri_data[batch_idx].append(new_batch_data.cpu())\n",
    "                        veri_logits[batch_idx].append(logits_temp.detach().cpu())\n",
    "                        veri_cls_indexes[batch_idx].append(cls_indexes_value)\n",
    "                        veri_embs[batch_idx].append(embs_temp.cpu())\n",
    "                        veri_col_num[batch_idx].append(len(x))\n",
    "                        veri_label[batch_idx].append(torch.tensor(predict_temp == label_i).long()) # indicate whether the permutation is correct or not\n",
    "                        veri_class[batch_idx].append(label_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhihao/jupyterprojects/jupyter/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/zhihao/jupyterprojects/jupyter/lib/python3.8/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "corrected = []\n",
    "permutation_correctness_false = []\n",
    "permutation_correctness_false_ratio = []\n",
    "permutation_correctness_true = []\n",
    "permutation_correctness_true_ratio = []\n",
    "false_idx = []\n",
    "for idx, corr in init_correctness.items():\n",
    "    if not corr:\n",
    "        permutation_correctness_false.extend(permutation_correctness[idx])\n",
    "        permutation_correctness_false_ratio.append(np.mean(permutation_correctness[idx]))\n",
    "        false_idx.append(idx)\n",
    "    else:\n",
    "        permutation_correctness_true.extend(permutation_correctness[idx][1:])\n",
    "        permutation_correctness_true_ratio.append(np.mean(permutation_correctness[idx][1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permutation_correctness_false_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation_correctness_false = np.array(permutation_correctness_false).reshape(-1)\n",
    "permutation_correctness_false_ratio = np.array(permutation_correctness_false_ratio).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "487"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([init_correctness[i] for i in init_correctness])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(permutation_correctness_false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24623115577889448"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.array(permutation_correctness_false_ratio)>0)/len(permutation_correctness_false_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_permutation[batch_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_permutation_i.remove(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_permutation_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7]\n",
      "[1, 0, 2, 3, 4, 5, 6, 7]\n",
      "[1, 2, 0, 3, 4, 5, 6, 7]\n",
      "[1, 2, 3, 0, 4, 5, 6, 7]\n",
      "[1, 2, 3, 4, 0, 5, 6, 7]\n",
      "[1, 2, 3, 4, 5, 0, 6, 7]\n",
      "[1, 2, 3, 4, 5, 6, 0, 7]\n",
      "[1, 2, 3, 4, 5, 6, 7, 0]\n"
     ]
    }
   ],
   "source": [
    "for pos in range(len(init_permutation_i)+1):\n",
    "    print(init_permutation_i[:pos] + [0] + init_permutation_i[pos:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'veri_class' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mveri_class\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'veri_class' is not defined"
     ]
    }
   ],
   "source": [
    "veri_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Threshold: 1.5****************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3640352/3930690298.py:31: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
      "/tmp/ipykernel_3640352/3930690298.py:61: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [141]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m new_batch_data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(new_batch_data, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     59\u001b[0m cls_indexes \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m0\u001b[39m, cls_indexes_value])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 60\u001b[0m logits_temp \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_batch_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcls_indexes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcls_indexes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m ood_score_temp \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(logits_temp\u001b[38;5;241m.\u001b[39mdetach())\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     62\u001b[0m score_permutation[batch_idx]\u001b[38;5;241m.\u001b[39mappend(ood_score_temp)\n",
      "File \u001b[0;32m~/jupyterprojects/jupyter/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/jupyterprojects/jupyter/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/jupyterprojects/TU/watchog/watchog/model.py:571\u001b[0m, in \u001b[0;36mBertForMultiOutputClassification.forward\u001b[0;34m(self, input_ids, get_enc, cls_indexes, token_type_ids)\u001b[0m\n\u001b[1;32m    569\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    570\u001b[0m \u001b[38;5;66;03m# BertModelMultiOutput\u001b[39;00m\n\u001b[0;32m--> 571\u001b[0m bert_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    572\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    573\u001b[0m table_length \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mlen\u001b[39m(input_ids[i]\u001b[38;5;241m.\u001b[39mnonzero()) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(input_ids))]\n\u001b[1;32m    574\u001b[0m \u001b[38;5;66;03m# Note: returned tensor contains pooled_output of all tokens (to make the tensor size consistent)\u001b[39;00m\n",
      "File \u001b[0;32m~/jupyterprojects/jupyter/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/jupyterprojects/jupyter/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/jupyterprojects/jupyter/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:1141\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1134\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m-> 1141\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1142\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1153\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1154\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/jupyterprojects/jupyter/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/jupyterprojects/jupyter/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/jupyterprojects/jupyter/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:694\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    683\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    684\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    685\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    691\u001b[0m         output_attentions,\n\u001b[1;32m    692\u001b[0m     )\n\u001b[1;32m    693\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 694\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    704\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/jupyterprojects/jupyter/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/jupyterprojects/jupyter/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/jupyterprojects/jupyter/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:626\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    623\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    624\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 626\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[1;32m    631\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[0;32m~/jupyterprojects/jupyter/lib/python3.8/site-packages/transformers/pytorch_utils.py:238\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/jupyterprojects/jupyter/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:639\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[1;32m    638\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate(attention_output)\n\u001b[0;32m--> 639\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mintermediate_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    640\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m~/jupyterprojects/jupyter/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/jupyterprojects/jupyter/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/jupyterprojects/jupyter/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:553\u001b[0m, in \u001b[0;36mBertOutput.forward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    551\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense(hidden_states)\n\u001b[1;32m    552\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n\u001b[0;32m--> 553\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(\u001b[43mhidden_states\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minput_tensor\u001b[49m)\n\u001b[1;32m    554\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# brute force perumate in validation TODO: restrict mamimus length of permutation\n",
    "import itertools\n",
    "import torch.nn.functional as F\n",
    "\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "for threshold in [1.5]:\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    log = defaultdict(list)\n",
    "    num_cols = []\n",
    "    corrected = 0\n",
    "    total_mistakes = 0\n",
    "    num_permutations = {}\n",
    "    init_permutation = {}\n",
    "    init_correctness = {}\n",
    "    score_init = {}\n",
    "    score_permutation = defaultdict(list)\n",
    "    permutation_correctness = defaultdict(list)\n",
    "    for batch_idx, batch in enumerate(valid_dataloader_iter):\n",
    "        cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "        target_col_mask = batch[\"target_col_mask\"].T\n",
    "        logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "        score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
    "        label_i = batch[\"label\"].item()\n",
    "        predict_init = logits.argmax().item()\n",
    "        init_permutation_i = get_permutation(target_col_mask)\n",
    "        init_permutation[batch_idx] = init_permutation_i\n",
    "        if predict_init == label_i:\n",
    "            init_correctness[batch_idx] = True\n",
    "        else:\n",
    "            init_correctness[batch_idx] = False\n",
    "        num_permutations[batch_idx] = 0\n",
    "        if 1 in target_col_mask:\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            assert -1 not in col_idx_set\n",
    "            for r in range(len(init_permutation_i), max(len(init_permutation_i)//2, len(init_permutation_i)-2), -1): # not \n",
    "                for subset in itertools.combinations(init_permutation_i, r):\n",
    "                    if 0 not in subset and r != 1:\n",
    "                        continue\n",
    "                    for x in itertools.permutations(subset):\n",
    "                        num_permutations[batch_idx] += 1\n",
    "                        new_batch_data = []\n",
    "                        for col_i in x:\n",
    "                            if col_i == 0:\n",
    "                                if len(new_batch_data) == 0:\n",
    "                                    cls_indexes_value = 0\n",
    "                                else:\n",
    "                                    cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                            new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                        new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                        cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                        logits_temp = model(new_batch_data, cls_indexes=cls_indexes,)\n",
    "                        ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n",
    "                        score_permutation[batch_idx].append(ood_score_temp)\n",
    "                        predict_temp = logits_temp.argmax().item()\n",
    "                        permutation_correctness[batch_idx].append(predict_temp == label_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Threshold: 1.5****************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2045046/2555221320.py:31: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
      "/tmp/ipykernel_2045046/2555221320.py:61: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n"
     ]
    }
   ],
   "source": [
    "# brute force perumate in validation TODO: restrict mamimus length of permutation\n",
    "import itertools\n",
    "import torch.nn.functional as F\n",
    "\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "for threshold in [1.5]:\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    log = defaultdict(list)\n",
    "    num_cols = []\n",
    "    corrected = 0\n",
    "    total_mistakes = 0\n",
    "    num_permutations = {}\n",
    "    init_permutation = {}\n",
    "    init_correctness = {}\n",
    "    score_init = {}\n",
    "    score_permutation = defaultdict(list)\n",
    "    permutation_correctness = defaultdict(list)\n",
    "    for batch_idx, batch in enumerate(valid_dataloader_iter):\n",
    "        cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "        target_col_mask = batch[\"target_col_mask\"].T\n",
    "        logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "        score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
    "        label_i = batch[\"label\"].item()\n",
    "        predict_init = logits.argmax().item()\n",
    "        init_permutation_i = get_permutation(target_col_mask)\n",
    "        init_permutation[batch_idx] = init_permutation_i\n",
    "        if predict_init == label_i:\n",
    "            init_correctness[batch_idx] = True\n",
    "        else:\n",
    "            init_correctness[batch_idx] = False\n",
    "        num_permutations[batch_idx] = 0\n",
    "        if 1 in target_col_mask:\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            assert -1 not in col_idx_set\n",
    "            for r in range(len(init_permutation_i), max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "                for x in itertools.combinations(init_permutation_i, r):\n",
    "                    if 0 not in x:\n",
    "                        continue\n",
    "\n",
    "                    num_permutations[batch_idx] += 1\n",
    "                    new_batch_data = []\n",
    "                    for col_i in x:\n",
    "                        if col_i == 0:\n",
    "                            if len(new_batch_data) == 0:\n",
    "                                cls_indexes_value = 0\n",
    "                            else:\n",
    "                                cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                        new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                    new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                    cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                    logits_temp = model(new_batch_data, cls_indexes=cls_indexes,)\n",
    "                    ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n",
    "                    score_permutation[batch_idx].append(ood_score_temp)\n",
    "                    predict_temp = logits_temp.argmax().item()\n",
    "                    permutation_correctness[batch_idx].append(predict_temp == label_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Threshold: 1.5****************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2045046/2462308489.py:31: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
      "/tmp/ipykernel_2045046/2462308489.py:61: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n"
     ]
    }
   ],
   "source": [
    "# brute force perumate in validation TODO: restrict mamimus length of permutation\n",
    "import itertools\n",
    "import torch.nn.functional as F\n",
    "\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "for threshold in [1.5]:\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    log = defaultdict(list)\n",
    "    num_cols = []\n",
    "    corrected = 0\n",
    "    total_mistakes = 0\n",
    "    num_permutations = {}\n",
    "    init_permutation = {}\n",
    "    init_correctness = {}\n",
    "    score_init = {}\n",
    "    score_permutation = defaultdict(list)\n",
    "    permutation_correctness = defaultdict(list)\n",
    "    for batch_idx, batch in enumerate(valid_dataloader_iter):\n",
    "        cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "        target_col_mask = batch[\"target_col_mask\"].T\n",
    "        logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "        score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
    "        label_i = batch[\"label\"].item()\n",
    "        predict_init = logits.argmax().item()\n",
    "        init_permutation_i = get_permutation(target_col_mask)\n",
    "        init_permutation[batch_idx] = init_permutation_i\n",
    "        if predict_init == label_i:\n",
    "            init_correctness[batch_idx] = True\n",
    "        else:\n",
    "            init_correctness[batch_idx] = False\n",
    "        num_permutations[batch_idx] = 0\n",
    "        if 1 in target_col_mask:\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            assert -1 not in col_idx_set\n",
    "            for r in range(len(init_permutation_i), 1, -1): # not \n",
    "                for x in itertools.combinations(init_permutation_i, r):\n",
    "                    if 0 not in x:\n",
    "                        continue\n",
    "\n",
    "                    num_permutations[batch_idx] += 1\n",
    "                    new_batch_data = []\n",
    "                    for col_i in x:\n",
    "                        if col_i == 0:\n",
    "                            if len(new_batch_data) == 0:\n",
    "                                cls_indexes_value = 0\n",
    "                            else:\n",
    "                                cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                        new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                    new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                    cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                    logits_temp = model(new_batch_data, cls_indexes=cls_indexes,)\n",
    "                    ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n",
    "                    score_permutation[batch_idx].append(ood_score_temp)\n",
    "                    predict_temp = logits_temp.argmax().item()\n",
    "                    permutation_correctness[batch_idx].append(predict_temp == label_i)\n",
    "                if r < max(len(init_permutation_i)//2, len(init_permutation_i)-3) and sum(permutation_correctness[batch_idx]) > 0:\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True, True, True]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permutation_correctness[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "False in init_correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhihao/jupyterprojects/jupyter/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/zhihao/jupyterprojects/jupyter/lib/python3.8/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "corrected = []\n",
    "permutation_correctness_false = []\n",
    "permutation_correctness_false_ratio = []\n",
    "permutation_correctness_true = []\n",
    "permutation_correctness_true_ratio = []\n",
    "for idx, corr in init_correctness.items():\n",
    "    if not corr:\n",
    "        permutation_correctness_false.extend(permutation_correctness[idx])\n",
    "        permutation_correctness_false_ratio.append(np.mean(permutation_correctness[idx]))\n",
    "    else:\n",
    "        permutation_correctness_true.extend(permutation_correctness[idx][1:])\n",
    "        permutation_correctness_true_ratio.append(np.mean(permutation_correctness[idx][1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36432160804020103"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.array(permutation_correctness_false_ratio)>0)/len(permutation_correctness_false_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2537688442211055"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.array(permutation_correctness_false_ratio)>0)/len(permutation_correctness_false_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.032663316582914576"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.array(permutation_correctness_false_ratio)>0.5)/len(permutation_correctness_false_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9948364888123924"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.array(permutation_correctness_true_ratio)>0)/len(permutation_correctness_true_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(permutation_correctness_true_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(permutation_correctness_false_ratio, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(permutation_correctness_false_ratio, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhihao/jupyterprojects/jupyter/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/zhihao/jupyterprojects/jupyter/lib/python3.8/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "permutation_correctness_ratio = []\n",
    "score_permutation_avg = []\n",
    "for i in score_init:\n",
    "    permutation_correctness_ratio.append(np.mean(permutation_correctness[i]))\n",
    "    score_permutation_avg.append(np.mean(score_permutation[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5218385215200051 0.35141242937853107 0.3107344632768362 0.6621468926553672\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(permutation_correctness_ratio)\n",
    "permutation_correctness_ratio = np.array(permutation_correctness_ratio)\n",
    "print(np.mean(permutation_correctness_ratio[~np.isnan(permutation_correctness_ratio)]), sum(permutation_correctness_ratio==1)/len(permutation_correctness_ratio), sum(permutation_correctness_ratio==0)/len(permutation_correctness_ratio), (sum(permutation_correctness_ratio==0)+sum(permutation_correctness_ratio==1))/len(permutation_correctness_ratio))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5166656624814163 0.3344632768361582 0.2858757062146893 0.6203389830508474\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(permutation_correctness_ratio)\n",
    "permutation_correctness_ratio = np.array(permutation_correctness_ratio)\n",
    "print(np.mean(permutation_correctness_ratio[~np.isnan(permutation_correctness_ratio)]), sum(permutation_correctness_ratio==1)/len(permutation_correctness_ratio), sum(permutation_correctness_ratio==0)/len(permutation_correctness_ratio), (sum(permutation_correctness_ratio==0)+sum(permutation_correctness_ratio==1))/len(permutation_correctness_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(labels_valid[permutation_correctness_ratio==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(labels_valid[permutation_correctness_ratio==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(labels_valid[(permutation_correctness_ratio==1)|(permutation_correctness_ratio==0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(885,)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permutation_correctness_ratio.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8309)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_init = torch.tensor(list(score_init.values()))\n",
    "score_init.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9881)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3888413/2131006282.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  permutation_correctness_ratio = torch.tensor(permutation_correctness_ratio)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permutation_correctness_ratio = torch.tensor(permutation_correctness_ratio)\n",
    "print(score_init[permutation_correctness_ratio==1].mean())\n",
    "False in torch.tensor(list(init_correctness.values()))[permutation_correctness_ratio==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7196)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(score_init[permutation_correctness_ratio==0].mean())\n",
    "True in torch.tensor(list(init_correctness.values()))[permutation_correctness_ratio==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_permutations_all = num_permutations.values()\n",
    "sns.histplot(num_permutations_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_permutations.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 8\n",
      "64 8\n",
      "64 8\n",
      "64 8\n",
      "4 4\n",
      "11 5\n",
      "3 3\n",
      "64 8\n",
      "64 8\n",
      "64 8\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(num_permutations[i], len(init_permutation[i]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_correct_permutations = [sum(permutation_correctness[i]) for i in permutation_correctness]\n",
    "num_wrong_permutations = [len(permutation_correctness[i])-sum(permutation_correctness[i]) for i in permutation_correctness]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.0\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 31, 32, 34, 35, 37, 38, 39,\n",
      "        40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58,\n",
      "        59, 60, 61, 62, 63, 64])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(np.median(num_correct_permutations))\n",
    "print(torch.tensor(num_correct_permutations).unique())\n",
    "sns.histplot(num_correct_permutations )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(np.median(num_wrong_permutations))\n",
    "sns.histplot(num_wrong_permutations )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 21, 22, 23, 24, 25, 26, 27, 29, 30, 32, 33, 34, 35, 37, 38, 39,\n",
       "        40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57,\n",
       "        58, 59, 60, 61, 62, 63, 64])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(num_wrong_permutations).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, batch in enumerate(valid_dataloader_iter):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "            veri_data[batch_idx].append(new_batch_data.cpu())\n",
    "            veri_label[batch_idx].append(torch.tensor(predict_temp == label_i).long())\n",
    "            veri_cls_indexes[batch_idx].append(cls_indexes_value)\n",
    "            veri_embs[batch_idx].append(embs_temp.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([-8.5623e-01,  7.9049e-02,  3.8569e-01, -6.6407e-01, -1.1610e-01,\n",
       "          1.2273e-02,  4.6107e-02, -1.1365e-01, -8.2460e-01, -2.5970e-01,\n",
       "          9.7081e-01,  8.7536e-01,  6.9931e-01, -3.7064e-01,  1.5717e-01,\n",
       "         -9.5941e-01, -3.9030e-01, -3.4365e-01, -5.4322e-01, -7.6414e-01,\n",
       "         -3.5498e-01,  5.3573e-01, -7.5528e-03,  8.9907e-01,  9.6517e-01,\n",
       "          7.3408e-01, -4.5198e-01,  8.5908e-01, -4.4580e-01,  2.2950e-01,\n",
       "          2.9253e-01, -8.5116e-01, -7.7495e-01, -1.1472e-01,  8.1374e-01,\n",
       "          7.2535e-01,  9.1710e-01,  1.3555e-02,  4.6910e-01,  4.4896e-01,\n",
       "          3.5230e-01,  8.2012e-02,  5.3267e-01,  3.2740e-01, -7.5726e-01,\n",
       "          7.6358e-01, -8.2322e-01, -1.7131e-01, -6.4406e-02,  6.8759e-01,\n",
       "         -1.0792e-01,  3.8933e-01, -7.8018e-01,  3.1049e-02, -7.4943e-01,\n",
       "         -7.5538e-01, -5.2140e-01, -4.5425e-01, -8.4437e-01, -7.2915e-01,\n",
       "         -9.2840e-01, -2.2128e-01,  9.5900e-03,  1.9464e-01,  5.9089e-01,\n",
       "         -3.3018e-01,  6.4489e-01,  4.9774e-02, -9.2997e-01,  4.3776e-01,\n",
       "          1.0284e-01,  1.6019e-01,  8.6100e-01,  4.6374e-02, -8.3401e-01,\n",
       "          8.8687e-01, -4.6522e-01, -9.9633e-02,  1.3309e-01, -6.3779e-01,\n",
       "          4.5469e-01, -6.3094e-01, -8.3818e-01,  7.7902e-01, -4.8522e-01,\n",
       "         -5.8834e-01,  3.0443e-01, -4.5932e-01, -4.8500e-01,  7.3405e-01,\n",
       "         -2.2945e-01, -6.5467e-01,  1.5972e-01, -7.8529e-01,  4.7632e-01,\n",
       "         -1.6704e-01,  6.2478e-01,  5.7767e-01,  1.8077e-01,  2.3625e-01,\n",
       "         -6.9748e-02,  7.2845e-01, -7.7958e-01, -5.9337e-01, -4.0002e-01,\n",
       "         -4.5135e-01,  7.5507e-01, -6.4107e-02,  4.7773e-01, -7.1739e-01,\n",
       "         -2.4171e-01, -4.6856e-01,  7.4073e-01,  8.1377e-01, -5.9937e-01,\n",
       "         -3.3553e-01, -5.7118e-01, -3.3919e-01, -1.8406e-01, -7.1625e-02,\n",
       "         -4.5884e-01, -1.0034e-01,  3.1261e-01, -2.0556e-01, -6.2962e-01,\n",
       "         -3.8913e-01, -1.4897e-01,  6.8997e-01, -9.3466e-01,  3.4187e-01,\n",
       "         -8.5936e-01, -6.0764e-01,  6.8325e-01, -8.2343e-01,  1.8576e-01,\n",
       "          5.0281e-01, -7.9032e-01, -7.4007e-01, -5.4861e-01, -1.7795e-01,\n",
       "          5.1216e-01,  7.3116e-01, -6.7707e-01, -1.4837e-01, -4.9129e-01,\n",
       "         -8.8045e-01,  3.3217e-01,  8.3993e-01,  3.6906e-01,  3.8254e-01,\n",
       "         -7.8751e-01,  3.7775e-01,  6.9343e-01,  8.9910e-02,  7.2131e-01,\n",
       "         -7.5399e-01, -2.7933e-01, -8.9220e-01,  2.6742e-02,  5.3237e-01,\n",
       "          6.4245e-03, -6.2414e-01,  8.5267e-01,  7.8956e-02, -9.1288e-02,\n",
       "          4.6367e-01,  3.6438e-01,  9.2669e-01, -4.1000e-01,  3.7184e-02,\n",
       "         -4.1953e-01, -2.3199e-01,  8.8206e-01,  2.6604e-01, -8.0095e-01,\n",
       "         -1.3355e-01,  2.3650e-01, -9.0282e-01, -7.3664e-01, -4.6503e-01,\n",
       "         -4.6129e-01,  7.0448e-01,  6.4684e-01,  7.2586e-01,  7.1911e-01,\n",
       "         -7.5786e-01,  2.2211e-02, -5.4806e-01, -4.3014e-01, -2.6077e-01,\n",
       "         -7.7279e-01, -4.6252e-01,  2.8167e-01,  7.2826e-01,  8.0485e-01,\n",
       "          8.6818e-01,  8.0037e-01,  2.3917e-02,  8.4762e-01,  2.6322e-01,\n",
       "         -3.8312e-01,  2.6779e-01,  2.7457e-01, -3.9080e-01,  6.5700e-01,\n",
       "          5.1854e-01,  4.1975e-01, -7.6554e-01, -7.5955e-01,  1.5819e-01,\n",
       "          7.4251e-01,  2.4341e-01,  2.8724e-01,  5.4345e-01,  8.2266e-01,\n",
       "         -2.0837e-01, -2.3573e-01,  1.6640e-01,  9.1155e-01,  2.0538e-01,\n",
       "          4.6584e-02, -5.4318e-01,  6.5159e-01, -4.4423e-01, -9.3825e-01,\n",
       "         -7.3861e-01,  2.0642e-01,  8.8241e-01,  8.5494e-01, -7.7170e-01,\n",
       "         -3.1426e-01, -9.4032e-01,  6.9622e-01, -9.9020e-02,  7.0305e-01,\n",
       "         -3.0909e-01,  4.2899e-01, -1.7392e-01, -4.0277e-01, -3.4227e-01,\n",
       "         -1.5637e-01, -4.5876e-01, -8.6723e-01, -4.4867e-01,  8.8071e-02,\n",
       "          1.6605e-01,  8.9950e-01,  1.7277e-01, -7.1548e-01, -9.7539e-02,\n",
       "         -1.3491e-01, -8.1651e-01,  6.7140e-01,  7.9758e-03,  2.6559e-01,\n",
       "         -6.4143e-01, -7.9564e-01, -2.2990e-01,  5.4632e-01,  9.1918e-01,\n",
       "         -9.4052e-01, -9.4658e-02,  3.1082e-01,  5.9198e-01, -5.8959e-01,\n",
       "         -7.5396e-01,  8.3938e-01, -8.8946e-01, -7.6854e-01, -7.9186e-01,\n",
       "          1.1314e-03, -6.3325e-01, -5.2427e-02, -8.1466e-01,  8.5430e-01,\n",
       "          3.9427e-01,  6.7478e-01,  2.3743e-01,  1.3130e-01, -5.7686e-01,\n",
       "          3.1649e-01,  5.8030e-01,  8.2057e-01, -9.1157e-01,  4.6872e-01,\n",
       "         -7.6012e-01, -8.4340e-01,  7.5792e-01,  8.4570e-01, -7.5303e-01,\n",
       "         -1.3999e-01,  7.7277e-01, -8.7166e-02,  7.0124e-01,  6.2984e-01,\n",
       "         -6.1046e-01, -3.6200e-01,  5.2416e-01, -8.9426e-01,  6.2043e-01,\n",
       "          2.7637e-02,  5.7253e-02, -4.5128e-01, -1.3188e-01, -4.3407e-01,\n",
       "          8.5860e-01, -2.6904e-01, -3.6082e-01, -3.6363e-01, -7.2381e-01,\n",
       "          6.9098e-01,  9.6876e-01,  8.5293e-01,  8.2201e-01,  5.7408e-01,\n",
       "         -8.9780e-01, -5.0414e-01,  6.2350e-01,  9.3174e-01, -3.5183e-01,\n",
       "          2.0676e-01, -3.8118e-01,  6.4834e-01,  8.4267e-01,  6.7675e-01,\n",
       "         -7.6749e-01,  2.2539e-01, -1.5995e-01, -6.2669e-01, -4.9293e-01,\n",
       "         -4.5727e-01, -7.3388e-01, -9.4609e-01, -1.0049e-01, -8.1275e-01,\n",
       "         -2.5594e-02,  3.4680e-01,  5.9887e-01,  6.5187e-01, -5.2278e-01,\n",
       "          7.7710e-01,  5.1189e-01, -7.0711e-01,  6.2841e-01, -7.2155e-01,\n",
       "         -2.7197e-02, -1.4755e-01,  3.3333e-01,  8.3686e-01,  8.0758e-03,\n",
       "          6.7653e-01, -6.6353e-01,  4.9868e-01, -1.2802e-01,  8.7592e-01,\n",
       "         -8.8727e-01, -7.8112e-01, -3.6341e-01, -2.6201e-02,  2.0956e-01,\n",
       "         -5.3734e-01, -8.5271e-01, -6.2272e-04,  5.1855e-01,  8.3033e-01,\n",
       "         -7.3489e-02,  8.0470e-01,  2.9269e-01,  7.9522e-01, -3.5807e-01,\n",
       "          7.2736e-02,  5.4007e-01,  4.0153e-01,  4.0626e-01,  3.2091e-01,\n",
       "          2.3945e-01, -1.4316e-01,  1.9871e-01,  7.1775e-01,  3.5864e-01,\n",
       "          5.8229e-01,  1.7104e-01, -3.6728e-01,  5.3679e-01,  3.1920e-03,\n",
       "         -7.0399e-01,  2.6032e-01, -9.0367e-01,  5.5331e-01,  1.8254e-01,\n",
       "         -6.8203e-01, -1.0755e-01, -5.1410e-01,  5.9838e-01,  7.7786e-01,\n",
       "         -8.8186e-01,  2.0714e-01, -9.0683e-01, -3.9055e-02, -6.0657e-01,\n",
       "         -5.6444e-01,  5.5286e-01,  7.5931e-01,  8.0558e-02,  7.3440e-01,\n",
       "         -4.5892e-01, -1.7047e-01, -1.9265e-01,  7.8241e-01,  8.2253e-01,\n",
       "          3.9744e-01, -6.8564e-01,  1.2127e-01,  9.2830e-01, -4.6815e-02,\n",
       "         -7.8807e-01,  8.8890e-01, -1.8047e-01, -8.0649e-01, -5.2637e-01,\n",
       "         -1.1280e-01, -1.4870e-01, -1.1930e-01,  8.3277e-01, -1.9009e-01,\n",
       "         -4.0286e-01,  5.0935e-01, -7.0209e-01, -6.7545e-01,  7.9817e-02,\n",
       "         -4.5328e-01, -7.6676e-01,  8.6277e-01,  4.0053e-01,  5.6281e-01,\n",
       "         -1.8276e-01,  3.9914e-01, -1.3258e-01, -8.1331e-01,  2.4526e-01,\n",
       "         -2.5562e-01,  4.7813e-01,  6.7300e-01,  1.3557e-01,  4.7740e-01,\n",
       "          5.1496e-01, -2.2047e-01,  1.7860e-01, -2.2343e-01, -5.2841e-01,\n",
       "          5.6990e-01,  3.8978e-01,  7.9770e-01, -6.7654e-01, -4.1109e-01,\n",
       "          2.7147e-01,  7.2863e-01,  7.0913e-01,  2.2197e-01,  5.1826e-01,\n",
       "          1.8768e-01,  5.1330e-01, -3.1289e-01,  5.4118e-01, -7.8997e-01,\n",
       "         -3.9946e-01, -8.6512e-01,  7.2357e-02, -2.4427e-01, -5.6578e-02,\n",
       "         -1.9551e-01, -3.5268e-01,  7.7386e-01, -7.8452e-01, -5.0103e-01,\n",
       "          6.0461e-01, -4.8676e-01, -1.9048e-01,  4.6340e-01, -1.6974e-01,\n",
       "          7.6498e-01, -6.7232e-01,  6.8587e-01, -8.7978e-01,  3.1598e-01,\n",
       "          7.2324e-02,  8.5847e-01, -6.3676e-01, -8.1595e-01,  6.8995e-01,\n",
       "          6.2565e-02,  6.2503e-01, -3.0401e-01,  3.8160e-01, -7.8338e-01,\n",
       "          7.1922e-01, -1.6708e-01,  6.6168e-01, -7.1425e-01, -9.2502e-01,\n",
       "         -2.6198e-02,  8.3896e-01,  7.5586e-01, -7.1259e-01, -7.5276e-01,\n",
       "          1.7419e-01, -5.0424e-01, -5.7191e-01,  1.1109e-01, -7.5829e-01,\n",
       "         -2.3279e-02, -6.0213e-02,  5.2972e-01, -7.0459e-01,  6.5937e-01,\n",
       "          7.7165e-01, -7.9421e-01,  2.6666e-01,  6.1308e-01,  1.1468e-01,\n",
       "         -8.0884e-01,  8.0407e-01,  5.4657e-01, -4.4781e-01, -2.0665e-01,\n",
       "          9.2080e-02,  4.6106e-01, -3.6852e-01,  3.2393e-01, -4.3468e-01,\n",
       "          5.7383e-01, -3.5863e-01,  3.5774e-01,  6.4757e-01,  8.4722e-01,\n",
       "         -3.2973e-01,  2.3245e-01, -3.8674e-01, -8.4149e-01, -3.1728e-01,\n",
       "         -3.9402e-02, -8.8654e-01,  1.5996e-02, -1.2009e-01,  8.9415e-01,\n",
       "          4.2419e-01,  5.7183e-01,  4.0045e-01, -6.6391e-01, -8.8426e-01,\n",
       "         -8.4343e-01, -3.7317e-01,  4.4247e-01,  8.5271e-01,  1.8046e-01,\n",
       "          5.7091e-01,  1.6058e-01,  4.8580e-01,  6.8642e-01,  6.7851e-01,\n",
       "         -6.9921e-01, -1.8731e-01,  1.2670e-01, -5.8069e-01,  2.3768e-01,\n",
       "          7.8594e-01,  3.9692e-01, -8.2854e-01,  6.5875e-01, -6.8777e-01,\n",
       "         -7.9663e-01,  4.3537e-01, -1.4040e-01, -6.6973e-02,  6.5267e-01,\n",
       "         -4.7372e-01,  4.3913e-01, -9.2917e-01,  6.2594e-01,  5.6787e-01,\n",
       "         -3.7278e-01, -5.6726e-02,  5.3190e-01, -5.7507e-01, -5.6386e-01,\n",
       "         -7.6401e-01,  6.5321e-01,  3.2644e-01,  6.9360e-01, -9.3016e-01,\n",
       "         -6.0963e-01, -2.1018e-01,  6.4928e-02,  2.9490e-02,  8.0170e-01,\n",
       "         -1.9368e-01,  7.1989e-01, -4.0945e-01, -6.9319e-01,  3.6349e-01,\n",
       "         -6.1711e-01, -4.0219e-01,  3.7298e-01,  8.5711e-01,  3.5791e-01,\n",
       "          6.1758e-01,  8.8118e-01,  6.9896e-01, -6.8463e-01, -8.2357e-01,\n",
       "          3.5237e-01,  8.2533e-01,  1.4300e-01,  5.3443e-01,  9.7982e-01,\n",
       "         -3.7924e-01, -8.0272e-01,  2.3019e-01, -9.5634e-01, -8.2990e-01,\n",
       "          1.2114e-01,  3.0614e-01, -1.4537e-01,  2.0661e-03,  7.4615e-01,\n",
       "          5.4242e-01,  1.2082e-02, -7.6953e-01,  2.2758e-01, -3.6681e-01,\n",
       "         -7.9441e-01,  4.6509e-01,  6.8412e-01,  4.9506e-01,  3.0209e-02,\n",
       "          4.9102e-01, -5.1945e-01,  6.4441e-01, -3.9129e-01,  1.3802e-01,\n",
       "         -7.4199e-01, -6.5160e-01,  9.0517e-01, -9.4869e-02,  4.7882e-01,\n",
       "          8.2833e-01, -3.1057e-01,  4.1580e-01, -6.5806e-01,  1.0839e-01,\n",
       "         -1.8233e-01,  8.5714e-01,  2.2412e-01, -7.9914e-01, -9.0287e-01,\n",
       "          3.9833e-01,  3.5188e-01,  3.8416e-01,  4.0814e-01,  6.5777e-01,\n",
       "          6.9596e-01, -5.0950e-01,  6.9615e-01,  7.2930e-01, -6.2079e-02,\n",
       "          2.7933e-01, -1.9087e-01,  1.5604e-01, -1.3225e-01, -6.8051e-01,\n",
       "          8.1466e-01, -6.5116e-01,  6.2242e-01, -8.8151e-01,  9.3323e-01,\n",
       "         -4.0729e-01,  5.4545e-01,  2.6862e-01, -8.8152e-01,  2.4044e-01,\n",
       "         -7.3386e-01, -1.2100e-01,  6.2302e-01, -5.7593e-01,  3.3305e-01,\n",
       "          1.0188e-01, -3.9346e-01, -9.6263e-01,  6.6759e-02, -4.1548e-02,\n",
       "         -8.3101e-01, -8.3877e-01, -1.7018e-01, -7.3835e-03,  1.0559e-01,\n",
       "          9.0343e-01, -8.4546e-01, -1.4125e-01, -8.0406e-01, -7.2022e-02,\n",
       "          9.0003e-01, -9.0830e-01, -5.5746e-01,  2.0790e-01, -8.6113e-01,\n",
       "         -5.9245e-01, -6.4533e-01,  6.4104e-01, -8.0210e-01,  2.9760e-01,\n",
       "          9.5748e-01,  6.6036e-01,  9.5483e-01,  8.0541e-01, -8.6956e-01,\n",
       "          6.1659e-02,  7.2008e-01, -8.0043e-01, -2.3715e-01,  3.2704e-01,\n",
       "          8.5116e-01,  8.1305e-01, -3.8354e-01,  5.8711e-01, -4.0044e-01,\n",
       "         -6.1141e-01,  8.5653e-01, -1.1388e-01, -4.2611e-01, -8.2079e-01,\n",
       "          7.8589e-01, -1.3588e-01,  7.7631e-01, -8.3279e-01, -7.1647e-01,\n",
       "          6.1920e-01, -8.5016e-01,  5.3284e-01,  3.7885e-01,  2.0164e-01,\n",
       "          5.8651e-01,  6.5473e-02, -4.3460e-01,  1.2571e-02, -6.6851e-01,\n",
       "         -1.1913e-01,  4.7744e-01,  2.6077e-01,  4.7925e-01,  7.2491e-01,\n",
       "          6.6953e-01, -5.8609e-01, -3.1541e-01,  1.4357e-01, -7.3044e-01,\n",
       "          5.0364e-01, -3.7064e-01, -8.2445e-01, -1.5979e-01,  1.4650e-01,\n",
       "          7.3500e-01, -5.0992e-01,  9.7544e-02,  7.7241e-01,  6.7351e-01,\n",
       "          2.4681e-01, -3.6575e-01, -2.5452e-02], grad_fn=<ToCopyBackward0>)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "veri_embs[batch_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1072582/2035222989.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n"
     ]
    }
   ],
   "source": [
    "if 1 in target_col_mask:\n",
    "    col_idx_set = target_col_mask.unique().tolist()\n",
    "    assert -1 not in col_idx_set\n",
    "    for r in range(len(init_permutation_i), max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "        for x in itertools.combinations(init_permutation_i, r):\n",
    "            if 0 not in x:\n",
    "                continue\n",
    "\n",
    "            num_permutations[batch_idx] += 1\n",
    "            new_batch_data = []\n",
    "            for col_i in x:\n",
    "                if col_i == 0:\n",
    "                    if len(new_batch_data) == 0:\n",
    "                        cls_indexes_value = 0\n",
    "                    else:\n",
    "                        cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "            new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "            cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "            logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "            logits_temp = logits_temp.detach().cpu()\n",
    "            ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n",
    "            score_permutation[batch_idx].append(ood_score_temp)\n",
    "            predict_temp = logits_temp.argmax().item()\n",
    "            permutation_correctness[batch_idx].append(predict_temp == label_i)\n",
    "            \n",
    "            # veri_data[batch_idx].append(new_batch_data.cpu())\n",
    "            # veri_label[batch_idx].append(torch.tensor(predict_temp == label_i).long())\n",
    "            # veri_cls_indexes[batch_idx].append(cls_indexes_value)\n",
    "            # veri_embs[batch_idx].append(embs_temp.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_cols' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnum_cols\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'num_cols' is not defined"
     ]
    }
   ],
   "source": [
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Threshold: 1.5****************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1200793/482508439.py:54: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
      "/tmp/ipykernel_1200793/482508439.py:101: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n"
     ]
    }
   ],
   "source": [
    "# brute force perumate in validation TODO: restrict mamimus length of permutation\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "import torch.nn.functional as F\n",
    "veri_data = defaultdict(list)\n",
    "veri_logits = defaultdict(list)\n",
    "veri_cls_indexes = defaultdict(list)\n",
    "veri_target_col_mask = defaultdict(list)\n",
    "veri_embs = defaultdict(list)\n",
    "veri_target_embs = defaultdict(list)\n",
    "veri_col_num = defaultdict(list)\n",
    "veri_label = defaultdict(list)\n",
    "veri_class = defaultdict(list)\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "for threshold in [1.5]:\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    log = defaultdict(list)\n",
    "    num_cols = []\n",
    "    corrected = 0\n",
    "    total_mistakes = 0\n",
    "    num_permutations = {}\n",
    "    init_permutation = {}\n",
    "    init_correctness = {}\n",
    "    score_init = {}\n",
    "    score_permutation = defaultdict(list)\n",
    "    permutation_correctness = defaultdict(list)\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(valid_dataloader_iter):\n",
    "            cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "            target_col_mask = batch[\"target_col_mask\"].T\n",
    "            logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "            score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
    "            label_i = batch[\"label\"].item()\n",
    "            predict_init = logits.argmax().item()\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            init_permutation[batch_idx] = init_permutation_i\n",
    "            if predict_init == label_i:\n",
    "                init_correctness[batch_idx] = True\n",
    "            else:\n",
    "                init_correctness[batch_idx] = False\n",
    "            num_permutations[batch_idx] = 0\n",
    "            \n",
    "            x = [0]\n",
    "            new_batch_data = []\n",
    "            for col_i in x:\n",
    "                if col_i == 0:\n",
    "                    if len(new_batch_data) == 0:\n",
    "                        cls_indexes_value = 0\n",
    "                    else:\n",
    "                        cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "            new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "            cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "            logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "            veri_target_embs[batch_idx].append(embs_temp.cpu())\n",
    "\n",
    "\n",
    "            num_cols.append(len(init_permutation_i))\n",
    "            labels_test.append(batch[\"label\"].cpu().item())\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            assert -1 not in col_idx_set\n",
    "            for r in range(len(init_permutation_i), 1, -1): # not \n",
    "                for x in itertools.combinations(init_permutation_i, r):\n",
    "                    if 0 not in x:\n",
    "                        continue\n",
    "\n",
    "                    num_permutations[batch_idx] += 1\n",
    "                    new_batch_data = []\n",
    "                    for col_i in x:\n",
    "                        if col_i == 0:\n",
    "                            if len(new_batch_data) == 0:\n",
    "                                cls_indexes_value = 0\n",
    "                            else:\n",
    "                                cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                        new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                    new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                    cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                    logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                    ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n",
    "                    score_permutation[batch_idx].append(ood_score_temp)\n",
    "                    predict_temp = logits_temp.argmax().item()\n",
    "                    permutation_correctness[batch_idx].append(predict_temp == label_i)\n",
    "                    # v3: add more neg examples\n",
    "                    if predict_temp == label_i and len(x) < max(len(init_permutation_i)//2, len(init_permutation_i)-2):\n",
    "                        continue\n",
    "                    \n",
    "                    veri_data[batch_idx].append(new_batch_data.cpu())\n",
    "                    veri_logits[batch_idx].append(logits_temp.detach().cpu())\n",
    "                    veri_cls_indexes[batch_idx].append(cls_indexes_value)\n",
    "                    veri_embs[batch_idx].append(embs_temp.cpu())\n",
    "                    veri_col_num[batch_idx].append(len(x))\n",
    "                    veri_label[batch_idx].append(torch.tensor(predict_temp == label_i).long()) # indicate whether the permutation is correct or not\n",
    "                    veri_class[batch_idx].append(label_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Threshold: 1.5****************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1200793/2998815280.py:55: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
      "/tmp/ipykernel_1200793/2998815280.py:102: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n"
     ]
    }
   ],
   "source": [
    "# brute force perumate in validation TODO: restrict mamimus length of permutation\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "import torch.nn.functional as F\n",
    "veri_data = defaultdict(list)\n",
    "veri_logits = defaultdict(list)\n",
    "veri_cls_indexes = defaultdict(list)\n",
    "veri_target_col_mask = defaultdict(list)\n",
    "veri_embs = defaultdict(list)\n",
    "veri_target_embs = defaultdict(list)\n",
    "veri_col_num = defaultdict(list)\n",
    "veri_label = defaultdict(list)\n",
    "veri_class = defaultdict(list)\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "max_col_length = 3\n",
    "for threshold in [1.5]:\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    log = defaultdict(list)\n",
    "    num_cols = []\n",
    "    corrected = 0\n",
    "    total_mistakes = 0\n",
    "    num_permutations = {}\n",
    "    init_permutation = {}\n",
    "    init_correctness = {}\n",
    "    score_init = {}\n",
    "    score_permutation = defaultdict(list)\n",
    "    permutation_correctness = defaultdict(list)\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(valid_dataloader_iter):\n",
    "            cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "            target_col_mask = batch[\"target_col_mask\"].T\n",
    "            logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "            score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
    "            label_i = batch[\"label\"].item()\n",
    "            predict_init = logits.argmax().item()\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            init_permutation[batch_idx] = init_permutation_i\n",
    "            if predict_init == label_i:\n",
    "                init_correctness[batch_idx] = True\n",
    "            else:\n",
    "                init_correctness[batch_idx] = False\n",
    "            num_permutations[batch_idx] = 0\n",
    "            \n",
    "            x = [0]\n",
    "            new_batch_data = []\n",
    "            for col_i in x:\n",
    "                if col_i == 0:\n",
    "                    if len(new_batch_data) == 0:\n",
    "                        cls_indexes_value = 0\n",
    "                    else:\n",
    "                        cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "            new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "            cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "            logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "            veri_target_embs[batch_idx].append(embs_temp.cpu())\n",
    "\n",
    "\n",
    "            num_cols.append(len(init_permutation_i))\n",
    "            labels_test.append(batch[\"label\"].cpu().item())\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            assert -1 not in col_idx_set\n",
    "            for r in range(1, min(len(col_idx_set), max_col_length) + 1):\n",
    "                for subset in itertools.combinations(col_idx_set, r):\n",
    "                    if 0 not in subset:\n",
    "                        continue\n",
    "                    for x in itertools.permutations(subset):\n",
    "                        num_permutations[batch_idx] += 1\n",
    "                        new_batch_data = []\n",
    "                        for col_i in x:\n",
    "                            if col_i == 0:\n",
    "                                if len(new_batch_data) == 0:\n",
    "                                    cls_indexes_value = 0\n",
    "                                else:\n",
    "                                    cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                            new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                        new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                        cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                        logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                        ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n",
    "                        score_permutation[batch_idx].append(ood_score_temp)\n",
    "                        predict_temp = logits_temp.argmax().item()\n",
    "                        permutation_correctness[batch_idx].append(predict_temp == label_i)\n",
    "                        \n",
    "                        veri_data[batch_idx].append(new_batch_data.cpu())\n",
    "                        veri_logits[batch_idx].append(logits_temp.detach().cpu())\n",
    "                        veri_cls_indexes[batch_idx].append(cls_indexes_value)\n",
    "                        veri_embs[batch_idx].append(embs_temp.cpu())\n",
    "                        veri_col_num[batch_idx].append(len(x))\n",
    "                        veri_label[batch_idx].append(torch.tensor(predict_temp == label_i).long()) # indicate whether the permutation is correct or not\n",
    "                        veri_class[batch_idx].append(label_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96763\n",
      "tensor(0.4410)\n"
     ]
    }
   ],
   "source": [
    "# V7\n",
    "veri_labels_all = torch.cat([torch.tensor(veri_label[i]) for i in veri_label], dim=0)\n",
    "print(len(veri_labels_all))\n",
    "print(veri_labels_all.sum()/len(veri_labels_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"/data/zhihao/TU/Watchog/verification\", exist_ok=True)\n",
    "# {args.task}_veri_data: min length: max(len(init_permutation_i)//2, len(init_permutation_i)-3)\n",
    "# {args.task}_veri_data_1: min length: for those without correct permutation, \n",
    "torch.save({\"data\": veri_data, \"label\": veri_label, \"logits\": veri_logits, \"cls_indexes\": veri_cls_indexes, \"embs\": veri_embs, \"target_embs\":veri_target_embs,  \"col_num\": veri_col_num}, f\"/data/zhihao/TU/Watchog/verification/{args.task}_veri_data_8.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122702\n",
      "tensor(0.5972)\n"
     ]
    }
   ],
   "source": [
    "# V4\n",
    "veri_labels_all = torch.cat([torch.tensor(train_label[i]) for i in train_label], dim=0)\n",
    "print(len(veri_labels_all))\n",
    "print(veri_labels_all.sum()/len(veri_labels_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1200793/3512779604.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  train_results = torch.load( f\"/data/zhihao/TU/Watchog/trainfication/{args.task}_train_data_8.pth\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.makedirs(\"/data/zhihao/TU/Watchog/trainfication\", exist_ok=True)\n",
    "train_results = torch.load( f\"/data/zhihao/TU/Watchog/trainfication/{args.task}_train_data_8.pth\")\n",
    "train_data = train_results[\"data\"]\n",
    "train_label = train_results[\"label\"]\n",
    "train_logits = train_results[\"logits\"]\n",
    "train_cls_indexes = train_results[\"cls_indexes\"]\n",
    "train_embs = train_results[\"embs\"]\n",
    "train_target_embs = train_results[\"target_embs\"]\n",
    "train_col_num = train_results[\"col_num\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "383924\n",
      "tensor(0.6839)\n"
     ]
    }
   ],
   "source": [
    "veri_labels_all = torch.cat([torch.tensor(train_label[i]) for i in train_label], dim=0)\n",
    "print(len(veri_labels_all))\n",
    "print(veri_labels_all.sum()/len(veri_labels_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1200793/757288286.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  valid_results = torch.load( f\"/data/zhihao/TU/Watchog/verification/{args.task}_veri_data_5.pth\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.makedirs(\"/data/zhihao/TU/Watchog/trainfication\", exist_ok=True)\n",
    "valid_results = torch.load( f\"/data/zhihao/TU/Watchog/verification/{args.task}_veri_data_5.pth\")\n",
    "veri_data = valid_results[\"data\"]\n",
    "veri_label = valid_results[\"label\"]\n",
    "veri_logits = valid_results[\"logits\"]\n",
    "veri_cls_indexes = valid_results[\"cls_indexes\"]\n",
    "veri_embs = valid_results[\"embs\"]\n",
    "veri_target_embs = valid_results[\"target_embs\"]\n",
    "veri_col_num = valid_results[\"col_num\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172055\n",
      "tensor(0.4884)\n"
     ]
    }
   ],
   "source": [
    "veri_labels_all = torch.cat([torch.tensor(veri_label[i]) for i in veri_label], dim=0)\n",
    "print(len(veri_labels_all))\n",
    "print(veri_labels_all.sum()/len(veri_labels_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = len(train_data)\n",
    "for i in veri_data:\n",
    "    train_data[num_train+i] = veri_data[i]\n",
    "    train_label[num_train+i] = veri_label[i]\n",
    "    train_logits[num_train+i] = veri_logits[i]\n",
    "    train_cls_indexes[num_train+i] = veri_cls_indexes[i]\n",
    "    train_embs[num_train+i] = veri_embs[i]\n",
    "    train_target_embs[num_train+i] = veri_target_embs[i]\n",
    "    train_col_num[num_train+i] = veri_col_num[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "296800\n",
      "tensor(0.2946)\n"
     ]
    }
   ],
   "source": [
    "# V9\n",
    "veri_labels_all = torch.cat([torch.tensor(train_label[i]) for i in train_label], dim=0)\n",
    "print(len(veri_labels_all))\n",
    "print(veri_labels_all.sum()/len(veri_labels_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "555979\n",
      "tensor(0.6234)\n"
     ]
    }
   ],
   "source": [
    "# V10\n",
    "veri_labels_all = torch.cat([torch.tensor(train_label[i]) for i in train_label], dim=0)\n",
    "print(len(veri_labels_all))\n",
    "print(veri_labels_all.sum()/len(veri_labels_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"/data/zhihao/TU/Watchog/verification\", exist_ok=True)\n",
    "torch.save({\"data\": train_data, \"label\": train_label, \"logits\": train_logits, \"cls_indexes\": train_cls_indexes, \"embs\": train_embs, \"target_embs\":train_target_embs , \"col_num\": train_col_num}, f\"/data/zhihao/TU/Watchog/verification/{args.task}_veri_data_10.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124745\n",
      "tensor(0.0273)\n"
     ]
    }
   ],
   "source": [
    "# V7\n",
    "veri_labels_all = torch.cat([torch.tensor(train_label[i]) for i in train_label], dim=0)\n",
    "print(len(veri_labels_all))\n",
    "print(veri_labels_all.sum()/len(veri_labels_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221508\n",
      "tensor(0.2080)\n"
     ]
    }
   ],
   "source": [
    "# V7 + veri\n",
    "veri_labels_all = torch.cat([torch.tensor(train_label[i]) for i in train_label], dim=0)\n",
    "print(len(veri_labels_all))\n",
    "print(veri_labels_all.sum()/len(veri_labels_all))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "veri_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"/data/zhihao/TU/Watchog/verification\", exist_ok=True)\n",
    "# {args.task}_veri_data: min length: max(len(init_permutation_i)//2, len(init_permutation_i)-3)\n",
    "# {args.task}_veri_data_1: min length: for those without correct permutation, \n",
    "torch.save({\"data\": veri_data, \"label\": veri_label, \"logits\": veri_logits, \"cls_indexes\": veri_cls_indexes, \"embs\": veri_embs, \"target_embs\":veri_target_embs,  \"col_num\": veri_col_num}, f\"/data/zhihao/TU/Watchog/verification/{args.task}_veri_data_3.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4346"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"/data/zhihao/TU/Watchog/verification\", exist_ok=True)\n",
    "torch.save({\"data\": train_data, \"label\": train_label, \"logits\": train_logits, \"cls_indexes\": train_cls_indexes, \"embs\": train_embs, \"target_embs\":train_target_embs , \"col_num\": train_col_num}, f\"/data/zhihao/TU/Watchog/verification/{args.task}_veri_data_4.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/zhihao/TU/Watchog/trainfication/gt-semtab22-dbpedia-all0_veri_data_4.pth'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " f\"/data/zhihao/TU/Watchog/trainfication/{args.task}_veri_data_4.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128489\n",
      "tensor(0.6493)\n"
     ]
    }
   ],
   "source": [
    "# V4\n",
    "veri_labels_all = torch.cat([torch.tensor(train_label[i]) for i in train_label], dim=0)\n",
    "print(len(veri_labels_all))\n",
    "print(veri_labels_all.sum()/len(veri_labels_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49353\n",
      "tensor(0.2178)\n"
     ]
    }
   ],
   "source": [
    "# V3\n",
    "print(len(veri_labels_all))\n",
    "print(veri_labels_all.sum()/len(veri_labels_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79593"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# V2\n",
    "len(veri_labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5150)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# V2\n",
    "veri_labels_all.sum()/len(veri_labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Threshold: 1.5****************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2045046/4267723283.py:54: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
      "/tmp/ipykernel_2045046/4267723283.py:101: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n"
     ]
    }
   ],
   "source": [
    "# brute force perumate in validation TODO: restrict mamimus length of permutation\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "import torch.nn.functional as F\n",
    "veri_data = defaultdict(list)\n",
    "veri_logits = defaultdict(list)\n",
    "veri_cls_indexes = defaultdict(list)\n",
    "veri_target_col_mask = defaultdict(list)\n",
    "veri_embs = defaultdict(list)\n",
    "veri_target_embs = defaultdict(list)\n",
    "veri_col_num = defaultdict(list)\n",
    "veri_label = defaultdict(list)\n",
    "veri_class = defaultdict(list)\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "for threshold in [1.5]:\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    log = defaultdict(list)\n",
    "    num_cols = []\n",
    "    corrected = 0\n",
    "    total_mistakes = 0\n",
    "    num_permutations = {}\n",
    "    init_permutation = {}\n",
    "    init_correctness = {}\n",
    "    score_init = {}\n",
    "    score_permutation = defaultdict(list)\n",
    "    permutation_correctness = defaultdict(list)\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(valid_dataloader_iter):\n",
    "            cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "            target_col_mask = batch[\"target_col_mask\"].T\n",
    "            logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "            score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
    "            label_i = batch[\"label\"].item()\n",
    "            predict_init = logits.argmax().item()\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            init_permutation[batch_idx] = init_permutation_i\n",
    "            if predict_init == label_i:\n",
    "                init_correctness[batch_idx] = True\n",
    "            else:\n",
    "                init_correctness[batch_idx] = False\n",
    "            num_permutations[batch_idx] = 0\n",
    "            \n",
    "            x = [0]\n",
    "            new_batch_data = []\n",
    "            for col_i in x:\n",
    "                if col_i == 0:\n",
    "                    if len(new_batch_data) == 0:\n",
    "                        cls_indexes_value = 0\n",
    "                    else:\n",
    "                        cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "            new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "            cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "            logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "            veri_target_embs[batch_idx].append(embs_temp.cpu())\n",
    "\n",
    "\n",
    "            num_cols.append(len(init_permutation_i))\n",
    "            labels_test.append(batch[\"label\"].cpu().item())\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            assert -1 not in col_idx_set\n",
    "            for r in range(len(init_permutation_i), 1, -1): # not \n",
    "                for x in itertools.combinations(init_permutation_i, r):\n",
    "                    if 0 not in x:\n",
    "                        continue\n",
    "\n",
    "                    num_permutations[batch_idx] += 1\n",
    "                    new_batch_data = []\n",
    "                    for col_i in x:\n",
    "                        if col_i == 0:\n",
    "                            if len(new_batch_data) == 0:\n",
    "                                cls_indexes_value = 0\n",
    "                            else:\n",
    "                                cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                        new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                    new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                    cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                    logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                    ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n",
    "                    score_permutation[batch_idx].append(ood_score_temp)\n",
    "                    predict_temp = logits_temp.argmax().item()\n",
    "                    permutation_correctness[batch_idx].append(predict_temp == label_i)\n",
    "                    \n",
    "                    veri_data[batch_idx].append(new_batch_data.cpu())\n",
    "                    veri_logits[batch_idx].append(logits_temp.detach().cpu())\n",
    "                    veri_cls_indexes[batch_idx].append(cls_indexes_value)\n",
    "                    veri_embs[batch_idx].append(embs_temp.cpu())\n",
    "                    veri_col_num[batch_idx].append(len(x))\n",
    "                    veri_label[batch_idx].append(torch.tensor(predict_temp == label_i).long()) # indicate whether the permutation is correct or not\n",
    "                    veri_class[batch_idx].append(label_i)\n",
    "                if r < max(len(init_permutation_i)//2, len(init_permutation_i)-3) and sum(permutation_correctness[batch_idx]) > 0:\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"/data/zhihao/TU/Watchog/verification\", exist_ok=True)\n",
    "# {args.task}_veri_data: min length: max(len(init_permutation_i)//2, len(init_permutation_i)-3)\n",
    "# {args.task}_veri_data_1: min length: for those without correct permutation, \n",
    "torch.save({\"data\": veri_data, \"label\": veri_label, \"logits\": veri_logits, \"cls_indexes\": veri_cls_indexes, \"embs\": veri_embs, \"target_embs\":veri_target_embs,  \"col_num\": veri_col_num}, f\"/data/zhihao/TU/Watchog/verification/{args.task}_veri_data_1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1200793/2535775824.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  res = torch.load(f\"/data/zhihao/TU/Watchog/verification/{args.task}_veri_data_1.pth\")\n"
     ]
    }
   ],
   "source": [
    "res = torch.load(f\"/data/zhihao/TU/Watchog/verification/{args.task}_veri_data_1.pth\")\n",
    "veri_label_1 = res[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "veri_label_1_all = torch.cat([torch.tensor(veri_label_1[i]) for i in veri_label_1], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67813"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(veri_label_1_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4861)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "veri_label_1_all.sum()/len(veri_label_1_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1200793/2986149398.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  res = torch.load(f\"/data/zhihao/TU/Watchog/verification/{args.task}_veri_data.pth\")\n"
     ]
    }
   ],
   "source": [
    "res = torch.load(f\"/data/zhihao/TU/Watchog/verification/{args.task}_veri_data.pth\")\n",
    "veri_label_old = res[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "veri_label_old_all = torch.cat([torch.tensor(veri_label_old[i]) for i in veri_label_old], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20130"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(veri_label_old_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5288)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "veri_label_old_all.sum()/len(veri_label_old_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veri_label_old[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_all_old = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "labels_test = []\n",
    "for batch in veri_class:\n",
    "    labels_test.append(batch[0])\n",
    "sns.histplot(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, test_counts = np.unique(labels_test, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([207, 113,  42,  37,  33,  20,  12,  13,  12,  19,  11,  14,  19,\n",
       "        11,  15,  13,   9,   3,  12,  10,   8,   9,   9,   8,   9,   7,\n",
       "         5,   6,   9,   3,   4,   4,   2,   6,   5,   3,   7,   2,   5,\n",
       "         3,   4,   1,   6,   8,   8,   4,   5,   1,   5,   2,   4,   2,\n",
       "         5,   1,   2,   3,   4,   5,   1,   5,   2,   3,   2,   1,   4,\n",
       "         4,   2,   2,   1,   1,   2,   4,   3,   2,   3,   4,   4,   1,\n",
       "         3,   2,   1,   1,   1,   2,   1,   1,   1,   2,   1,   1,   1,\n",
       "         2,   3,   1,   1])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, veri_counts = np.unique(labels_all, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4340, 2331,  923,  818,  700,  425,  328,  306,  253,  519,  209,\n",
       "        295,  393,  287,  359,  334,  120,   61,  335,  272,  219,  254,\n",
       "        221,  207,  240,  183,  132,  174,  210,   87,   47,   96,   58,\n",
       "        174,  125,   56,  153,   58,  138,   69,  109,   29,  117,  188,\n",
       "        214,  116,  145,   16,  111,   40,   80,   32,  138,   16,   58,\n",
       "         44,   85,  138,   16,  145,   32,   87,   32,   29,   90,  116,\n",
       "         58,   20,   29,   29,   45,   91,   80,   58,   69,  116,  116,\n",
       "         22,   67,   58,   29,   29,   29,   58,   29,   29,   29,   58,\n",
       "         29,   29,   29,   32,   87,   22,   22])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(max(test_counts)/min(test_counts), )\n",
    "veri_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "labels_all = []\n",
    "for batch in veri_class:\n",
    "    for label in veri_class[batch]:\n",
    "        labels_all.append(label)\n",
    "sns.histplot(labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhihao/jupyterprojects/jupyter/lib/python3.8/site-packages/seaborn/_core.py:721: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  values = np.atleast_1d(np.asarray(data, dtype=object))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [98]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43msns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/jupyterprojects/jupyter/lib/python3.8/site-packages/seaborn/distributions.py:1462\u001b[0m, in \u001b[0;36mhistplot\u001b[0;34m(data, x, y, hue, weights, stat, bins, binwidth, binrange, discrete, cumulative, common_bins, common_norm, multiple, element, fill, shrink, kde, kde_kws, line_kws, thresh, pthresh, pmax, cbar, cbar_ax, cbar_kws, palette, hue_order, hue_norm, color, log_scale, legend, ax, **kwargs)\u001b[0m\n\u001b[1;32m   1451\u001b[0m estimate_kws \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m   1452\u001b[0m     stat\u001b[38;5;241m=\u001b[39mstat,\n\u001b[1;32m   1453\u001b[0m     bins\u001b[38;5;241m=\u001b[39mbins,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1457\u001b[0m     cumulative\u001b[38;5;241m=\u001b[39mcumulative,\n\u001b[1;32m   1458\u001b[0m )\n\u001b[1;32m   1460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39munivariate:\n\u001b[0;32m-> 1462\u001b[0m     \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_univariate_histogram\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmultiple\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmultiple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[43m        \u001b[49m\u001b[43melement\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43melement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1465\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1466\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshrink\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshrink\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1467\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcommon_norm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommon_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1468\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcommon_bins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommon_bins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkde\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkde\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1470\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkde_kws\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkde_kws\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1471\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1472\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlegend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlegend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1473\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimate_kws\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimate_kws\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1474\u001b[0m \u001b[43m        \u001b[49m\u001b[43mline_kws\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mline_kws\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1475\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1476\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1480\u001b[0m     p\u001b[38;5;241m.\u001b[39mplot_bivariate_histogram(\n\u001b[1;32m   1481\u001b[0m         common_bins\u001b[38;5;241m=\u001b[39mcommon_bins,\n\u001b[1;32m   1482\u001b[0m         common_norm\u001b[38;5;241m=\u001b[39mcommon_norm,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1492\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1493\u001b[0m     )\n",
      "File \u001b[0;32m~/jupyterprojects/jupyter/lib/python3.8/site-packages/seaborn/distributions.py:428\u001b[0m, in \u001b[0;36m_DistributionPlotter.plot_univariate_histogram\u001b[0;34m(self, multiple, element, fill, common_norm, common_bins, shrink, kde, kde_kws, color, legend, line_kws, estimate_kws, **plot_kws)\u001b[0m\n\u001b[1;32m    418\u001b[0m     densities \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_univariate_density(\n\u001b[1;32m    419\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_variable,\n\u001b[1;32m    420\u001b[0m         common_norm,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    424\u001b[0m         warn_singular\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    425\u001b[0m     )\n\u001b[1;32m    427\u001b[0m \u001b[38;5;66;03m# First pass through the data to compute the histograms\u001b[39;00m\n\u001b[0;32m--> 428\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sub_vars, sub_data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_data(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhue\u001b[39m\u001b[38;5;124m\"\u001b[39m, from_comp_data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    429\u001b[0m \n\u001b[1;32m    430\u001b[0m     \u001b[38;5;66;03m# Prepare the relevant data\u001b[39;00m\n\u001b[1;32m    431\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(sub_vars\u001b[38;5;241m.\u001b[39mitems())\n\u001b[1;32m    432\u001b[0m     sub_data \u001b[38;5;241m=\u001b[39m sub_data\u001b[38;5;241m.\u001b[39mdropna()\n",
      "File \u001b[0;32m~/jupyterprojects/jupyter/lib/python3.8/site-packages/seaborn/_core.py:997\u001b[0m, in \u001b[0;36mVectorPlotter.iter_data\u001b[0;34m(self, grouping_vars, reverse, from_comp_data)\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m grouping_vars:\n\u001b[1;32m    995\u001b[0m     grouping_keys\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvar_levels\u001b[38;5;241m.\u001b[39mget(var, []))\n\u001b[0;32m--> 997\u001b[0m iter_keys \u001b[38;5;241m=\u001b[39m \u001b[43mitertools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgrouping_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    998\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reverse:\n\u001b[1;32m    999\u001b[0m     iter_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mlist\u001b[39m(iter_keys))\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20130"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs_temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 378])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_batch_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_indexes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 504])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"data\"].T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in veri_data:\n",
    "    assert len(veri_data[i]) == len(veri_label[i]) == len(veri_cls_indexes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Threshold: 1.5****************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3640352/1600745436.py:54: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
      "/tmp/ipykernel_3640352/1600745436.py:86: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n"
     ]
    }
   ],
   "source": [
    "# brute force perumate in validation TODO: restrict mamimus length of permutation\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "import torch.nn.functional as F\n",
    "test_data = defaultdict(list)\n",
    "test_logits = defaultdict(list)\n",
    "test_cls_indexes = defaultdict(list)\n",
    "test_target_col_mask = defaultdict(list)\n",
    "test_embs = defaultdict(list)\n",
    "test_col_num = defaultdict(list)\n",
    "test_label = defaultdict(list)\n",
    "test_class = defaultdict(list)\n",
    "\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "for threshold in [1.5]:\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    log = defaultdict(list)\n",
    "    num_cols = []\n",
    "    corrected = 0\n",
    "    total_mistakes = 0\n",
    "    num_permutations = {}\n",
    "    init_permutation = {}\n",
    "    init_correctness = {}\n",
    "    score_init = {}\n",
    "    score_permutation = defaultdict(list)\n",
    "    permutation_correctness = defaultdict(list)\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "            cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "            target_col_mask = batch[\"target_col_mask\"].T\n",
    "            logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "            score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
    "            label_i = batch[\"label\"].item()\n",
    "            predict_init = logits.argmax().item()\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            init_permutation[batch_idx] = init_permutation_i\n",
    "            if predict_init == label_i:\n",
    "                init_correctness[batch_idx] = True\n",
    "            else:\n",
    "                init_correctness[batch_idx] = False\n",
    "            num_permutations[batch_idx] = 0\n",
    "\n",
    "            num_cols.append(len(init_permutation_i))\n",
    "            labels_test.append(batch[\"label\"].cpu())\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            assert -1 not in col_idx_set\n",
    "            for r in range(len(init_permutation_i), max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "                for x in itertools.combinations(init_permutation_i, r):\n",
    "                    if 0 not in x:\n",
    "                        continue\n",
    "\n",
    "                    num_permutations[batch_idx] += 1\n",
    "                    new_batch_data = []\n",
    "                    for col_i in x:\n",
    "                        if col_i == 0:\n",
    "                            if len(new_batch_data) == 0:\n",
    "                                cls_indexes_value = 0\n",
    "                            else:\n",
    "                                cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                        new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                    new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                    cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                    logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                    ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n",
    "                    score_permutation[batch_idx].append(ood_score_temp)\n",
    "                    predict_temp = logits_temp.argmax().item()\n",
    "                    permutation_correctness[batch_idx].append(predict_temp == label_i)\n",
    "                    \n",
    "                    test_data[batch_idx].append(new_batch_data.cpu())\n",
    "                    test_logits[batch_idx].append(logits_temp.detach().cpu())\n",
    "                    test_cls_indexes[batch_idx].append(cls_indexes_value)\n",
    "                    test_embs[batch_idx].append(embs_temp.cpu())\n",
    "                    test_col_num[batch_idx].append(len(x))\n",
    "                    test_label[batch_idx].append(torch.tensor(predict_temp == label_i).long()) # indicate whether the permutation is correct or not\n",
    "                    test_class[batch_idx].append(label_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Threshold: 1.5****************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1200793/848650604.py:54: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
      "/tmp/ipykernel_1200793/848650604.py:86: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n"
     ]
    }
   ],
   "source": [
    "# brute force perumate in validation TODO: restrict mamimus length of permutation\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "import torch.nn.functional as F\n",
    "test_data = defaultdict(list)\n",
    "test_logits = defaultdict(list)\n",
    "test_cls_indexes = defaultdict(list)\n",
    "test_target_col_mask = defaultdict(list)\n",
    "test_embs = defaultdict(list)\n",
    "test_col_num = defaultdict(list)\n",
    "test_label = defaultdict(list)\n",
    "test_class = defaultdict(list)\n",
    "\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "for threshold in [1.5]:\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    log = defaultdict(list)\n",
    "    num_cols = []\n",
    "    corrected = 0\n",
    "    total_mistakes = 0\n",
    "    num_permutations = {}\n",
    "    init_permutation = {}\n",
    "    init_correctness = {}\n",
    "    score_init = {}\n",
    "    score_permutation = defaultdict(list)\n",
    "    permutation_correctness = defaultdict(list)\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "            cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "            target_col_mask = batch[\"target_col_mask\"].T\n",
    "            logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "            score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
    "            label_i = batch[\"label\"].item()\n",
    "            predict_init = logits.argmax().item()\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            init_permutation[batch_idx] = init_permutation_i\n",
    "            if predict_init == label_i:\n",
    "                init_correctness[batch_idx] = True\n",
    "            else:\n",
    "                init_correctness[batch_idx] = False\n",
    "            num_permutations[batch_idx] = 0\n",
    "\n",
    "            num_cols.append(len(init_permutation_i))\n",
    "            labels_test.append(batch[\"label\"].cpu())\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            assert -1 not in col_idx_set\n",
    "            for r in range(len(init_permutation_i), 1, -1): # not \n",
    "                for x in itertools.combinations(init_permutation_i, r):\n",
    "                    if 0 not in x:\n",
    "                        continue\n",
    "\n",
    "                    num_permutations[batch_idx] += 1\n",
    "                    new_batch_data = []\n",
    "                    for col_i in x:\n",
    "                        if col_i == 0:\n",
    "                            if len(new_batch_data) == 0:\n",
    "                                cls_indexes_value = 0\n",
    "                            else:\n",
    "                                cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                        new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                    new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                    cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                    logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                    ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n",
    "                    score_permutation[batch_idx].append(ood_score_temp)\n",
    "                    predict_temp = logits_temp.argmax().item()\n",
    "                    permutation_correctness[batch_idx].append(predict_temp == label_i)\n",
    "                    \n",
    "                    test_data[batch_idx].append(new_batch_data.cpu())\n",
    "                    test_logits[batch_idx].append(logits_temp.detach().cpu())\n",
    "                    test_cls_indexes[batch_idx].append(cls_indexes_value)\n",
    "                    test_embs[batch_idx].append(embs_temp.cpu())\n",
    "                    test_col_num[batch_idx].append(len(x))\n",
    "                    test_label[batch_idx].append(torch.tensor(predict_temp == label_i).long()) # indicate whether the permutation is correct or not\n",
    "                    test_class[batch_idx].append(label_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Threshold: 1.5****************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1200793/3827576329.py:56: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
      "/tmp/ipykernel_1200793/3827576329.py:88: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n"
     ]
    }
   ],
   "source": [
    "# brute force perumate in validation TODO: restrict mamimus length of permutation\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "import torch.nn.functional as F\n",
    "test_data = defaultdict(list)\n",
    "test_logits = defaultdict(list)\n",
    "test_cls_indexes = defaultdict(list)\n",
    "test_target_col_mask = defaultdict(list)\n",
    "test_embs = defaultdict(list)\n",
    "test_col_num = defaultdict(list)\n",
    "test_label = defaultdict(list)\n",
    "test_class = defaultdict(list)\n",
    "\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "\n",
    "max_col_length = 3\n",
    "for threshold in [1.5]:\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    log = defaultdict(list)\n",
    "    num_cols = []\n",
    "    corrected = 0\n",
    "    total_mistakes = 0\n",
    "    num_permutations = {}\n",
    "    init_permutation = {}\n",
    "    init_correctness = {}\n",
    "    score_init = {}\n",
    "    score_permutation = defaultdict(list)\n",
    "    permutation_correctness = defaultdict(list)\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "            cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "            target_col_mask = batch[\"target_col_mask\"].T\n",
    "            logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "            score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
    "            label_i = batch[\"label\"].item()\n",
    "            predict_init = logits.argmax().item()\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            init_permutation[batch_idx] = init_permutation_i\n",
    "            if predict_init == label_i:\n",
    "                init_correctness[batch_idx] = True\n",
    "            else:\n",
    "                init_correctness[batch_idx] = False\n",
    "            num_permutations[batch_idx] = 0\n",
    "\n",
    "            num_cols.append(len(init_permutation_i))\n",
    "            labels_test.append(batch[\"label\"].cpu())\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            assert -1 not in col_idx_set\n",
    "            for r in range(1, min(len(col_idx_set), max_col_length) + 1):\n",
    "                for subset in itertools.combinations(col_idx_set, r):\n",
    "                    if 0 not in subset:\n",
    "                        continue\n",
    "                    for x in itertools.permutations(subset):\n",
    "                        num_permutations[batch_idx] += 1\n",
    "                        new_batch_data = []\n",
    "                        for col_i in x:\n",
    "                            if col_i == 0:\n",
    "                                if len(new_batch_data) == 0:\n",
    "                                    cls_indexes_value = 0\n",
    "                                else:\n",
    "                                    cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                            new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                        new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                        cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                        logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                        ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n",
    "                        score_permutation[batch_idx].append(ood_score_temp)\n",
    "                        predict_temp = logits_temp.argmax().item()\n",
    "                        permutation_correctness[batch_idx].append(predict_temp == label_i)\n",
    "                        \n",
    "                        test_data[batch_idx].append(new_batch_data.cpu())\n",
    "                        test_logits[batch_idx].append(logits_temp.detach().cpu())\n",
    "                        test_cls_indexes[batch_idx].append(cls_indexes_value)\n",
    "                        test_embs[batch_idx].append(embs_temp.cpu())\n",
    "                        test_col_num[batch_idx].append(len(x))\n",
    "                        test_label[batch_idx].append(torch.tensor(predict_temp == label_i).long()) # indicate whether the permutation is correct or not\n",
    "                        test_class[batch_idx].append(label_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"/data/zhihao/TU/Watchog/verification\", exist_ok=True)\n",
    "torch.save({\"data\": test_data, \"logits\": test_logits, \"cls_indexes\": test_cls_indexes, \n",
    "            \"embs\": test_embs, \"col_num\": test_col_num, \"label\": test_label, \"class\": test_class}, f\"/data/zhihao/TU/Watchog/verification/{args.task}_test_data_3.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gt-semtab22-dbpedia-all0'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_veri = torch.load(\"/data/zhihao/TU/Watchog/verification/test_data.pth\")\n",
    "test_data = test_veri[\"data\"]\n",
    "test_logits = test_veri[\"logits\"]\n",
    "test_cls_indexes = test_veri[\"cls_indexes\"]\n",
    "test_embs = test_veri[\"embs\"]\n",
    "test_col_num = test_veri[\"col_num\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5288)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels = []\n",
    "for i in veri_label:\n",
    "    all_labels.extend(veri_label[i])\n",
    "all_labels = torch.tensor(all_labels).reshape(-1)\n",
    "all_labels.sum()/len(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veri_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VerificationDataset(data.Dataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            data_path: str = \"/data/zhihao/TU/Watchog/verification/veri_data.pth\",\n",
    "            max_list_length: int = 10,\n",
    "            pos_ratio : int = 0.5, # None: only control pos_ratio to be less than 0.5\n",
    "            label_padding_value: int = -1,\n",
    "            data_padding_value: int = 0,\n",
    "            ): \n",
    "        data_raw = torch.load(data_path)\n",
    "        veri_label = data_raw[\"label\"]\n",
    "        veri_data = data_raw[\"data\"]\n",
    "        veri_cls_indexes = data_raw[\"cls_indexes\"]\n",
    "        self.label_padding_value = label_padding_value\n",
    "        self.data_padding_value = data_padding_value\n",
    "        self.max_list_length = max_list_length\n",
    "        self.pos_ratio = pos_ratio\n",
    "        self.veri_label = {}\n",
    "        self.veri_data = {}\n",
    "        self.veri_cls_indexes = {}\n",
    "        i = 0\n",
    "        for veri_i in veri_label:\n",
    "            labels_i = torch.tensor(veri_label[veri_i]).reshape(-1)\n",
    "            \n",
    "            if 0 not in labels_i or 1 not in labels_i:\n",
    "                continue\n",
    "            self.veri_data[i] = veri_data[veri_i]\n",
    "            self.veri_label[i] = labels_i\n",
    "            self.veri_cls_indexes[i] = veri_cls_indexes[veri_i]\n",
    "            i += 1\n",
    "    def sample(self, labels):\n",
    "        labels = labels.tolist()  # Convert tensor to list for easier manipulation\n",
    "        positive_indices = [i for i, label in enumerate(labels) if label == 1]\n",
    "        negative_indices = [i for i, label in enumerate(labels) if label == 0]\n",
    "\n",
    "        # Determine how many positives we can sample, respecting the ratio requirement\n",
    "        max_num_positives = max_num_negatives = min(len(positive_indices), len(negative_indices), self.max_list_length // 2)\n",
    "        \n",
    "        # Randomly sample the positives and negatives\n",
    "        sampled_positives = random.sample(positive_indices, max_num_positives)\n",
    "        sampled_negatives = random.sample(negative_indices, max_num_negatives)\n",
    "\n",
    "        # Combine and shuffle the indices\n",
    "        sampled_indices = sampled_positives + sampled_negatives\n",
    "\n",
    "        return sampled_indices\n",
    "        # {\"data\": veri_data, \"label\": veri_label, \"cls_indexes\": veri_cls_indexes}\n",
    "    def __len__(self):\n",
    "        return len(self.veri_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        labels = self.veri_label[idx]\n",
    "        sampled_indices = self.sample(labels)\n",
    "        sampled_labels = torch.tensor([labels[i] for i in sampled_indices]).reshape(-1)\n",
    "        sampled_data = [self.veri_data[idx][i].reshape(-1) for i in sampled_indices]\n",
    "        sampled_cls_indexes = torch.tensor([self.veri_cls_indexes[idx][i] for i in sampled_indices], dtype=torch.long)\n",
    "        if len(sampled_indices) < self.max_list_length:\n",
    "            sampled_labels = torch.cat([sampled_labels, torch.ones(self.max_list_length - len(sampled_labels))*self.label_padding_value])\n",
    "            sampled_data.extend([torch.tensor([self.data_padding_value]) for _ in range(self.max_list_length - len(sampled_data))])\n",
    "            sampled_cls_indexes = torch.cat([sampled_cls_indexes, torch.zeros(self.max_list_length - len(sampled_cls_indexes))])\n",
    "        return {\n",
    "            \"data\": sampled_data,\n",
    "            \"label\": sampled_labels,\n",
    "            \"cls_indexes\": sampled_cls_indexes, \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VerificationBinaryDataset(data.Dataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            data_path: str = \"/data/zhihao/TU/Watchog/verification/veri_data.pth\",\n",
    "            pos_ratio = None, # clone the negative samples\n",
    "            ): \n",
    "        data_raw = torch.load(data_path)\n",
    "        veri_label = data_raw[\"label\"]\n",
    "        veri_data = data_raw[\"data\"]\n",
    "        veri_cls_indexes = data_raw[\"cls_indexes\"]\n",
    "        veri_embs = data_raw[\"embs\"]\n",
    "        veri_logits = data_raw[\"logits\"]\n",
    "        self.neg_expand = int(1/pos_ratio)-1 if pos_ratio is not None else 1\n",
    "        self.veri_label = {}\n",
    "        self.veri_data = {}\n",
    "        self.veri_embs = {}\n",
    "        self.veri_cls_indexes = {}\n",
    "        self.veri_logits = {}\n",
    "        i = 0\n",
    "        for veri_i in veri_label:\n",
    "            for veri_j in range(len(veri_label[veri_i])):\n",
    "                if veri_label[veri_i][veri_j] == 1:\n",
    "                    labels_i = torch.tensor([1]).reshape(-1)\n",
    "                    self.veri_data[i] = veri_data[veri_i][veri_j]\n",
    "                    self.veri_label[i] = labels_i\n",
    "                    self.veri_cls_indexes[i] = veri_cls_indexes[veri_i][veri_j]\n",
    "                    self.veri_embs[i] = veri_embs[veri_i][veri_j]\n",
    "                    self.veri_logits[i] = veri_logits[veri_i][veri_j]\n",
    "                    i += 1\n",
    "                else:\n",
    "                    for _ in range(self.neg_expand):\n",
    "                        labels_i = torch.tensor([0]).reshape(-1)\n",
    "                        self.veri_data[i] = veri_data[veri_i][veri_j]\n",
    "                        self.veri_label[i] = labels_i\n",
    "                        self.veri_cls_indexes[i] = veri_cls_indexes[veri_i][veri_j]\n",
    "                        self.veri_embs[i] = veri_embs[veri_i][veri_j]\n",
    "                        self.veri_logits[i] = veri_logits[veri_i][veri_j]\n",
    "                        i += 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.veri_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            # \"data\": self.veri_data[idx].reshape(-1),\n",
    "            \"embs\": self.veri_embs[idx].reshape(-1),\n",
    "            \"label\": self.veri_label[idx],\n",
    "            \"logits\": self.veri_logits[idx],\n",
    "            # \"cls_indexes\": self.veri_cls_indexes[idx], \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'veri_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mveri_dataset\u001b[49m), \u001b[38;5;28mlen\u001b[39m(veri_dataset\u001b[38;5;241m.\u001b[39mveri_data), \u001b[38;5;28mlen\u001b[39m(veri_dataset\u001b[38;5;241m.\u001b[39mveri_label), \u001b[38;5;28mlen\u001b[39m(veri_dataset\u001b[38;5;241m.\u001b[39mveri_cls_indexes))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'veri_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "print(len(veri_dataset), len(veri_dataset.veri_data), len(veri_dataset.veri_label), len(veri_dataset.veri_cls_indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1072582/3275163660.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data_raw = torch.load(data_path)\n"
     ]
    }
   ],
   "source": [
    "verit_binary_dataset = VerificationBinaryDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48583"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(verit_binary_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.nn.utils.rnn.pad_sequence(\n",
    "            [verit_binary_dataset[i][\"data\"] for i in range(10)], padding_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verit_binary_dataset[0][\"embs\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "verit_labels = []\n",
    "for i in range(len(verit_binary_dataset)):\n",
    "    verit_labels.append(verit_binary_dataset[i][\"label\"].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2191)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(verit_labels).sum()/len(verit_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(veri_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_345769/3192291341.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data_raw = torch.load(data_path)\n"
     ]
    }
   ],
   "source": [
    "veri_dataset = VerificationDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(veri_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = veri_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res[\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([352])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"data\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"label\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = []\n",
    "for i in range(len(veri_dataset)):\n",
    "    data_test.extend(veri_dataset[i][\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2500"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def veri_collate_fn(pad_token_id, binary=False):\n",
    "    '''padder for input batch'''\n",
    "    \n",
    "    def padder(samples):    \n",
    "        data = []\n",
    "        for sample in samples:\n",
    "            data.extend(sample[\"data\"])\n",
    "        data =torch.nn.utils.rnn.pad_sequence(\n",
    "            data, padding_value=pad_token_id)\n",
    "\n",
    "        label = torch.cat([sample[\"label\"] for sample in samples], dim=-1)\n",
    "        batch = {\"data\": data, \"label\": label}\n",
    "        if \"cls_indexes\" in samples[0]:\n",
    "            i = 0\n",
    "            cls_indexes = []\n",
    "            for sample in samples:\n",
    "                for value in sample[\"cls_indexes\"]:\n",
    "                    cls_indexes.append(torch.tensor([i, value]))\n",
    "                    i += 1\n",
    "            cls_indexes = torch.stack(cls_indexes, dim=0).long()\n",
    "            batch[\"cls_indexes\"] = cls_indexes\n",
    "        return batch\n",
    "    \n",
    "    def padder_binary(samples):   \n",
    "\n",
    "        label = torch.cat([sample[\"label\"] for sample in samples], dim=-1)\n",
    "        batch = {\"label\": label}\n",
    "        if  \"data\" in samples[0]:\n",
    "            data = torch.nn.utils.rnn.pad_sequence(\n",
    "                [sample[\"data\"] for sample in samples], padding_value=pad_token_id)\n",
    "            batch[\"data\"] = data\n",
    "        if \"cls_indexes\" in samples[0]:\n",
    "            i = 0\n",
    "            cls_indexes = []\n",
    "            for sample in samples:\n",
    "                value =  sample[\"cls_indexes\"]\n",
    "                cls_indexes.append(torch.tensor([i, value]))\n",
    "                i += 1\n",
    "            cls_indexes = torch.stack(cls_indexes, dim=0).long()\n",
    "            batch[\"cls_indexes\"] = cls_indexes\n",
    "        if \"embs\" in samples[0]:\n",
    "            embs = torch.stack([sample[\"embs\"] for sample in samples], dim=0)\n",
    "            batch[\"embs\"] = embs\n",
    "        if \"logits\" in samples[0]:\n",
    "            logits = torch.stack([sample[\"logits\"] for sample in samples], dim=0)\n",
    "            batch[\"logits\"] = logits\n",
    "        return batch\n",
    "    if binary:\n",
    "        return padder_binary\n",
    "    else:\n",
    "        return padder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'veri_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m veri_padder \u001b[38;5;241m=\u001b[39m veri_collate_fn(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      2\u001b[0m veri_dataloader \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mDataLoader(\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mveri_dataset\u001b[49m, batch_size\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, collate_fn\u001b[38;5;241m=\u001b[39mveri_padder\n\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m veri_dataloader:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'veri_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "veri_padder = veri_collate_fn(0)\n",
    "veri_dataloader = data.DataLoader(\n",
    "    veri_dataset, batch_size=args.batch_size, shuffle=True, num_workers=4, collate_fn=veri_padder\n",
    ")\n",
    "for batch in veri_dataloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "veri_binary_padder = veri_collate_fn(0, binary=True)\n",
    "veri_binary_dataloader = data.DataLoader(\n",
    "    verit_binary_dataset, batch_size=args.batch_size, shuffle=True, num_workers=4, collate_fn=veri_binary_padder\n",
    ")\n",
    "for batch_idx, batch in enumerate(veri_binary_dataloader):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 768])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"embs\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 101])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"logits\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"label\"].to(device).squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model = model.to(device)\n",
    "verifier.train()\n",
    "verifier = verifier.to(device)\n",
    "pos_ratio = 0.1\n",
    "pos_weight = torch.tensor([(1-pos_ratio)/pos_ratio]).to(device)\n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "for batch_idx, batch in enumerate(veri_binary_dataloader ):\n",
    "    cls_indexes = batch[\"cls_indexes\"].to(device)\n",
    "    input_data = batch[\"data\"].T.to(device)\n",
    "    logits, embs = model(input_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "    scores = verifier(embs).squeeze()\n",
    "    loss = loss_fn(scores, batch[\"label\"].to(device).squeeze().float())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " batch[\"label\"].to(device).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([378, 3])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"data\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([365, 30])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"data\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"label\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 2])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"cls_indexes\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "verifier = Verifier(norm=\"batch_norm\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3640352/19018059.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  veri_state_dict = torch.load(\"/data/zhihao/TU/Watchog/outputs/gt-semtab22-dbpedia-all0/bert-base-uncased-fromscratch-semi1-Binary-Reweight-lr@0.0001-warmup@0.0-dp@0.0-norm@batch_norm-pos@0.5-poolv0-unlabeled8-randFalse-bs64-ml128-ne200-do0.0_verifier_binary_best_f1_macro.pt\")\n"
     ]
    }
   ],
   "source": [
    "veri_state_dict = torch.load(\"/data/zhihao/TU/Watchog/outputs/gt-semtab22-dbpedia-all0/bert-base-uncased-fromscratch-semi1-Binary-Reweight-lr@0.0001-warmup@0.0-dp@0.0-norm@batch_norm-pos@0.5-poolv0-unlabeled8-randFalse-bs64-ml128-ne200-do0.0_verifier_binary_best_f1_macro.pt\")\n",
    "# veri_state_dict = torch.load(\"/data/zhihao/TU/Watchog/outputs/gt-semtab22-dbpedia-all0/bert-base-uncased-fromscratch-semi1-Binary-Reweight-lr@0.01-pos@0.2-poolv0-unlabeled8-randFalse-bs64-ml128-ne200-do0.1_verifierbinary_best_f1_micro.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verifier.load_state_dict(veri_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Verifier(\n",
       "  (ffn): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (1): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): SiLU()\n",
       "    (3): Dropout(p=0.0, inplace=False)\n",
       "    (4): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (5): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): SiLU()\n",
       "    (7): Dropout(p=0.0, inplace=False)\n",
       "    (8): Linear(in_features=768, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verifier.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhihao/jupyterprojects/jupyter/lib/python3.8/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(verifier.parameters(), lr=args.lr, eps=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.to(device)\n",
    "verifier.train()\n",
    "tr_loss = 0.0\n",
    "for batch_idx, batch in enumerate(veri_dataloader):\n",
    "    cls_indexes = batch[\"cls_indexes\"].to(device)\n",
    "    input_data = batch[\"data\"].T.to(device)\n",
    "    logits, embs = model(input_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "    scores = verifier(embs)\n",
    "    loss = listMLE(scores.reshape(args.batch_size, -1), batch[\"label\"].to(device).reshape(args.batch_size, -1))\n",
    "\n",
    "    accelerator.backward(loss)\n",
    "    # loss.backward()\n",
    "    tr_loss += loss.cpu().detach().item()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def listMLE(y_pred, y_true, eps=1e-10, padded_value_indicator=-1):\n",
    "    \"\"\"\n",
    "    ListMLE loss introduced in \"Listwise Approach to Learning to Rank - Theory and Algorithm\".\n",
    "    :param y_pred: predictions from the model, shape [batch_size, slate_length]\n",
    "    :param y_true: ground truth labels, shape [batch_size, slate_length]\n",
    "    :param eps: epsilon value, used for numerical stability\n",
    "    :param padded_value_indicator: an indicator of the y_true index containing a padded item, e.g. -1\n",
    "    :return: loss value, a torch.Tensor\n",
    "    \"\"\"\n",
    "    # shuffle for randomised tie resolution\n",
    "    random_indices = torch.randperm(y_pred.shape[-1])\n",
    "    y_pred_shuffled = y_pred[:, random_indices]\n",
    "    y_true_shuffled = y_true[:, random_indices]\n",
    "\n",
    "    y_true_sorted, indices = y_true_shuffled.sort(descending=True, dim=-1)\n",
    "\n",
    "    mask = y_true_sorted == padded_value_indicator\n",
    "\n",
    "    preds_sorted_by_true = torch.gather(y_pred_shuffled, dim=1, index=indices)\n",
    "    preds_sorted_by_true[mask] = float(\"-inf\")\n",
    "\n",
    "    max_pred_values, _ = preds_sorted_by_true.max(dim=1, keepdim=True)\n",
    "\n",
    "    preds_sorted_by_true_minus_max = preds_sorted_by_true - max_pred_values\n",
    "\n",
    "    cumsums = torch.cumsum(preds_sorted_by_true_minus_max.exp().flip(dims=[1]), dim=1).flip(dims=[1])\n",
    "\n",
    "    observation_loss = torch.log(cumsums + eps) - preds_sorted_by_true_minus_max\n",
    "\n",
    "    observation_loss[mask] = 0.0\n",
    "\n",
    "    return torch.mean(torch.sum(observation_loss, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.9761, device='cuda:2', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "\n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "verifier.eval()\n",
    "verifier = verifier.to(device)\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "init_scores = []\n",
    "init_correctness = []\n",
    "final_scores = []\n",
    "final_correctness = []\n",
    "\n",
    "for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    scores_init = verifier(embs)\n",
    "    max_score = -float(\"inf\")\n",
    "    if 1 in target_col_mask:\n",
    "        init_scores.append(scores_init.item())\n",
    "        init_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "        init_permutation_i = get_permutation(target_col_mask)\n",
    "        col_idx_set = target_col_mask.unique().tolist()\n",
    "        early_stop = False\n",
    "        assert -1 not in col_idx_set\n",
    "        for r in range(len(init_permutation_i), max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "            for x in itertools.combinations(init_permutation_i, r):\n",
    "                if 0 not in x:\n",
    "                    continue\n",
    "                new_batch_data = []\n",
    "                for col_i in x:\n",
    "                    if col_i == 0:\n",
    "                        if len(new_batch_data) == 0:\n",
    "                            cls_indexes_value = 0\n",
    "                        else:\n",
    "                            cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                    new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                if 0 not in x:\n",
    "                    cls_indexes_value = 0\n",
    "                new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                logits_temp, embs = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                scores_temp = verifier(embs).item()\n",
    "                predict_temp = logits_temp.argmax().item()\n",
    "                    # if len(x) == 1 and 0 in x:\n",
    "                    #     predict_target = predict_temp\n",
    "                    #     msp_target = msp_temp\n",
    "                    # # print(x, msp_temp, predict_temp)\n",
    "                    # if 0 not in x and msp_temp > debias_threshold and (predict_temp != predict_target):\n",
    "                    #     debias_classes.append(predict_temp)\n",
    "                    #     continue\n",
    "                if scores_temp > max_score:\n",
    "                    max_score = scores_temp\n",
    "                    logits = logits_temp.clone()\n",
    "        final_scores.append(max_score)\n",
    "        final_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "    labels_test.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "labels_test = torch.cat(labels_test, dim=0)\n",
    "logits_test = torch.stack(logits_test, dim=0)\n",
    "preds_test = torch.argmax(logits_test, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_correctness = torch.tensor(init_correctness)\n",
    "final_correctness = torch.tensor(final_correctness)\n",
    "init_scores = torch.tensor(init_scores)\n",
    "final_scores = torch.tensor(final_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(637)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(init_correctness | final_correctness).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(init_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(F.sigmoid(init_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6686)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.sigmoid(init_scores)[init_correctness].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5715)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.sigmoid(init_scores)[~init_correctness].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7619)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.sigmoid(final_scores)[init_correctness].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7984)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.sigmoid(final_scores)[~init_correctness].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(final_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(F.sigmoid(final_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2509825123311368"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_macro_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Threshold: 0.6****************************\n",
      "Init\n",
      "374 637 0.5871271585557299\n",
      "206 447 0.4608501118568233\n",
      "MSP\n",
      "366 637 0.5745682888540031\n",
      "209 447 0.46756152125279643\n",
      "MSP & Init\n",
      "343\n",
      "397 637 0.6232339089481946\n",
      "240 447 0.5369127516778524\n",
      "*********************Threshold: 0.7****************************\n",
      "Init\n",
      "250 463 0.5399568034557235\n",
      "330 621 0.5314009661835749\n",
      "MSP\n",
      "250 463 0.5399568034557235\n",
      "325 621 0.5233494363929146\n",
      "MSP & Init\n",
      "229\n",
      "271 463 0.5853131749460043\n",
      "366 621 0.5893719806763285\n",
      "*********************Threshold: 0.8****************************\n",
      "Init\n",
      "184 339 0.5427728613569321\n",
      "396 745 0.5315436241610738\n",
      "MSP\n",
      "178 339 0.5250737463126843\n",
      "397 745 0.5328859060402684\n",
      "MSP & Init\n",
      "170\n",
      "192 339 0.5663716814159292\n",
      "445 745 0.5973154362416108\n",
      "*********************Threshold: 0.9****************************\n",
      "Init\n",
      "130 209 0.6220095693779905\n",
      "450 875 0.5142857142857142\n",
      "MSP\n",
      "126 209 0.6028708133971292\n",
      "449 875 0.5131428571428571\n",
      "MSP & Init\n",
      "122\n",
      "134 209 0.6411483253588517\n",
      "503 875 0.5748571428571428\n"
     ]
    }
   ],
   "source": [
    "correct_init_mask = init_correctness\n",
    "correct_msp_mask = final_correctness\n",
    "for threshold in [0.6, 0.7, 0.8, 0.9]:\n",
    "    uncertain_init_mask = F.sigmoid(init_scores) < threshold\n",
    "    condition_mask = ~uncertain_init_mask\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    print(\"Init\")\n",
    "    # init prediction\n",
    "    print((condition_mask&correct_init_mask).sum().item(), \n",
    "        (condition_mask).sum().item(), \n",
    "        (condition_mask&correct_init_mask).sum().item()/(condition_mask).sum().item())\n",
    "    # init prediction\n",
    "    print((~condition_mask&correct_init_mask).sum().item(), \n",
    "        (~condition_mask).sum().item(), \n",
    "       (~condition_mask&correct_init_mask).sum().item()/(~condition_mask).sum().item())\n",
    "    print(\"MSP\")\n",
    "    # msp prediction\n",
    "    print((condition_mask&correct_msp_mask).sum().item(), \n",
    "        (condition_mask).sum().item(), \n",
    "        (condition_mask&correct_msp_mask).sum().item()/(condition_mask).sum().item())\n",
    "    # msp prediction\n",
    "    print((~condition_mask&correct_msp_mask).sum().item(), \n",
    "        (~condition_mask).sum().item(), \n",
    "        (~condition_mask&correct_msp_mask).sum().item()/(~condition_mask).sum().item())\n",
    "    print(\"MSP & Init\")\n",
    "    print(((condition_mask&correct_init_mask)&(condition_mask&correct_msp_mask)).sum().item())\n",
    "    # print(((~(init_target_mask&(~uncertain_init_mask & ~uncertain_target_mask))& correct_msp_mask)&(~(init_target_mask&(~uncertain_init_mask & ~uncertain_target_mask))& correct_init_mask)).sum().item())\n",
    "    print(((condition_mask&correct_init_mask)|(condition_mask&correct_msp_mask)).sum().item(),\n",
    "          (condition_mask).sum().item(), \n",
    "          ((condition_mask&correct_init_mask)|(condition_mask&correct_msp_mask)).sum().item()/(condition_mask).sum().item())\n",
    "    print(((~condition_mask&correct_init_mask)|(~condition_mask&correct_msp_mask)).sum().item(),\n",
    "          (~condition_mask).sum().item(), \n",
    "          ((~condition_mask&correct_init_mask)|(~condition_mask&correct_msp_mask)).sum().item()/(~condition_mask).sum().item())\n",
    "    # print(\"Permutation\")\n",
    "    # print((condition_mask&correct_permutation_mask).sum().item(), \n",
    "    #     (condition_mask).sum().item(), \n",
    "    #     (condition_mask&correct_permutation_mask).sum().item()/(condition_mask).sum().item())\n",
    "    # print((~condition_mask&correct_permutation_mask).sum().item(), \n",
    "    #      (~condition_mask).sum().item(), \n",
    "    #     (~condition_mask&correct_permutation_mask).sum().item()/(~condition_mask).sum().item())\n",
    "    # print(\"Permutation Confident\")\n",
    "    # print((condition_mask&correct_permutation_confident_mask).sum().item(), \n",
    "    #     (condition_mask).sum().item(), \n",
    "    #     (condition_mask&correct_permutation_confident_mask).sum().item()/(condition_mask).sum().item())\n",
    "    # print((~condition_mask&correct_permutation_confident_mask).sum().item(),\n",
    "    #         (~condition_mask).sum().item(), \n",
    "    #         (~condition_mask&correct_permutation_confident_mask).sum().item()/(~condition_mask).sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_micro_f1=0.5503, ts_macro_f1=0.3178\n",
      "ts_micro_f1=0.5493, ts_macro_f1=0.3178\n",
      "ts_micro_f1=1.0000, ts_macro_f1=1.0000\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(valid_dataloader_iter):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    labels_test.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "    num_cols.append(batch[\"target_col_mask\"].max().item())\n",
    "    ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "labels_test = torch.cat(labels_test, dim=0)\n",
    "logits_test = torch.stack(logits_test, dim=0)\n",
    "preds_test = torch.argmax(logits_test, dim=1)\n",
    "num_cols = torch.tensor(num_cols)\n",
    "ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "mask = num_cols > 0\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach()[mask].numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach()[~mask].numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = veri_embs[batch_idx][0].reshape(1,-1).to(device)\n",
    "scores_init = verifier(embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veri_label[batch_idx][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_micro_f1=0.6621, ts_macro_f1=0.4545\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "\n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "verifier.eval()\n",
    "verifier = verifier.to(device)\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "init_scores = []\n",
    "init_correctness = []\n",
    "final_scores = []\n",
    "final_correctness = []\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in enumerate(valid_dataloader_iter):\n",
    "        embs = veri_embs[batch_idx][0].reshape(1,-1).to(device)\n",
    "        logits = veri_logits[batch_idx][0].reshape(-1).to(device)\n",
    "        scores_init = verifier(embs)\n",
    "        max_score = -float(\"inf\")\n",
    "\n",
    "        init_scores.append(scores_init.item())\n",
    "        init_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "        init_permutation_i = get_permutation(target_col_mask)\n",
    "        col_idx_set = target_col_mask.unique().tolist()\n",
    "        early_stop = False\n",
    "        for i in range(len(veri_embs[batch_idx])):\n",
    "            logits_temp = veri_logits[batch_idx][i].reshape(-1).to(device)\n",
    "            embs_temp = veri_embs[batch_idx][i].reshape(1,-1).to(device)\n",
    "            scores_temp = verifier(embs_temp).item()\n",
    "            predict_temp = logits_temp.argmax().item()\n",
    "            # if len(x) == 1 and 0 in x:\n",
    "            #     predict_target = predict_temp\n",
    "            #     msp_target = msp_temp\n",
    "            # # print(x, msp_temp, predict_temp)\n",
    "            # if 0 not in x and msp_temp > debias_threshold and (predict_temp != predict_target):\n",
    "            #     debias_classes.append(predict_temp)\n",
    "            #     continue\n",
    "            if scores_temp > max_score:\n",
    "                max_score = scores_temp\n",
    "                logits = logits_temp.clone()\n",
    "        final_scores.append(max_score)\n",
    "        final_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "        labels_test.append(batch[\"label\"].cpu())\n",
    "        logits_test.append(logits.detach().cpu())\n",
    "    labels_test = torch.cat(labels_test, dim=0)\n",
    "    logits_test = torch.stack(logits_test, dim=0)\n",
    "    preds_test = torch.argmax(logits_test, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_micro_f1=0.5576, ts_macro_f1=0.2834\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "\n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "verifier.eval()\n",
    "verifier = verifier.to(device)\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "init_scores = []\n",
    "init_correctness = []\n",
    "final_scores = []\n",
    "final_correctness = []\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "        embs = test_embs[batch_idx][0].reshape(1,-1).to(device)\n",
    "        logits = test_logits[batch_idx][0].reshape(-1).to(device)\n",
    "        scores_init = verifier(embs)\n",
    "        max_score = -float(\"inf\")\n",
    "\n",
    "        init_scores.append(scores_init.item())\n",
    "        init_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "        init_permutation_i = get_permutation(target_col_mask)\n",
    "        col_idx_set = target_col_mask.unique().tolist()\n",
    "        early_stop = False\n",
    "        for i in range(len(test_embs[batch_idx])):\n",
    "            logits_temp = test_logits[batch_idx][i].reshape(-1).to(device)\n",
    "            embs_temp = test_embs[batch_idx][i].reshape(1,-1).to(device)\n",
    "            scores_temp = verifier(embs_temp).item()\n",
    "            predict_temp = logits_temp.argmax().item()\n",
    "            # if len(x) == 1 and 0 in x:\n",
    "            #     predict_target = predict_temp\n",
    "            #     msp_target = msp_temp\n",
    "            # # print(x, msp_temp, predict_temp)\n",
    "            # if 0 not in x and msp_temp > debias_threshold and (predict_temp != predict_target):\n",
    "            #     debias_classes.append(predict_temp)\n",
    "            #     continue\n",
    "            if scores_temp > max_score:\n",
    "                max_score = scores_temp\n",
    "                logits = logits_temp.clone()\n",
    "        final_scores.append(max_score)\n",
    "        final_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "        labels_test.append(batch[\"label\"].cpu())\n",
    "        logits_test.append(logits.detach().cpu())\n",
    "    labels_test = torch.cat(labels_test, dim=0)\n",
    "    logits_test = torch.stack(logits_test, dim=0)\n",
    "    preds_test = torch.argmax(logits_test, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "ts_f1_full = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=None)\n",
    "# full_f1_init\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03246206, -0.04829908,  0.086727  ,  0.04106206, -0.01851852,\n",
       "       -0.03611111, -0.05656566,  0.02      , -0.18245614, -0.04158004,\n",
       "        0.10636443,  0.0872211 , -0.01515152,  0.24728261,  0.00579151,\n",
       "        0.02988506,  0.07655502,  0.03333333,  0.07142857,  0.07692308,\n",
       "        0.07179487,  0.03259259,  0.03428571,  0.1122807 ,  0.160401  ,\n",
       "       -0.02564103,  0.16190476,  0.        ,  0.01098901,  0.1       ,\n",
       "        0.        ,  0.        ,  0.        , -0.22794118, -0.14444444,\n",
       "        0.07142857, -0.26666667,  0.02222222,  0.08333333, -0.2       ,\n",
       "        0.        ,  0.        , -0.02197802,  0.14141414,  0.        ,\n",
       "        0.        ,  0.        ,  0.4       ,  0.23809524,  0.0952381 ,\n",
       "        0.28571429,  0.66666667,  0.16666667,  0.03571429, -0.66666667,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.06060606,  0.        ,\n",
       "        0.        ,  0.        ,  0.16666667, -0.33333333,  0.16666667,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "       -0.06349206, -0.33333333,  0.        , -0.28571429,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.06349206,\n",
       "        0.        ,  0.        , -0.5       ,  0.        ,  0.        ,\n",
       "        0.        ,  0.16666667,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_f1_full - full_f1_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Threshold: 0.5****************************\n",
      "Init\n",
      "449 617 0.7277147487844409\n",
      "132 468 0.28205128205128205\n",
      "MSP\n",
      "451 617 0.7309562398703403\n",
      "155 468 0.3311965811965812\n",
      "MSP & Init\n",
      "441\n",
      "459 617 0.7439222042139384\n",
      "188 468 0.4017094017094017\n",
      "*********************Threshold: 0.6****************************\n",
      "Init\n",
      "433 586 0.7389078498293515\n",
      "148 499 0.2965931863727455\n",
      "MSP\n",
      "432 586 0.7372013651877133\n",
      "174 499 0.3486973947895792\n",
      "MSP & Init\n",
      "425\n",
      "440 586 0.7508532423208191\n",
      "207 499 0.4148296593186373\n",
      "*********************Threshold: 0.7****************************\n",
      "Init\n",
      "413 555 0.7441441441441441\n",
      "168 530 0.3169811320754717\n",
      "MSP\n",
      "413 555 0.7441441441441441\n",
      "193 530 0.3641509433962264\n",
      "MSP & Init\n",
      "406\n",
      "420 555 0.7567567567567568\n",
      "227 530 0.42830188679245285\n",
      "*********************Threshold: 0.8****************************\n",
      "Init\n",
      "393 524 0.75\n",
      "188 561 0.33511586452762926\n",
      "MSP\n",
      "393 524 0.75\n",
      "213 561 0.37967914438502676\n",
      "MSP & Init\n",
      "387\n",
      "399 524 0.7614503816793893\n",
      "248 561 0.44206773618538325\n",
      "*********************Threshold: 0.9****************************\n",
      "Init\n",
      "351 450 0.78\n",
      "230 635 0.36220472440944884\n",
      "MSP\n",
      "353 450 0.7844444444444445\n",
      "253 635 0.3984251968503937\n",
      "MSP & Init\n",
      "348\n",
      "356 450 0.7911111111111111\n",
      "291 635 0.4582677165354331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3640352/4058371166.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  init_scores = torch.tensor(init_scores)\n",
      "/tmp/ipykernel_3640352/4058371166.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  final_scores = torch.tensor(final_scores)\n"
     ]
    }
   ],
   "source": [
    "correct_init_mask = torch.tensor(init_correctness)\n",
    "correct_msp_mask = torch.tensor(final_correctness)\n",
    "init_scores = torch.tensor(init_scores)\n",
    "final_scores = torch.tensor(final_scores)\n",
    "for threshold in [0.5, 0.6, 0.7, 0.8, 0.9]:\n",
    "    uncertain_init_mask = F.sigmoid(init_scores) < threshold\n",
    "    condition_mask = ~uncertain_init_mask\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    print(\"Init\")\n",
    "    # init prediction\n",
    "    print((condition_mask&correct_init_mask).sum().item(), \n",
    "        (condition_mask).sum().item(), \n",
    "        (condition_mask&correct_init_mask).sum().item()/(condition_mask).sum().item())\n",
    "    # init prediction\n",
    "    print((~condition_mask&correct_init_mask).sum().item(), \n",
    "        (~condition_mask).sum().item(), \n",
    "       (~condition_mask&correct_init_mask).sum().item()/(~condition_mask).sum().item())\n",
    "    print(\"MSP\")\n",
    "    # msp prediction\n",
    "    print((condition_mask&correct_msp_mask).sum().item(), \n",
    "        (condition_mask).sum().item(), \n",
    "        (condition_mask&correct_msp_mask).sum().item()/(condition_mask).sum().item())\n",
    "    # msp prediction\n",
    "    print((~condition_mask&correct_msp_mask).sum().item(), \n",
    "        (~condition_mask).sum().item(), \n",
    "        (~condition_mask&correct_msp_mask).sum().item()/(~condition_mask).sum().item())\n",
    "    print(\"MSP & Init\")\n",
    "    print(((condition_mask&correct_init_mask)&(condition_mask&correct_msp_mask)).sum().item())\n",
    "    # print(((~(init_target_mask&(~uncertain_init_mask & ~uncertain_target_mask))& correct_msp_mask)&(~(init_target_mask&(~uncertain_init_mask & ~uncertain_target_mask))& correct_init_mask)).sum().item())\n",
    "    print(((condition_mask&correct_init_mask)|(condition_mask&correct_msp_mask)).sum().item(),\n",
    "          (condition_mask).sum().item(), \n",
    "          ((condition_mask&correct_init_mask)|(condition_mask&correct_msp_mask)).sum().item()/(condition_mask).sum().item())\n",
    "    print(((~condition_mask&correct_init_mask)|(~condition_mask&correct_msp_mask)).sum().item(),\n",
    "          (~condition_mask).sum().item(), \n",
    "          ((~condition_mask&correct_init_mask)|(~condition_mask&correct_msp_mask)).sum().item()/(~condition_mask).sum().item())\n",
    "    # print(\"Permutation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# table search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list_1 = [\n",
    "    \"Name: Philip Duffy; Jeremy Oppenheim; Mark Sedwill;\",\n",
    "    \"Mode of Travel: Air; Taxi; Air;\",\n",
    "    \"Purpose: Regional Meeting; Exchange Visit; Evening Meal;\",\n",
    "    \"Destination: London; Ottawa; Bristol;\",\n",
    "    \"Day: 10; 30; 02;\",\n",
    "    \"Month: April; July; September;\",\n",
    "    \"Year: 2019; 2019; 2019;\",\n",
    "    \"Expense: 189.06; 8.08; 50.00;\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cur_maxlen = min(max_length, 512 // len(column_list_1) - 1)\n",
    "\n",
    "# print(tokenizer.cls_token)\n",
    "# print(group_df[\"data\"])\n",
    "token_ids_list = [tokenizer.encode(\n",
    "                tokenizer.cls_token + \" \" + str(x), add_special_tokens=False, max_length=cur_maxlen, truncation=True) for x in column_list_1]\n",
    "token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                    token_ids_list)).to(device)\n",
    "cls_index_list = [0] + np.cumsum(\n",
    "    np.array([len(x) for x in token_ids_list])).tolist()[:-1]\n",
    "cls_indexes = torch.LongTensor(cls_index_list).to(device).reshape(-1, 1)\n",
    "cls_indexes = torch.hstack([torch.zeros_like(cls_indexes), cls_indexes])\n",
    "logits, embs_1 = model(token_ids.reshape(1, -1), cls_indexes=cls_indexes, get_enc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "cur_maxlen = min(max_length, 512 // len(column_list_1) - 1)\n",
    "\n",
    "# print(tokenizer.cls_token)\n",
    "# print(group_df[\"data\"])\n",
    "token_ids_list = [tokenizer.encode(\n",
    "                tokenizer.cls_token + \" \" + str(x), add_special_tokens=False, max_length=cur_maxlen, truncation=True) for x in column_list_1]\n",
    "token_ids = nn.utils.rnn.pad_sequence(\n",
    "      [torch.tensor(x) for x in token_ids_list], padding_value=tokenizer.pad_token_id).to(device)\n",
    "cls_indexes = torch.nonzero(\n",
    "                token_ids == tokenizer.cls_token_id)\n",
    "logits, embs_1_seperate = model(token_ids, cls_indexes=cls_indexes, get_enc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list_2 = [\n",
    "    \"Name: Clark; Gyimah; Harrington;\",\n",
    "    \"Date: 23/07; 03/09; 05/08;\",\n",
    "    \"Destination: France; Belgium; China;\",\n",
    "    \"Purpose: Discuss EU; Build Relations; Discuss Productivity;\",\n",
    "]\n",
    "cur_maxlen = min(max_length, 512 // len(column_list_2) - 1)\n",
    "\n",
    "# print(tokenizer.cls_token)\n",
    "# print(group_df[\"data\"])\n",
    "token_ids_list = [tokenizer.encode(\n",
    "                tokenizer.cls_token + \" \" + str(x), add_special_tokens=False, max_length=cur_maxlen, truncation=True) \n",
    "                  for x in column_list_2]\n",
    "token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                    token_ids_list)).to(device)\n",
    "cls_index_list = [0] + np.cumsum(\n",
    "    np.array([len(x) for x in token_ids_list])).tolist()[:-1]\n",
    "cls_indexes = torch.LongTensor(cls_index_list).to(device).reshape(-1, 1)\n",
    "cls_indexes = torch.hstack([torch.zeros_like(cls_indexes), cls_indexes])\n",
    "logits, embs_2 = model(token_ids.reshape(1, -1), cls_indexes=cls_indexes, get_enc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertSdpaSelfAttention is used but `torch.nn.functional.scaled_dot_product_attention` does not support non-absolute `position_embedding_type` or `output_attentions=True` or `head_mask`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n"
     ]
    }
   ],
   "source": [
    "token_ids = token_ids.reshape(1, -1)\n",
    "attention_mask = token_ids != 0\n",
    "res = model.bert(token_ids, attention_mask=attention_mask, return_dict=True, output_attentions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res['attentions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 47, 47])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['attentions'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([47, 47])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['attentions'][0].squeeze().mean(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1229, 0.2070, 0.1410, 0.1387],\n",
       "        [0.0706, 0.2805, 0.1124, 0.0850],\n",
       "        [0.0726, 0.1788, 0.2063, 0.1059],\n",
       "        [0.0787, 0.1273, 0.1170, 0.2293]], device='cuda:0',\n",
       "       grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['attentions'][0].squeeze().mean(0)[cls_mask][:, cls_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0862, 0.1984, 0.1442, 0.1397], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.1911, 0.1100, 0.1367, 0.1355], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.3175, 0.0678, 0.1071, 0.0799], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.2838, 0.0439, 0.0646, 0.0359], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.0532, 0.0339, 0.0359, 0.0215], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.0197, 0.0310, 0.0400, 0.0251], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.0175, 0.0553, 0.0463, 0.0215], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.0207, 0.0101, 0.0224, 0.0223], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.0221, 0.0504, 0.0575, 0.0379], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.0858, 0.0916, 0.1262, 0.0552], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.0429, 0.0663, 0.1021, 0.0942], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.0207, 0.0475, 0.0998, 0.0851], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "*********************************************\n",
      "tensor([0.0968, 0.0672, 0.0819, 0.0628], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "cls_mask = (token_ids==tokenizer.cls_token_id).reshape(-1)\n",
    "acc_attention = []\n",
    "for i in range(len(res['attentions'])):\n",
    "    attn_i = res['attentions'][i].squeeze().mean(0)[cls_mask][:, cls_mask].mean(0)\n",
    "    acc_attention.append(attn_i)\n",
    "    print(attn_i)\n",
    "acc_attention = torch.stack(acc_attention, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0207, 0.0475, 0.0998, 0.0851], device='cuda:0',\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([0.0009, 0.0032, 0.0102, 0.0080], device='cuda:0',\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([7.6240e-05, 2.8848e-04, 1.2860e-03, 4.4200e-04], device='cuda:0',\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([1.6872e-06, 1.4552e-05, 7.4002e-05, 1.6757e-05], device='cuda:0',\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([3.4952e-08, 1.4639e-07, 1.6596e-06, 3.7438e-07], device='cuda:0',\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([6.1142e-10, 8.0929e-09, 7.6920e-08, 8.0513e-09], device='cuda:0',\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([1.2015e-11, 2.5077e-10, 3.0805e-09, 2.0201e-10], device='cuda:0',\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([6.3881e-13, 8.5117e-12, 1.1060e-10, 4.3394e-12], device='cuda:0',\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([1.8127e-13, 3.7366e-13, 7.1448e-12, 1.5571e-13], device='cuda:0',\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([5.7560e-14, 2.5345e-14, 7.6492e-13, 1.2436e-14], device='cuda:0',\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([1.1001e-14, 2.7890e-15, 1.0458e-13, 1.6845e-15], device='cuda:0',\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([9.4820e-16, 5.5333e-16, 1.5076e-14, 2.3538e-16], device='cuda:0',\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "cls_mask = (token_ids==tokenizer.cls_token_id).reshape(-1)\n",
    "acc_attention = torch.ones_like(res['attentions'][0].squeeze().mean(0)[cls_mask][:, cls_mask].mean(0))\n",
    "for i in range(len(res['attentions'])-1, -1, -1):\n",
    "    attn_i = res['attentions'][i].squeeze().mean(0)[cls_mask][:, cls_mask].mean(0)\n",
    "    acc_attention = acc_attention * attn_i\n",
    "    print(acc_attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0555, 0.1283, 0.0926, 0.0824], device='cuda:0',\n",
       "       grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['attentions'][0].squeeze().mean(0)[cls_mask][:, cls_mask].fill_diagonal_(0).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "cur_maxlen = min(max_length, 512 // len(column_list_2) - 1)\n",
    "\n",
    "# print(tokenizer.cls_token)\n",
    "# print(group_df[\"data\"])\n",
    "token_ids_list = [tokenizer.encode(\n",
    "                tokenizer.cls_token + \" \" + str(x), add_special_tokens=False, max_length=cur_maxlen, truncation=True) \n",
    "                  for x in column_list_2]\n",
    "token_ids = nn.utils.rnn.pad_sequence(\n",
    "      [torch.tensor(x) for x in token_ids_list], padding_value=tokenizer.pad_token_id).to(device)\n",
    "cls_indexes = torch.nonzero(\n",
    "                token_ids == tokenizer.cls_token_id)\n",
    "logits, embs_2_seperate = model(token_ids, cls_indexes=cls_indexes, get_enc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list_3 = [\n",
    "    'Bird Name: Pine Siskin; American Robin; Northern Flicker;',\n",
    "    'Scientific Name: Carduelis Pinus; Turdus migratorius; Colaptes auratus;',\n",
    "    'Date: 2019; 2019; 2019;',\n",
    "    'Location: Ottawa; Ottawa; London;'\n",
    "]\n",
    "\n",
    "cur_maxlen = min(max_length, 512 // len(column_list_3) - 1)\n",
    "\n",
    "# print(tokenizer.cls_token)\n",
    "# print(group_df[\"data\"])\n",
    "token_ids_list = [tokenizer.encode(\n",
    "                tokenizer.cls_token + \" \" + str(x), add_special_tokens=False, max_length=cur_maxlen, truncation=True) \n",
    "                  for x in column_list_3]\n",
    "token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                    token_ids_list)).to(device)\n",
    "cls_index_list = [0] + np.cumsum(\n",
    "    np.array([len(x) for x in token_ids_list])).tolist()[:-1]\n",
    "cls_indexes = torch.LongTensor(cls_index_list).to(device).reshape(-1, 1)\n",
    "cls_indexes = torch.hstack([torch.zeros_like(cls_indexes), cls_indexes])\n",
    "logits, embs_3 = model(token_ids.reshape(1, -1), cls_indexes=cls_indexes, get_enc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "cur_maxlen = min(max_length, 512 // len(column_list_3) - 1)\n",
    "\n",
    "# print(tokenizer.cls_token)\n",
    "# print(group_df[\"data\"])\n",
    "token_ids_list = [tokenizer.encode(\n",
    "                tokenizer.cls_token + \" \" + str(x), add_special_tokens=False, max_length=cur_maxlen, truncation=True) \n",
    "                  for x in column_list_3]\n",
    "token_ids = nn.utils.rnn.pad_sequence(\n",
    "      [torch.tensor(x) for x in token_ids_list], padding_value=tokenizer.pad_token_id).to(device)\n",
    "cls_indexes = torch.nonzero(\n",
    "                token_ids == tokenizer.cls_token_id)\n",
    "logits, embs_3_seperate = model(token_ids, cls_indexes=cls_indexes, get_enc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 768])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.8207278 ,  0.19450662,  0.20627114,  0.27426058],\n",
       "       [ 0.3452878 ,  0.23242974,  0.5336273 ,  0.64597607],\n",
       "       [ 0.33870924,  0.39381886,  0.5873476 ,  0.6411325 ],\n",
       "       [ 0.34317726,  0.29647005,  0.68273383,  0.58981204],\n",
       "       [ 0.12590188,  0.57557684,  0.12846455,  0.02838844],\n",
       "       [ 0.08469278,  0.53540766,  0.01483871, -0.0364889 ],\n",
       "       [ 0.11339067,  0.5485551 , -0.00187877, -0.03961209],\n",
       "       [ 0.16596259,  0.13950422,  0.3106986 ,  0.34296668]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_similarity(embs_1.detach().cpu().numpy(), embs_2.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8207278  0.57557684 0.68273383 0.64597607]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.7250144"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(cosine_similarity(embs_1.detach().cpu().numpy(), embs_2.detach().cpu().numpy()).max(0))\n",
    "cosine_similarity(embs_1.detach().cpu().numpy(), embs_2.detach().cpu().numpy()).max(0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96244603 0.963094   0.96277654 0.9627989 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.8511155"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(cosine_similarity(embs_1_seperate.detach().cpu().numpy(), embs_2_seperate.detach().cpu().numpy()).max(0))\n",
    "cosine_similarity(embs_1_seperate.detach().cpu().numpy(), embs_2_seperate.detach().cpu().numpy()).max(0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.4807e-01,  7.9468e-02,  8.3252e-02,  8.0013e-04],\n",
       "       [ 9.3811e-02,  8.0750e-02,  1.4503e-02,  8.5144e-02],\n",
       "       [ 1.4343e-01,  1.2451e-01,  1.3757e-01,  1.8555e-01],\n",
       "       [ 1.3525e-01,  1.2488e-01,  4.9103e-02,  5.0732e-01],\n",
       "       [ 1.3702e-02,  5.0278e-03,  4.6436e-01, -5.0476e-02],\n",
       "       [ 3.7079e-03,  3.2673e-03,  6.6455e-01, -9.7839e-02],\n",
       "       [ 4.4365e-03,  1.0633e-03,  7.2607e-01, -1.0065e-01],\n",
       "       [-1.2636e-04, -5.4512e-03,  4.3701e-02,  3.2495e-01]],\n",
       "      dtype=float16)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_similarity(embs_1.detach().cpu().numpy(), embs_3.detach().cpu().numpy()).astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1481 0.1249 0.726  0.5073]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.506"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(cosine_similarity(embs_1.detach().cpu().numpy(), embs_3.detach().cpu().numpy()).astype(np.float16).max(0))\n",
    "cosine_similarity(embs_1.detach().cpu().numpy(), embs_3.detach().cpu().numpy()).astype(np.float16).max(0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9623717  0.9630035  0.96271193 0.9627304 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.8508177"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(cosine_similarity(embs_1_seperate.detach().cpu().numpy(), embs_3_seperate.detach().cpu().numpy()).max(0))\n",
    "cosine_similarity(embs_1_seperate.detach().cpu().numpy(), embs_3_seperate.detach().cpu().numpy()).max(0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
