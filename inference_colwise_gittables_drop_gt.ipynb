{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/zhihao/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/zhihao/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "from time import time\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from collections import defaultdict\n",
    "\n",
    "# import pytrec_eval\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss, BCEWithLogitsLoss\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, BertConfig, AutoTokenizer\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from accelerate import Accelerator\n",
    "from copy import deepcopy\n",
    "\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "from watchog.dataset import (\n",
    "    # collate_fn,\n",
    "    TURLColTypeTablewiseDataset,\n",
    "    TURLRelExtTablewiseDataset,\n",
    "    SatoCVTablewiseDataset,\n",
    "    ColPoplTablewiseDataset\n",
    ")\n",
    "\n",
    "from watchog.dataset import TableDataset, SupCLTableDataset, SemtableCVTablewiseDataset, GittablesColwiseDataset, GittablesTablewiseDataset\n",
    "from watchog.model import BertMultiPairPooler, BertForMultiOutputClassification, BertForMultiOutputClassificationColPopl, Verifier\n",
    "from watchog.model import SupCLforTable, UnsupCLforTable, lm_mp\n",
    "from watchog.utils import load_checkpoint, f1_score_multilabel, collate_fn, get_col_pred, ColPoplEvaluator\n",
    "from watchog.utils import task_num_class_dict\n",
    "from accelerate import DistributedDataParallelKwargs\n",
    "import wandb\n",
    "\n",
    "from argparse import Namespace\n",
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import re\n",
    "import transformers\n",
    "from torch.utils import data\n",
    "from torch.nn.utils import rnn\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from typing import List\n",
    "from functools import reduce\n",
    "import operator\n",
    "\n",
    "from itertools import chain\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args={\"wandb\": false, \"model\": \"Watchog\", \"unlabeled_train_only\": false, \"context_encoding_type\": \"v0\", \"pool_version\": \"v0.2\", \"random_sample\": false, \"comment\": \"debug\", \"shortcut_name\": \"bert-base-uncased\", \"max_length\": 64, \"adaptive_max_length\": false, \"max_num_col\": 8, \"batch_size\": 3, \"epoch\": 1, \"random_seed\": 4649, \"train_n_seed_cols\": -1, \"num_classes\": 101, \"multi_gpu\": false, \"fp16\": false, \"warmup\": 0.0, \"lr\": 5e-05, \"task\": \"gt-semtab22-dbpedia-all0\", \"colpair\": false, \"metadata\": false, \"from_scratch\": false, \"cl_tag\": \"wikitables/simclr/bert_100000_10_32_256_5e-05_sample_row4,sample_row4_tfidf_entity_column_0.05_0_last.pt\", \"dropout_prob\": 0.5, \"eval_test\": true, \"small_tag\": \"semi1\", \"data_path\": \"/data/zhihao/TU/\", \"pretrained_ckpt_path\": \"/data/zhihao/TU/Watchog/model/\"}\n",
      "gt-semtab22-dbpedia-all0/wikitables-simclr-bert_100000_10_32_256_5e-05_sample_row4,sample_row4_tfidf_entity_column_0.05_0_last.pt_bert-base-uncased-poolsemi1-max_colsv0.2-rand8-bsFalse-ml3-ne64-do10.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "/tmp/ipykernel_102876/3989646571.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(ckpt_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(augment_op='sample_row4,sample_row4', batch_size=32, data_path='/data/zhihao/TU/TURL/', fp16=True, gpus='0', lm='bert', logdir='/data/zhihao/TU/Watchog/model/', lr=5e-05, max_len=256, mode='simclr', model='Watchog', n_epochs=10, pretrain_data='wikitables', pretrained_model_path='', projector=768, run_id=0, sample_meth='tfidf_entity', save_model=10, single_column=False, size=100000, table_order='column', temperature=0.05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "    device = torch.device(2)\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--wandb\", type=bool, default=False)\n",
    "    parser.add_argument(\"--model\", type=str, default=\"Watchog\")\n",
    "    parser.add_argument(\"--unlabeled_train_only\", type=bool, default=False)\n",
    "    parser.add_argument(\"--context_encoding_type\", type=str, default=\"v0\")\n",
    "    parser.add_argument(\"--pool_version\", type=str, default=\"v0.2\")\n",
    "    parser.add_argument(\"--random_sample\", type=bool, default=False)\n",
    "    parser.add_argument(\"--comment\", type=str, default=\"debug\", help=\"to distinguish the runs\")\n",
    "    parser.add_argument(\n",
    "        \"--shortcut_name\",\n",
    "        default=\"bert-base-uncased\",\n",
    "        type=str,\n",
    "        help=\"Huggingface model shortcut name \",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--max_length\",\n",
    "        default=64,\n",
    "        type=int,\n",
    "        help=\n",
    "        \"The maximum total input sequence length after tokenization. Sequences longer \"\n",
    "        \"than this will be truncated, sequences shorter will be padded.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--adaptive_max_length\",\n",
    "        default=False,\n",
    "        type=bool,\n",
    "    )    \n",
    "    parser.add_argument(\n",
    "        \"--max_num_col\",\n",
    "        default=8,\n",
    "        type=int,\n",
    "    )   \n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--batch_size\",\n",
    "        default=3,\n",
    "        type=int,\n",
    "        help=\"Batch size\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--epoch\",\n",
    "        default=1,\n",
    "        type=int,\n",
    "        help=\"Number of epochs for training\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--random_seed\",\n",
    "        default=4649,\n",
    "        type=int,\n",
    "        help=\"Random seed\",\n",
    "    )\n",
    "    \n",
    "    parser.add_argument(\n",
    "        \"--train_n_seed_cols\",\n",
    "        default=-1,\n",
    "        type=int,\n",
    "        help=\"number of seeding columns in training\",\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--num_classes\",\n",
    "        default=78,\n",
    "        type=int,\n",
    "        help=\"Number of classes\",\n",
    "    )\n",
    "    parser.add_argument(\"--multi_gpu\",\n",
    "                        action=\"store_true\",\n",
    "                        default=False,\n",
    "                        help=\"Use multiple GPU\")\n",
    "    parser.add_argument(\"--fp16\",\n",
    "                        action=\"store_true\",\n",
    "                        default=False,\n",
    "                        help=\"Use FP16\")\n",
    "    parser.add_argument(\"--warmup\",\n",
    "                        type=float,\n",
    "                        default=0.,\n",
    "                        help=\"Warmup ratio\")\n",
    "    parser.add_argument(\"--lr\", type=float, default=5e-5, help=\"Learning rate\")\n",
    "    parser.add_argument(\"--task\",\n",
    "                        type=str,\n",
    "                        default='gt-semtab22-dbpedia-all0',\n",
    "                        choices=[\n",
    "                            \"sato0\", \"sato1\", \"sato2\", \"sato3\", \"sato4\",\n",
    "                            \"msato0\", \"msato1\", \"msato2\", \"msato3\", \"msato4\",\n",
    "                            \"gt-dbpedia0\", \"gt-dbpedia1\", \"gt-dbpedia2\", \"gt-dbpedia3\", \"gt-dbpedia4\",\n",
    "                            \"gt-dbpedia-all0\", \"gt-dbpedia-all1\", \"gt-dbpedia-all2\", \"gt-dbpedia-all3\", \"gt-dbpedia-all4\",\n",
    "                            \"gt-schema-all0\", \"gt-schema-all1\", \"gt-schema-all2\", \"gt-schema-all3\", \"gt-schema-all4\",\n",
    "                            \"gt-semtab22-dbpedia\", \"gt-semtab22-dbpedia0\", \"gt-semtab22-dbpedia1\", \"gt-semtab22-dbpedia2\", \"gt-semtab22-dbpedia3\", \"gt-semtab22-dbpedia4\",\n",
    "                            \"gt-semtab22-dbpedia-all\", \"gt-semtab22-dbpedia-all0\", \"gt-semtab22-dbpedia-all1\", \"gt-semtab22-dbpedia-all2\", \"gt-semtab22-dbpedia-all3\", \"gt-semtab22-dbpedia-all4\",\n",
    "                            \"gt-semtab22-schema-class-all\", \"gt-semtab22-schema-property-all\",\n",
    "                            \"turl\", \"turl-re\", \"col-popl-1\", \"col-popl-2\", \"col-popl-3\", \"row-popl\",\n",
    "                            \"col-popl-turl-0\", \"col-popl-turl-1\", \"col-popl-turl-2\",\n",
    "                            \"col-popl-turl-mdonly-0\", \"col-popl-turl-mdonly-1\", \"col-popl-turl-mdonly-2\"\n",
    "                        ],\n",
    "                        help=\"Task names}\")\n",
    "    parser.add_argument(\"--colpair\",\n",
    "                        action=\"store_true\",\n",
    "                        help=\"Use column pair embedding\")\n",
    "    parser.add_argument(\"--metadata\",\n",
    "                        action=\"store_true\",\n",
    "                        help=\"Use column header metadata\")\n",
    "    parser.add_argument(\"--from_scratch\",\n",
    "                        action=\"store_true\",\n",
    "                        help=\"Training from scratch\")\n",
    "    parser.add_argument(\"--cl_tag\",\n",
    "                        type=str,\n",
    "                        default=\"wikitables/simclr/bert_100000_10_32_256_5e-05_sample_row4,sample_row4_tfidf_entity_column_0.05_0_last.pt\",\n",
    "                        help=\"path to the pre-trained file\")\n",
    "    parser.add_argument(\"--dropout_prob\",\n",
    "                        type=float,\n",
    "                        default=0.5)\n",
    "    parser.add_argument(\"--eval_test\",\n",
    "                        action=\"store_true\",\n",
    "                        help=\"evaluate on testset and do not save the model file\")\n",
    "    parser.add_argument(\"--small_tag\",\n",
    "                        type=str,\n",
    "                        default=\"semi1\",\n",
    "                        help=\"e.g., by_table_t5_v1\")\n",
    "    parser.add_argument(\"--data_path\",\n",
    "                        type=str,\n",
    "                        default=\"/data/zhihao/TU/\")\n",
    "    parser.add_argument(\"--pretrained_ckpt_path\",\n",
    "                        type=str,\n",
    "                        default=\"/data/zhihao/TU/Watchog/model/\")    \n",
    "\n",
    "    args = parser.parse_args([])\n",
    "    task = args.task\n",
    "    if args.small_tag != \"\":\n",
    "        args.eval_test = True\n",
    "    \n",
    "    args.num_classes = task_num_class_dict[task]\n",
    "    if args.colpair:\n",
    "        assert \"turl-re\" == task, \"colpair can be only used for Relation Extraction\"\n",
    "    if args.metadata:\n",
    "        assert \"turl-re\" == task or \"turl\" == task, \"metadata can be only used for TURL datasets\"\n",
    "    if \"col-popl\":\n",
    "        # metrics = {\n",
    "        #     \"accuracy\": CategoricalAccuracy(tie_break=True),\n",
    "        # }\n",
    "        if args.train_n_seed_cols != -1:\n",
    "            if \"col-popl\" in task:\n",
    "                assert args.train_n_seed_cols == int(task[-1]),  \"# of seed columns must match\"\n",
    "\n",
    "    print(\"args={}\".format(json.dumps(vars(args))))\n",
    "\n",
    "    max_length = args.max_length\n",
    "    batch_size = args.batch_size\n",
    "    num_train_epochs = args.epoch\n",
    "\n",
    "    shortcut_name = args.shortcut_name\n",
    "\n",
    "    if args.colpair and args.metadata:\n",
    "        taskname = \"{}-colpair-metadata\".format(task)\n",
    "    elif args.colpair:\n",
    "        taskname = \"{}-colpair\".format(task)\n",
    "    elif args.metadata:\n",
    "        taskname = \"{}-metadata\".format(task)\n",
    "    elif args.train_n_seed_cols == -1 and 'popl' in task:\n",
    "        taskname = \"{}-mix\".format(task)\n",
    "    else:\n",
    "        taskname = \"\".join(task)\n",
    "    cv = int(task[-1])\n",
    "\n",
    "    if args.from_scratch:\n",
    "        if \"gt\" in task:\n",
    "            tag_name = \"{}/{}-{}-{}-pool{}-max_cols{}-rand{}-bs{}-ml{}-ne{}-do{}{}\".format(\n",
    "                taskname,  \"{}-fromscratch\".format(shortcut_name), args.small_tag, args.comment, args.pool_version, args.max_num_col, args.random_sample,\n",
    "                batch_size, max_length, num_train_epochs, args.dropout_prob, \n",
    "                '-rs{}'.format(args.random_seed) if args.random_seed != 4649 else '')\n",
    "        else:\n",
    "            tag_name = \"{}/{}-{}-{}-bs{}-ml{}-ne{}-do{}{}\".format(\n",
    "                taskname,  \"{}-fromscratch\".format(shortcut_name), args.small_tag, args.comment, \n",
    "                batch_size, max_length, num_train_epochs, args.dropout_prob, \n",
    "                '-rs{}'.format(args.random_seed) if args.random_seed != 4649 else '')\n",
    "        \n",
    "    else:\n",
    "        if \"gt\" in task:\n",
    "            tag_name = \"{}/{}_{}-pool{}-max_cols{}-rand{}-bs{}-ml{}-ne{}-do{}{}\".format(\n",
    "                taskname, args.cl_tag.replace('/', '-'),  shortcut_name, args.small_tag, args.pool_version, args.max_num_col, args.random_sample,\n",
    "                batch_size, max_length, num_train_epochs, args.dropout_prob,\n",
    "                '-rs{}'.format(args.random_seed) if args.random_seed != 4649 else '')\n",
    "        else:\n",
    "            tag_name = \"{}/{}_{}-{}-bs{}-ml{}-ne{}-do{}{}\".format(\n",
    "                taskname, args.cl_tag.replace('/', '-'),  shortcut_name, args.small_tag,\n",
    "                batch_size, max_length, num_train_epochs, args.dropout_prob,\n",
    "                '-rs{}'.format(args.random_seed) if args.random_seed != 4649 else '')\n",
    "\n",
    "    # if args.eval_test:\n",
    "    #     if args.small_tag != '':\n",
    "    #         tag_name = tag_name.replace('outputs', 'small_outputs')\n",
    "    #         tag_name += '-' + args.small_tag\n",
    "    print(tag_name)\n",
    "    file_path = os.path.join(args.data_path, \"Watchog\", \"outputs\", tag_name)\n",
    "\n",
    "    dirpath = os.path.dirname(file_path)\n",
    "    if not os.path.exists(dirpath):\n",
    "        print(\"{} not exists. Created\".format(dirpath))\n",
    "        os.makedirs(dirpath)\n",
    "    \n",
    "    if args.fp16:\n",
    "        torch.backends.cuda.matmul.allow_fp16_reduced_precision_reduction = True\n",
    "        \n",
    "      \n",
    "        \n",
    "    # accelerator = Accelerator(mixed_precision=\"no\" if not args.fp16 else \"fp16\")   \n",
    "    ddp_kwargs = DistributedDataParallelKwargs(find_unused_parameters=True)\n",
    "    accelerator = Accelerator(mixed_precision=\"no\" if not args.fp16 else \"fp16\", kwargs_handlers=[ddp_kwargs])\n",
    "\n",
    "    device = torch.device(0)\n",
    "    ckpt_path = os.path.join(args.pretrained_ckpt_path, args.cl_tag)\n",
    "    # ckpt_path = '/efs/checkpoints/{}.pt'.format(args.cl_tag)\n",
    "    ckpt = torch.load(ckpt_path, map_location=device)\n",
    "    ckpt_hp = ckpt['hp']\n",
    "    print(ckpt_hp)\n",
    " \n",
    "    setattr(ckpt_hp, 'batch_size', args.batch_size)\n",
    "    setattr(ckpt_hp, 'hidden_dropout_prob', args.dropout_prob)\n",
    "    setattr(ckpt_hp, 'shortcut_name', args.shortcut_name)\n",
    "    setattr(ckpt_hp, 'num_labels', args.num_classes)\n",
    "    \n",
    "    \n",
    "    \n",
    "    tokenizer = BertTokenizer.from_pretrained(shortcut_name)\n",
    "    padder = collate_fn(tokenizer.pad_token_id)\n",
    "    if task == \"turl-re\" and args.colpair:\n",
    "        model = BertForMultiOutputClassification(ckpt_hp, device=device, lm=ckpt['hp'].lm, col_pair='Pair')\n",
    "    elif \"col-popl\" in task:\n",
    "        model = BertForMultiOutputClassificationColPopl(ckpt_hp, device=device, lm=ckpt['hp'].lm, n_seed_cols=int(task[i][-1]), cls_for_md=\"md\" in task)\n",
    "    else:\n",
    "        model = BertForMultiOutputClassification(ckpt_hp, device=device, lm=ckpt['hp'].lm, version=\"v0\", use_attention_mask=True)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_102876/3246719115.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_state_dict = torch.load(\"/data/zhihao/TU/Watchog/outputs/gt-semtab22-dbpedia-all0/bert-base-uncased-fromscratch-semi1-GT-Repeat@5-AttnMask-max-unlabeled@8-poolv0-unlabeled8-randTrue-bs16-ml128-ne50-do0.1_best_last_3.pt\", map_location=device)\n"
     ]
    }
   ],
   "source": [
    "# best_state_dict = torch.load(\"/data/zhihao/TU/Watchog/outputs/gt-semtab22-dbpedia-all0/bert-base-uncased-fromscratch-semi1-AttnMask-max-unlabeled@8-poolv0-unlabeled8-randFalse-bs16-ml128-ne50-do0.1_best_f1_micro.pt\", map_location=device)\n",
    "best_state_dict = torch.load(\"/data/zhihao/TU/Watchog/outputs/gt-semtab22-dbpedia-all0/bert-base-uncased-fromscratch-semi1-GT-Repeat@5-AttnMask-max-unlabeled@8-poolv0-unlabeled8-randTrue-bs16-ml128-ne50-do0.1_best_last_3.pt\", map_location=device)\n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join(\"/data/zhihao/TU/GitTables/semtab_gittables/2022\",\"semi_cv_{}.csv\".format(0))\n",
    "df = pd.read_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>table_id</th>\n",
       "      <th>col_idx</th>\n",
       "      <th>class</th>\n",
       "      <th>class_id</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GitTables_100277</td>\n",
       "      <td>0</td>\n",
       "      <td>id</td>\n",
       "      <td>0</td>\n",
       "      <td>state_id_0;state_id_1;state_id_2;state_id_3;st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GitTables_100277</td>\n",
       "      <td>1</td>\n",
       "      <td>name</td>\n",
       "      <td>1</td>\n",
       "      <td>Alytaus apskritis;Kauno apskritis;Klaipėdos ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GitTables_100277</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>A;K;L;M;P;S;J;T;U;V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GitTables_100277</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>base.lt;base.lt;base.lt;base.lt;base.lt;base.l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GitTables_100850</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>A1234582;13;A1234624;A1234595;A1234578;A123460...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9170</th>\n",
       "      <td>GitTables_99850</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0;0.0;0.0;0.0;0.0;0.0;0.0;0.0;0.0;0.0;-10.0;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9171</th>\n",
       "      <td>GitTables_99850</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>rpm;Nm;rpm;rpm;KW;KW;W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9172</th>\n",
       "      <td>GitTables_99885</td>\n",
       "      <td>0</td>\n",
       "      <td>id</td>\n",
       "      <td>0</td>\n",
       "      <td>1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9173</th>\n",
       "      <td>GitTables_99885</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>1;1;1;1;1;1;1;1;1;1;1;1;1;1;3;3;3;3;3;3;3;3;3;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9174</th>\n",
       "      <td>GitTables_99885</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>102;103;104;105;106;107;108;109;110;111;112;11...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9175 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              table_id  col_idx class  class_id  \\\n",
       "0     GitTables_100277        0    id         0   \n",
       "1     GitTables_100277        1  name         1   \n",
       "2     GitTables_100277        2   NaN        -1   \n",
       "3     GitTables_100277        3   NaN        -1   \n",
       "4     GitTables_100850        0   NaN        -1   \n",
       "...                ...      ...   ...       ...   \n",
       "9170   GitTables_99850       15   NaN        -1   \n",
       "9171   GitTables_99850       16   NaN        -1   \n",
       "9172   GitTables_99885        0    id         0   \n",
       "9173   GitTables_99885        1   NaN        -1   \n",
       "9174   GitTables_99885        2   NaN        -1   \n",
       "\n",
       "                                                   data  \n",
       "0     state_id_0;state_id_1;state_id_2;state_id_3;st...  \n",
       "1     Alytaus apskritis;Kauno apskritis;Klaipėdos ap...  \n",
       "2                                   A;K;L;M;P;S;J;T;U;V  \n",
       "3     base.lt;base.lt;base.lt;base.lt;base.lt;base.l...  \n",
       "4     A1234582;13;A1234624;A1234595;A1234578;A123460...  \n",
       "...                                                 ...  \n",
       "9170  0.0;0.0;0.0;0.0;0.0;0.0;0.0;0.0;0.0;0.0;-10.0;...  \n",
       "9171                             rpm;Nm;rpm;rpm;KW;KW;W  \n",
       "9172  1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;1...  \n",
       "9173  1;1;1;1;1;1;1;1;1;1;1;1;1;1;3;3;3;3;3;3;3;3;3;...  \n",
       "9174  102;103;104;105;106;107;108;109;110;111;112;11...  \n",
       "\n",
       "[9175 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labeled = df[df['class_id'] > -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols_labeled = []\n",
    "for index, group_df in df_labeled.groupby('table_id'):\n",
    "    num_cols_labeled.append(len(group_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>table_id</th>\n",
       "      <th>col_idx</th>\n",
       "      <th>class</th>\n",
       "      <th>class_id</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9172</th>\n",
       "      <td>GitTables_99885</td>\n",
       "      <td>0</td>\n",
       "      <td>id</td>\n",
       "      <td>0</td>\n",
       "      <td>1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             table_id  col_idx class  class_id  \\\n",
       "9172  GitTables_99885        0    id         0   \n",
       "\n",
       "                                                   data  \n",
       "9172  1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;1...  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.histplot(num_cols_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = []\n",
    "for i in range(5):\n",
    "    if i == cv:\n",
    "        continue\n",
    "    filepath = os.path.join(\"/data/zhihao/TU/GitTables/semtab_gittables/2022\",\"semi_cv_{}.csv\".format(i))\n",
    "    df_train.append(pd.read_csv(filepath))\n",
    "df_train = pd.concat(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_labeled = df_train[df_train['class_id'] != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_cols_labeled_train = []\n",
    "for index, group_df in df_train_labeled.groupby('table_id'):\n",
    "    num_cols_labeled_train.append(len(group_df))\n",
    "sns.histplot(num_cols_labeled_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3254)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cols_labeled_train = torch.tensor(num_cols_labeled_train)\n",
    "(num_cols_labeled_train>1).sum()/len(num_cols_labeled_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "    if len(group_df) >= 8 and len(group_df[group_df['class_id'] > -1]) >=4:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_column(values):\n",
    "    \"\"\"\n",
    "    Classify column values into one of three types:\n",
    "    1. All Characters: All values are alphabetic.\n",
    "    2. Both Characters and Numerics: At least one value contains both letters and numbers.\n",
    "    3. All Numerics: All values are numeric (integers or floats).\n",
    "\n",
    "    Args:\n",
    "        values (list): List of column values (as strings).\n",
    "    \n",
    "    Returns:\n",
    "        str: Classification of the column ('All Characters', 'Both Characters and Numerics', 'All Numerics').\n",
    "    \"\"\"\n",
    "    if type(values) != list:\n",
    "        raise ValueError(\"Invalid input type\")\n",
    "    importance = 0\n",
    "    all_characters = True\n",
    "    all_numerics = True\n",
    "    mixed = False\n",
    "    for value in values:\n",
    "        # Strip any whitespace around the value\n",
    "        value = value.replace(' ', '')\n",
    "        if value.replace('-', '', 1).replace('.', '', 1).isdigit():\n",
    "            all_characters = False\n",
    "        if value.isalpha():\n",
    "            all_numerics = False\n",
    "    if all_characters and all_numerics:\n",
    "        all_characters = False\n",
    "        all_numerics = False\n",
    "    if not all_characters and not all_numerics:\n",
    "        mixed = True\n",
    "    if all_characters:\n",
    "        importance += 200\n",
    "    elif mixed:\n",
    "        importance += 100\n",
    "    elif all_numerics:\n",
    "        importance += 0\n",
    "    else:\n",
    "        raise ValueError(\"Invalid column values\")\n",
    "    unique_values = set(values) \n",
    "    importance += min(99, len(unique_values))\n",
    "    \n",
    "\n",
    "    return importance\n",
    "\n",
    "# Example usage:\n",
    "values1 = [\"state id\"]\n",
    "values2 = [\"0.0\", \"0.0\", \"0.0\", \"-10.0\"]\n",
    "values3 = [\"1997-1-1\"]\n",
    "values4 = [\"2020\", \"123\", \"abc\"]\n",
    "\n",
    "print(classify_column(values1))  # Output: Both Characters and Numerics\n",
    "print(classify_column(values2))  # Output: All Numerics\n",
    "print(classify_column(values3))  # Output: Both Characters and Numerics\n",
    "print(classify_column(values4))  # Output: Both Characters and Numerics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_scores = group_df[\"data\"].apply(lambda x: classify_column(x.split(';'))).tolist(\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df[\"class_id\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels_raw = []\n",
    "for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "    group_df.sort_values(by=['col_idx'], inplace=True)\n",
    "    all_labels_raw.append(torch.tensor(group_df[\"class_id\"].values))\n",
    "all_labels_raw = torch.cat(all_labels_raw)\n",
    "all_labels_raw = all_labels_raw[all_labels_raw > -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_labels_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.equal(all_labels_raw, labels_test_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GittablesTablewiseLabelLastDataset(data.Dataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            cv: int,\n",
    "            split: str,\n",
    "            src: str,  # train or test\n",
    "            tokenizer: AutoTokenizer,\n",
    "            max_length: int = 256,\n",
    "            gt_only: bool = False,\n",
    "            device: torch.device = None,\n",
    "            base_dirpath: str = \"/data/zhihao/TU/GitTables/semtab_gittables/2022\",\n",
    "            base_tag: str = '', # blank, comma\n",
    "            small_tag: str = \"\",\n",
    "            train_ratio: float = 1.0,\n",
    "            max_unlabeled=8,\n",
    "            adaptive_max_length=True,\n",
    "            random_sample=False, # TODO\n",
    "            train_only=False,\n",
    "            seed=0): # TODO\n",
    "        if device is None:\n",
    "            device = torch.device('cpu')\n",
    "        basename = small_tag+ \"_cv_{}.csv\"\n",
    "    \n",
    "        if split in [\"train\", \"valid\"]:\n",
    "            df_list = []\n",
    "            for i in range(5):\n",
    "                if i == cv:\n",
    "                    continue\n",
    "                filepath = os.path.join(base_dirpath, basename.format(i))\n",
    "                df_list.append(pd.read_csv(filepath))\n",
    "                print(split, i)\n",
    "            df = pd.concat(df_list, axis=0)\n",
    "        else:\n",
    "            # test\n",
    "            filepath = os.path.join(base_dirpath, basename.format(cv))\n",
    "            df = pd.read_csv(filepath)\n",
    "            print(split)\n",
    "\n",
    "\n",
    "        if gt_only:\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "        if train_only and split != \"train\":\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "\n",
    "        \n",
    "        data_list = []\n",
    "        \n",
    "        df['class_id'] = df['class_id'].astype(int)\n",
    "        df.drop(df[(df['data'].isna()) & (df['class_id'] == -1)].index, inplace=True)\n",
    "        df['col_idx'] = df['col_idx'].astype(int)\n",
    "        df['data'] = df['data'].astype(str)\n",
    "        \n",
    "        num_tables = len(df.groupby(\"table_id\"))\n",
    "        valid_index = int(num_tables * 0.8)\n",
    "        num_train = int(train_ratio * num_tables * 0.8)        \n",
    "        \n",
    "        # df.drop(df[(df['data'] == '') & (df['class_id'] == -1)].index, inplace=True)\n",
    "        total_num_cols = 0\n",
    "        for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "            if (split == \"train\") and ((i >= num_train) or (i >= valid_index)):\n",
    "                break\n",
    "            if split == \"valid\" and i < valid_index:\n",
    "                continue\n",
    "            #     break\n",
    "            num_cols = len(group_df)\n",
    "            group_df.sort_values(by=['col_idx'], inplace=True)\n",
    "            labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "            unlabeled_columns = group_df[group_df['class_id'] == -1]\n",
    "            num_unlabeled = min(max(max_unlabeled-len(labeled_columns), 0), len(unlabeled_columns)) if max_unlabeled > 0 else len(unlabeled_columns)\n",
    "            unlabeled_columns = unlabeled_columns.tail(num_unlabeled)\n",
    "            # group_df = pd.concat([group_df[group_df['class_id'] > -1], unlabeled_columns.sample(min(10-len(labeled_columns), len(unlabeled_columns)))])\n",
    "            # group_df = pd.concat([group_df[group_df['class_id'] > -1], unlabeled_columns[0:min(max(10-len(labeled_columns), 0), len(unlabeled_columns))]])\n",
    "            group_df = pd.concat([group_df[group_df['class_id'] > -1], unlabeled_columns]) \n",
    "            group_df.sort_values(by=['col_idx'], inplace=True) # TODO \n",
    "            col_idx_list = group_df[\"col_idx\"].values\n",
    "            \n",
    "            if max_length <= 128 and adaptive_max_length:\n",
    "                cur_maxlen = min(max_length, 512 // len(target_table) - 1)\n",
    "            else:\n",
    "                cur_maxlen = max_length\n",
    "                \n",
    "            token_ids_list = group_df[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=cur_maxlen, truncation=True)).tolist(\n",
    "                )\n",
    "            token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                                token_ids_list)).to(device)\n",
    "            for col_i in range(len(token_ids_list)):\n",
    "                if group_df[\"class_id\"].values[col_i] == -1:\n",
    "                    continue\n",
    "                target_col_mask = []\n",
    "                cls_index_value = 0\n",
    "                context_id = 1\n",
    "                for col_j in range(len(token_ids_list)):\n",
    "                    if col_j == col_i:\n",
    "                        target_col_mask += [0] * len(token_ids_list[col_j])\n",
    "                    else:\n",
    "                        target_col_mask += [context_id] * len(token_ids_list[col_j])\n",
    "                        context_id += 1\n",
    "                    if col_j < col_i:\n",
    "                        cls_index_value += len(token_ids_list[col_j])\n",
    "                cls_index_list = [cls_index_value] \n",
    "                for cls_index in cls_index_list:\n",
    "                    assert token_ids[\n",
    "                        cls_index] == tokenizer.cls_token_id, \"cls_indexes validation\"\n",
    "                cls_indexes = torch.LongTensor(cls_index_list).to(device)\n",
    "                class_ids = torch.LongTensor(\n",
    "                    [group_df[\"class_id\"].values[col_i]]).to(device)\n",
    "                target_col_mask = torch.LongTensor(target_col_mask).to(device)\n",
    "                data_list.append(\n",
    "                    [index,\n",
    "                    len(group_df), token_ids, class_ids, cls_indexes, target_col_mask, num_cols, col_idx_list])                \n",
    "        print(split, len(data_list))\n",
    "        self.table_df = pd.DataFrame(data_list,\n",
    "                                     columns=[\n",
    "                                         \"table_id\", \"num_col\", \"data_tensor\",\n",
    "                                         \"label_tensor\", \"cls_indexes\", \"target_col_mask\", \"initial_num_col\", \"col_idx_list\"\n",
    "                                     ])\n",
    "        \"\"\"\n",
    "        # NOTE: msato contains a small portion of single-col tables. keep it to be consistent.  \n",
    "        if multicol_only:\n",
    "            # Check\n",
    "            num_all_tables = len(self.table_df)\n",
    "            self.table_df = self.table_df[self.table_df[\"num_col\"] > 1]\n",
    "            assert len(self.table_df) == num_all_tables\n",
    "        \"\"\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.table_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"data\": self.table_df.iloc[idx][\"data_tensor\"],\n",
    "            \"label\": self.table_df.iloc[idx][\"label_tensor\"],\n",
    "            \"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"],\n",
    "            \"target_col_mask\": self.table_df.iloc[idx][\"target_col_mask\"],\n",
    "            \"initial_num_col\": self.table_df.iloc[idx][\"initial_num_col\"],\n",
    "            \"col_idx_list\": self.table_df.iloc[idx][\"col_idx_list\"],\n",
    "        }\n",
    "        #\"idx\": torch.LongTensor([idx])}\n",
    "        #\"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GittablesTablewiseLabelFirstDataset(data.Dataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            cv: int,\n",
    "            split: str,\n",
    "            src: str,  # train or test\n",
    "            tokenizer: AutoTokenizer,\n",
    "            max_length: int = 256,\n",
    "            gt_only: bool = False,\n",
    "            device: torch.device = None,\n",
    "            base_dirpath: str = \"/data/zhihao/TU/GitTables/semtab_gittables/2022\",\n",
    "            base_tag: str = '', # blank, comma\n",
    "            small_tag: str = \"\",\n",
    "            train_ratio: float = 1.0,\n",
    "            max_unlabeled=8,\n",
    "            adaptive_max_length=True,\n",
    "            random_sample=False, # TODO\n",
    "            train_only=False,\n",
    "            seed=0): # TODO\n",
    "        if device is None:\n",
    "            device = torch.device('cpu')\n",
    "        basename = small_tag+ \"_cv_{}.csv\"\n",
    "    \n",
    "        if split in [\"train\", \"valid\"]:\n",
    "            df_list = []\n",
    "            for i in range(5):\n",
    "                if i == cv:\n",
    "                    continue\n",
    "                filepath = os.path.join(base_dirpath, basename.format(i))\n",
    "                df_list.append(pd.read_csv(filepath))\n",
    "                print(split, i)\n",
    "            df = pd.concat(df_list, axis=0)\n",
    "        else:\n",
    "            # test\n",
    "            filepath = os.path.join(base_dirpath, basename.format(cv))\n",
    "            df = pd.read_csv(filepath)\n",
    "            print(split)\n",
    "\n",
    "\n",
    "        if gt_only:\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "        if train_only and split != \"train\":\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "\n",
    "        \n",
    "        data_list = []\n",
    "        \n",
    "        df['class_id'] = df['class_id'].astype(int)\n",
    "        df.drop(df[(df['data'].isna()) & (df['class_id'] == -1)].index, inplace=True)\n",
    "        df['col_idx'] = df['col_idx'].astype(int)\n",
    "        df['data'] = df['data'].astype(str)\n",
    "        \n",
    "        num_tables = len(df.groupby(\"table_id\"))\n",
    "        valid_index = int(num_tables * 0.8)\n",
    "        num_train = int(train_ratio * num_tables * 0.8)        \n",
    "        \n",
    "        # df.drop(df[(df['data'] == '') & (df['class_id'] == -1)].index, inplace=True)\n",
    "        total_num_cols = 0\n",
    "        for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "            if (split == \"train\") and ((i >= num_train) or (i >= valid_index)):\n",
    "                break\n",
    "            if split == \"valid\" and i < valid_index:\n",
    "                continue\n",
    "            #     break\n",
    "            num_cols = len(group_df)\n",
    "            group_df.sort_values(by=['col_idx'], inplace=True)\n",
    "            labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "            unlabeled_columns = group_df[group_df['class_id'] == -1]\n",
    "            num_unlabeled = min(max(max_unlabeled-len(labeled_columns), 0), len(unlabeled_columns)) if max_unlabeled > 0 else len(unlabeled_columns)\n",
    "            unlabeled_columns = unlabeled_columns.head(num_unlabeled)\n",
    "            # group_df = pd.concat([group_df[group_df['class_id'] > -1], unlabeled_columns.sample(min(10-len(labeled_columns), len(unlabeled_columns)))])\n",
    "            # group_df = pd.concat([group_df[group_df['class_id'] > -1], unlabeled_columns[0:min(max(10-len(labeled_columns), 0), len(unlabeled_columns))]])\n",
    "            group_df = pd.concat([group_df[group_df['class_id'] > -1], unlabeled_columns]) \n",
    "            group_df.sort_values(by=['col_idx'], inplace=True) # TODO \n",
    "\n",
    "            if max_length <= 128 and adaptive_max_length:\n",
    "                cur_maxlen = min(max_length, 512 // len(target_table) - 1)\n",
    "            else:\n",
    "                cur_maxlen = max_length\n",
    "                \n",
    "            token_ids_list = group_df[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=cur_maxlen, truncation=True)).tolist(\n",
    "                )\n",
    "            token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                                token_ids_list)).to(device)\n",
    "            for col_i in range(len(token_ids_list)):\n",
    "                if group_df[\"class_id\"].values[col_i] == -1:\n",
    "                    continue\n",
    "                target_col_mask = []\n",
    "                cls_index_value = 0\n",
    "                context_id = 1\n",
    "                for col_j in range(len(token_ids_list)):\n",
    "                    if col_j == col_i:\n",
    "                        target_col_mask += [0] * len(token_ids_list[col_j])\n",
    "                    else:\n",
    "                        target_col_mask += [context_id] * len(token_ids_list[col_j])\n",
    "                        context_id += 1\n",
    "                    if col_j < col_i:\n",
    "                        cls_index_value += len(token_ids_list[col_j])\n",
    "                cls_index_list = [cls_index_value] \n",
    "                for cls_index in cls_index_list:\n",
    "                    assert token_ids[\n",
    "                        cls_index] == tokenizer.cls_token_id, \"cls_indexes validation\"\n",
    "                cls_indexes = torch.LongTensor(cls_index_list).to(device)\n",
    "                class_ids = torch.LongTensor(\n",
    "                    [group_df[\"class_id\"].values[col_i]]).to(device)\n",
    "                target_col_mask = torch.LongTensor(target_col_mask).to(device)\n",
    "                data_list.append(\n",
    "                    [index,\n",
    "                    len(group_df), token_ids, class_ids, cls_indexes, target_col_mask, num_cols])                \n",
    "        print(split, len(data_list))\n",
    "        self.table_df = pd.DataFrame(data_list,\n",
    "                                     columns=[\n",
    "                                         \"table_id\", \"num_col\", \"data_tensor\",\n",
    "                                         \"label_tensor\", \"cls_indexes\", \"target_col_mask\", \"initial_num_col\"\n",
    "                                     ])\n",
    "        \"\"\"\n",
    "        # NOTE: msato contains a small portion of single-col tables. keep it to be consistent.  \n",
    "        if multicol_only:\n",
    "            # Check\n",
    "            num_all_tables = len(self.table_df)\n",
    "            self.table_df = self.table_df[self.table_df[\"num_col\"] > 1]\n",
    "            assert len(self.table_df) == num_all_tables\n",
    "        \"\"\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.table_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"data\": self.table_df.iloc[idx][\"data_tensor\"],\n",
    "            \"label\": self.table_df.iloc[idx][\"label_tensor\"],\n",
    "            \"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"],\n",
    "            \"target_col_mask\": self.table_df.iloc[idx][\"target_col_mask\"],\n",
    "            \"initial_num_col\": self.table_df.iloc[idx][\"initial_num_col\"],\n",
    "        }\n",
    "        #\"idx\": torch.LongTensor([idx])}\n",
    "        #\"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GittablesTablewiseRandomDataset(data.Dataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            cv: int,\n",
    "            split: str,\n",
    "            src: str,  # train or test\n",
    "            tokenizer: AutoTokenizer,\n",
    "            max_length: int = 256,\n",
    "            gt_only: bool = False,\n",
    "            device: torch.device = None,\n",
    "            base_dirpath: str = \"/data/zhihao/TU/GitTables/semtab_gittables/2022\",\n",
    "            base_tag: str = '', # blank, comma\n",
    "            small_tag: str = \"\",\n",
    "            train_ratio: float = 1.0,\n",
    "            max_unlabeled=8,\n",
    "            adaptive_max_length=True,\n",
    "            random_sample=False, # TODO\n",
    "            train_only=False,\n",
    "            seed=0): # TODO\n",
    "        if device is None:\n",
    "            device = torch.device('cpu')\n",
    "        basename = small_tag+ \"_cv_{}.csv\"\n",
    "    \n",
    "        if split in [\"train\", \"valid\"]:\n",
    "            df_list = []\n",
    "            for i in range(5):\n",
    "                if i == cv:\n",
    "                    continue\n",
    "                filepath = os.path.join(base_dirpath, basename.format(i))\n",
    "                df_list.append(pd.read_csv(filepath))\n",
    "                print(split, i)\n",
    "            df = pd.concat(df_list, axis=0)\n",
    "        else:\n",
    "            # test\n",
    "            filepath = os.path.join(base_dirpath, basename.format(cv))\n",
    "            df = pd.read_csv(filepath)\n",
    "            print(split)\n",
    "\n",
    "\n",
    "        if gt_only:\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "        if train_only and split != \"train\":\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "\n",
    "        \n",
    "        data_list = []\n",
    "        \n",
    "        df['class_id'] = df['class_id'].astype(int)\n",
    "        df.drop(df[(df['data'].isna()) & (df['class_id'] == -1)].index, inplace=True)\n",
    "        df['col_idx'] = df['col_idx'].astype(int)\n",
    "        df['data'] = df['data'].astype(str)\n",
    "        \n",
    "        num_tables = len(df.groupby(\"table_id\"))\n",
    "        valid_index = int(num_tables * 0.8)\n",
    "        num_train = int(train_ratio * num_tables * 0.8)        \n",
    "        \n",
    "        # df.drop(df[(df['data'] == '') & (df['class_id'] == -1)].index, inplace=True)\n",
    "        total_num_cols = 0\n",
    "        for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "            if (split == \"train\") and ((i >= num_train) or (i >= valid_index)):\n",
    "                break\n",
    "            if split == \"valid\" and i < valid_index:\n",
    "                continue\n",
    "            #     break\n",
    "            labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "            for index, target_column in labeled_columns.iterrows():\n",
    "                target_col_idx = target_column[\"col_idx\"]\n",
    "                \n",
    "                other_columns = group_df.drop(index).sample(min(max_unlabeled, len(group_df))-1, random_state=seed)\n",
    "                \n",
    "\n",
    "                target_table = pd.concat([target_column.to_frame().T, other_columns], ignore_index=True)\n",
    "\n",
    "                # other_columns['distance'] = abs(other_columns['col_idx'] - target_col_idx)\n",
    "                # other_columns.sort_values(by='distance', inplace=True)\n",
    "                # nearby_columns = other_columns.head(max_unlabeled-1)\n",
    "                # target_table = pd.concat([target_column.to_frame().T, nearby_columns], ignore_index=True)\n",
    "                \n",
    "                \n",
    "                target_cls = target_column[\"class_id\"]\n",
    "                target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "                col_idx_list = target_table[\"col_idx\"].tolist()\n",
    "\n",
    "                if max_length <= 128 and adaptive_max_length:\n",
    "                    cur_maxlen = min(max_length, 512 // len(target_table) - 1)\n",
    "                else:\n",
    "                    cur_maxlen = max_length\n",
    "                    \n",
    "                token_ids_list = target_table[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                    tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=cur_maxlen, truncation=True)).tolist(\n",
    "                    )\n",
    "                token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                                    token_ids_list)).to(device)\n",
    "\n",
    "                target_col_mask = []\n",
    "                cls_index_value = 0\n",
    "                context_id = 1\n",
    "                meet_target = False\n",
    "                for idx, col_i in enumerate(col_idx_list):\n",
    "                    if col_i == target_col_idx:\n",
    "                        target_col_mask += [0] * len(token_ids_list[idx])\n",
    "                        meet_target = True\n",
    "                    else:\n",
    "                        target_col_mask += [context_id] * len(token_ids_list[idx])\n",
    "                        context_id += 1\n",
    "                    if not meet_target:\n",
    "                        cls_index_value += len(token_ids_list[idx])\n",
    "                cls_index_list = [cls_index_value] \n",
    "                for cls_index in cls_index_list:\n",
    "                    assert token_ids[\n",
    "                        cls_index] == tokenizer.cls_token_id, \"cls_indexes validation\"\n",
    "                cls_indexes = torch.LongTensor(cls_index_list).to(device)\n",
    "                class_ids = torch.LongTensor(\n",
    "                    [target_cls]).to(device)\n",
    "                target_col_mask = torch.LongTensor(target_col_mask).to(device)\n",
    "                data_list.append(\n",
    "                    [index,\n",
    "                    len(target_table), token_ids, class_ids, cls_indexes, target_col_mask, len(group_df)])         \n",
    "        print(split, len(data_list))\n",
    "        self.table_df = pd.DataFrame(data_list,\n",
    "                                     columns=[\n",
    "                                         \"table_id\", \"num_col\", \"data_tensor\",\n",
    "                                         \"label_tensor\", \"cls_indexes\", \"target_col_mask\", \"initial_num_col\"\n",
    "                                     ])\n",
    "        \"\"\"\n",
    "        # NOTE: msato contains a small portion of single-col tables. keep it to be consistent.  \n",
    "        if multicol_only:\n",
    "            # Check\n",
    "            num_all_tables = len(self.table_df)\n",
    "            self.table_df = self.table_df[self.table_df[\"num_col\"] > 1]\n",
    "            assert len(self.table_df) == num_all_tables\n",
    "        \"\"\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.table_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"data\": self.table_df.iloc[idx][\"data_tensor\"],\n",
    "            \"label\": self.table_df.iloc[idx][\"label_tensor\"],\n",
    "            \"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"],\n",
    "            \"target_col_mask\": self.table_df.iloc[idx][\"target_col_mask\"],\n",
    "            \"initial_num_col\": self.table_df.iloc[idx][\"initial_num_col\"],\n",
    "        }\n",
    "        #\"idx\": torch.LongTensor([idx])}\n",
    "        #\"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GittablesTablewiseLabelRandomDataset(data.Dataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            cv: int,\n",
    "            split: str,\n",
    "            src: str,  # train or test\n",
    "            tokenizer: AutoTokenizer,\n",
    "            max_length: int = 256,\n",
    "            gt_only: bool = False,\n",
    "            device: torch.device = None,\n",
    "            base_dirpath: str = \"/data/zhihao/TU/GitTables/semtab_gittables/2022\",\n",
    "            base_tag: str = '', # blank, comma\n",
    "            small_tag: str = \"\",\n",
    "            train_ratio: float = 1.0,\n",
    "            max_unlabeled=8,\n",
    "            adaptive_max_length=True,\n",
    "            random_sample=False, # TODO\n",
    "            train_only=False,\n",
    "            seed=0): # TODO\n",
    "        if device is None:\n",
    "            device = torch.device('cpu')\n",
    "        basename = small_tag+ \"_cv_{}.csv\"\n",
    "    \n",
    "        if split in [\"train\", \"valid\"]:\n",
    "            df_list = []\n",
    "            for i in range(5):\n",
    "                if i == cv:\n",
    "                    continue\n",
    "                filepath = os.path.join(base_dirpath, basename.format(i))\n",
    "                df_list.append(pd.read_csv(filepath))\n",
    "                print(split, i)\n",
    "            df = pd.concat(df_list, axis=0)\n",
    "        else:\n",
    "            # test\n",
    "            filepath = os.path.join(base_dirpath, basename.format(cv))\n",
    "            df = pd.read_csv(filepath)\n",
    "            print(split)\n",
    "\n",
    "\n",
    "        if gt_only:\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "        if train_only and split != \"train\":\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "\n",
    "        \n",
    "        data_list = []\n",
    "        \n",
    "        df['class_id'] = df['class_id'].astype(int)\n",
    "        df.drop(df[(df['data'].isna()) & (df['class_id'] == -1)].index, inplace=True)\n",
    "        df['col_idx'] = df['col_idx'].astype(int)\n",
    "        df['data'] = df['data'].astype(str)\n",
    "        \n",
    "        num_tables = len(df.groupby(\"table_id\"))\n",
    "        valid_index = int(num_tables * 0.8)\n",
    "        num_train = int(train_ratio * num_tables * 0.8)        \n",
    "        \n",
    "        # df.drop(df[(df['data'] == '') & (df['class_id'] == -1)].index, inplace=True)\n",
    "        total_num_cols = 0\n",
    "        for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "            if (split == \"train\") and ((i >= num_train) or (i >= valid_index)):\n",
    "                break\n",
    "            if split == \"valid\" and i < valid_index:\n",
    "                continue\n",
    "            #     break\n",
    "            num_cols = len(group_df)\n",
    "            group_df.sort_values(by=['col_idx'], inplace=True)\n",
    "            labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "            unlabeled_columns = group_df[group_df['class_id'] == -1]\n",
    "            num_unlabeled = min(max(max_unlabeled-len(labeled_columns), 0), len(unlabeled_columns)) if max_unlabeled > 0 else len(unlabeled_columns)\n",
    "            unlabeled_columns = unlabeled_columns.sample(num_unlabeled, random_state=seed) \n",
    "            # group_df = pd.concat([group_df[group_df['class_id'] > -1], unlabeled_columns.sample(min(10-len(labeled_columns), len(unlabeled_columns)))])\n",
    "            # group_df = pd.concat([group_df[group_df['class_id'] > -1], unlabeled_columns[0:min(max(10-len(labeled_columns), 0), len(unlabeled_columns))]])\n",
    "            group_df = pd.concat([group_df[group_df['class_id'] > -1], unlabeled_columns]) \n",
    "            group_df.sort_values(by=['col_idx'], inplace=True) # TODO \n",
    "\n",
    "            if max_length <= 128 and adaptive_max_length:\n",
    "                cur_maxlen = min(max_length, 512 // len(target_table) - 1)\n",
    "            else:\n",
    "                cur_maxlen = max_length\n",
    "                \n",
    "            token_ids_list = group_df[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=cur_maxlen, truncation=True)).tolist(\n",
    "                )\n",
    "            token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                                token_ids_list)).to(device)\n",
    "            for col_i in range(len(token_ids_list)):\n",
    "                if group_df[\"class_id\"].values[col_i] == -1:\n",
    "                    continue\n",
    "                target_col_mask = []\n",
    "                cls_index_value = 0\n",
    "                context_id = 1\n",
    "                for col_j in range(len(token_ids_list)):\n",
    "                    if col_j == col_i:\n",
    "                        target_col_mask += [0] * len(token_ids_list[col_j])\n",
    "                    else:\n",
    "                        target_col_mask += [context_id] * len(token_ids_list[col_j])\n",
    "                        context_id += 1\n",
    "                    if col_j < col_i:\n",
    "                        cls_index_value += len(token_ids_list[col_j])\n",
    "                cls_index_list = [cls_index_value] \n",
    "                for cls_index in cls_index_list:\n",
    "                    assert token_ids[\n",
    "                        cls_index] == tokenizer.cls_token_id, \"cls_indexes validation\"\n",
    "                cls_indexes = torch.LongTensor(cls_index_list).to(device)\n",
    "                class_ids = torch.LongTensor(\n",
    "                    [group_df[\"class_id\"].values[col_i]]).to(device)\n",
    "                target_col_mask = torch.LongTensor(target_col_mask).to(device)\n",
    "                data_list.append(\n",
    "                    [index,\n",
    "                    len(group_df), token_ids, class_ids, cls_indexes, target_col_mask, num_cols])                \n",
    "        print(split, len(data_list))\n",
    "        self.table_df = pd.DataFrame(data_list,\n",
    "                                     columns=[\n",
    "                                         \"table_id\", \"num_col\", \"data_tensor\",\n",
    "                                         \"label_tensor\", \"cls_indexes\", \"target_col_mask\", \"initial_num_col\"\n",
    "                                     ])\n",
    "        \"\"\"\n",
    "        # NOTE: msato contains a small portion of single-col tables. keep it to be consistent.  \n",
    "        if multicol_only:\n",
    "            # Check\n",
    "            num_all_tables = len(self.table_df)\n",
    "            self.table_df = self.table_df[self.table_df[\"num_col\"] > 1]\n",
    "            assert len(self.table_df) == num_all_tables\n",
    "        \"\"\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.table_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"data\": self.table_df.iloc[idx][\"data_tensor\"],\n",
    "            \"label\": self.table_df.iloc[idx][\"label_tensor\"],\n",
    "            \"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"],\n",
    "            \"target_col_mask\": self.table_df.iloc[idx][\"target_col_mask\"],\n",
    "            \"initial_num_col\": self.table_df.iloc[idx][\"initial_num_col\"],\n",
    "        }\n",
    "        #\"idx\": torch.LongTensor([idx])}\n",
    "        #\"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GittablesTablewiseIterateRandomDataset(data.Dataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            cv: int,\n",
    "            split: str,\n",
    "            src: str,  # train or test\n",
    "            tokenizer: AutoTokenizer,\n",
    "            max_length: int = 256,\n",
    "            gt_only: bool = False,\n",
    "            device: torch.device = None,\n",
    "            base_dirpath: str = \"/data/zhihao/TU/GitTables/semtab_gittables/2022\",\n",
    "            base_tag: str = '', # blank, comma\n",
    "            small_tag: str = \"\",\n",
    "            train_ratio: float = 1.0,\n",
    "            max_unlabeled=8,\n",
    "            adaptive_max_length=True,\n",
    "            random_sample=False, # TODO\n",
    "            train_only=False): # TODO\n",
    "        if device is None:\n",
    "            device = torch.device('cpu')\n",
    "        basename = small_tag+ \"_cv_{}.csv\"\n",
    "    \n",
    "        if split in [\"train\", \"valid\"]:\n",
    "            df_list = []\n",
    "            for i in range(5):\n",
    "                if i == cv:\n",
    "                    continue\n",
    "                filepath = os.path.join(base_dirpath, basename.format(i))\n",
    "                df_list.append(pd.read_csv(filepath))\n",
    "                print(split, i)\n",
    "            df = pd.concat(df_list, axis=0)\n",
    "        else:\n",
    "            # test\n",
    "            filepath = os.path.join(base_dirpath, basename.format(cv))\n",
    "            df = pd.read_csv(filepath)\n",
    "            print(split)\n",
    "\n",
    "\n",
    "        if gt_only:\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "        if train_only and split != \"train\":\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "\n",
    "        \n",
    "        data_list = []\n",
    "        \n",
    "        df['class_id'] = df['class_id'].astype(int)\n",
    "        df.drop(df[(df['data'].isna()) & (df['class_id'] == -1)].index, inplace=True)\n",
    "        df['col_idx'] = df['col_idx'].astype(int)\n",
    "        df['data'] = df['data'].astype(str)\n",
    "        \n",
    "        num_tables = len(df.groupby(\"table_id\"))\n",
    "        valid_index = int(num_tables * 0.8)\n",
    "        num_train = int(train_ratio * num_tables * 0.8)        \n",
    "        \n",
    "        # df.drop(df[(df['data'] == '') & (df['class_id'] == -1)].index, inplace=True)\n",
    "        total_num_cols = 0\n",
    "        for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "            if (split == \"train\") and ((i >= num_train) or (i >= valid_index)):\n",
    "                break\n",
    "            if split == \"valid\" and i < valid_index:\n",
    "                continue\n",
    "            #     break\n",
    "            num_cols = len(group_df)\n",
    "            group_df.sort_values(by=['col_idx'], inplace=True)\n",
    "            labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "            unlabeled_columns = group_df[group_df['class_id'] == -1]\n",
    "            if len(group_df) <= max_unlabeled:\n",
    "                num_unlabeled = min(max(max_unlabeled-len(labeled_columns), 0), len(unlabeled_columns)) if max_unlabeled > 0 else len(unlabeled_columns)\n",
    "                unlabeled_columns = unlabeled_columns.sample(num_unlabeled) if random_sample else unlabeled_columns[0:num_unlabeled]\n",
    "                # group_df = pd.concat([group_df[group_df['class_id'] > -1], unlabeled_columns.sample(min(10-len(labeled_columns), len(unlabeled_columns)))])\n",
    "                # group_df = pd.concat([group_df[group_df['class_id'] > -1], unlabeled_columns[0:min(max(10-len(labeled_columns), 0), len(unlabeled_columns))]])\n",
    "                current_df = pd.concat([labeled_columns, unlabeled_columns]) \n",
    "                current_df.sort_values(by=['col_idx'], inplace=True) # TODO \n",
    "                if max_length <= 128 and adaptive_max_length:\n",
    "                    cur_maxlen = min(max_length, 512 // len(current_df) - 1)\n",
    "                else:\n",
    "                    cur_maxlen = max_length\n",
    "                    \n",
    "                token_ids_list = current_df[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                    tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=cur_maxlen, truncation=True)).tolist(\n",
    "                    )\n",
    "                token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                                    token_ids_list)).to(device)\n",
    "                for col_i in range(len(token_ids_list)):\n",
    "                    if group_df[\"class_id\"].values[col_i] == -1:\n",
    "                        continue\n",
    "                    target_col_mask = []\n",
    "                    cls_index_value = 0\n",
    "                    context_id = 1\n",
    "                    for col_j in range(len(token_ids_list)):\n",
    "                        if col_j == col_i:\n",
    "                            target_col_mask += [0] * len(token_ids_list[col_j])\n",
    "                        else:\n",
    "                            target_col_mask += [context_id] * len(token_ids_list[col_j])\n",
    "                            context_id += 1\n",
    "                        if col_j < col_i:\n",
    "                            cls_index_value += len(token_ids_list[col_j])\n",
    "                    cls_index_list = [cls_index_value] \n",
    "                    for cls_index in cls_index_list:\n",
    "                        assert token_ids[\n",
    "                            cls_index] == tokenizer.cls_token_id, \"cls_indexes validation\"\n",
    "                    cls_indexes = torch.LongTensor(cls_index_list).to(device)\n",
    "                    class_ids = torch.LongTensor(\n",
    "                        [group_df[\"class_id\"].values[col_i]]).to(device)\n",
    "                    target_col_mask = torch.LongTensor(target_col_mask).to(device)\n",
    "                    col_idx = group_df[\"col_idx\"].values\n",
    "                    data_list.append(\n",
    "                        [index,\n",
    "                        len(group_df), token_ids, class_ids, cls_indexes, target_col_mask, num_cols, col_idx])  \n",
    "            else:\n",
    "                num_cols_to_append = max_unlabeled-len(labeled_columns)\n",
    "                num_repeat = min(len(unlabeled_columns)//num_cols_to_append, 100) \n",
    "                rest_unlabeled_columns = unlabeled_columns\n",
    "                for repeat_i in range(num_repeat):\n",
    "                    columns_to_append = rest_unlabeled_columns.sample(num_cols_to_append)\n",
    "                    rest_unlabeled_columns = rest_unlabeled_columns.drop(columns_to_append.index)\n",
    "                    current_df = pd.concat([labeled_columns, columns_to_append]) \n",
    "                    current_df.sort_values(by=['col_idx'], inplace=True) # TODO \n",
    "                    if max_length <= 128 and adaptive_max_length:\n",
    "                        cur_maxlen = min(max_length, 512 // len(current_df) - 1)\n",
    "                    else:\n",
    "                        cur_maxlen = max_length\n",
    "                        \n",
    "                    token_ids_list = current_df[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                        tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=cur_maxlen, truncation=True)).tolist(\n",
    "                        )\n",
    "                    token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                                        token_ids_list)).to(device)\n",
    "                    for col_i in range(len(token_ids_list)):\n",
    "                        if group_df[\"class_id\"].values[col_i] == -1:\n",
    "                            continue\n",
    "                        target_col_mask = []\n",
    "                        cls_index_value = 0\n",
    "                        context_id = 1\n",
    "                        for col_j in range(len(token_ids_list)):\n",
    "                            if col_j == col_i:\n",
    "                                target_col_mask += [0] * len(token_ids_list[col_j])\n",
    "                            else:\n",
    "                                target_col_mask += [context_id] * len(token_ids_list[col_j])\n",
    "                                context_id += 1\n",
    "                            if col_j < col_i:\n",
    "                                cls_index_value += len(token_ids_list[col_j])\n",
    "                        cls_index_list = [cls_index_value] \n",
    "                        for cls_index in cls_index_list:\n",
    "                            assert token_ids[\n",
    "                                cls_index] == tokenizer.cls_token_id, \"cls_indexes validation\"\n",
    "                        cls_indexes = torch.LongTensor(cls_index_list).to(device)\n",
    "                        class_ids = torch.LongTensor(\n",
    "                            [group_df[\"class_id\"].values[col_i]]).to(device)\n",
    "                        target_col_mask = torch.LongTensor(target_col_mask).to(device)\n",
    "                        col_idx = group_df[\"col_idx\"].values\n",
    "                        data_list.append(\n",
    "                            [index,\n",
    "                            len(group_df), token_ids, class_ids, cls_indexes, target_col_mask, num_cols, col_idx])  \n",
    "                \n",
    "        print(split, len(data_list))\n",
    "        self.table_df = pd.DataFrame(data_list,\n",
    "                                     columns=[\n",
    "                                         \"table_id\", \"num_col\", \"data_tensor\",\n",
    "                                         \"label_tensor\", \"cls_indexes\", \"target_col_mask\", \"initial_num_col\", \"col_idx\"\n",
    "                                     ])\n",
    "        \"\"\"\n",
    "        # NOTE: msato contains a small portion of single-col tables. keep it to be consistent.  \n",
    "        if multicol_only:\n",
    "            # Check\n",
    "            num_all_tables = len(self.table_df)\n",
    "            self.table_df = self.table_df[self.table_df[\"num_col\"] > 1]\n",
    "            assert len(self.table_df) == num_all_tables\n",
    "        \"\"\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.table_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"data\": self.table_df.iloc[idx][\"data_tensor\"],\n",
    "            \"label\": self.table_df.iloc[idx][\"label_tensor\"],\n",
    "            \"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"],\n",
    "            \"target_col_mask\": self.table_df.iloc[idx][\"target_col_mask\"],\n",
    "            \"initial_num_col\": self.table_df.iloc[idx][\"initial_num_col\"],\n",
    "            \"col_idx\": self.table_df.iloc[idx][\"col_idx\"]\n",
    "        }\n",
    "        #\"idx\": torch.LongTensor([idx])}\n",
    "        #\"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GittablesTablewiseIterateDataset(data.Dataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            cv: int,\n",
    "            split: str,\n",
    "            src: str,  # train or test\n",
    "            tokenizer: AutoTokenizer,\n",
    "            max_length: int = 256,\n",
    "            gt_only: bool = False,\n",
    "            device: torch.device = None,\n",
    "            base_dirpath: str = \"/data/zhihao/TU/GitTables/semtab_gittables/2022\",\n",
    "            base_tag: str = '', # blank, comma\n",
    "            small_tag: str = \"\",\n",
    "            train_ratio: float = 1.0,\n",
    "            max_unlabeled=8,\n",
    "            adaptive_max_length=True,\n",
    "            random_sample=False, # TODO\n",
    "            train_only=False): # TODO\n",
    "        if device is None:\n",
    "            device = torch.device('cpu')\n",
    "        basename = small_tag+ \"_cv_{}.csv\"\n",
    "    \n",
    "        if split in [\"train\", \"valid\"]:\n",
    "            df_list = []\n",
    "            for i in range(5):\n",
    "                if i == cv:\n",
    "                    continue\n",
    "                filepath = os.path.join(base_dirpath, basename.format(i))\n",
    "                df_list.append(pd.read_csv(filepath))\n",
    "                print(split, i)\n",
    "            df = pd.concat(df_list, axis=0)\n",
    "        else:\n",
    "            # test\n",
    "            filepath = os.path.join(base_dirpath, basename.format(cv))\n",
    "            df = pd.read_csv(filepath)\n",
    "            print(split)\n",
    "\n",
    "\n",
    "        if gt_only:\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "        if train_only and split != \"train\":\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "\n",
    "        \n",
    "        data_list = []\n",
    "        \n",
    "        df['class_id'] = df['class_id'].astype(int)\n",
    "        df.drop(df[(df['data'].isna()) & (df['class_id'] == -1)].index, inplace=True)\n",
    "        df['col_idx'] = df['col_idx'].astype(int)\n",
    "        df['data'] = df['data'].astype(str)\n",
    "        \n",
    "        num_tables = len(df.groupby(\"table_id\"))\n",
    "        valid_index = int(num_tables * 0.8)\n",
    "        num_train = int(train_ratio * num_tables * 0.8)        \n",
    "        \n",
    "        # df.drop(df[(df['data'] == '') & (df['class_id'] == -1)].index, inplace=True)\n",
    "        total_num_cols = 0\n",
    "        for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "            if (split == \"train\") and ((i >= num_train) or (i >= valid_index)):\n",
    "                break\n",
    "            if split == \"valid\" and i < valid_index:\n",
    "                continue\n",
    "            #     break\n",
    "            num_cols = len(group_df)\n",
    "            group_df.sort_values(by=['col_idx'], inplace=True)\n",
    "            labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "            unlabeled_columns = group_df[group_df['class_id'] == -1]\n",
    "            num_unlabeled = min(max(max_unlabeled-len(labeled_columns), 0), len(unlabeled_columns)) if max_unlabeled > 0 else len(unlabeled_columns)\n",
    "            unlabeled_columns = unlabeled_columns.sample(num_unlabeled) if random_sample else unlabeled_columns[0:num_unlabeled]\n",
    "            # group_df = pd.concat([group_df[group_df['class_id'] > -1], unlabeled_columns.sample(min(10-len(labeled_columns), len(unlabeled_columns)))])\n",
    "            # group_df = pd.concat([group_df[group_df['class_id'] > -1], unlabeled_columns[0:min(max(10-len(labeled_columns), 0), len(unlabeled_columns))]])\n",
    "            group_df = pd.concat([group_df[group_df['class_id'] > -1], unlabeled_columns]) \n",
    "            group_df.sort_values(by=['col_idx'], inplace=True) # TODO \n",
    "\n",
    "            if max_length <= 128 and adaptive_max_length:\n",
    "                cur_maxlen = min(max_length, 512 // len(group_df) - 1)\n",
    "            else:\n",
    "                cur_maxlen = max_length\n",
    "                \n",
    "            token_ids_list = group_df[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=cur_maxlen, truncation=True)).tolist(\n",
    "                )\n",
    "            token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                                token_ids_list)).to(device)\n",
    "            for col_i in range(len(token_ids_list)):\n",
    "                if group_df[\"class_id\"].values[col_i] == -1:\n",
    "                    continue\n",
    "                target_col_mask = []\n",
    "                cls_index_value = 0\n",
    "                context_id = 1\n",
    "                for col_j in range(len(token_ids_list)):\n",
    "                    if col_j == col_i:\n",
    "                        target_col_mask += [0] * len(token_ids_list[col_j])\n",
    "                    else:\n",
    "                        target_col_mask += [context_id] * len(token_ids_list[col_j])\n",
    "                        context_id += 1\n",
    "                    if col_j < col_i:\n",
    "                        cls_index_value += len(token_ids_list[col_j])\n",
    "                cls_index_list = [cls_index_value] \n",
    "                for cls_index in cls_index_list:\n",
    "                    assert token_ids[\n",
    "                        cls_index] == tokenizer.cls_token_id, \"cls_indexes validation\"\n",
    "                cls_indexes = torch.LongTensor(cls_index_list).to(device)\n",
    "                class_ids = torch.LongTensor(\n",
    "                    [group_df[\"class_id\"].values[col_i]]).to(device)\n",
    "                target_col_mask = torch.LongTensor(target_col_mask).to(device)\n",
    "                col_idx = group_df[\"col_idx\"].values\n",
    "                data_list.append(\n",
    "                    [index,\n",
    "                    len(group_df), token_ids, class_ids, cls_indexes, target_col_mask, num_cols, col_idx])                \n",
    "        print(split, len(data_list))\n",
    "        self.table_df = pd.DataFrame(data_list,\n",
    "                                     columns=[\n",
    "                                         \"table_id\", \"num_col\", \"data_tensor\",\n",
    "                                         \"label_tensor\", \"cls_indexes\", \"target_col_mask\", \"initial_num_col\", \"col_idx\"\n",
    "                                     ])\n",
    "        \"\"\"\n",
    "        # NOTE: msato contains a small portion of single-col tables. keep it to be consistent.  \n",
    "        if multicol_only:\n",
    "            # Check\n",
    "            num_all_tables = len(self.table_df)\n",
    "            self.table_df = self.table_df[self.table_df[\"num_col\"] > 1]\n",
    "            assert len(self.table_df) == num_all_tables\n",
    "        \"\"\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.table_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"data\": self.table_df.iloc[idx][\"data_tensor\"],\n",
    "            \"label\": self.table_df.iloc[idx][\"label_tensor\"],\n",
    "            \"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"],\n",
    "            \"target_col_mask\": self.table_df.iloc[idx][\"target_col_mask\"],\n",
    "            \"initial_num_col\": self.table_df.iloc[idx][\"initial_num_col\"],\n",
    "            \"col_idx\": self.table_df.iloc[idx][\"col_idx\"]\n",
    "        }\n",
    "        #\"idx\": torch.LongTensor([idx])}\n",
    "        #\"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df[\"col_idx\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_columns.iloc[:len(other_columns)//2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GittablesTablewiseFirstDataset(data.Dataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            cv: int,\n",
    "            split: str,\n",
    "            src: str,  # train or test\n",
    "            tokenizer: AutoTokenizer,\n",
    "            max_length: int = 256,\n",
    "            gt_only: bool = False,\n",
    "            device: torch.device = None,\n",
    "            base_dirpath: str = \"/data/zhihao/TU/GitTables/semtab_gittables/2022\",\n",
    "            base_tag: str = '', # blank, comma\n",
    "            small_tag: str = \"\",\n",
    "            train_ratio: float = 1.0,\n",
    "            max_unlabeled=8,\n",
    "            adaptive_max_length=True,\n",
    "            random_sample=False, # TODO\n",
    "            train_only=False): # TODO\n",
    "        if device is None:\n",
    "            device = torch.device('cpu')\n",
    "        basename = small_tag+ \"_cv_{}.csv\"\n",
    "    \n",
    "        if split in [\"train\", \"valid\"]:\n",
    "            df_list = []\n",
    "            for i in range(5):\n",
    "                if i == cv:\n",
    "                    continue\n",
    "                filepath = os.path.join(base_dirpath, basename.format(i))\n",
    "                df_list.append(pd.read_csv(filepath))\n",
    "                print(split, i)\n",
    "            df = pd.concat(df_list, axis=0)\n",
    "        else:\n",
    "            # test\n",
    "            filepath = os.path.join(base_dirpath, basename.format(cv))\n",
    "            df = pd.read_csv(filepath)\n",
    "            print(split)\n",
    "\n",
    "\n",
    "        if gt_only:\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "        if train_only and split != \"train\":\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "\n",
    "        \n",
    "        data_list = []\n",
    "        \n",
    "        df['class_id'] = df['class_id'].astype(int)\n",
    "        df.drop(df[(df['data'].isna()) & (df['class_id'] == -1)].index, inplace=True)\n",
    "        df['col_idx'] = df['col_idx'].astype(int)\n",
    "        df['data'] = df['data'].astype(str)\n",
    "        \n",
    "        num_tables = len(df.groupby(\"table_id\"))\n",
    "        valid_index = int(num_tables * 0.8)\n",
    "        num_train = int(train_ratio * num_tables * 0.8)        \n",
    "        \n",
    "        # df.drop(df[(df['data'] == '') & (df['class_id'] == -1)].index, inplace=True)\n",
    "        total_num_cols = 0\n",
    "        for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "            if (split == \"train\") and ((i >= num_train) or (i >= valid_index)):\n",
    "                break\n",
    "            if split == \"valid\" and i < valid_index:\n",
    "                continue\n",
    "            #     break\n",
    "            group_df.sort_values(by=['col_idx'], inplace=True)\n",
    "            group_df = group_df.reset_index(drop=True)\n",
    "            labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "            labeled_columns.sort_values(by=['col_idx'], inplace=True)\n",
    "            for index, target_column in labeled_columns.iterrows():\n",
    "                other_columns = group_df.drop(index).head(max_unlabeled-1)\n",
    "                # if len(group_df)-len(target_column)+1 >= max_unlabeled: # TODO\n",
    "                #     other_columns = group_df.drop(labeled_columns.index).head(max_unlabeled-1)\n",
    "                # else:\n",
    "                #     other_columns = group_df.drop(index).head(max_unlabeled-1)\n",
    "\n",
    "                target_table = pd.concat([target_column.to_frame().T, other_columns], ignore_index=True)\n",
    "                # target_table = pd.concat([other_columns.iloc[:len(other_columns)//2], target_column.to_frame().T, other_columns.iloc[len(other_columns)//2:]], ignore_index=True)\n",
    "\n",
    "                target_col_idx = target_column[\"col_idx\"]\n",
    "                target_cls = target_column[\"class_id\"]\n",
    "                target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "                col_idx_list = target_table[\"col_idx\"].tolist()\n",
    "\n",
    "\n",
    "                if max_length <= 128 and adaptive_max_length:\n",
    "                    cur_maxlen = min(max_length, 512 // len(target_table) - 1)\n",
    "                else:\n",
    "                    cur_maxlen = max_length\n",
    "                    \n",
    "                token_ids_list = target_table[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                    tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=cur_maxlen, truncation=True)).tolist(\n",
    "                    )\n",
    "                token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                                    token_ids_list)).to(device)\n",
    "\n",
    "                target_col_mask = []\n",
    "                cls_index_value = 0\n",
    "                context_id = 1\n",
    "                meet_target = False\n",
    "                for idx, col_i in enumerate(col_idx_list):\n",
    "                    if col_i == target_col_idx:\n",
    "                        target_col_mask += [0] * len(token_ids_list[idx])\n",
    "                        meet_target = True\n",
    "                    else:\n",
    "                        target_col_mask += [context_id] * len(token_ids_list[idx])\n",
    "                        context_id += 1\n",
    "                    if not meet_target:\n",
    "                        cls_index_value += len(token_ids_list[idx])\n",
    "                cls_index_list = [cls_index_value] \n",
    "                for cls_index in cls_index_list:\n",
    "                    assert token_ids[\n",
    "                        cls_index] == tokenizer.cls_token_id, \"cls_indexes validation\"\n",
    "                cls_indexes = torch.LongTensor(cls_index_list).to(device)\n",
    "                class_ids = torch.LongTensor(\n",
    "                    [target_cls]).to(device)\n",
    "                target_col_mask = torch.LongTensor(target_col_mask).to(device)\n",
    "                data_list.append(\n",
    "                    [index,\n",
    "                    len(target_table), token_ids, class_ids, cls_indexes, target_col_mask])                        \n",
    "        print(split, len(data_list))\n",
    "        self.table_df = pd.DataFrame(data_list,\n",
    "                                     columns=[\n",
    "                                         \"table_id\", \"num_col\", \"data_tensor\",\n",
    "                                         \"label_tensor\", \"cls_indexes\", \"target_col_mask\",\n",
    "                                     ])\n",
    "        \"\"\"\n",
    "        # NOTE: msato contains a small portion of single-col tables. keep it to be consistent.  \n",
    "        if multicol_only:\n",
    "            # Check\n",
    "            num_all_tables = len(self.table_df)\n",
    "            self.table_df = self.table_df[self.table_df[\"num_col\"] > 1]\n",
    "            assert len(self.table_df) == num_all_tables\n",
    "        \"\"\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.table_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"data\": self.table_df.iloc[idx][\"data_tensor\"],\n",
    "            \"label\": self.table_df.iloc[idx][\"label_tensor\"],\n",
    "            \"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"],\n",
    "            \"target_col_mask\": self.table_df.iloc[idx][\"target_col_mask\"],\n",
    "            \"num_col\": self.table_df.iloc[idx][\"num_col\"],\n",
    "            # \"initial_num_col\": self.table_df.iloc[idx][\"initial_num_col\"],\n",
    "        }\n",
    "        #\"idx\": torch.LongTensor([idx])}\n",
    "        #\"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GittablesTablewiseLastDataset(data.Dataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            cv: int,\n",
    "            split: str,\n",
    "            src: str,  # train or test\n",
    "            tokenizer: AutoTokenizer,\n",
    "            max_length: int = 256,\n",
    "            gt_only: bool = False,\n",
    "            device: torch.device = None,\n",
    "            base_dirpath: str = \"/data/zhihao/TU/GitTables/semtab_gittables/2022\",\n",
    "            base_tag: str = '', # blank, comma\n",
    "            small_tag: str = \"\",\n",
    "            train_ratio: float = 1.0,\n",
    "            max_unlabeled=8,\n",
    "            adaptive_max_length=True,\n",
    "            random_sample=False, # TODO\n",
    "            train_only=False): # TODO\n",
    "        if device is None:\n",
    "            device = torch.device('cpu')\n",
    "        basename = small_tag+ \"_cv_{}.csv\"\n",
    "    \n",
    "        if split in [\"train\", \"valid\"]:\n",
    "            df_list = []\n",
    "            for i in range(5):\n",
    "                if i == cv:\n",
    "                    continue\n",
    "                filepath = os.path.join(base_dirpath, basename.format(i))\n",
    "                df_list.append(pd.read_csv(filepath))\n",
    "                print(split, i)\n",
    "            df = pd.concat(df_list, axis=0)\n",
    "        else:\n",
    "            # test\n",
    "            filepath = os.path.join(base_dirpath, basename.format(cv))\n",
    "            df = pd.read_csv(filepath)\n",
    "            print(split)\n",
    "\n",
    "\n",
    "        if gt_only:\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "        if train_only and split != \"train\":\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "\n",
    "        \n",
    "        data_list = []\n",
    "        \n",
    "        df['class_id'] = df['class_id'].astype(int)\n",
    "        df.drop(df[(df['data'].isna()) & (df['class_id'] == -1)].index, inplace=True)\n",
    "        df['col_idx'] = df['col_idx'].astype(int)\n",
    "        df['data'] = df['data'].astype(str)\n",
    "        \n",
    "        num_tables = len(df.groupby(\"table_id\"))\n",
    "        valid_index = int(num_tables * 0.8)\n",
    "        num_train = int(train_ratio * num_tables * 0.8)        \n",
    "        \n",
    "        # df.drop(df[(df['data'] == '') & (df['class_id'] == -1)].index, inplace=True)\n",
    "        total_num_cols = 0\n",
    "        self.col_idx_list = []\n",
    "        for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "            if (split == \"train\") and ((i >= num_train) or (i >= valid_index)):\n",
    "                break\n",
    "            if split == \"valid\" and i < valid_index:\n",
    "                continue\n",
    "            #     break\n",
    "            group_df.sort_values(by=['col_idx'], inplace=True)\n",
    "            group_df = group_df.reset_index(drop=True)\n",
    "            labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "            labeled_columns.sort_values(by=['col_idx'], inplace=True)\n",
    "            unlabeled_columns = group_df[group_df['class_id'] == -1]\n",
    "            for index, target_column in labeled_columns.iterrows():\n",
    "                other_columns = group_df.drop(index).tail(max_unlabeled-1)\n",
    "                target_table = pd.concat([target_column.to_frame().T, other_columns], ignore_index=True)\n",
    "                \n",
    "                # num_unlabeled = min(max(max_unlabeled-len(labeled_columns), 0), len(unlabeled_columns)) if max_unlabeled > 0 else len(unlabeled_columns)\n",
    "                # target_table = pd.concat([labeled_columns, unlabeled_columns.tail(num_unlabeled)], ignore_index=True)\n",
    "                # if len(group_df) >= 8:\n",
    "                #     assert len(target_table) == max_unlabeled\n",
    "                # else:\n",
    "                #     assert len(target_table) == len(group_df)\n",
    "    \n",
    "                target_col_idx =target_column[\"col_idx\"]\n",
    "                target_cls = target_column[\"class_id\"]\n",
    "                target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "                col_idx_list = target_table[\"col_idx\"].tolist()\n",
    "\n",
    "\n",
    "                if max_length <= 128 and adaptive_max_length:\n",
    "                    cur_maxlen = min(max_length, 512 // len(target_table) - 1)\n",
    "                else:\n",
    "                    cur_maxlen = max_length\n",
    "                    \n",
    "                token_ids_list = target_table[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                    tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=cur_maxlen, truncation=True)).tolist(\n",
    "                    )\n",
    "                token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                                    token_ids_list)).to(device)\n",
    "\n",
    "                target_col_mask = []\n",
    "                cls_index_value = 0\n",
    "                context_id = 1\n",
    "                meet_target = False\n",
    "                for idx, col_i in enumerate(col_idx_list):\n",
    "                    if col_i == target_col_idx:\n",
    "                        target_col_mask += [0] * len(token_ids_list[idx])\n",
    "                        meet_target = True\n",
    "                    else:\n",
    "                        target_col_mask += [context_id] * len(token_ids_list[idx])\n",
    "                        context_id += 1\n",
    "                    if not meet_target:\n",
    "                        cls_index_value += len(token_ids_list[idx])\n",
    "                cls_index_list = [cls_index_value] \n",
    "                for cls_index in cls_index_list:\n",
    "                    assert token_ids[\n",
    "                        cls_index] == tokenizer.cls_token_id, \"cls_indexes validation\"\n",
    "                cls_indexes = torch.LongTensor(cls_index_list).to(device)\n",
    "                class_ids = torch.LongTensor(\n",
    "                    [target_cls]).to(device)\n",
    "                target_col_mask = torch.LongTensor(target_col_mask).to(device)\n",
    "                data_list.append(\n",
    "                    [index,\n",
    "                    len(target_table), token_ids, class_ids, cls_indexes, target_col_mask, col_idx_list])                        \n",
    "        print(split, len(data_list))\n",
    "        self.table_df = pd.DataFrame(data_list,\n",
    "                                     columns=[\n",
    "                                         \"table_id\", \"num_col\", \"data_tensor\",\n",
    "                                         \"label_tensor\", \"cls_indexes\", \"target_col_mask\", \"col_idx_list\"\n",
    "                                     ])\n",
    "        \"\"\"\n",
    "        # NOTE: msato contains a small portion of single-col tables. keep it to be consistent.  \n",
    "        if multicol_only:\n",
    "            # Check\n",
    "            num_all_tables = len(self.table_df)\n",
    "            self.table_df = self.table_df[self.table_df[\"num_col\"] > 1]\n",
    "            assert len(self.table_df) == num_all_tables\n",
    "        \"\"\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.table_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"data\": self.table_df.iloc[idx][\"data_tensor\"],\n",
    "            \"label\": self.table_df.iloc[idx][\"label_tensor\"],\n",
    "            \"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"],\n",
    "            \"target_col_mask\": self.table_df.iloc[idx][\"target_col_mask\"],\n",
    "            \"col_idx_list\": self.table_df.iloc[idx][\"col_idx_list\"],\n",
    "            # \"initial_num_col\": self.table_df.iloc[idx][\"initial_num_col\"],\n",
    "        }\n",
    "        #\"idx\": torch.LongTensor([idx])}\n",
    "        #\"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labeled = df[df[\"class_id\"] > -1]\n",
    "test_labels = df_labeled[\"class_id\"].values\n",
    "similar_label = []\n",
    "for label, x in zip(df_labeled[\"class_id\"], df_labeled[\"data\"]):\n",
    "    scores = bm25.get_scores(tokenizer.encode(\n",
    "                    tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=max_length, truncation=True))\n",
    "    top_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:1]\n",
    "    similar_label.append(training_labeled_class[top_indices[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    token_list = group_df[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "            tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=max_length, truncation=True)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm_group_scores = defaultdict(list)\n",
    "i = 0\n",
    "bm_group_scores[i] =[bm25.get_scores(x) for x in token_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(bm_group_scores[i][0]).topk(1).values.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_classify_acc = 0\n",
    "bm_group_scores = defaultdict(list)\n",
    "K = 1\n",
    "for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "    group_df = group_df.reset_index(drop=True)\n",
    "    # scores = bm25.get_scores(test_dataset_gt[idx][\"data\"].cpu().tolist())\n",
    "    token_list = group_df[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "            tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=max_length, truncation=True)).tolist()\n",
    "    \n",
    "    bm_group_scores[i] =[bm25.get_scores(x) for x in token_list]\n",
    "    semantic_scores = torch.tensor([torch.tensor(score).topk(K).values.mean().item() for score in bm_group_scores[i]])\n",
    "    labeled_columns_index = group_df[group_df['class_id'] > -1].index.to_list()\n",
    "    assert len(labeled_columns_index) < 8\n",
    "    if set(labeled_columns_index).issubset(set(semantic_scores.topk(min(len(group_df), 8)).indices.tolist())):\n",
    "        label_classify_acc += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for K in [1,3,5]:\n",
    "    label_classify_acc = 0\n",
    "    for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "        group_df = group_df.reset_index(drop=True)\n",
    "        # scores = bm25.get_scores(test_dataset_gt[idx][\"data\"].cpu().tolist())\n",
    "        semantic_scores = torch.tensor([torch.tensor(score).topk(K).values.mean().item() for score in bm_group_scores[i]])\n",
    "        labeled_columns_index = group_df[group_df['class_id'] > -1].index.to_list()\n",
    "        assert len(labeled_columns_index) < 8\n",
    "        if set(labeled_columns_index).issubset(set(semantic_scores.topk(min(len(group_df), 8)).indices.tolist())):\n",
    "            label_classify_acc += 1\n",
    "    print(f\"************************** K={K} **************************\")\n",
    "    print(label_classify_acc/len(df.groupby(\"table_id\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_classify_acc = 0\n",
    "bm_group_scores_ind = defaultdict(list)\n",
    "K = 1\n",
    "for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "    group_df = group_df.reset_index(drop=True)\n",
    "    # scores = bm25.get_scores(test_dataset_gt[idx][\"data\"].cpu().tolist())\n",
    "    token_list = group_df[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "            tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=max_length, truncation=True)).tolist()\n",
    "    \n",
    "    bm_group_scores_ind[i] =[bm25_ind.get_scores(x) for x in token_list]\n",
    "    semantic_scores = torch.tensor([torch.tensor(score).topk(K).values.mean().item() for score in bm_group_scores_ind[i]])\n",
    "    labeled_columns_index = group_df[group_df['class_id'] > -1].index.to_list()\n",
    "    assert len(labeled_columns_index) < 8\n",
    "    if set(labeled_columns_index).issubset(set(semantic_scores.topk(min(len(group_df), 8)).indices.tolist())):\n",
    "        label_classify_acc += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for K in [1,3,5]:\n",
    "    label_classify_acc = 0\n",
    "    for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "        group_df = group_df.reset_index(drop=True)\n",
    "        # scores = bm25.get_scores(test_dataset_gt[idx][\"data\"].cpu().tolist())\n",
    "        semantic_scores = torch.tensor([torch.tensor(score).topk(K).values.mean().item() for score in bm_group_scores_ind[i]])\n",
    "        labeled_columns_index = group_df[group_df['class_id'] > -1].index.to_list()\n",
    "        assert len(labeled_columns_index) < 8\n",
    "        if set(labeled_columns_index).issubset(set(semantic_scores.topk(min(len(group_df), 8)).indices.tolist())):\n",
    "            label_classify_acc += 1\n",
    "    print(f\"************************** K={K} **************************\")\n",
    "    print(label_classify_acc/len(df.groupby(\"table_id\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for K in [1]:\n",
    "    label_classify_acc = []\n",
    "    for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "        group_df = group_df.reset_index(drop=True)\n",
    "        # scores = bm25.get_scores(test_dataset_gt[idx][\"data\"].cpu().tolist())\n",
    "        semantic_scores = torch.tensor([torch.tensor(score).topk(K).values.mean().item() for score in bm_group_scores_ind[i]])\n",
    "        labeled_columns_index = group_df[group_df['class_id'] > -1].index.to_list()\n",
    "        assert len(labeled_columns_index) < 8\n",
    "        if set(labeled_columns_index).issubset(set(semantic_scores.topk(min(len(group_df), 8)).indices.tolist())):\n",
    "            label_classify_acc.append(1)\n",
    "        else:\n",
    "            label_classify_acc.append(0)\n",
    "    print(f\"************************** K={K} **************************\")\n",
    "    label_classify_acc = torch.tensor(label_classify_acc)\n",
    "    print(label_classify_acc[num_cols>8].sum()/(num_cols>8).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_classify_acc/len(df.groupby(\"table_id\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_scores.topk(min(len(group_df), 8)).indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_label = torch.tensor(similar_label)\n",
    "test_labels = torch.tensor(test_labels)\n",
    "(similar_label==test_labels).sum().item()/len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labeled = df[df[\"class_id\"] > -1]\n",
    "test_labels = df_labeled[\"class_id\"].values\n",
    "similar_label = []\n",
    "for label, x in zip(df_labeled[\"class_id\"], df_labeled[\"data\"]):\n",
    "    scores = F.cosine_similarity(training_corpus_embs, torch.tensor(sb_model.encode([x])).cpu().reshape(1,-1))\n",
    "    top_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:1]\n",
    "    similar_label.append(training_labeled_class[top_indices[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_label = torch.tensor(similar_label)\n",
    "test_labels = torch.tensor(test_labels)\n",
    "(similar_label==test_labels).sum().item()/len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_classify_acc = 0\n",
    "for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "    group_df = group_df.reset_index(drop=True)\n",
    "    # scores = bm25.get_scores(test_dataset_gt[idx][\"data\"].cpu().tolist())\n",
    "    semantic_scores = torch.tensor(group_df[\"data\"].apply(lambda x: max(F.cosine_similarity(training_corpus_embs, torch.tensor(sb_model.encode([x])).cpu().reshape(1,-1)))))\n",
    "    labeled_columns_index = group_df[group_df['class_id'] > -1].index.to_list()\n",
    "    assert len(labeled_columns_index) < 8\n",
    "    if set(labeled_columns_index).issubset(set(semantic_scores.topk(min(len(group_df), 8)).indices.tolist())):\n",
    "        label_classify_acc += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_classify_acc/len(df.groupby(\"table_id\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_list = sb_model.encode(group_df[\"data\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = []\n",
    "for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "    num_cols.append(len(group_df))\n",
    "num_cols = torch.tensor(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_classify_acc = []\n",
    "for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "    group_df = group_df.reset_index(drop=True)\n",
    "    # scores = bm25.get_scores(test_dataset_gt[idx][\"data\"].cpu().tolist())\n",
    "    semantic_scores = torch.tensor(group_df[\"data\"].apply(lambda x: max(F.cosine_similarity(training_corpus_embs_ind, torch.tensor(sb_model.encode([x])).cpu().reshape(1,-1)))))\n",
    "    labeled_columns_index = group_df[group_df['class_id'] > -1].index.to_list()\n",
    "    assert len(labeled_columns_index) < 8\n",
    "    if set(labeled_columns_index).issubset(set(semantic_scores.topk(min(len(group_df), 8)).indices.tolist())):\n",
    "        label_classify_acc.append(1)\n",
    "    else:\n",
    "        label_classify_acc.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_classify_acc = torch.tensor(label_classify_acc)\n",
    "print(label_classify_acc.sum().item()/len(df.groupby(\"table_id\")))\n",
    "print(label_classify_acc[num_cols>8].sum()/(num_cols>8).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_classify_acc = []\n",
    "for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "    group_df = group_df.reset_index(drop=True)\n",
    "    # scores = bm25.get_scores(test_dataset_gt[idx][\"data\"].cpu().tolist())\n",
    "    semantic_scores = torch.tensor(group_df[\"data\"].apply(lambda x: max(F.cosine_similarity(training_corpus_embs_ind, torch.tensor(sb_model.encode([x])).cpu().reshape(1,-1)))))\n",
    "    labeled_columns_index = group_df[group_df['class_id'] > -1].index.to_list()\n",
    "    assert len(labeled_columns_index) < 8\n",
    "    if set(labeled_columns_index).issubset(set(semantic_scores.topk(min(len(group_df), 8)).indices.tolist())):\n",
    "        label_classify_acc.append(1)\n",
    "    else:\n",
    "        label_classify_acc.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = group_df[\"data\"].to_list()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EU distance\n",
    "label_classify_acc = []\n",
    "for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "    group_df = group_df.reset_index(drop=True)\n",
    "    # scores = bm25.get_scores(test_dataset_gt[idx][\"data\"].cpu().tolist())\n",
    "    semantic_scores = torch.tensor(group_df[\"data\"].apply(lambda x: (1/(torch.cdist(training_corpus_embs_ind, torch.tensor(sb_model.encode([x])).cpu().reshape(1,-1)+1e-5))).max().item()).tolist())\n",
    "    labeled_columns_index = group_df[group_df['class_id'] > -1].index.to_list()\n",
    "    assert len(labeled_columns_index) < 8\n",
    "    if set(labeled_columns_index).issubset(set(semantic_scores.topk(min(len(group_df), 8)).indices.tolist())):\n",
    "        label_classify_acc.append(1)\n",
    "    else:\n",
    "        label_classify_acc.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_classify_acc = torch.tensor(label_classify_acc)\n",
    "print(label_classify_acc.sum().item()/len(df.groupby(\"table_id\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MahalanobisDistance(object):\n",
    "    def __init__(self, ftrain, labels_train):\n",
    "        self.xc = [ftrain[labels_train == i] for i in np.unique(labels_train)]\n",
    "        self.cov_inv = torch.linalg.pinv(torch.Tensor(np.cov(ftrain.T, bias=True))).numpy()\n",
    "    def __call__(self, ftest):\n",
    "        dtest = [\n",
    "            np.sum(\n",
    "                (ftest - np.mean(x, axis=0, keepdims=True))\n",
    "                * (\n",
    "                    self.cov_inv.dot(\n",
    "                        (ftest - np.mean(x, axis=0, keepdims=True)).T\n",
    "                    )\n",
    "                ).T,\n",
    "                axis=-1,\n",
    "            )\n",
    "            for x in self.xc\n",
    "        ]\n",
    "\n",
    "        dtest = np.min(dtest, axis=0)\n",
    "\n",
    "        return dtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_distance = MahalanobisDistance(training_corpus_embs_doduo.numpy(), training_corpus_labels.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_corpus_embs_doduo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4348, 768])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_corpus_embs_doduo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mahalanobis distance\n",
    "for K in [1]:\n",
    "    print(f\"************************** K={K} **************************\")\n",
    "    label_classify_acc = []\n",
    "    for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "        group_df = group_df.reset_index(drop=True)\n",
    "        token_list = group_df[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=max_length, truncation=True)).tolist()\n",
    "        token_list = torch.nn.utils.rnn.pad_sequence(\n",
    "        [torch.LongTensor(tokens) for tokens in token_list], padding_value=0).T.to(device)\n",
    "        cls_indexes = torch.nonzero(\n",
    "                    token_list == tokenizer.cls_token_id)\n",
    "        logits, embs = model(token_list, cls_indexes=cls_indexes, get_enc=True)\n",
    "        embs = embs.cpu()\n",
    "        if len(embs.size()) == 1:\n",
    "            embs = embs.unsqueeze(0)\n",
    "        semantic_scores = 1 / torch.tensor(md_distance(embs.detach().cpu().numpy()))\n",
    "        labeled_columns_index = group_df[group_df['class_id'] > -1].index.to_list()\n",
    "        assert len(labeled_columns_index) < 8\n",
    "        if set(labeled_columns_index).issubset(set(semantic_scores.topk(min(len(group_df), 8)).indices.tolist())):\n",
    "            label_classify_acc.append(1)\n",
    "        else:\n",
    "            label_classify_acc.append(0)\n",
    "    label_classify_acc = torch.tensor(label_classify_acc)\n",
    "    print(label_classify_acc.sum().item()/len(df.groupby(\"table_id\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_corpus_embs_doduo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.norm(training_corpus_embs_doduo, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_distance_cos = MahalanobisDistance(F.normalize(training_corpus_embs_doduo).numpy(), training_corpus_labels.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = F.normalize(training_corpus_embs_doduo).mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = F.normalize(training_corpus_embs_doduo.mean(1, keepdim=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mahalanobis distance COS\n",
    "for K in [1]:\n",
    "    print(f\"************************** K={K} **************************\")\n",
    "    label_classify_acc = []\n",
    "    for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "        group_df = group_df.reset_index(drop=True)\n",
    "        token_list = group_df[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=max_length, truncation=True)).tolist()\n",
    "        token_list = torch.nn.utils.rnn.pad_sequence(\n",
    "        [torch.LongTensor(tokens) for tokens in token_list], padding_value=0).T.to(device)\n",
    "        cls_indexes = torch.nonzero(\n",
    "                    token_list == tokenizer.cls_token_id)\n",
    "        logits, embs = model(token_list, cls_indexes=cls_indexes, get_enc=True)\n",
    "        embs = embs.cpu()\n",
    "        if len(embs.size()) == 1:\n",
    "            embs = embs.unsqueeze(0)\n",
    "        semantic_scores = 1 / torch.tensor(md_distance_cos(F.normalize(embs.detach().cpu()).numpy()))\n",
    "        labeled_columns_index = group_df[group_df['class_id'] > -1].index.to_list()\n",
    "        assert len(labeled_columns_index) < 8\n",
    "        if set(labeled_columns_index).issubset(set(semantic_scores.topk(min(len(group_df), 8)).indices.tolist())):\n",
    "            label_classify_acc.append(1)\n",
    "        else:\n",
    "            label_classify_acc.append(0)\n",
    "    label_classify_acc = torch.tensor(label_classify_acc)\n",
    "    print(label_classify_acc.sum().item()/len(df.groupby(\"table_id\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for K in [1,3,5]:\n",
    "    print(f\"************************** K={K} **************************\")\n",
    "    label_classify_acc = []\n",
    "    for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "        group_df = group_df.reset_index(drop=True)\n",
    "        token_list = group_df[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=max_length, truncation=True)).tolist()\n",
    "        token_list = torch.nn.utils.rnn.pad_sequence(\n",
    "        [torch.LongTensor(tokens) for tokens in token_list], padding_value=0).T.to(device)\n",
    "        cls_indexes = torch.nonzero(\n",
    "                    token_list == tokenizer.cls_token_id)\n",
    "        logits, embs = model(token_list, cls_indexes=cls_indexes, get_enc=True)\n",
    "        embs = embs.cpu()\n",
    "        if len(embs.size()) == 1:\n",
    "            embs = embs.unsqueeze(0)\n",
    "        semantic_scores = torch.mm(training_corpus_embs_doduo/ training_corpus_embs_doduo.norm(dim=1, keepdim=True), (embs/ embs.norm(dim=1, keepdim=True)).T).T.topk(K).values.mean(1)\n",
    "        labeled_columns_index = group_df[group_df['class_id'] > -1].index.to_list()\n",
    "        assert len(labeled_columns_index) < 8\n",
    "        if set(labeled_columns_index).issubset(set(semantic_scores.topk(min(len(group_df), 8)).indices.tolist())):\n",
    "            label_classify_acc.append(1)\n",
    "        else:\n",
    "            label_classify_acc.append(0)\n",
    "    label_classify_acc = torch.tensor(label_classify_acc)\n",
    "    print(label_classify_acc.sum().item()/len(df.groupby(\"table_id\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EU\n",
    "for K in [1]:\n",
    "    print(f\"************************** K={K} **************************\")\n",
    "    label_classify_acc = []\n",
    "    for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "        group_df = group_df.reset_index(drop=True)\n",
    "        token_list = group_df[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=max_length, truncation=True)).tolist()\n",
    "        token_list = torch.nn.utils.rnn.pad_sequence(\n",
    "        [torch.LongTensor(tokens) for tokens in token_list], padding_value=0).T.to(device)\n",
    "        cls_indexes = torch.nonzero(\n",
    "                    token_list == tokenizer.cls_token_id)\n",
    "        logits, embs = model(token_list, cls_indexes=cls_indexes, get_enc=True)\n",
    "        embs = embs.cpu()\n",
    "        if len(embs.size()) == 1:\n",
    "            embs = embs.unsqueeze(0)\n",
    "        semantic_scores = (1/ (torch.cdist(embs, training_corpus_embs_doduo)+1e-5)).topk(K).values.mean(1)\n",
    "        labeled_columns_index = group_df[group_df['class_id'] > -1].index.to_list()\n",
    "        assert len(labeled_columns_index) < 8\n",
    "        if set(labeled_columns_index).issubset(set(semantic_scores.topk(min(len(group_df), 8)).indices.tolist())):\n",
    "            label_classify_acc.append(1)\n",
    "        else:\n",
    "            label_classify_acc.append(0)\n",
    "    label_classify_acc = torch.tensor(label_classify_acc)\n",
    "    print(label_classify_acc.sum().item()/len(df.groupby(\"table_id\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_corpus_embs_doduo_center.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class center\n",
    "for K in [1,3,5]:\n",
    "    print(f\"************************** K={K} **************************\")\n",
    "    label_classify_acc = []\n",
    "    for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "        group_df = group_df.reset_index(drop=True)\n",
    "        token_list = group_df[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=max_length, truncation=True)).tolist()\n",
    "        token_list = torch.nn.utils.rnn.pad_sequence(\n",
    "        [torch.LongTensor(tokens) for tokens in token_list], padding_value=0).T.to(device)\n",
    "        cls_indexes = torch.nonzero(\n",
    "                    token_list == tokenizer.cls_token_id)\n",
    "        logits, embs = model(token_list, cls_indexes=cls_indexes, get_enc=True)\n",
    "        embs = embs.cpu()\n",
    "        if len(embs.size()) == 1:\n",
    "            embs = embs.unsqueeze(0)\n",
    "        semantic_scores = torch.mm(training_corpus_embs_doduo_center/ training_corpus_embs_doduo_center.norm(dim=1, keepdim=True), (embs/ embs.norm(dim=1, keepdim=True)).T).T.topk(K).values.mean(1)\n",
    "        labeled_columns_index = group_df[group_df['class_id'] > -1].index.to_list()\n",
    "        assert len(labeled_columns_index) < 8\n",
    "        if set(labeled_columns_index).issubset(set(semantic_scores.topk(min(len(group_df), 8)).indices.tolist())):\n",
    "            label_classify_acc.append(1)\n",
    "        else:\n",
    "            label_classify_acc.append(0)\n",
    "    label_classify_acc = torch.tensor(label_classify_acc)\n",
    "    print(label_classify_acc.sum().item()/len(df.groupby(\"table_id\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class center EU\n",
    "for K in [1,3,5]:\n",
    "    print(f\"************************** K={K} **************************\")\n",
    "    label_classify_acc = []\n",
    "    for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "        group_df = group_df.reset_index(drop=True)\n",
    "        token_list = group_df[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=max_length, truncation=True)).tolist()\n",
    "        token_list = torch.nn.utils.rnn.pad_sequence(\n",
    "        [torch.LongTensor(tokens) for tokens in token_list], padding_value=0).T.to(device)\n",
    "        cls_indexes = torch.nonzero(\n",
    "                    token_list == tokenizer.cls_token_id)\n",
    "        logits, embs = model(token_list, cls_indexes=cls_indexes, get_enc=True)\n",
    "        embs = embs.cpu()\n",
    "        if len(embs.size()) == 1:\n",
    "            embs = embs.unsqueeze(0)\n",
    "        semantic_scores = (1/ (torch.cdist(embs, training_corpus_embs_doduo_center)+1e-5)).topk(K).values.mean(1)\n",
    "        labeled_columns_index = group_df[group_df['class_id'] > -1].index.to_list()\n",
    "        assert len(labeled_columns_index) < 8\n",
    "        if set(labeled_columns_index).issubset(set(semantic_scores.topk(min(len(group_df), 8)).indices.tolist())):\n",
    "            label_classify_acc.append(1)\n",
    "        else:\n",
    "            label_classify_acc.append(0)\n",
    "    label_classify_acc = torch.tensor(label_classify_acc)\n",
    "    print(label_classify_acc.sum().item()/len(df.groupby(\"table_id\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all training embs\n",
    "for K in [1,3,5]:\n",
    "    print(f\"************************** K={K} **************************\")\n",
    "    label_classify_acc = []\n",
    "    for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "        group_df = group_df.reset_index(drop=True)\n",
    "        token_list = group_df[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=max_length, truncation=True)).tolist()\n",
    "        token_list = torch.nn.utils.rnn.pad_sequence(\n",
    "        [torch.LongTensor(tokens) for tokens in token_list], padding_value=0).T.to(device)\n",
    "        cls_indexes = torch.nonzero(\n",
    "                    token_list == tokenizer.cls_token_id)\n",
    "        logits, embs = model(token_list, cls_indexes=cls_indexes, get_enc=True)\n",
    "        embs = embs.cpu()\n",
    "        if len(embs.size()) == 1:\n",
    "            embs = embs.unsqueeze(0)\n",
    "        semantic_scores = torch.mm(training_corpus_embs_doduo_all/ training_corpus_embs_doduo_all.norm(dim=1, keepdim=True), (embs/ embs.norm(dim=1, keepdim=True)).T).T.topk(K).values.mean(1)\n",
    "        labeled_columns_index = group_df[group_df['class_id'] > -1].index.to_list()\n",
    "        assert len(labeled_columns_index) < 8\n",
    "        if set(labeled_columns_index).issubset(set(semantic_scores.topk(min(len(group_df), 8)).indices.tolist())):\n",
    "            label_classify_acc.append(1)\n",
    "        else:\n",
    "            label_classify_acc.append(0)\n",
    "    label_classify_acc = torch.tensor(label_classify_acc)\n",
    "    print(label_classify_acc.sum().item()/len(df.groupby(\"table_id\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mm(training_corpus_embs_doduo/ training_corpus_embs_doduo.norm(dim=1, keepdim=True), (embs/ embs.norm(dim=1, keepdim=True)).T).T.topk(5).values.mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(num_cols>8).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_classify_acc/len(df.groupby(\"table_id\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = F.cosine_similarity(training_corpus_embs_ind, torch.tensor(sb_model.encode([df_labeled_corpus[idx]])).cpu().reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in group_df[\"data\"]:\n",
    "#     print(x)\n",
    "#     scores = bm25.get_scores(tokenizer.encode(\n",
    "#                     tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=max_length, truncation=True))\n",
    "#     top_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:5]\n",
    "\n",
    "#     # Fetch the top 5 documents\n",
    "#     top_documents = [training_labeled_corpus[i] for i in top_indices]\n",
    "#     for i, doc in enumerate(top_documents):\n",
    "#         print(f\"Rank {i+1}: Document: {tokenizer.decode(doc)} => BM25 Score: {scores[top_indices[i]]}\")\n",
    "#     print(\"*******************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "class GittablesTablewiseIterateClusterExtraDataset(data.Dataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            cv: int,\n",
    "            split: str,\n",
    "            src: str,  # train or test\n",
    "            tokenizer: AutoTokenizer,\n",
    "            max_length: int = 256,\n",
    "            gt_only: bool = False,\n",
    "            device: torch.device = None,\n",
    "            base_dirpath: str = \"/data/zhihao/TU/GitTables/semtab_gittables/2022\",\n",
    "            base_tag: str = '', # blank, comma\n",
    "            small_tag: str = \"\",\n",
    "            train_ratio: float = 1.0,\n",
    "            max_unlabeled=8,\n",
    "            adaptive_max_length=True,\n",
    "            random_sample=False, # TODO\n",
    "            train_only=False,\n",
    "            training_corpus_embs_doduo=None,\n",
    "            df_train_labeled=None, \n",
    "            kmeans=None): # TODO\n",
    "        if device is None:\n",
    "            device = torch.device('cpu')\n",
    "        basename = small_tag+ \"_cv_{}.csv\"\n",
    "    \n",
    "        if split in [\"train\", \"valid\"]:\n",
    "            df_list = []\n",
    "            for i in range(5):\n",
    "                if i == cv:\n",
    "                    continue\n",
    "                filepath = os.path.join(base_dirpath, basename.format(i))\n",
    "                df_list.append(pd.read_csv(filepath))\n",
    "                print(split, i)\n",
    "            df = pd.concat(df_list, axis=0)\n",
    "        else:\n",
    "            # test\n",
    "            filepath = os.path.join(base_dirpath, basename.format(cv))\n",
    "            df = pd.read_csv(filepath)\n",
    "            print(split)\n",
    "\n",
    "\n",
    "        if gt_only:\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "        if train_only and split != \"train\":\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "\n",
    "        \n",
    "        data_list = []\n",
    "        \n",
    "        df['class_id'] = df['class_id'].astype(int)\n",
    "        df.drop(df[(df['data'].isna()) & (df['class_id'] == -1)].index, inplace=True)\n",
    "        df['col_idx'] = df['col_idx'].astype(int)\n",
    "        df['data'] = df['data'].astype(str)\n",
    "        \n",
    "        num_tables = len(df.groupby(\"table_id\"))\n",
    "        valid_index = int(num_tables * 0.8)\n",
    "        num_train = int(train_ratio * num_tables * 0.8)        \n",
    "        \n",
    "        \n",
    "\n",
    "        # kmeans = KMeans(n_clusters=max_unlabeled-1, random_state=0).fit(training_corpus_embs_doduo)\n",
    "        centers = torch.tensor(kmeans.cluster_centers_)\n",
    "        cluster_labels = torch.tensor(kmeans.labels_)\n",
    "        training_embs_cluster = []\n",
    "        training_embs_cluster_index = []\n",
    "        for cluster_i in np.unique(kmeans.labels_):\n",
    "            training_embs_cluster.append(training_corpus_embs_doduo[cluster_labels == cluster_i])\n",
    "            training_embs_cluster_index.append((cluster_labels == cluster_i).nonzero().reshape(-1))\n",
    "        num_clusters = len(training_embs_cluster)\n",
    "                \n",
    "                \n",
    "        total_num_cols = 0\n",
    "        self.correctness_checklist = []\n",
    "        for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "            if (split == \"train\") and ((i >= num_train) or (i >= valid_index)):\n",
    "                break\n",
    "            if split == \"valid\" and i < valid_index:\n",
    "                continue\n",
    "            #     break\n",
    "            \n",
    "            group_df = group_df.reset_index(drop=True)\n",
    "\n",
    "                \n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                token_list = group_df[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                        tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=max_length, truncation=True)).tolist()\n",
    "                token_list = torch.nn.utils.rnn.pad_sequence(\n",
    "                [torch.LongTensor(tokens) for tokens in token_list], padding_value=0).T.to(device)\n",
    "                cls_indexes = torch.nonzero(\n",
    "                            token_list == tokenizer.cls_token_id)\n",
    "                logits, embs = model(token_list, cls_indexes=cls_indexes, get_enc=True)\n",
    "                col_embs = embs.cpu()\n",
    "                if len(embs.size()) == 1:\n",
    "                    col_embs = col_embs.unsqueeze(0)\n",
    "                        \n",
    "            labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "            labeled_columns.sort_values(by=['col_idx'], inplace=True)\n",
    "            for index, target_column in labeled_columns.iterrows():\n",
    "                target_col_idx = target_column[\"col_idx\"]\n",
    "                if len(group_df) < max_unlabeled:\n",
    "                    closest_cols = []\n",
    "                    cloeses_scores = []\n",
    "                    for i in range(num_clusters):\n",
    "                        sim = F.cosine_similarity(training_embs_cluster[i], col_embs[index].reshape(1, -1))\n",
    "                        sim_score_i = sim.max().item()\n",
    "                        closest_index = training_embs_cluster_index[i][sim.argmax().item()].item()\n",
    "                        closest_cols.append(closest_index)\n",
    "                        cloeses_scores.append(sim_score_i)\n",
    "                    cloeses_scores_topk = torch.Tensor(cloeses_scores).argsort(descending=True)[:max_unlabeled-len(group_df)]\n",
    "                    closest_cols = torch.tensor(closest_cols)[cloeses_scores_topk].tolist()\n",
    "                    target_table = pd.concat([group_df, df_train_labeled.iloc[closest_cols]], ignore_index=True)\n",
    "                    assert len(target_table) == max_unlabeled\n",
    "                    # if len(target_table) < max_unlabeled:\n",
    "                    #     print(len(target_table), max_unlabeled)\n",
    "                else:\n",
    "                    target_table = group_df\n",
    "\n",
    "    \n",
    "                \n",
    "                target_cls = target_column[\"class_id\"]\n",
    "                target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "                col_idx_list = target_table[\"col_idx\"].tolist()\n",
    "                # target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "\n",
    "                if max_length <= 128 and adaptive_max_length:\n",
    "                    cur_maxlen = min(max_length, 512 // len(target_table) - 1)\n",
    "                else:\n",
    "                    cur_maxlen = max_length\n",
    "                    \n",
    "                token_ids_list = target_table[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                    tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=cur_maxlen, truncation=True)).tolist(\n",
    "                    )\n",
    "                token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                                    token_ids_list)).to(device)\n",
    "\n",
    "                target_col_mask = []\n",
    "                cls_index_value = 0\n",
    "                context_id = 1\n",
    "                meet_target = False\n",
    "                for idx, col_i in enumerate(col_idx_list):\n",
    "                    if col_i == target_col_idx:\n",
    "                        target_col_mask += [0] * len(token_ids_list[idx])\n",
    "                        meet_target = True\n",
    "                    else:\n",
    "                        target_col_mask += [context_id] * len(token_ids_list[idx])\n",
    "                        context_id += 1\n",
    "                    if not meet_target:\n",
    "                        cls_index_value += len(token_ids_list[idx])\n",
    "                cls_index_list = [cls_index_value] \n",
    "                for cls_index in cls_index_list:\n",
    "                    assert token_ids[\n",
    "                        cls_index] == tokenizer.cls_token_id, \"cls_indexes validation\"\n",
    "                cls_indexes = torch.LongTensor(cls_index_list).to(device)\n",
    "                class_ids = torch.LongTensor(\n",
    "                    [target_cls]).to(device)\n",
    "                target_col_mask = torch.LongTensor(target_col_mask).to(device)\n",
    "                data_list.append(\n",
    "                    [index,\n",
    "                    len(target_table), token_ids, class_ids, cls_indexes, target_col_mask])                \n",
    "        print(split, len(data_list))\n",
    "        self.table_df = pd.DataFrame(data_list,\n",
    "                                     columns=[\n",
    "                                         \"table_id\", \"num_col\", \"data_tensor\",\n",
    "                                         \"label_tensor\", \"cls_indexes\", \"target_col_mask\"\n",
    "                                     ])\n",
    "        \"\"\"\n",
    "        # NOTE: msato contains a small portion of single-col tables. keep it to be consistent.  \n",
    "        if multicol_only:\n",
    "            # Check\n",
    "            num_all_tables = len(self.table_df)\n",
    "            self.table_df = self.table_df[self.table_df[\"num_col\"] > 1]\n",
    "            assert len(self.table_df) == num_all_tables\n",
    "        \"\"\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.table_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"data\": self.table_df.iloc[idx][\"data_tensor\"],\n",
    "            \"label\": self.table_df.iloc[idx][\"label_tensor\"],\n",
    "            \"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"],\n",
    "            \"target_col_mask\": self.table_df.iloc[idx][\"target_col_mask\"],\n",
    "        }\n",
    "        #\"idx\": torch.LongTensor([idx])}\n",
    "        #\"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "class GittablesTablewiseIterateClusterDataset(data.Dataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            cv: int,\n",
    "            split: str,\n",
    "            src: str,  # train or test\n",
    "            tokenizer: AutoTokenizer,\n",
    "            max_length: int = 256,\n",
    "            gt_only: bool = False,\n",
    "            device: torch.device = None,\n",
    "            base_dirpath: str = \"/data/zhihao/TU/GitTables/semtab_gittables/2022\",\n",
    "            base_tag: str = '', # blank, comma\n",
    "            small_tag: str = \"\",\n",
    "            train_ratio: float = 1.0,\n",
    "            max_unlabeled=8,\n",
    "            adaptive_max_length=True,\n",
    "            random_sample=False, # TODO\n",
    "            train_only=False): # TODO\n",
    "        if device is None:\n",
    "            device = torch.device('cpu')\n",
    "        basename = small_tag+ \"_cv_{}.csv\"\n",
    "    \n",
    "        if split in [\"train\", \"valid\"]:\n",
    "            df_list = []\n",
    "            for i in range(5):\n",
    "                if i == cv:\n",
    "                    continue\n",
    "                filepath = os.path.join(base_dirpath, basename.format(i))\n",
    "                df_list.append(pd.read_csv(filepath))\n",
    "                print(split, i)\n",
    "            df = pd.concat(df_list, axis=0)\n",
    "        else:\n",
    "            # test\n",
    "            filepath = os.path.join(base_dirpath, basename.format(cv))\n",
    "            df = pd.read_csv(filepath)\n",
    "            print(split)\n",
    "\n",
    "\n",
    "        if gt_only:\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "        if train_only and split != \"train\":\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "\n",
    "        \n",
    "        data_list = []\n",
    "        \n",
    "        df['class_id'] = df['class_id'].astype(int)\n",
    "        df.drop(df[(df['data'].isna()) & (df['class_id'] == -1)].index, inplace=True)\n",
    "        df['col_idx'] = df['col_idx'].astype(int)\n",
    "        df['data'] = df['data'].astype(str)\n",
    "        \n",
    "        num_tables = len(df.groupby(\"table_id\"))\n",
    "        valid_index = int(num_tables * 0.8)\n",
    "        num_train = int(train_ratio * num_tables * 0.8)        \n",
    "        \n",
    "        # df.drop(df[(df['data'] == '') & (df['class_id'] == -1)].index, inplace=True)\n",
    "        total_num_cols = 0\n",
    "        self.correctness_checklist = []\n",
    "        for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "            if (split == \"train\") and ((i >= num_train) or (i >= valid_index)):\n",
    "                break\n",
    "            if split == \"valid\" and i < valid_index:\n",
    "                continue\n",
    "            #     break\n",
    "            \n",
    "            group_df = group_df.reset_index(drop=True)\n",
    "            # scores = bm25.get_scores(test_dataset_gt[idx][\"data\"].cpu().tolist())\n",
    "            # semantic_scores = torch.tensor(group_df[\"data\"].apply(lambda x: max(bm25.get_scores(tokenizer.encode(\n",
    "            #         tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=max_length, truncation=True)))))\n",
    "            \n",
    "            # labeled_columns_index = group_df[group_df['class_id'] > -1].index.to_list()\n",
    "            # assert len(labeled_columns_index) < 8\n",
    "            # if set(labeled_columns_index).issubset(set(semantic_scores.topk(min(len(group_df), max_unlabeled)).indices.tolist())):\n",
    "            #     self.correctness_checklist.append(1)\n",
    "            # else:\n",
    "            #     self.correctness_checklist.append(0)\n",
    "            if len(group_df) > max_unlabeled:\n",
    "                # col_embs = sb_model.encode(group_df[\"data\"].to_list())\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    model.eval()\n",
    "                    token_list = group_df[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                            tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=max_length, truncation=True)).tolist()\n",
    "                    token_list = torch.nn.utils.rnn.pad_sequence(\n",
    "                    [torch.LongTensor(tokens) for tokens in token_list], padding_value=0).T.to(device)\n",
    "                    cls_indexes = torch.nonzero(\n",
    "                                token_list == tokenizer.cls_token_id)\n",
    "                    logits, embs = model(token_list, cls_indexes=cls_indexes, get_enc=True)\n",
    "                    col_embs = embs.cpu()\n",
    "                    if len(embs.size()) == 1:\n",
    "                        col_embs = col_embs.unsqueeze(0)\n",
    "                        \n",
    "                kmeans = KMeans(n_clusters=max_unlabeled-1, random_state=0).fit(col_embs)\n",
    "                centers = torch.tensor(kmeans.cluster_centers_)\n",
    "                col_embs = torch.tensor(col_embs)\n",
    "                cluster_labels = torch.tensor(kmeans.labels_)\n",
    "                col_embs_cluster = []\n",
    "                col_embs_cluster_index = []\n",
    "                for cluster_i in np.unique(kmeans.labels_):\n",
    "                    col_embs_cluster.append(col_embs[cluster_labels == cluster_i])\n",
    "                    col_embs_cluster_index.append((cluster_labels == cluster_i).nonzero().reshape(-1))\n",
    "                num_clusters = len(col_embs_cluster)\n",
    "            labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "            labeled_columns.sort_values(by=['col_idx'], inplace=True)\n",
    "            for index, target_column in labeled_columns.iterrows():\n",
    "                target_col_idx = target_column[\"col_idx\"]\n",
    "                if len(group_df) > max_unlabeled:\n",
    "                    closest_cols = []\n",
    "                    for i in range(num_clusters):\n",
    "                        # try:\n",
    "                        sim = F.cosine_similarity(col_embs_cluster[i], col_embs[index].reshape(1, -1))\n",
    "                        # except:\n",
    "                        #     raise ValueError(\"here\")\n",
    "                        # try:\n",
    "                        closest_index = col_embs_cluster_index[i][sim.argmax().item()].item()\n",
    "                        # except:\n",
    "                        #     print(\"here\")\n",
    "                        if closest_index == index and len(col_embs_cluster[i]) > 1:\n",
    "                            closest_index = col_embs_cluster_index[i][sim.argsort(descending=True)[1].item()].item()\n",
    "                        closest_cols.append(closest_index)\n",
    "                    other_columns = group_df.iloc[closest_cols]\n",
    "                else:\n",
    "                    other_columns = group_df.drop(index)\n",
    "                target_table = pd.concat([target_column.to_frame().T, other_columns], ignore_index=True)\n",
    "                \n",
    "                # if len(group_df) >= 8:\n",
    "                #     assert len(target_table) == max_unlabeled\n",
    "                # else:\n",
    "                #     assert len(target_table) == len(group_df)\n",
    "    \n",
    "                \n",
    "                target_cls = target_column[\"class_id\"]\n",
    "                target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "                col_idx_list = target_table[\"col_idx\"].tolist()\n",
    "                # target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "\n",
    "                if max_length <= 128 and adaptive_max_length:\n",
    "                    cur_maxlen = min(max_length, 512 // len(target_table) - 1)\n",
    "                else:\n",
    "                    cur_maxlen = max_length\n",
    "                    \n",
    "                token_ids_list = target_table[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                    tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=cur_maxlen, truncation=True)).tolist(\n",
    "                    )\n",
    "                token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                                    token_ids_list)).to(device)\n",
    "\n",
    "                target_col_mask = []\n",
    "                cls_index_value = 0\n",
    "                context_id = 1\n",
    "                meet_target = False\n",
    "                for idx, col_i in enumerate(col_idx_list):\n",
    "                    if col_i == target_col_idx:\n",
    "                        target_col_mask += [0] * len(token_ids_list[idx])\n",
    "                        meet_target = True\n",
    "                    else:\n",
    "                        target_col_mask += [context_id] * len(token_ids_list[idx])\n",
    "                        context_id += 1\n",
    "                    if not meet_target:\n",
    "                        cls_index_value += len(token_ids_list[idx])\n",
    "                cls_index_list = [cls_index_value] \n",
    "                for cls_index in cls_index_list:\n",
    "                    assert token_ids[\n",
    "                        cls_index] == tokenizer.cls_token_id, \"cls_indexes validation\"\n",
    "                cls_indexes = torch.LongTensor(cls_index_list).to(device)\n",
    "                class_ids = torch.LongTensor(\n",
    "                    [target_cls]).to(device)\n",
    "                target_col_mask = torch.LongTensor(target_col_mask).to(device)\n",
    "                data_list.append(\n",
    "                    [index,\n",
    "                    len(target_table), token_ids, class_ids, cls_indexes, target_col_mask])                \n",
    "        print(split, len(data_list))\n",
    "        self.table_df = pd.DataFrame(data_list,\n",
    "                                     columns=[\n",
    "                                         \"table_id\", \"num_col\", \"data_tensor\",\n",
    "                                         \"label_tensor\", \"cls_indexes\", \"target_col_mask\"\n",
    "                                     ])\n",
    "        \"\"\"\n",
    "        # NOTE: msato contains a small portion of single-col tables. keep it to be consistent.  \n",
    "        if multicol_only:\n",
    "            # Check\n",
    "            num_all_tables = len(self.table_df)\n",
    "            self.table_df = self.table_df[self.table_df[\"num_col\"] > 1]\n",
    "            assert len(self.table_df) == num_all_tables\n",
    "        \"\"\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.table_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"data\": self.table_df.iloc[idx][\"data_tensor\"],\n",
    "            \"label\": self.table_df.iloc[idx][\"label_tensor\"],\n",
    "            \"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"],\n",
    "            \"target_col_mask\": self.table_df.iloc[idx][\"target_col_mask\"],\n",
    "        }\n",
    "        #\"idx\": torch.LongTensor([idx])}\n",
    "        #\"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class GittablesTablewiseIterateClusterDataset(data.Dataset):\n",
    "\n",
    "#     def __init__(\n",
    "#             self,\n",
    "#             cv: int,\n",
    "#             split: str,\n",
    "#             src: str,  # train or test\n",
    "#             tokenizer: AutoTokenizer,\n",
    "#             max_length: int = 256,\n",
    "#             gt_only: bool = False,\n",
    "#             device: torch.device = None,\n",
    "#             base_dirpath: str = \"/data/zhihao/TU/GitTables/semtab_gittables/2022\",\n",
    "#             base_tag: str = '', # blank, comma\n",
    "#             small_tag: str = \"\",\n",
    "#             train_ratio: float = 1.0,\n",
    "#             max_unlabeled=8,\n",
    "#             adaptive_max_length=True,\n",
    "#             random_sample=False, # TODO\n",
    "#             train_only=False): # TODO\n",
    "#         if device is None:\n",
    "#             device = torch.device('cpu')\n",
    "#         basename = small_tag+ \"_cv_{}.csv\"\n",
    "    \n",
    "#         if split in [\"train\", \"valid\"]:\n",
    "#             df_list = []\n",
    "#             for i in range(5):\n",
    "#                 if i == cv:\n",
    "#                     continue\n",
    "#                 filepath = os.path.join(base_dirpath, basename.format(i))\n",
    "#                 df_list.append(pd.read_csv(filepath))\n",
    "#                 print(split, i)\n",
    "#             df = pd.concat(df_list, axis=0)\n",
    "#         else:\n",
    "#             # test\n",
    "#             filepath = os.path.join(base_dirpath, basename.format(cv))\n",
    "#             df = pd.read_csv(filepath)\n",
    "#             print(split)\n",
    "\n",
    "\n",
    "#         if gt_only:\n",
    "#             df = df[df[\"class_id\"] > -1]\n",
    "#         if train_only and split != \"train\":\n",
    "#             df = df[df[\"class_id\"] > -1]\n",
    "\n",
    "        \n",
    "#         data_list = []\n",
    "        \n",
    "#         df['class_id'] = df['class_id'].astype(int)\n",
    "#         df.drop(df[(df['data'].isna()) & (df['class_id'] == -1)].index, inplace=True)\n",
    "#         df['col_idx'] = df['col_idx'].astype(int)\n",
    "#         df['data'] = df['data'].astype(str)\n",
    "        \n",
    "#         num_tables = len(df.groupby(\"table_id\"))\n",
    "#         valid_index = int(num_tables * 0.8)\n",
    "#         num_train = int(train_ratio * num_tables * 0.8)        \n",
    "        \n",
    "#         # df.drop(df[(df['data'] == '') & (df['class_id'] == -1)].index, inplace=True)\n",
    "#         total_num_cols = 0\n",
    "#         self.correctness_checklist = []\n",
    "#         for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "#             if (split == \"train\") and ((i >= num_train) or (i >= valid_index)):\n",
    "#                 break\n",
    "#             if split == \"valid\" and i < valid_index:\n",
    "#                 continue\n",
    "#             #     break\n",
    "            \n",
    "#             group_df = group_df.reset_index(drop=True)\n",
    "#             # scores = bm25.get_scores(test_dataset_gt[idx][\"data\"].cpu().tolist())\n",
    "#             # semantic_scores = torch.tensor(group_df[\"data\"].apply(lambda x: max(bm25.get_scores(tokenizer.encode(\n",
    "#             #         tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=max_length, truncation=True)))))\n",
    "            \n",
    "#             # labeled_columns_index = group_df[group_df['class_id'] > -1].index.to_list()\n",
    "#             # assert len(labeled_columns_index) < 8\n",
    "#             # if set(labeled_columns_index).issubset(set(semantic_scores.topk(min(len(group_df), max_unlabeled)).indices.tolist())):\n",
    "#             #     self.correctness_checklist.append(1)\n",
    "#             # else:\n",
    "#             #     self.correctness_checklist.append(0)\n",
    "#             if len(group_df) > max_unlabeled:\n",
    "#                 # col_embs = sb_model.encode(group_df[\"data\"].to_list())\n",
    "                \n",
    "#                 with torch.no_grad():\n",
    "#                     model.eval()\n",
    "#                     token_list = group_df[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "#                             tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=max_length, truncation=True)).tolist()\n",
    "#                     token_list = torch.nn.utils.rnn.pad_sequence(\n",
    "#                     [torch.LongTensor(tokens) for tokens in token_list], padding_value=0).T.to(device)\n",
    "#                     cls_indexes = torch.nonzero(\n",
    "#                                 token_list == tokenizer.cls_token_id)\n",
    "#                     logits, embs = model(token_list, cls_indexes=cls_indexes, get_enc=True)\n",
    "#                     col_embs = embs.cpu()\n",
    "#                     if len(embs.size()) == 1:\n",
    "#                         col_embs = col_embs.unsqueeze(0)\n",
    "                        \n",
    "#                 kmeans = KMeans(n_clusters=max_unlabeled-1, random_state=0).fit(col_embs)\n",
    "#                 centers = torch.tensor(kmeans.cluster_centers_)\n",
    "#                 col_embs = torch.tensor(col_embs)\n",
    "#                 cluster_labels = torch.tensor(kmeans.labels_)\n",
    "#                 col_embs_cluster = []\n",
    "#                 col_embs_cluster_index = []\n",
    "#                 for cluster_i in np.unique(kmeans.labels_):\n",
    "#                     col_embs_cluster.append(col_embs[cluster_labels == cluster_i])\n",
    "#                     col_embs_cluster_index.append((cluster_labels == cluster_i).nonzero().reshape(-1))\n",
    "#                 num_clusters = len(col_embs_cluster)\n",
    "#             labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "#             labeled_columns.sort_values(by=['col_idx'], inplace=True)\n",
    "#             for index, target_column in labeled_columns.iterrows():\n",
    "#                 target_col_idx = target_column[\"col_idx\"]\n",
    "#                 if len(group_df) > max_unlabeled:\n",
    "#                     closest_cols = []\n",
    "#                     for i in range(num_clusters):\n",
    "#                         # try:\n",
    "#                         sim = F.cosine_similarity(col_embs_cluster[i], col_embs[index].reshape(1, -1))\n",
    "#                         # except:\n",
    "#                         #     raise ValueError(\"here\")\n",
    "#                         # try:\n",
    "#                         closest_index = col_embs_cluster_index[i][sim.argmax().item()].item()\n",
    "#                         # except:\n",
    "#                         #     print(\"here\")\n",
    "#                         if closest_index == index and len(col_embs_cluster[i]) > 1:\n",
    "#                             closest_index = col_embs_cluster_index[i][sim.argsort(descending=True)[1].item()].item()\n",
    "#                         closest_cols.append(closest_index)\n",
    "#                     other_columns = group_df.iloc[closest_cols]\n",
    "#                 else:\n",
    "#                     other_columns = group_df.drop(index)\n",
    "#                 target_table = pd.concat([target_column.to_frame().T, other_columns], ignore_index=True)\n",
    "                \n",
    "#                 # if len(group_df) >= 8:\n",
    "#                 #     assert len(target_table) == max_unlabeled\n",
    "#                 # else:\n",
    "#                 #     assert len(target_table) == len(group_df)\n",
    "    \n",
    "                \n",
    "#                 target_cls = target_column[\"class_id\"]\n",
    "#                 target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "#                 col_idx_list = target_table[\"col_idx\"].tolist()\n",
    "#                 # target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "\n",
    "#                 if max_length <= 128 and adaptive_max_length:\n",
    "#                     cur_maxlen = min(max_length, 512 // len(target_table) - 1)\n",
    "#                 else:\n",
    "#                     cur_maxlen = max_length\n",
    "                    \n",
    "#                 token_ids_list = target_table[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "#                     tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=cur_maxlen, truncation=True)).tolist(\n",
    "#                     )\n",
    "#                 token_ids = torch.LongTensor(reduce(operator.add,\n",
    "#                                                     token_ids_list)).to(device)\n",
    "\n",
    "#                 target_col_mask = []\n",
    "#                 cls_index_value = 0\n",
    "#                 context_id = 1\n",
    "#                 meet_target = False\n",
    "#                 for idx, col_i in enumerate(col_idx_list):\n",
    "#                     if col_i == target_col_idx:\n",
    "#                         target_col_mask += [0] * len(token_ids_list[idx])\n",
    "#                         meet_target = True\n",
    "#                     else:\n",
    "#                         target_col_mask += [context_id] * len(token_ids_list[idx])\n",
    "#                         context_id += 1\n",
    "#                     if not meet_target:\n",
    "#                         cls_index_value += len(token_ids_list[idx])\n",
    "#                 cls_index_list = [cls_index_value] \n",
    "#                 for cls_index in cls_index_list:\n",
    "#                     assert token_ids[\n",
    "#                         cls_index] == tokenizer.cls_token_id, \"cls_indexes validation\"\n",
    "#                 cls_indexes = torch.LongTensor(cls_index_list).to(device)\n",
    "#                 class_ids = torch.LongTensor(\n",
    "#                     [target_cls]).to(device)\n",
    "#                 target_col_mask = torch.LongTensor(target_col_mask).to(device)\n",
    "#                 data_list.append(\n",
    "#                     [index,\n",
    "#                     len(target_table), token_ids, class_ids, cls_indexes, target_col_mask])                \n",
    "#         print(split, len(data_list))\n",
    "#         self.table_df = pd.DataFrame(data_list,\n",
    "#                                      columns=[\n",
    "#                                          \"table_id\", \"num_col\", \"data_tensor\",\n",
    "#                                          \"label_tensor\", \"cls_indexes\", \"target_col_mask\"\n",
    "#                                      ])\n",
    "#         \"\"\"\n",
    "#         # NOTE: msato contains a small portion of single-col tables. keep it to be consistent.  \n",
    "#         if multicol_only:\n",
    "#             # Check\n",
    "#             num_all_tables = len(self.table_df)\n",
    "#             self.table_df = self.table_df[self.table_df[\"num_col\"] > 1]\n",
    "#             assert len(self.table_df) == num_all_tables\n",
    "#         \"\"\"\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.table_df)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         return {\n",
    "#             \"data\": self.table_df.iloc[idx][\"data_tensor\"],\n",
    "#             \"label\": self.table_df.iloc[idx][\"label_tensor\"],\n",
    "#             \"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"],\n",
    "#             \"target_col_mask\": self.table_df.iloc[idx][\"target_col_mask\"],\n",
    "#         }\n",
    "#         #\"idx\": torch.LongTensor([idx])}\n",
    "#         #\"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class GittablesTablewiseIterateClusterDataset(data.Dataset):\n",
    "\n",
    "#     def __init__(\n",
    "#             self,\n",
    "#             cv: int,\n",
    "#             split: str,\n",
    "#             src: str,  # train or test\n",
    "#             tokenizer: AutoTokenizer,\n",
    "#             max_length: int = 256,\n",
    "#             gt_only: bool = False,\n",
    "#             device: torch.device = None,\n",
    "#             base_dirpath: str = \"/data/zhihao/TU/GitTables/semtab_gittables/2022\",\n",
    "#             base_tag: str = '', # blank, comma\n",
    "#             small_tag: str = \"\",\n",
    "#             train_ratio: float = 1.0,\n",
    "#             max_unlabeled=8,\n",
    "#             adaptive_max_length=True,\n",
    "#             random_sample=False, # TODO\n",
    "#             train_only=False): # TODO\n",
    "#         if device is None:\n",
    "#             device = torch.device('cpu')\n",
    "#         basename = small_tag+ \"_cv_{}.csv\"\n",
    "    \n",
    "#         if split in [\"train\", \"valid\"]:\n",
    "#             df_list = []\n",
    "#             for i in range(5):\n",
    "#                 if i == cv:\n",
    "#                     continue\n",
    "#                 filepath = os.path.join(base_dirpath, basename.format(i))\n",
    "#                 df_list.append(pd.read_csv(filepath))\n",
    "#                 print(split, i)\n",
    "#             df = pd.concat(df_list, axis=0)\n",
    "#         else:\n",
    "#             # test\n",
    "#             filepath = os.path.join(base_dirpath, basename.format(cv))\n",
    "#             df = pd.read_csv(filepath)\n",
    "#             print(split)\n",
    "\n",
    "\n",
    "#         if gt_only:\n",
    "#             df = df[df[\"class_id\"] > -1]\n",
    "#         if train_only and split != \"train\":\n",
    "#             df = df[df[\"class_id\"] > -1]\n",
    "\n",
    "        \n",
    "#         data_list = []\n",
    "        \n",
    "#         df['class_id'] = df['class_id'].astype(int)\n",
    "#         df.drop(df[(df['data'].isna()) & (df['class_id'] == -1)].index, inplace=True)\n",
    "#         df['col_idx'] = df['col_idx'].astype(int)\n",
    "#         df['data'] = df['data'].astype(str)\n",
    "        \n",
    "#         num_tables = len(df.groupby(\"table_id\"))\n",
    "#         valid_index = int(num_tables * 0.8)\n",
    "#         num_train = int(train_ratio * num_tables * 0.8)        \n",
    "        \n",
    "#         # df.drop(df[(df['data'] == '') & (df['class_id'] == -1)].index, inplace=True)\n",
    "#         total_num_cols = 0\n",
    "#         self.correctness_checklist = []\n",
    "#         for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "#             if (split == \"train\") and ((i >= num_train) or (i >= valid_index)):\n",
    "#                 break\n",
    "#             if split == \"valid\" and i < valid_index:\n",
    "#                 continue\n",
    "#             #     break\n",
    "            \n",
    "#             group_df = group_df.reset_index(drop=True)\n",
    "#             # scores = bm25.get_scores(test_dataset_gt[idx][\"data\"].cpu().tolist())\n",
    "#             # semantic_scores = torch.tensor(group_df[\"data\"].apply(lambda x: max(bm25.get_scores(tokenizer.encode(\n",
    "#             #         tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=max_length, truncation=True)))))\n",
    "            \n",
    "#             # labeled_columns_index = group_df[group_df['class_id'] > -1].index.to_list()\n",
    "#             # assert len(labeled_columns_index) < 8\n",
    "#             # if set(labeled_columns_index).issubset(set(semantic_scores.topk(min(len(group_df), max_unlabeled)).indices.tolist())):\n",
    "#             #     self.correctness_checklist.append(1)\n",
    "#             # else:\n",
    "#             #     self.correctness_checklist.append(0)\n",
    "#             if len(group_df) > max_unlabeled:\n",
    "#                 # col_embs = sb_model.encode(group_df[\"data\"].to_list())\n",
    "                \n",
    "#                 with torch.no_grad():\n",
    "#                     model.eval()\n",
    "#                     token_list = group_df[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "#                             tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=max_length, truncation=True)).tolist()\n",
    "#                     token_list = torch.nn.utils.rnn.pad_sequence(\n",
    "#                     [torch.LongTensor(tokens) for tokens in token_list], padding_value=0).T.to(device)\n",
    "#                     cls_indexes = torch.nonzero(\n",
    "#                                 token_list == tokenizer.cls_token_id)\n",
    "#                     logits, embs = model(token_list, cls_indexes=cls_indexes, get_enc=True)\n",
    "#                     col_embs = embs.cpu()\n",
    "#                     if len(embs.size()) == 1:\n",
    "#                         col_embs = col_embs.unsqueeze(0)\n",
    "                        \n",
    "#                 kmeans = KMeans(n_clusters=max_unlabeled-1, random_state=0).fit(col_embs)\n",
    "#                 centers = torch.tensor(kmeans.cluster_centers_)\n",
    "#                 col_embs = torch.tensor(col_embs)\n",
    "                \n",
    "#             labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "#             labeled_columns.sort_values(by=['col_idx'], inplace=True)\n",
    "#             for index, target_column in labeled_columns.iterrows():\n",
    "#                 target_col_idx = target_column[\"col_idx\"]\n",
    "#                 if len(group_df) > max_unlabeled:\n",
    "#                     closest_cols = []\n",
    "#                     for i in range(max_unlabeled-1):\n",
    "#                         sim = F.cosine_similarity(col_embs, centers[i].reshape(1, -1))\n",
    "#                         closest_index = sim.argmax().item()\n",
    "#                         if closest_index == target_col_idx:\n",
    "#                             closest_index = sim.argsort(descending=True)[1].item()\n",
    "#                         closest_cols.append(closest_index)\n",
    "#                     other_columns = group_df.iloc[closest_cols]\n",
    "#                 else:\n",
    "#                     other_columns = group_df.drop(index)\n",
    "#                 target_table = pd.concat([target_column.to_frame().T, other_columns], ignore_index=True)\n",
    "                \n",
    "#                 # if len(group_df) >= 8:\n",
    "#                 #     assert len(target_table) == max_unlabeled\n",
    "#                 # else:\n",
    "#                 #     assert len(target_table) == len(group_df)\n",
    "    \n",
    "                \n",
    "#                 target_cls = target_column[\"class_id\"]\n",
    "#                 target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "#                 col_idx_list = target_table[\"col_idx\"].tolist()\n",
    "#                 # target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "\n",
    "#                 if max_length <= 128 and adaptive_max_length:\n",
    "#                     cur_maxlen = min(max_length, 512 // len(target_table) - 1)\n",
    "#                 else:\n",
    "#                     cur_maxlen = max_length\n",
    "                    \n",
    "#                 token_ids_list = target_table[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "#                     tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=cur_maxlen, truncation=True)).tolist(\n",
    "#                     )\n",
    "#                 token_ids = torch.LongTensor(reduce(operator.add,\n",
    "#                                                     token_ids_list)).to(device)\n",
    "\n",
    "#                 target_col_mask = []\n",
    "#                 cls_index_value = 0\n",
    "#                 context_id = 1\n",
    "#                 meet_target = False\n",
    "#                 for idx, col_i in enumerate(col_idx_list):\n",
    "#                     if col_i == target_col_idx:\n",
    "#                         target_col_mask += [0] * len(token_ids_list[idx])\n",
    "#                         meet_target = True\n",
    "#                     else:\n",
    "#                         target_col_mask += [context_id] * len(token_ids_list[idx])\n",
    "#                         context_id += 1\n",
    "#                     if not meet_target:\n",
    "#                         cls_index_value += len(token_ids_list[idx])\n",
    "#                 cls_index_list = [cls_index_value] \n",
    "#                 for cls_index in cls_index_list:\n",
    "#                     assert token_ids[\n",
    "#                         cls_index] == tokenizer.cls_token_id, \"cls_indexes validation\"\n",
    "#                 cls_indexes = torch.LongTensor(cls_index_list).to(device)\n",
    "#                 class_ids = torch.LongTensor(\n",
    "#                     [target_cls]).to(device)\n",
    "#                 target_col_mask = torch.LongTensor(target_col_mask).to(device)\n",
    "#                 data_list.append(\n",
    "#                     [index,\n",
    "#                     len(target_table), token_ids, class_ids, cls_indexes, target_col_mask])                \n",
    "#         print(split, len(data_list))\n",
    "#         self.table_df = pd.DataFrame(data_list,\n",
    "#                                      columns=[\n",
    "#                                          \"table_id\", \"num_col\", \"data_tensor\",\n",
    "#                                          \"label_tensor\", \"cls_indexes\", \"target_col_mask\"\n",
    "#                                      ])\n",
    "#         \"\"\"\n",
    "#         # NOTE: msato contains a small portion of single-col tables. keep it to be consistent.  \n",
    "#         if multicol_only:\n",
    "#             # Check\n",
    "#             num_all_tables = len(self.table_df)\n",
    "#             self.table_df = self.table_df[self.table_df[\"num_col\"] > 1]\n",
    "#             assert len(self.table_df) == num_all_tables\n",
    "#         \"\"\"\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.table_df)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         return {\n",
    "#             \"data\": self.table_df.iloc[idx][\"data_tensor\"],\n",
    "#             \"label\": self.table_df.iloc[idx][\"label_tensor\"],\n",
    "#             \"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"],\n",
    "#             \"target_col_mask\": self.table_df.iloc[idx][\"target_col_mask\"],\n",
    "#         }\n",
    "#         #\"idx\": torch.LongTensor([idx])}\n",
    "#         #\"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = torch.randn(10, 768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_scores = md_distance(embs.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GittablesTablewiseIterateLabelDataset(data.Dataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            cv: int,\n",
    "            split: str,\n",
    "            src: str,  # train or test\n",
    "            tokenizer: AutoTokenizer,\n",
    "            max_length: int = 256,\n",
    "            gt_only: bool = False,\n",
    "            device: torch.device = None,\n",
    "            base_dirpath: str = \"/data/zhihao/TU/GitTables/semtab_gittables/2022\",\n",
    "            base_tag: str = '', # blank, comma\n",
    "            small_tag: str = \"\",\n",
    "            train_ratio: float = 1.0,\n",
    "            max_unlabeled=8,\n",
    "            adaptive_max_length=True,\n",
    "            random_sample=False, # TODO\n",
    "            train_only=False): # TODO\n",
    "        if device is None:\n",
    "            device = torch.device('cpu')\n",
    "        basename = small_tag+ \"_cv_{}.csv\"\n",
    "    \n",
    "        if split in [\"train\", \"valid\"]:\n",
    "            df_list = []\n",
    "            for i in range(5):\n",
    "                if i == cv:\n",
    "                    continue\n",
    "                filepath = os.path.join(base_dirpath, basename.format(i))\n",
    "                df_list.append(pd.read_csv(filepath))\n",
    "                print(split, i)\n",
    "            df = pd.concat(df_list, axis=0)\n",
    "        else:\n",
    "            # test\n",
    "            filepath = os.path.join(base_dirpath, basename.format(cv))\n",
    "            df = pd.read_csv(filepath)\n",
    "            print(split)\n",
    "\n",
    "\n",
    "        if gt_only:\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "        if train_only and split != \"train\":\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "\n",
    "        \n",
    "        data_list = []\n",
    "        \n",
    "        df['class_id'] = df['class_id'].astype(int)\n",
    "        df.drop(df[(df['data'].isna()) & (df['class_id'] == -1)].index, inplace=True)\n",
    "        df['col_idx'] = df['col_idx'].astype(int)\n",
    "        df['data'] = df['data'].astype(str)\n",
    "        \n",
    "        num_tables = len(df.groupby(\"table_id\"))\n",
    "        valid_index = int(num_tables * 0.8)\n",
    "        num_train = int(train_ratio * num_tables * 0.8)        \n",
    "        \n",
    "        # df.drop(df[(df['data'] == '') & (df['class_id'] == -1)].index, inplace=True)\n",
    "        total_num_cols = 0\n",
    "        self.correctness_checklist = []\n",
    "        for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "            if (split == \"train\") and ((i >= num_train) or (i >= valid_index)):\n",
    "                break\n",
    "            if split == \"valid\" and i < valid_index:\n",
    "                continue\n",
    "            #     break\n",
    "            \n",
    "            group_df = group_df.reset_index(drop=True)\n",
    "            # scores = bm25.get_scores(test_dataset_gt[idx][\"data\"].cpu().tolist())\n",
    "            # semantic_scores = torch.tensor(group_df[\"data\"].apply(lambda x: max(bm25.get_scores(tokenizer.encode(\n",
    "            #         tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=max_length, truncation=True)))))\n",
    "            \n",
    "            # labeled_columns_index = group_df[group_df['class_id'] > -1].index.to_list()\n",
    "            # assert len(labeled_columns_index) < 8\n",
    "            # if set(labeled_columns_index).issubset(set(semantic_scores.topk(min(len(group_df), max_unlabeled)).indices.tolist())):\n",
    "            #     self.correctness_checklist.append(1)\n",
    "            # else:\n",
    "            #     self.correctness_checklist.append(0)\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                token_list = group_df[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                        tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=max_length, truncation=True)).tolist()\n",
    "                token_list = torch.nn.utils.rnn.pad_sequence(\n",
    "                [torch.LongTensor(tokens) for tokens in token_list], padding_value=0).T.to(device)\n",
    "                cls_indexes = torch.nonzero(\n",
    "                            token_list == tokenizer.cls_token_id)\n",
    "                logits, embs = model(token_list, cls_indexes=cls_indexes, get_enc=True)\n",
    "                embs = embs.cpu()\n",
    "                if len(embs.size()) == 1:\n",
    "                    embs = embs.unsqueeze(0)\n",
    "                # semantic_scores = torch.mm(training_corpus_embs_doduo_center/ training_corpus_embs_doduo_center.norm(dim=1, keepdim=True), (embs/ embs.norm(dim=1, keepdim=True)).T).T.topk(1).values.mean(1)\n",
    "                semantic_scores = torch.mm(training_corpus_embs_doduo/ training_corpus_embs_doduo.norm(dim=1, keepdim=True), (embs/ embs.norm(dim=1, keepdim=True)).T).T.topk(1).values.mean(1)\n",
    "                # semantic_scores = (1/ (torch.cdist(embs, training_corpus_embs_doduo)+1e-5)).topk(1).values.mean(1)\n",
    "                # semantic_scores = 1/md_distance(embs.numpy())\n",
    "                \n",
    "            group_df[\"semantic_scores\"] = semantic_scores\n",
    "            group_df.sort_values(by=['semantic_scores'], ascending=False, inplace=True) \n",
    "            labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "            labeled_columns.sort_values(by=['col_idx'], inplace=True)\n",
    "            for index, target_column in labeled_columns.iterrows():\n",
    "                other_columns = group_df.drop(index)\n",
    "                # other_labeled = other_columns[other_columns['class_id'] > -1].head(max_unlabeled-1)\n",
    "                # other_unlabeled = other_columns[other_columns['class_id'] == -1].drop_duplicates(subset=['data'], keep='first').head(max_unlabeled-len(other_labeled)-1)\n",
    "                # target_table = pd.concat([target_column.to_frame().T, other_labeled, other_unlabeled], ignore_index=True)\n",
    "                \n",
    "                other_columns = other_columns.head(max_unlabeled-1)\n",
    "                # other_columns.sort_values(by=['col_idx'], inplace=True)\n",
    "                target_table = pd.concat([target_column.to_frame().T, other_columns], ignore_index=True)\n",
    "                \n",
    "                # if len(group_df) >= 8:\n",
    "                #     assert len(target_table) == max_unlabeled\n",
    "                # else:\n",
    "                #     assert len(target_table) == len(group_df)\n",
    "    \n",
    "                target_col_idx = target_column[\"col_idx\"]\n",
    "                target_cls = target_column[\"class_id\"]\n",
    "                # target_table.sort_values(by=['col_idx'], inplace=True) # TODO\n",
    "                col_idx_list = target_table[\"col_idx\"].tolist()\n",
    "                # target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "\n",
    "                if max_length <= 128 and adaptive_max_length:\n",
    "                    cur_maxlen = min(max_length, 512 // len(target_table) - 1)\n",
    "                else:\n",
    "                    cur_maxlen = max_length\n",
    "                    \n",
    "                token_ids_list = target_table[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                    tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=cur_maxlen, truncation=True)).tolist(\n",
    "                    )\n",
    "                token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                                    token_ids_list)).to(device)\n",
    "\n",
    "                target_col_mask = []\n",
    "                cls_index_value = 0\n",
    "                context_id = 1\n",
    "                meet_target = False\n",
    "                for idx, col_i in enumerate(col_idx_list):\n",
    "                    if col_i == target_col_idx:\n",
    "                        target_col_mask += [0] * len(token_ids_list[idx])\n",
    "                        meet_target = True\n",
    "                    else:\n",
    "                        target_col_mask += [context_id] * len(token_ids_list[idx])\n",
    "                        context_id += 1\n",
    "                    if not meet_target:\n",
    "                        cls_index_value += len(token_ids_list[idx])\n",
    "                cls_index_list = [cls_index_value] \n",
    "                for cls_index in cls_index_list:\n",
    "                    assert token_ids[\n",
    "                        cls_index] == tokenizer.cls_token_id, \"cls_indexes validation\"\n",
    "                cls_indexes = torch.LongTensor(cls_index_list).to(device)\n",
    "                class_ids = torch.LongTensor(\n",
    "                    [target_cls]).to(device)\n",
    "                target_col_mask = torch.LongTensor(target_col_mask).to(device)\n",
    "                data_list.append(\n",
    "                    [index,\n",
    "                    len(target_table), token_ids, class_ids, cls_indexes, target_col_mask])                \n",
    "        print(split, len(data_list))\n",
    "        self.table_df = pd.DataFrame(data_list,\n",
    "                                     columns=[\n",
    "                                         \"table_id\", \"num_col\", \"data_tensor\",\n",
    "                                         \"label_tensor\", \"cls_indexes\", \"target_col_mask\"\n",
    "                                     ])\n",
    "        \"\"\"\n",
    "        # NOTE: msato contains a small portion of single-col tables. keep it to be consistent.  \n",
    "        if multicol_only:\n",
    "            # Check\n",
    "            num_all_tables = len(self.table_df)\n",
    "            self.table_df = self.table_df[self.table_df[\"num_col\"] > 1]\n",
    "            assert len(self.table_df) == num_all_tables\n",
    "        \"\"\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.table_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"data\": self.table_df.iloc[idx][\"data_tensor\"],\n",
    "            \"label\": self.table_df.iloc[idx][\"label_tensor\"],\n",
    "            \"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"],\n",
    "            \"target_col_mask\": self.table_df.iloc[idx][\"target_col_mask\"],\n",
    "        }\n",
    "        #\"idx\": torch.LongTensor([idx])}\n",
    "        #\"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GittablesTablewiseIterateSemanticDataset(data.Dataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            cv: int,\n",
    "            split: str,\n",
    "            src: str,  # train or test\n",
    "            tokenizer: AutoTokenizer,\n",
    "            max_length: int = 256,\n",
    "            gt_only: bool = False,\n",
    "            device: torch.device = None,\n",
    "            base_dirpath: str = \"/data/zhihao/TU/GitTables/semtab_gittables/2022\",\n",
    "            base_tag: str = '', # blank, comma\n",
    "            small_tag: str = \"\",\n",
    "            train_ratio: float = 1.0,\n",
    "            max_unlabeled=8,\n",
    "            adaptive_max_length=True,\n",
    "            random_sample=False, # TODO\n",
    "            train_only=False): # TODO\n",
    "        if device is None:\n",
    "            device = torch.device('cpu')\n",
    "        basename = small_tag+ \"_cv_{}.csv\"\n",
    "    \n",
    "        if split in [\"train\", \"valid\"]:\n",
    "            df_list = []\n",
    "            for i in range(5):\n",
    "                if i == cv:\n",
    "                    continue\n",
    "                filepath = os.path.join(base_dirpath, basename.format(i))\n",
    "                df_list.append(pd.read_csv(filepath))\n",
    "                print(split, i)\n",
    "            df = pd.concat(df_list, axis=0)\n",
    "        else:\n",
    "            # test\n",
    "            filepath = os.path.join(base_dirpath, basename.format(cv))\n",
    "            df = pd.read_csv(filepath)\n",
    "            print(split)\n",
    "\n",
    "\n",
    "        if gt_only:\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "        if train_only and split != \"train\":\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "\n",
    "        \n",
    "        data_list = []\n",
    "        \n",
    "        df['class_id'] = df['class_id'].astype(int)\n",
    "        df.drop(df[(df['data'].isna()) & (df['class_id'] == -1)].index, inplace=True)\n",
    "        df['col_idx'] = df['col_idx'].astype(int)\n",
    "        df['data'] = df['data'].astype(str)\n",
    "        \n",
    "        num_tables = len(df.groupby(\"table_id\"))\n",
    "        valid_index = int(num_tables * 0.8)\n",
    "        num_train = int(train_ratio * num_tables * 0.8)        \n",
    "        \n",
    "        # df.drop(df[(df['data'] == '') & (df['class_id'] == -1)].index, inplace=True)\n",
    "        total_num_cols = 0\n",
    "        for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "            if (split == \"train\") and ((i >= num_train) or (i >= valid_index)):\n",
    "                break\n",
    "            if split == \"valid\" and i < valid_index:\n",
    "                continue\n",
    "            #     break\n",
    "            \n",
    "            group_df = group_df.reset_index(drop=True)\n",
    "            semantic_scores = torch.tensor(group_df[\"data\"].apply(lambda x: classify_column(x.split(';'))).tolist())\n",
    "            group_df[\"semantic_scores\"] = semantic_scores\n",
    "            group_df.sort_values(by=['semantic_scores'], ascending=False, inplace=True) \n",
    "            labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "            labeled_columns.sort_values(by=['col_idx'], inplace=True)\n",
    "            for index, target_column in labeled_columns.iterrows():\n",
    "                other_columns = group_df.drop(index).drop_duplicates(subset=['data'], keep='first')\n",
    "                # other_labeled = other_columns[other_columns['class_id'] > -1].head(max_unlabeled-1)\n",
    "                # other_unlabeled = other_columns[other_columns['class_id'] == -1].drop_duplicates(subset=['data'], keep='first').head(max_unlabeled-len(other_labeled)-1)\n",
    "                # target_table = pd.concat([target_column.to_frame().T, other_labeled, other_unlabeled], ignore_index=True)\n",
    "                \n",
    "                other_columns = other_columns.head(max_unlabeled-1)\n",
    "                target_table = pd.concat([target_column.to_frame().T, other_columns], ignore_index=True)\n",
    "                \n",
    "                # if len(group_df) >= 8:\n",
    "                #     assert len(target_table) == max_unlabeled\n",
    "                # else:\n",
    "                #     assert len(target_table) == len(group_df)\n",
    "    \n",
    "                target_col_idx = target_table[\"col_idx\"].values[0]\n",
    "                target_cls = target_table[\"class_id\"].values[0]\n",
    "                target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "                col_idx_list = target_table[\"col_idx\"].tolist()\n",
    "                # target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "\n",
    "                if max_length <= 128 and adaptive_max_length:\n",
    "                    cur_maxlen = min(max_length, 512 // len(target_table) - 1)\n",
    "                else:\n",
    "                    cur_maxlen = max_length\n",
    "                    \n",
    "                token_ids_list = target_table[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                    tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=cur_maxlen, truncation=True)).tolist(\n",
    "                    )\n",
    "                token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                                    token_ids_list)).to(device)\n",
    "\n",
    "                target_col_mask = []\n",
    "                cls_index_value = 0\n",
    "                context_id = 1\n",
    "                meet_target = False\n",
    "                for idx, col_i in enumerate(col_idx_list):\n",
    "                    if col_i == target_col_idx:\n",
    "                        target_col_mask += [0] * len(token_ids_list[idx])\n",
    "                        meet_target = True\n",
    "                    else:\n",
    "                        target_col_mask += [context_id] * len(token_ids_list[idx])\n",
    "                        context_id += 1\n",
    "                    if not meet_target:\n",
    "                        cls_index_value += len(token_ids_list[idx])\n",
    "                cls_index_list = [cls_index_value] \n",
    "                for cls_index in cls_index_list:\n",
    "                    assert token_ids[\n",
    "                        cls_index] == tokenizer.cls_token_id, \"cls_indexes validation\"\n",
    "                cls_indexes = torch.LongTensor(cls_index_list).to(device)\n",
    "                class_ids = torch.LongTensor(\n",
    "                    [target_cls]).to(device)\n",
    "                target_col_mask = torch.LongTensor(target_col_mask).to(device)\n",
    "                data_list.append(\n",
    "                    [index,\n",
    "                    len(target_table), token_ids, class_ids, cls_indexes, target_col_mask])                \n",
    "        print(split, len(data_list))\n",
    "        self.table_df = pd.DataFrame(data_list,\n",
    "                                     columns=[\n",
    "                                         \"table_id\", \"num_col\", \"data_tensor\",\n",
    "                                         \"label_tensor\", \"cls_indexes\", \"target_col_mask\"\n",
    "                                     ])\n",
    "        \"\"\"\n",
    "        # NOTE: msato contains a small portion of single-col tables. keep it to be consistent.  \n",
    "        if multicol_only:\n",
    "            # Check\n",
    "            num_all_tables = len(self.table_df)\n",
    "            self.table_df = self.table_df[self.table_df[\"num_col\"] > 1]\n",
    "            assert len(self.table_df) == num_all_tables\n",
    "        \"\"\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.table_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"data\": self.table_df.iloc[idx][\"data_tensor\"],\n",
    "            \"label\": self.table_df.iloc[idx][\"label_tensor\"],\n",
    "            \"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"],\n",
    "            \"target_col_mask\": self.table_df.iloc[idx][\"target_col_mask\"],\n",
    "        }\n",
    "        #\"idx\": torch.LongTensor([idx])}\n",
    "        #\"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptive_max_length=True\n",
    "global_i = 0 \n",
    "for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "    #     break\n",
    "    group_df = group_df.reset_index(drop=True)\n",
    "    semantic_scores = torch.tensor(group_df[\"data\"].apply(lambda x: classify_column(x.split(';'))).tolist())\n",
    "    group_df[\"semantic_scores\"] = semantic_scores\n",
    "    group_df.sort_values(by=['semantic_scores'], ascending=False, inplace=True) \n",
    "    labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "    labeled_columns.sort_values(by=['col_idx'], inplace=True)\n",
    "    for index_i, target_column in labeled_columns.iterrows():\n",
    "        other_columns = group_df.drop(index_i).drop_duplicates(subset=['data'], keep='first')\n",
    "        other_labeled = other_columns[other_columns['class_id'] > -1].head(max_unlabeled-1)\n",
    "        other_unlabeled = other_columns[other_columns['class_id'] == -1].head(max_unlabeled-len(other_labeled)-1)\n",
    "\n",
    "    \n",
    "        target_table = pd.concat([target_column.to_frame().T, other_labeled, other_unlabeled], ignore_index=True)\n",
    "    \n",
    "        target_col_idx = target_table[\"col_idx\"].values[0]\n",
    "        target_cls = target_table[\"class_id\"].values[0]\n",
    "        target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "        col_idx_list = target_table[\"col_idx\"].tolist()\n",
    "        # target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "        if target_cls != labels_test_original[global_i]:\n",
    "            print(i, target_cls, labels_test_original[global_i].item())\n",
    "            raise ValueError(\"target_cls != labels_test_original[global_i]\")\n",
    "        global_i += 1\n",
    "        if max_length <= 128 and adaptive_max_length:\n",
    "            cur_maxlen = min(max_length, 512 // len(target_table) - 1)\n",
    "        else:\n",
    "            cur_maxlen = max_length\n",
    "            \n",
    "        token_ids_list = target_table[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "            tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=cur_maxlen, truncation=True)).tolist(\n",
    "            )\n",
    "        token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                            token_ids_list)).to(device)\n",
    "\n",
    "        target_col_mask = []\n",
    "        cls_index_value = 0\n",
    "        context_id = 1\n",
    "        meet_target = False\n",
    "        for idx, col_i in enumerate(col_idx_list):\n",
    "            if col_i == target_col_idx:\n",
    "                target_col_mask += [0] * len(token_ids_list[idx])\n",
    "                meet_target = True\n",
    "            else:\n",
    "                target_col_mask += [context_id] * len(token_ids_list[idx])\n",
    "                context_id += 1\n",
    "            if not meet_target:\n",
    "                cls_index_value += len(token_ids_list[idx])\n",
    "        cls_index_list = [cls_index_value] \n",
    "        for cls_index in cls_index_list:\n",
    "            assert token_ids[\n",
    "                cls_index] == tokenizer.cls_token_id, \"cls_indexes validation\"\n",
    "        cls_indexes = torch.LongTensor(cls_index_list).to(device)\n",
    "        class_ids = torch.LongTensor(\n",
    "            [target_cls]).to(device)\n",
    "        target_col_mask = torch.LongTensor(target_col_mask).to(device)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "    if i == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GittablesTablewiseIterateDistantDataset(data.Dataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            cv: int,\n",
    "            split: str,\n",
    "            src: str,  # train or test\n",
    "            tokenizer: AutoTokenizer,\n",
    "            max_length: int = 256,\n",
    "            gt_only: bool = False,\n",
    "            device: torch.device = None,\n",
    "            base_dirpath: str = \"/data/zhihao/TU/GitTables/semtab_gittables/2022\",\n",
    "            base_tag: str = '', # blank, comma\n",
    "            small_tag: str = \"\",\n",
    "            train_ratio: float = 1.0,\n",
    "            max_unlabeled=8,\n",
    "            adaptive_max_length=True,\n",
    "            random_sample=False, # TODO\n",
    "            train_only=False): # TODO\n",
    "        if device is None:\n",
    "            device = torch.device('cpu')\n",
    "        basename = small_tag+ \"_cv_{}.csv\"\n",
    "    \n",
    "        if split in [\"train\", \"valid\"]:\n",
    "            df_list = []\n",
    "            for i in range(5):\n",
    "                if i == cv:\n",
    "                    continue\n",
    "                filepath = os.path.join(base_dirpath, basename.format(i))\n",
    "                df_list.append(pd.read_csv(filepath))\n",
    "                print(split, i)\n",
    "            df = pd.concat(df_list, axis=0)\n",
    "        else:\n",
    "            # test\n",
    "            filepath = os.path.join(base_dirpath, basename.format(cv))\n",
    "            df = pd.read_csv(filepath)\n",
    "            print(split)\n",
    "\n",
    "\n",
    "        if gt_only:\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "        if train_only and split != \"train\":\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "\n",
    "        \n",
    "        data_list = []\n",
    "        \n",
    "        df['class_id'] = df['class_id'].astype(int)\n",
    "        df.drop(df[(df['data'].isna()) & (df['class_id'] == -1)].index, inplace=True)\n",
    "        df['col_idx'] = df['col_idx'].astype(int)\n",
    "        df['data'] = df['data'].astype(str)\n",
    "        \n",
    "        num_tables = len(df.groupby(\"table_id\"))\n",
    "        valid_index = int(num_tables * 0.8)\n",
    "        num_train = int(train_ratio * num_tables * 0.8)        \n",
    "        \n",
    "        # df.drop(df[(df['data'] == '') & (df['class_id'] == -1)].index, inplace=True)\n",
    "        total_num_cols = 0\n",
    "        for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "            if (split == \"train\") and ((i >= num_train) or (i >= valid_index)):\n",
    "                break\n",
    "            if split == \"valid\" and i < valid_index:\n",
    "                continue\n",
    "            #     break\n",
    "            labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "            for index, target_column in labeled_columns.iterrows():\n",
    "                target_col_idx = target_column[\"col_idx\"]\n",
    "                \n",
    "                other_columns = group_df.drop(index)\n",
    "                \n",
    "                other_columns['distance'] = abs(other_columns['col_idx'] - target_col_idx)\n",
    "                other_columns.sort_values(by='distance', inplace=True)\n",
    "                nearby_columns = other_columns.tail(max_unlabeled-1)\n",
    "                target_table = pd.concat([target_column.to_frame().T, nearby_columns], ignore_index=True)\n",
    "                \n",
    "                \n",
    "                \n",
    "                # other_labeled = other_columns[other_columns['class_id'] > -1].head(max_unlabeled-1)\n",
    "                # other_unlabeled = other_columns[other_columns['class_id'] == -1]\n",
    "                # other_unlabeled['distance'] = abs(other_unlabeled['col_idx'] - target_col_idx)\n",
    "                # other_unlabeled.sort_values(by='distance', inplace=True)\n",
    "                # nearby_columns = other_unlabeled.head(max_unlabeled-len(other_labeled)-1)\n",
    "                # target_table = pd.concat([target_column.to_frame().T, other_labeled, nearby_columns], ignore_index=True)\n",
    "\n",
    "                # other_columns['distance'] = abs(other_columns['col_idx'] - target_col_idx)\n",
    "                # other_columns.sort_values(by='distance', inplace=True)\n",
    "                # nearby_columns = other_columns.head(max_unlabeled-1)\n",
    "                # target_table = pd.concat([target_column.to_frame().T, nearby_columns], ignore_index=True)\n",
    "                \n",
    "                \n",
    "                target_cls = target_column[\"class_id\"]\n",
    "                target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "                col_idx_list = target_table[\"col_idx\"].tolist()\n",
    "\n",
    "                if max_length <= 128 and adaptive_max_length:\n",
    "                    cur_maxlen = min(max_length, 512 // len(target_table) - 1)\n",
    "                else:\n",
    "                    cur_maxlen = max_length\n",
    "                    \n",
    "                token_ids_list = target_table[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                    tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=cur_maxlen, truncation=True)).tolist(\n",
    "                    )\n",
    "                token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                                    token_ids_list)).to(device)\n",
    "\n",
    "                target_col_mask = []\n",
    "                cls_index_value = 0\n",
    "                context_id = 1\n",
    "                meet_target = False\n",
    "                for idx, col_i in enumerate(col_idx_list):\n",
    "                    if col_i == target_col_idx:\n",
    "                        target_col_mask += [0] * len(token_ids_list[idx])\n",
    "                        meet_target = True\n",
    "                    else:\n",
    "                        target_col_mask += [context_id] * len(token_ids_list[idx])\n",
    "                        context_id += 1\n",
    "                    if not meet_target:\n",
    "                        cls_index_value += len(token_ids_list[idx])\n",
    "                cls_index_list = [cls_index_value] \n",
    "                for cls_index in cls_index_list:\n",
    "                    assert token_ids[\n",
    "                        cls_index] == tokenizer.cls_token_id, \"cls_indexes validation\"\n",
    "                cls_indexes = torch.LongTensor(cls_index_list).to(device)\n",
    "                class_ids = torch.LongTensor(\n",
    "                    [target_cls]).to(device)\n",
    "                target_col_mask = torch.LongTensor(target_col_mask).to(device)\n",
    "                data_list.append(\n",
    "                    [index,\n",
    "                    len(target_table), token_ids, class_ids, cls_indexes, target_col_mask])                \n",
    "        print(split, len(data_list))\n",
    "        self.table_df = pd.DataFrame(data_list,\n",
    "                                     columns=[\n",
    "                                         \"table_id\", \"num_col\", \"data_tensor\",\n",
    "                                         \"label_tensor\", \"cls_indexes\", \"target_col_mask\"\n",
    "                                     ])\n",
    "        \"\"\"\n",
    "        # NOTE: msato contains a small portion of single-col tables. keep it to be consistent.  \n",
    "        if multicol_only:\n",
    "            # Check\n",
    "            num_all_tables = len(self.table_df)\n",
    "            self.table_df = self.table_df[self.table_df[\"num_col\"] > 1]\n",
    "            assert len(self.table_df) == num_all_tables\n",
    "        \"\"\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.table_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"data\": self.table_df.iloc[idx][\"data_tensor\"],\n",
    "            \"label\": self.table_df.iloc[idx][\"label_tensor\"],\n",
    "            \"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"],\n",
    "            \"target_col_mask\": self.table_df.iloc[idx][\"target_col_mask\"],\n",
    "        }\n",
    "        #\"idx\": torch.LongTensor([idx])}\n",
    "        #\"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GittablesTablewiseIterateAllDataset(data.Dataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            cv: int,\n",
    "            split: str,\n",
    "            src: str,  # train or test\n",
    "            tokenizer: AutoTokenizer,\n",
    "            max_length: int = 256,\n",
    "            gt_only: bool = False,\n",
    "            device: torch.device = None,\n",
    "            base_dirpath: str = \"/data/zhihao/TU/GitTables/semtab_gittables/2022\",\n",
    "            base_tag: str = '', # blank, comma\n",
    "            small_tag: str = \"\",\n",
    "            train_ratio: float = 1.0,\n",
    "            max_unlabeled=8,\n",
    "            adaptive_max_length=True,\n",
    "            random_sample=False, # TODO\n",
    "            train_only=False): # TODO\n",
    "        if device is None:\n",
    "            device = torch.device('cpu')\n",
    "        basename = small_tag+ \"_cv_{}.csv\"\n",
    "    \n",
    "        if split in [\"train\", \"valid\"]:\n",
    "            df_list = []\n",
    "            for i in range(5):\n",
    "                if i == cv:\n",
    "                    continue\n",
    "                filepath = os.path.join(base_dirpath, basename.format(i))\n",
    "                df_list.append(pd.read_csv(filepath))\n",
    "                print(split, i)\n",
    "            df = pd.concat(df_list, axis=0)\n",
    "        else:\n",
    "            # test\n",
    "            filepath = os.path.join(base_dirpath, basename.format(cv))\n",
    "            df = pd.read_csv(filepath)\n",
    "            print(split)\n",
    "\n",
    "\n",
    "        if gt_only:\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "        if train_only and split != \"train\":\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "\n",
    "        \n",
    "        data_list = []\n",
    "        \n",
    "        df['class_id'] = df['class_id'].astype(int)\n",
    "        df.drop(df[(df['data'].isna()) & (df['class_id'] == -1)].index, inplace=True)\n",
    "        df['col_idx'] = df['col_idx'].astype(int)\n",
    "        df['data'] = df['data'].astype(str)\n",
    "        \n",
    "        num_tables = len(df.groupby(\"table_id\"))\n",
    "        valid_index = int(num_tables * 0.8)\n",
    "        num_train = int(train_ratio * num_tables * 0.8)        \n",
    "        \n",
    "        # df.drop(df[(df['data'] == '') & (df['class_id'] == -1)].index, inplace=True)\n",
    "        total_num_cols = 0\n",
    "        for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "            if (split == \"train\") and ((i >= num_train) or (i >= valid_index)):\n",
    "                break\n",
    "            if split == \"valid\" and i < valid_index:\n",
    "                continue\n",
    "            #     break\n",
    "            labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "            for index, target_column in labeled_columns.iterrows():\n",
    "                target_col_idx = target_column[\"col_idx\"]\n",
    "                \n",
    "                other_columns = group_df.drop(index)\n",
    "                # target_table = group_df\n",
    "                target_table = pd.concat([target_column.to_frame().T, other_columns], ignore_index=True)\n",
    "                \n",
    "                \n",
    "                \n",
    "                # other_labeled = other_columns[other_columns['class_id'] > -1].head(max_unlabeled-1)\n",
    "                # other_unlabeled = other_columns[other_columns['class_id'] == -1]\n",
    "                # other_unlabeled['distance'] = abs(other_unlabeled['col_idx'] - target_col_idx)\n",
    "                # other_unlabeled.sort_values(by='distance', inplace=True)\n",
    "                # nearby_columns = other_unlabeled.head(max_unlabeled-len(other_labeled)-1)\n",
    "                # target_table = pd.concat([target_column.to_frame().T, other_labeled, nearby_columns], ignore_index=True)\n",
    "\n",
    "                # other_columns['distance'] = abs(other_columns['col_idx'] - target_col_idx)\n",
    "                # other_columns.sort_values(by='distance', inplace=True)\n",
    "                # nearby_columns = other_columns.head(max_unlabeled-1)\n",
    "                # target_table = pd.concat([target_column.to_frame().T, nearby_columns], ignore_index=True)\n",
    "                \n",
    "                \n",
    "                target_cls = target_column[\"class_id\"]\n",
    "                # target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "                col_idx_list = target_table[\"col_idx\"].tolist()\n",
    "\n",
    "                if max_length <= 128 and adaptive_max_length:\n",
    "                    cur_maxlen = min(max_length, 512 // len(target_table) - 1)\n",
    "                else:\n",
    "                    cur_maxlen = max_length\n",
    "                    \n",
    "                token_ids_list = target_table[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                    tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=cur_maxlen, truncation=True)).tolist(\n",
    "                    )\n",
    "                token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                                    token_ids_list)).to(device)\n",
    "\n",
    "                target_col_mask = []\n",
    "                cls_index_value = 0\n",
    "                context_id = 1\n",
    "                meet_target = False\n",
    "                for idx, col_i in enumerate(col_idx_list):\n",
    "                    if col_i == target_col_idx:\n",
    "                        target_col_mask += [0] * len(token_ids_list[idx])\n",
    "                        meet_target = True\n",
    "                    else:\n",
    "                        target_col_mask += [context_id] * len(token_ids_list[idx])\n",
    "                        context_id += 1\n",
    "                    if not meet_target:\n",
    "                        cls_index_value += len(token_ids_list[idx])\n",
    "                cls_index_list = [cls_index_value] \n",
    "                for cls_index in cls_index_list:\n",
    "                    assert token_ids[\n",
    "                        cls_index] == tokenizer.cls_token_id, \"cls_indexes validation\"\n",
    "                cls_indexes = torch.LongTensor(cls_index_list).to(device)\n",
    "                class_ids = torch.LongTensor(\n",
    "                    [target_cls]).to(device)\n",
    "                target_col_mask = torch.LongTensor(target_col_mask).to(device)\n",
    "                data_list.append(\n",
    "                    [index,\n",
    "                    len(target_table), token_ids, class_ids, cls_indexes, target_col_mask])                \n",
    "        print(split, len(data_list))\n",
    "        self.table_df = pd.DataFrame(data_list,\n",
    "                                     columns=[\n",
    "                                         \"table_id\", \"num_col\", \"data_tensor\",\n",
    "                                         \"label_tensor\", \"cls_indexes\", \"target_col_mask\"\n",
    "                                     ])\n",
    "        \"\"\"\n",
    "        # NOTE: msato contains a small portion of single-col tables. keep it to be consistent.  \n",
    "        if multicol_only:\n",
    "            # Check\n",
    "            num_all_tables = len(self.table_df)\n",
    "            self.table_df = self.table_df[self.table_df[\"num_col\"] > 1]\n",
    "            assert len(self.table_df) == num_all_tables\n",
    "        \"\"\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.table_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"data\": self.table_df.iloc[idx][\"data_tensor\"],\n",
    "            \"label\": self.table_df.iloc[idx][\"label_tensor\"],\n",
    "            \"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"],\n",
    "            \"target_col_mask\": self.table_df.iloc[idx][\"target_col_mask\"],\n",
    "        }\n",
    "        #\"idx\": torch.LongTensor([idx])}\n",
    "        #\"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GittablesTablewiseIterateNearbyFirstDataset(data.Dataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            cv: int,\n",
    "            split: str,\n",
    "            src: str,  # train or test\n",
    "            tokenizer: AutoTokenizer,\n",
    "            max_length: int = 256,\n",
    "            gt_only: bool = False,\n",
    "            device: torch.device = None,\n",
    "            base_dirpath: str = \"/data/zhihao/TU/GitTables/semtab_gittables/2022\",\n",
    "            base_tag: str = '', # blank, comma\n",
    "            small_tag: str = \"\",\n",
    "            train_ratio: float = 1.0,\n",
    "            max_unlabeled=8,\n",
    "            adaptive_max_length=True,\n",
    "            random_sample=False, # TODO\n",
    "            train_only=False,\n",
    "            nearby_num=2): # TODO\n",
    "        if device is None:\n",
    "            device = torch.device('cpu')\n",
    "        basename = small_tag+ \"_cv_{}.csv\"\n",
    "    \n",
    "        if split in [\"train\", \"valid\"]:\n",
    "            df_list = []\n",
    "            for i in range(5):\n",
    "                if i == cv:\n",
    "                    continue\n",
    "                filepath = os.path.join(base_dirpath, basename.format(i))\n",
    "                df_list.append(pd.read_csv(filepath))\n",
    "                print(split, i)\n",
    "            df = pd.concat(df_list, axis=0)\n",
    "        else:\n",
    "            # test\n",
    "            filepath = os.path.join(base_dirpath, basename.format(cv))\n",
    "            df = pd.read_csv(filepath)\n",
    "            print(split)\n",
    "\n",
    "\n",
    "        if gt_only:\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "        if train_only and split != \"train\":\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "\n",
    "        \n",
    "        data_list = []\n",
    "        \n",
    "        df['class_id'] = df['class_id'].astype(int)\n",
    "        df.drop(df[(df['data'].isna()) & (df['class_id'] == -1)].index, inplace=True)\n",
    "        df['col_idx'] = df['col_idx'].astype(int)\n",
    "        df['data'] = df['data'].astype(str)\n",
    "        \n",
    "        num_tables = len(df.groupby(\"table_id\"))\n",
    "        valid_index = int(num_tables * 0.8)\n",
    "        num_train = int(train_ratio * num_tables * 0.8)        \n",
    "        \n",
    "        # df.drop(df[(df['data'] == '') & (df['class_id'] == -1)].index, inplace=True)\n",
    "        total_num_cols = 0\n",
    "        for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "            if (split == \"train\") and ((i >= num_train) or (i >= valid_index)):\n",
    "                break\n",
    "            if split == \"valid\" and i < valid_index:\n",
    "                continue\n",
    "            #     break\n",
    "            labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "            for index, target_column in labeled_columns.iterrows():\n",
    "                target_col_idx = target_column[\"col_idx\"]\n",
    "                \n",
    "                other_columns = group_df.drop(index)\n",
    "                \n",
    "                other_columns['distance'] = abs(other_columns['col_idx'] - target_col_idx)\n",
    "                other_columns.sort_values(by='distance', inplace=True)\n",
    "                nearby_columns = other_columns.head(min(nearby_num, max_unlabeled-1))\n",
    "                other_columns = other_columns.drop(nearby_columns.index)\n",
    "                other_columns.sort_values(by=['col_idx'], inplace=True)\n",
    "                first_columns = other_columns.head(max(max_unlabeled-1-nearby_num, 0))\n",
    "                target_table = pd.concat([target_column.to_frame().T, nearby_columns, first_columns], ignore_index=True)\n",
    "                \n",
    "                \n",
    "                \n",
    "                # other_labeled = other_columns[other_columns['class_id'] > -1].head(max_unlabeled-1)\n",
    "                # other_unlabeled = other_columns[other_columns['class_id'] == -1]\n",
    "                # other_unlabeled['distance'] = abs(other_unlabeled['col_idx'] - target_col_idx)\n",
    "                # other_unlabeled.sort_values(by='distance', inplace=True)\n",
    "                # nearby_columns = other_unlabeled.head(max_unlabeled-len(other_labeled)-1)\n",
    "                # target_table = pd.concat([target_column.to_frame().T, other_labeled, nearby_columns], ignore_index=True)\n",
    "\n",
    "                # other_columns['distance'] = abs(other_columns['col_idx'] - target_col_idx)\n",
    "                # other_columns.sort_values(by='distance', inplace=True)\n",
    "                # nearby_columns = other_columns.head(max_unlabeled-1)\n",
    "                # target_table = pd.concat([target_column.to_frame().T, nearby_columns], ignore_index=True)\n",
    "                \n",
    "                \n",
    "                target_cls = target_column[\"class_id\"]\n",
    "                target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "                col_idx_list = target_table[\"col_idx\"].tolist()\n",
    "\n",
    "                if max_length <= 128 and adaptive_max_length:\n",
    "                    cur_maxlen = min(max_length, 512 // len(target_table) - 1)\n",
    "                else:\n",
    "                    cur_maxlen = max_length\n",
    "                    \n",
    "                token_ids_list = target_table[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                    tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=cur_maxlen, truncation=True)).tolist(\n",
    "                    )\n",
    "                token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                                    token_ids_list)).to(device)\n",
    "\n",
    "                target_col_mask = []\n",
    "                cls_index_value = 0\n",
    "                context_id = 1\n",
    "                meet_target = False\n",
    "                for idx, col_i in enumerate(col_idx_list):\n",
    "                    if col_i == target_col_idx:\n",
    "                        target_col_mask += [0] * len(token_ids_list[idx])\n",
    "                        meet_target = True\n",
    "                    else:\n",
    "                        target_col_mask += [context_id] * len(token_ids_list[idx])\n",
    "                        context_id += 1\n",
    "                    if not meet_target:\n",
    "                        cls_index_value += len(token_ids_list[idx])\n",
    "                cls_index_list = [cls_index_value] \n",
    "                for cls_index in cls_index_list:\n",
    "                    assert token_ids[\n",
    "                        cls_index] == tokenizer.cls_token_id, \"cls_indexes validation\"\n",
    "                cls_indexes = torch.LongTensor(cls_index_list).to(device)\n",
    "                class_ids = torch.LongTensor(\n",
    "                    [target_cls]).to(device)\n",
    "                target_col_mask = torch.LongTensor(target_col_mask).to(device)\n",
    "                data_list.append(\n",
    "                    [index,\n",
    "                    len(target_table), token_ids, class_ids, cls_indexes, target_col_mask])                \n",
    "        print(split, len(data_list))\n",
    "        self.table_df = pd.DataFrame(data_list,\n",
    "                                     columns=[\n",
    "                                         \"table_id\", \"num_col\", \"data_tensor\",\n",
    "                                         \"label_tensor\", \"cls_indexes\", \"target_col_mask\"\n",
    "                                     ])\n",
    "        \"\"\"\n",
    "        # NOTE: msato contains a small portion of single-col tables. keep it to be consistent.  \n",
    "        if multicol_only:\n",
    "            # Check\n",
    "            num_all_tables = len(self.table_df)\n",
    "            self.table_df = self.table_df[self.table_df[\"num_col\"] > 1]\n",
    "            assert len(self.table_df) == num_all_tables\n",
    "        \"\"\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.table_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"data\": self.table_df.iloc[idx][\"data_tensor\"],\n",
    "            \"label\": self.table_df.iloc[idx][\"label_tensor\"],\n",
    "            \"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"],\n",
    "            \"target_col_mask\": self.table_df.iloc[idx][\"target_col_mask\"],\n",
    "        }\n",
    "        #\"idx\": torch.LongTensor([idx])}\n",
    "        #\"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GittablesTablewiseIterateNearbyDataset(data.Dataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            cv: int,\n",
    "            split: str,\n",
    "            src: str,  # train or test\n",
    "            tokenizer: AutoTokenizer,\n",
    "            max_length: int = 256,\n",
    "            gt_only: bool = False,\n",
    "            device: torch.device = None,\n",
    "            base_dirpath: str = \"/data/zhihao/TU/GitTables/semtab_gittables/2022\",\n",
    "            base_tag: str = '', # blank, comma\n",
    "            small_tag: str = \"\",\n",
    "            train_ratio: float = 1.0,\n",
    "            max_unlabeled=8,\n",
    "            adaptive_max_length=True,\n",
    "            random_sample=False, # TODO\n",
    "            train_only=False): # TODO\n",
    "        if device is None:\n",
    "            device = torch.device('cpu')\n",
    "        basename = small_tag+ \"_cv_{}.csv\"\n",
    "    \n",
    "        if split in [\"train\", \"valid\"]:\n",
    "            df_list = []\n",
    "            for i in range(5):\n",
    "                if i == cv:\n",
    "                    continue\n",
    "                filepath = os.path.join(base_dirpath, basename.format(i))\n",
    "                df_list.append(pd.read_csv(filepath))\n",
    "                print(split, i)\n",
    "            df = pd.concat(df_list, axis=0)\n",
    "        else:\n",
    "            # test\n",
    "            filepath = os.path.join(base_dirpath, basename.format(cv))\n",
    "            df = pd.read_csv(filepath)\n",
    "            print(split)\n",
    "\n",
    "\n",
    "        if gt_only:\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "        if train_only and split != \"train\":\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "\n",
    "        \n",
    "        data_list = []\n",
    "        \n",
    "        df['class_id'] = df['class_id'].astype(int)\n",
    "        df.drop(df[(df['data'].isna()) & (df['class_id'] == -1)].index, inplace=True)\n",
    "        df['col_idx'] = df['col_idx'].astype(int)\n",
    "        df['data'] = df['data'].astype(str)\n",
    "        \n",
    "        num_tables = len(df.groupby(\"table_id\"))\n",
    "        valid_index = int(num_tables * 0.8)\n",
    "        num_train = int(train_ratio * num_tables * 0.8)        \n",
    "        \n",
    "        # df.drop(df[(df['data'] == '') & (df['class_id'] == -1)].index, inplace=True)\n",
    "        total_num_cols = 0\n",
    "        for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "            if (split == \"train\") and ((i >= num_train) or (i >= valid_index)):\n",
    "                break\n",
    "            if split == \"valid\" and i < valid_index:\n",
    "                continue\n",
    "            #     break\n",
    "            labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "            for index, target_column in labeled_columns.iterrows():\n",
    "                target_col_idx = target_column[\"col_idx\"]\n",
    "                \n",
    "                other_columns = group_df.drop(index)\n",
    "                \n",
    "                other_columns['distance'] = abs(other_columns['col_idx'] - target_col_idx)\n",
    "                other_columns.sort_values(by='distance', inplace=True)\n",
    "                nearby_columns = other_columns.head(max_unlabeled-1)\n",
    "                target_table = pd.concat([target_column.to_frame().T, nearby_columns], ignore_index=True)\n",
    "                \n",
    "                \n",
    "                \n",
    "                # other_labeled = other_columns[other_columns['class_id'] > -1].head(max_unlabeled-1)\n",
    "                # other_unlabeled = other_columns[other_columns['class_id'] == -1]\n",
    "                # other_unlabeled['distance'] = abs(other_unlabeled['col_idx'] - target_col_idx)\n",
    "                # other_unlabeled.sort_values(by='distance', inplace=True)\n",
    "                # nearby_columns = other_unlabeled.head(max_unlabeled-len(other_labeled)-1)\n",
    "                # target_table = pd.concat([target_column.to_frame().T, other_labeled, nearby_columns], ignore_index=True)\n",
    "\n",
    "                # other_columns['distance'] = abs(other_columns['col_idx'] - target_col_idx)\n",
    "                # other_columns.sort_values(by='distance', inplace=True)\n",
    "                # nearby_columns = other_columns.head(max_unlabeled-1)\n",
    "                # target_table = pd.concat([target_column.to_frame().T, nearby_columns], ignore_index=True)\n",
    "                \n",
    "                \n",
    "                target_cls = target_column[\"class_id\"]\n",
    "                # target_table.sort_values(by=['col_idx'], inplace=True) # TODO:\n",
    "                col_idx_list = target_table[\"col_idx\"].tolist()\n",
    "\n",
    "                if max_length <= 128 and adaptive_max_length:\n",
    "                    cur_maxlen = min(max_length, 512 // len(target_table) - 1)\n",
    "                else:\n",
    "                    cur_maxlen = max_length\n",
    "                    \n",
    "                token_ids_list = target_table[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                    tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=cur_maxlen, truncation=True)).tolist(\n",
    "                    )\n",
    "                token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                                    token_ids_list)).to(device)\n",
    "\n",
    "                target_col_mask = []\n",
    "                cls_index_value = 0\n",
    "                context_id = 1\n",
    "                meet_target = False\n",
    "                for idx, col_i in enumerate(col_idx_list):\n",
    "                    if col_i == target_col_idx:\n",
    "                        target_col_mask += [0] * len(token_ids_list[idx])\n",
    "                        meet_target = True\n",
    "                    else:\n",
    "                        target_col_mask += [context_id] * len(token_ids_list[idx])\n",
    "                        context_id += 1\n",
    "                    if not meet_target:\n",
    "                        cls_index_value += len(token_ids_list[idx])\n",
    "                cls_index_list = [cls_index_value] \n",
    "                for cls_index in cls_index_list:\n",
    "                    assert token_ids[\n",
    "                        cls_index] == tokenizer.cls_token_id, \"cls_indexes validation\"\n",
    "                cls_indexes = torch.LongTensor(cls_index_list).to(device)\n",
    "                class_ids = torch.LongTensor(\n",
    "                    [target_cls]).to(device)\n",
    "                target_col_mask = torch.LongTensor(target_col_mask).to(device)\n",
    "                data_list.append(\n",
    "                    [index,\n",
    "                    len(target_table), token_ids, class_ids, cls_indexes, target_col_mask])                \n",
    "        print(split, len(data_list))\n",
    "        self.table_df = pd.DataFrame(data_list,\n",
    "                                     columns=[\n",
    "                                         \"table_id\", \"num_col\", \"data_tensor\",\n",
    "                                         \"label_tensor\", \"cls_indexes\", \"target_col_mask\"\n",
    "                                     ])\n",
    "        \"\"\"\n",
    "        # NOTE: msato contains a small portion of single-col tables. keep it to be consistent.  \n",
    "        if multicol_only:\n",
    "            # Check\n",
    "            num_all_tables = len(self.table_df)\n",
    "            self.table_df = self.table_df[self.table_df[\"num_col\"] > 1]\n",
    "            assert len(self.table_df) == num_all_tables\n",
    "        \"\"\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.table_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"data\": self.table_df.iloc[idx][\"data_tensor\"],\n",
    "            \"label\": self.table_df.iloc[idx][\"label_tensor\"],\n",
    "            \"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"],\n",
    "            \"target_col_mask\": self.table_df.iloc[idx][\"target_col_mask\"],\n",
    "        }\n",
    "        #\"idx\": torch.LongTensor([idx])}\n",
    "        #\"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get first 8 columns, put target column in the last\n",
    "class GittablesTablewiseIterateNearbyLastDataset(data.Dataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            cv: int,\n",
    "            split: str,\n",
    "            src: str,  # train or test\n",
    "            tokenizer: AutoTokenizer,\n",
    "            max_length: int = 256,\n",
    "            gt_only: bool = False,\n",
    "            device: torch.device = None,\n",
    "            base_dirpath: str = \"/data/zhihao/TU/GitTables/semtab_gittables/2022\",\n",
    "            base_tag: str = '', # blank, comma\n",
    "            small_tag: str = \"\",\n",
    "            train_ratio: float = 1.0,\n",
    "            max_unlabeled=8,\n",
    "            adaptive_max_length=True,\n",
    "            random_sample=False, # TODO\n",
    "            train_only=False): # TODO\n",
    "        if device is None:\n",
    "            device = torch.device('cpu')\n",
    "        basename = small_tag+ \"_cv_{}.csv\"\n",
    "    \n",
    "        if split in [\"train\", \"valid\"]:\n",
    "            df_list = []\n",
    "            for i in range(5):\n",
    "                if i == cv:\n",
    "                    continue\n",
    "                filepath = os.path.join(base_dirpath, basename.format(i))\n",
    "                df_list.append(pd.read_csv(filepath))\n",
    "                print(split, i)\n",
    "            df = pd.concat(df_list, axis=0)\n",
    "        else:\n",
    "            # test\n",
    "            filepath = os.path.join(base_dirpath, basename.format(cv))\n",
    "            df = pd.read_csv(filepath)\n",
    "            print(split)\n",
    "\n",
    "\n",
    "        if gt_only:\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "        if train_only and split != \"train\":\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "\n",
    "        \n",
    "        data_list = []\n",
    "        \n",
    "        df['class_id'] = df['class_id'].astype(int)\n",
    "        df.drop(df[(df['data'].isna()) & (df['class_id'] == -1)].index, inplace=True)\n",
    "        df['col_idx'] = df['col_idx'].astype(int)\n",
    "        df['data'] = df['data'].astype(str)\n",
    "        \n",
    "        num_tables = len(df.groupby(\"table_id\"))\n",
    "        valid_index = int(num_tables * 0.8)\n",
    "        num_train = int(train_ratio * num_tables * 0.8)        \n",
    "        \n",
    "        # df.drop(df[(df['data'] == '') & (df['class_id'] == -1)].index, inplace=True)\n",
    "        total_num_cols = 0\n",
    "        for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "            if (split == \"train\") and ((i >= num_train) or (i >= valid_index)):\n",
    "                break\n",
    "            if split == \"valid\" and i < valid_index:\n",
    "                continue\n",
    "            #     break\n",
    "            labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "            for index, target_column in labeled_columns.iterrows():\n",
    "                target_col_idx = target_column[\"col_idx\"]\n",
    "                \n",
    "                other_columns = group_df.drop(index)\n",
    "                \n",
    "                # other_columns['distance'] = abs(other_columns['col_idx'] - target_col_idx)\n",
    "                # other_columns.sort_values(by='distance', inplace=True)\n",
    "                # nearby_columns = other_columns.head(max_unlabeled-1)\n",
    "                # target_table = pd.concat([target_column.to_frame().T, nearby_columns], ignore_index=True)\n",
    "                \n",
    "                \n",
    "                \n",
    "                # other_labeled = other_columns[other_columns['class_id'] > -1].head(max_unlabeled-1)\n",
    "                # other_unlabeled = other_columns[other_columns['class_id'] == -1]\n",
    "                # other_unlabeled['distance'] = abs(other_unlabeled['col_idx'] - target_col_idx)\n",
    "                # other_unlabeled.sort_values(by='distance', inplace=True)\n",
    "                # nearby_columns = other_unlabeled.head(max_unlabeled-len(other_labeled)-1)\n",
    "                # target_table = pd.concat([target_column.to_frame().T, other_labeled, nearby_columns], ignore_index=True)\n",
    "\n",
    "                other_columns['distance'] = abs(other_columns['col_idx'] - target_col_idx)\n",
    "                other_columns.sort_values(by='distance', inplace=True)\n",
    "                nearby_columns = other_columns.head(max_unlabeled-1)\n",
    "                nearby_columns.sort_values(by=['col_idx'], inplace=True)\n",
    "                target_table = pd.concat([ target_column.to_frame().T, nearby_columns], ignore_index=True)\n",
    "                \n",
    "                \n",
    "                target_cls = target_table[\"class_id\"].values[0]\n",
    "                \n",
    "                \n",
    "                # target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "                col_idx_list = target_table[\"col_idx\"].tolist()\n",
    "\n",
    "                if max_length <= 128 and adaptive_max_length:\n",
    "                    cur_maxlen = min(max_length, 512 // len(target_table) - 1)\n",
    "                else:\n",
    "                    cur_maxlen = max_length\n",
    "                    \n",
    "                token_ids_list = target_table[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                    tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=cur_maxlen, truncation=True)).tolist(\n",
    "                    )\n",
    "                token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                                    token_ids_list)).to(device)\n",
    "\n",
    "                target_col_mask = []\n",
    "                cls_index_value = 0\n",
    "                context_id = 1\n",
    "                meet_target = False\n",
    "                for idx, col_i in enumerate(col_idx_list):\n",
    "                    if col_i == target_col_idx:\n",
    "                        target_col_mask += [0] * len(token_ids_list[idx])\n",
    "                        meet_target = True\n",
    "                    else:\n",
    "                        target_col_mask += [context_id] * len(token_ids_list[idx])\n",
    "                        context_id += 1\n",
    "                    if not meet_target:\n",
    "                        cls_index_value += len(token_ids_list[idx])\n",
    "                cls_index_list = [cls_index_value] \n",
    "                for cls_index in cls_index_list:\n",
    "                    assert token_ids[\n",
    "                        cls_index] == tokenizer.cls_token_id, \"cls_indexes validation\"\n",
    "                cls_indexes = torch.LongTensor(cls_index_list).to(device)\n",
    "                class_ids = torch.LongTensor(\n",
    "                    [target_cls]).to(device)\n",
    "                target_col_mask = torch.LongTensor(target_col_mask).to(device)\n",
    "                data_list.append(\n",
    "                    [index,\n",
    "                    len(target_table), token_ids, class_ids, cls_indexes, target_col_mask])                \n",
    "        print(split, len(data_list))\n",
    "        self.table_df = pd.DataFrame(data_list,\n",
    "                                     columns=[\n",
    "                                         \"table_id\", \"num_col\", \"data_tensor\",\n",
    "                                         \"label_tensor\", \"cls_indexes\", \"target_col_mask\"\n",
    "                                     ])\n",
    "        \"\"\"\n",
    "        # NOTE: msato contains a small portion of single-col tables. keep it to be consistent.  \n",
    "        if multicol_only:\n",
    "            # Check\n",
    "            num_all_tables = len(self.table_df)\n",
    "            self.table_df = self.table_df[self.table_df[\"num_col\"] > 1]\n",
    "            assert len(self.table_df) == num_all_tables\n",
    "        \"\"\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.table_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"data\": self.table_df.iloc[idx][\"data_tensor\"],\n",
    "            \"label\": self.table_df.iloc[idx][\"label_tensor\"],\n",
    "            \"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"],\n",
    "            \"target_col_mask\": self.table_df.iloc[idx][\"target_col_mask\"],\n",
    "        }\n",
    "        #\"idx\": torch.LongTensor([idx])}\n",
    "        #\"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GittablesTablewiseIterateHybridDataset(data.Dataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            cv: int,\n",
    "            split: str,\n",
    "            src: str,  # train or test\n",
    "            tokenizer: AutoTokenizer,\n",
    "            max_length: int = 256,\n",
    "            gt_only: bool = False,\n",
    "            device: torch.device = None,\n",
    "            base_dirpath: str = \"/data/zhihao/TU/GitTables/semtab_gittables/2022\",\n",
    "            base_tag: str = '', # blank, comma\n",
    "            small_tag: str = \"\",\n",
    "            train_ratio: float = 1.0,\n",
    "            max_unlabeled=8,\n",
    "            adaptive_max_length=True,\n",
    "            random_sample=False, # TODO\n",
    "            train_only=False): # TODO\n",
    "        if device is None:\n",
    "            device = torch.device('cpu')\n",
    "        basename = small_tag+ \"_cv_{}.csv\"\n",
    "    \n",
    "        if split in [\"train\", \"valid\"]:\n",
    "            df_list = []\n",
    "            for i in range(5):\n",
    "                if i == cv:\n",
    "                    continue\n",
    "                filepath = os.path.join(base_dirpath, basename.format(i))\n",
    "                df_list.append(pd.read_csv(filepath))\n",
    "                print(split, i)\n",
    "            df = pd.concat(df_list, axis=0)\n",
    "        else:\n",
    "            # test\n",
    "            filepath = os.path.join(base_dirpath, basename.format(cv))\n",
    "            df = pd.read_csv(filepath)\n",
    "            print(split)\n",
    "\n",
    "\n",
    "        if gt_only:\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "        if train_only and split != \"train\":\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "\n",
    "        \n",
    "        data_list = []\n",
    "        \n",
    "        df['class_id'] = df['class_id'].astype(int)\n",
    "        df.drop(df[(df['data'].isna()) & (df['class_id'] == -1)].index, inplace=True)\n",
    "        df['col_idx'] = df['col_idx'].astype(int)\n",
    "        df['data'] = df['data'].astype(str)\n",
    "        \n",
    "        num_tables = len(df.groupby(\"table_id\"))\n",
    "        valid_index = int(num_tables * 0.8)\n",
    "        num_train = int(train_ratio * num_tables * 0.8)        \n",
    "        \n",
    "        # df.drop(df[(df['data'] == '') & (df['class_id'] == -1)].index, inplace=True)\n",
    "        total_num_cols = 0\n",
    "        for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "            if (split == \"train\") and ((i >= num_train) or (i >= valid_index)):\n",
    "                break\n",
    "            if split == \"valid\" and i < valid_index:\n",
    "                continue\n",
    "            #     break\n",
    "            labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "            # if len(group_df) > 10:\n",
    "            #     print(i, len(group_df))\n",
    "            for index, target_column in labeled_columns.iterrows():\n",
    "                first_col_num = 3\n",
    "                target_col_idx = target_column[\"col_idx\"]\n",
    "                \n",
    "                other_columns = group_df.drop(index).sort_values(by=['col_idx'])\n",
    "                first_columns = other_columns.head(first_col_num)\n",
    "                other_columns = other_columns.drop(first_columns.index.values)\n",
    "                \n",
    "                # if len(other_columns) > 0:\n",
    "                other_columns['distance'] = abs(other_columns['col_idx'] - target_col_idx)\n",
    "                other_columns.sort_values(by='distance', inplace=True)\n",
    "                nearby_columns = other_columns.head(max_unlabeled-1-first_col_num)\n",
    "                target_table = pd.concat([target_column.to_frame().T, first_columns, nearby_columns], ignore_index=True)\n",
    "                \n",
    "                \n",
    "                target_cls = target_table[\"class_id\"].values[0]\n",
    "                target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "                col_idx_list = target_table[\"col_idx\"].tolist()\n",
    "                # target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "\n",
    "                if max_length <= 128 and adaptive_max_length:\n",
    "                    cur_maxlen = min(max_length, 512 // len(target_table) - 1)\n",
    "                else:\n",
    "                    cur_maxlen = max_length\n",
    "                    \n",
    "                token_ids_list = target_table[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                    tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=cur_maxlen, truncation=True)).tolist(\n",
    "                    )\n",
    "                token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                                    token_ids_list)).to(device)\n",
    "\n",
    "                target_col_mask = []\n",
    "                cls_index_value = 0\n",
    "                context_id = 1\n",
    "                meet_target = False\n",
    "                for idx, col_i in enumerate(col_idx_list):\n",
    "                    if col_i == target_col_idx:\n",
    "                        target_col_mask += [0] * len(token_ids_list[idx])\n",
    "                        meet_target = True\n",
    "                    else:\n",
    "                        target_col_mask += [context_id] * len(token_ids_list[idx])\n",
    "                        context_id += 1\n",
    "                    if not meet_target:\n",
    "                        cls_index_value += len(token_ids_list[idx])\n",
    "                cls_index_list = [cls_index_value] \n",
    "                for cls_index in cls_index_list:\n",
    "                    assert token_ids[\n",
    "                        cls_index] == tokenizer.cls_token_id, \"cls_indexes validation\"\n",
    "                cls_indexes = torch.LongTensor(cls_index_list).to(device)\n",
    "                class_ids = torch.LongTensor(\n",
    "                    [target_cls]).to(device)\n",
    "                target_col_mask = torch.LongTensor(target_col_mask).to(device)\n",
    "                data_list.append(\n",
    "                    [index,\n",
    "                    len(target_table), token_ids, class_ids, cls_indexes, target_col_mask])                \n",
    "        print(split, len(data_list))\n",
    "        self.table_df = pd.DataFrame(data_list,\n",
    "                                     columns=[\n",
    "                                         \"table_id\", \"num_col\", \"data_tensor\",\n",
    "                                         \"label_tensor\", \"cls_indexes\", \"target_col_mask\"\n",
    "                                     ])\n",
    "        \"\"\"\n",
    "        # NOTE: msato contains a small portion of single-col tables. keep it to be consistent.  \n",
    "        if multicol_only:\n",
    "            # Check\n",
    "            num_all_tables = len(self.table_df)\n",
    "            self.table_df = self.table_df[self.table_df[\"num_col\"] > 1]\n",
    "            assert len(self.table_df) == num_all_tables\n",
    "        \"\"\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.table_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"data\": self.table_df.iloc[idx][\"data_tensor\"],\n",
    "            \"label\": self.table_df.iloc[idx][\"label_tensor\"],\n",
    "            \"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"],\n",
    "            \"target_col_mask\": self.table_df.iloc[idx][\"target_col_mask\"],\n",
    "        }\n",
    "        #\"idx\": torch.LongTensor([idx])}\n",
    "        #\"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_columns = group_df.sort_values(by=['col_idx'])\n",
    "first_columns = other_columns.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_columns.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_columns = other_columns.drop(first_columns.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(labeled_columns.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "sb_model = SentenceTransformer(\"all-mpnet-base-v2\", cache_folder=\"/data/zhihao/TU/Watchog/sentence_transformers_cache\")\n",
    "\n",
    "class GittablesTablewiseIterateSentenceDataset(data.Dataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            cv: int,\n",
    "            split: str,\n",
    "            src: str,  # train or test\n",
    "            tokenizer: AutoTokenizer,\n",
    "            max_length: int = 256,\n",
    "            gt_only: bool = False,\n",
    "            device: torch.device = None,\n",
    "            base_dirpath: str = \"/data/zhihao/TU/GitTables/semtab_gittables/2022\",\n",
    "            base_tag: str = '', # blank, comma\n",
    "            small_tag: str = \"\",\n",
    "            train_ratio: float = 1.0,\n",
    "            max_unlabeled=8,\n",
    "            adaptive_max_length=True,\n",
    "            random_sample=False, # TODO\n",
    "            train_only=False): # TODO\n",
    "        if device is None:\n",
    "            device = torch.device('cpu')\n",
    "        basename = small_tag+ \"_cv_{}.csv\"\n",
    "    \n",
    "        if split in [\"train\", \"valid\"]:\n",
    "            df_list = []\n",
    "            for i in range(5):\n",
    "                if i == cv:\n",
    "                    continue\n",
    "                filepath = os.path.join(base_dirpath, basename.format(i))\n",
    "                df_list.append(pd.read_csv(filepath))\n",
    "                print(split, i)\n",
    "            df = pd.concat(df_list, axis=0)\n",
    "        else:\n",
    "            # test\n",
    "            filepath = os.path.join(base_dirpath, basename.format(cv))\n",
    "            df = pd.read_csv(filepath)\n",
    "            print(split)\n",
    "\n",
    "\n",
    "        if gt_only:\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "        if train_only and split != \"train\":\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "\n",
    "        \n",
    "        data_list = []\n",
    "        \n",
    "        df['class_id'] = df['class_id'].astype(int)\n",
    "        df.drop(df[(df['data'].isna()) & (df['class_id'] == -1)].index, inplace=True)\n",
    "        df['col_idx'] = df['col_idx'].astype(int)\n",
    "        df['data'] = df['data'].astype(str)\n",
    "        \n",
    "        num_tables = len(df.groupby(\"table_id\"))\n",
    "        valid_index = int(num_tables * 0.8)\n",
    "        num_train = int(train_ratio * num_tables * 0.8)        \n",
    "        \n",
    "        # df.drop(df[(df['data'] == '') & (df['class_id'] == -1)].index, inplace=True)\n",
    "        total_num_cols = 0\n",
    "        for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "            if (split == \"train\") and ((i >= num_train) or (i >= valid_index)):\n",
    "                break\n",
    "            if split == \"valid\" and i < valid_index:\n",
    "                continue\n",
    "            #     break\n",
    "            group_df.sort_values(by=[\"col_idx\"], inplace=True)\n",
    "            unlabeled_columns = group_df[group_df['class_id'] == -1]\n",
    "            labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "            unlabeled_columns = unlabeled_columns.drop_duplicates(subset=['data'], keep='last')\n",
    "            group_df = pd.concat([labeled_columns, unlabeled_columns])\n",
    "            group_df.sort_values(by=['col_idx'], inplace=True)\n",
    "            group_df = group_df.reset_index(drop=True)\n",
    "            \n",
    "            # col_embs = torch.tensor(sb_model.encode(group_df[\"data\"].to_list()))\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                token_list = group_df[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                        tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=max_length, truncation=True)).tolist()\n",
    "                token_list = torch.nn.utils.rnn.pad_sequence(\n",
    "                [torch.LongTensor(tokens) for tokens in token_list], padding_value=0).T.to(device)\n",
    "                cls_indexes = torch.nonzero(\n",
    "                            token_list == tokenizer.cls_token_id)\n",
    "                logits, embs = model(token_list, cls_indexes=cls_indexes, get_enc=True)\n",
    "                col_embs = embs.cpu()\n",
    "                if len(embs.size()) == 1:\n",
    "                    col_embs = col_embs.unsqueeze(0)\n",
    "\n",
    "            labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "            unlabeled_columns = group_df[group_df['class_id'] == -1]\n",
    "            col_embs_unlabeled = col_embs[torch.tensor(unlabeled_columns.index.values)]\n",
    "            for index_i, target_column in labeled_columns.iterrows():\n",
    "                \n",
    "                chosen_columns_idx = F.cosine_similarity(col_embs[index_i].reshape(1,-1), col_embs).argsort(descending=True)[:max_unlabeled+1].tolist()\n",
    "                chosen_columns_idx = chosen_columns_idx[1:]\n",
    "                target_table = group_df.iloc[chosen_columns_idx]\n",
    "                target_table = pd.concat([target_column.to_frame().T, target_table], ignore_index=True)\n",
    "                \n",
    "                # other_labeled = labeled_columns.drop(index_i)\n",
    "                # chosen_columns_idx = F.cosine_similarity(col_embs[index_i].reshape(1,-1), col_embs_unlabeled).argsort(descending=True)[:max_unlabeled-len(other_labeled)-1].tolist()\n",
    "                # target_table = unlabeled_columns.iloc[chosen_columns_idx]\n",
    "                # target_table = pd.concat([target_column.to_frame().T, other_labeled, target_table], ignore_index=True)\n",
    "                \n",
    "                \n",
    "                target_col_idx = target_table[\"col_idx\"].values[0]\n",
    "                target_cls = target_table[\"class_id\"].values[0]\n",
    "                # target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "                col_idx_list = target_table[\"col_idx\"].tolist()\n",
    "\n",
    "\n",
    "                if max_length <= 128 and adaptive_max_length:\n",
    "                    cur_maxlen = min(max_length, 512 // len(target_table) - 1)\n",
    "                else:\n",
    "                    cur_maxlen = max_length\n",
    "                    \n",
    "                token_ids_list = target_table[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                    tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=cur_maxlen, truncation=True)).tolist(\n",
    "                    )\n",
    "                token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                                    token_ids_list)).to(device)\n",
    "\n",
    "                target_col_mask = []\n",
    "                cls_index_value = 0\n",
    "                context_id = 1\n",
    "                meet_target = False\n",
    "                for idx, col_i in enumerate(col_idx_list):\n",
    "                    if col_i == target_col_idx:\n",
    "                        target_col_mask += [0] * len(token_ids_list[idx])\n",
    "                        meet_target = True\n",
    "                    else:\n",
    "                        target_col_mask += [context_id] * len(token_ids_list[idx])\n",
    "                        context_id += 1\n",
    "                    if not meet_target:\n",
    "                        cls_index_value += len(token_ids_list[idx])\n",
    "                cls_index_list = [cls_index_value] \n",
    "                for cls_index in cls_index_list:\n",
    "                    assert token_ids[\n",
    "                        cls_index] == tokenizer.cls_token_id, \"cls_indexes validation\"\n",
    "                cls_indexes = torch.LongTensor(cls_index_list).to(device)\n",
    "                class_ids = torch.LongTensor(\n",
    "                    [target_cls]).to(device)\n",
    "                target_col_mask = torch.LongTensor(target_col_mask).to(device)\n",
    "                data_list.append(\n",
    "                    [index,\n",
    "                    len(target_table), token_ids, class_ids, cls_indexes, target_col_mask])                \n",
    "        print(split, len(data_list))\n",
    "        self.table_df = pd.DataFrame(data_list,\n",
    "                                     columns=[\n",
    "                                         \"table_id\", \"num_col\", \"data_tensor\",\n",
    "                                         \"label_tensor\", \"cls_indexes\", \"target_col_mask\"\n",
    "                                     ])\n",
    "        \"\"\"\n",
    "        # NOTE: msato contains a small portion of single-col tables. keep it to be consistent.  \n",
    "        if multicol_only:\n",
    "            # Check\n",
    "            num_all_tables = len(self.table_df)\n",
    "            self.table_df = self.table_df[self.table_df[\"num_col\"] > 1]\n",
    "            assert len(self.table_df) == num_all_tables\n",
    "        \"\"\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.table_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"data\": self.table_df.iloc[idx][\"data_tensor\"],\n",
    "            \"label\": self.table_df.iloc[idx][\"label_tensor\"],\n",
    "            \"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"],\n",
    "            \"target_col_mask\": self.table_df.iloc[idx][\"target_col_mask\"],\n",
    "        }\n",
    "        #\"idx\": torch.LongTensor([idx])}\n",
    "        #\"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sentence_transformers import SentenceTransformer\n",
    "# sb_model = SentenceTransformer(\"all-mpnet-base-v2\", cache_folder=\"/data/zhihao/TU/Watchog/sentence_transformers_cache\")\n",
    "\n",
    "class GittablesTablewiseCorrelationDataset(data.Dataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            cv: int,\n",
    "            split: str,\n",
    "            src: str,  # train or test\n",
    "            tokenizer: AutoTokenizer,\n",
    "            max_length: int = 256,\n",
    "            gt_only: bool = False,\n",
    "            device: torch.device = None,\n",
    "            base_dirpath: str = \"/data/zhihao/TU/GitTables/semtab_gittables/2022\",\n",
    "            base_tag: str = '', # blank, comma\n",
    "            small_tag: str = \"\",\n",
    "            train_ratio: float = 1.0,\n",
    "            max_unlabeled=8,\n",
    "            adaptive_max_length=True,\n",
    "            random_sample=False, # TODO\n",
    "            train_only=False): # TODO\n",
    "        if device is None:\n",
    "            device = torch.device('cpu')\n",
    "        basename = small_tag+ \"_cv_{}.csv\"\n",
    "    \n",
    "        if split in [\"train\", \"valid\"]:\n",
    "            df_list = []\n",
    "            for i in range(5):\n",
    "                if i == cv:\n",
    "                    continue\n",
    "                filepath = os.path.join(base_dirpath, basename.format(i))\n",
    "                df_list.append(pd.read_csv(filepath))\n",
    "                print(split, i)\n",
    "            df = pd.concat(df_list, axis=0)\n",
    "        else:\n",
    "            # test\n",
    "            filepath = os.path.join(base_dirpath, basename.format(cv))\n",
    "            df = pd.read_csv(filepath)\n",
    "            print(split)\n",
    "\n",
    "\n",
    "        if gt_only:\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "        if train_only and split != \"train\":\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "\n",
    "        \n",
    "        data_list = []\n",
    "        \n",
    "        df['class_id'] = df['class_id'].astype(int)\n",
    "        df.drop(df[(df['data'].isna()) & (df['class_id'] == -1)].index, inplace=True)\n",
    "        df['col_idx'] = df['col_idx'].astype(int)\n",
    "        df['data'] = df['data'].astype(str)\n",
    "        \n",
    "        num_tables = len(df.groupby(\"table_id\"))\n",
    "        valid_index = int(num_tables * 0.8)\n",
    "        num_train = int(train_ratio * num_tables * 0.8)        \n",
    "        \n",
    "        # df.drop(df[(df['data'] == '') & (df['class_id'] == -1)].index, inplace=True)\n",
    "        total_num_cols = 0\n",
    "        for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "            if (split == \"train\") and ((i >= num_train) or (i >= valid_index)):\n",
    "                break\n",
    "            if split == \"valid\" and i < valid_index:\n",
    "                continue\n",
    "            #     break\n",
    "            group_df.sort_values(by=['col_idx'], inplace=True)\n",
    "            group_df = group_df.reset_index(drop=True)\n",
    "            labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "            # if len(group_df) > 10:\n",
    "            #     print(i, len(group_df))\n",
    "            for index, target_column in labeled_columns.iterrows():\n",
    "                other_columns = group_df.drop(index)\n",
    "                # other_columns = group_df.drop(labeled_columns.index) # TODO\n",
    "                target_col_idx = target_column[\"col_idx\"]\n",
    "                if len(other_columns) ==  0:\n",
    "                    target_table = group_df\n",
    "                else:\n",
    "                    column_pairs = []\n",
    "                    for index in range(len(other_columns)):\n",
    "                        if other_columns.iloc[index][\"col_idx\"] <= target_col_idx:\n",
    "                            column_pairs.append((other_columns.iloc[index][\"data\"], target_column[\"data\"]))\n",
    "                        else:\n",
    "                            column_pairs.append((target_column[\"data\"], other_columns.iloc[index][\"data\"]))\n",
    "                    encoded_pairs = tokenizer.batch_encode_plus(\n",
    "                        column_pairs,\n",
    "                        return_tensors='pt',  # Return PyTorch tensors\n",
    "                        max_length=512,  # Set a maximum length for each pair\n",
    "                        truncation=True,  # Enable truncation\n",
    "                        padding=True  # Pad to the longest sequence in the batch\n",
    "                    )\n",
    "                    with torch.no_grad():\n",
    "                        outputs = next_predictor(**encoded_pairs)\n",
    "                    scores = torch.softmax(outputs.logits, dim=1)[:, 0]\n",
    "                    selected_idx = scores.topk(min(max_unlabeled, len(group_df))-1).indices.tolist()\n",
    "                    target_table = pd.concat([target_column.to_frame().T, other_columns.iloc[selected_idx]], ignore_index=True) \n",
    "                    # selected_idx = scores.topk(min(max_unlabeled, len(group_df))-1-len(labeled_columns)).indices.tolist() # TODO\n",
    "                    # target_table = pd.concat([labeled_columns, other_columns.iloc[selected_idx]], ignore_index=True) # TODO\n",
    "                target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "                \n",
    "                target_cls = target_column[\"class_id\"]\n",
    "                col_idx_list = target_table[\"col_idx\"].tolist()\n",
    "                assert target_col_idx in col_idx_list\n",
    "                target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "\n",
    "                if max_length <= 128 and adaptive_max_length:\n",
    "                    cur_maxlen = min(max_length, 512 // len(target_table) - 1)\n",
    "                else:\n",
    "                    cur_maxlen = max_length\n",
    "                    \n",
    "                token_ids_list = target_table[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                    tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=cur_maxlen, truncation=True)).tolist(\n",
    "                    )\n",
    "                token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                                    token_ids_list)).to(device)\n",
    "\n",
    "                target_col_mask = []\n",
    "                cls_index_value = 0\n",
    "                context_id = 1\n",
    "                meet_target = False\n",
    "                for idx, col_i in enumerate(col_idx_list):\n",
    "                    if col_i == target_col_idx:\n",
    "                        target_col_mask += [0] * len(token_ids_list[idx])\n",
    "                        meet_target = True\n",
    "                    else:\n",
    "                        target_col_mask += [context_id] * len(token_ids_list[idx])\n",
    "                        context_id += 1\n",
    "                    if not meet_target:\n",
    "                        cls_index_value += len(token_ids_list[idx])\n",
    "                cls_index_list = [cls_index_value] \n",
    "                for cls_index in cls_index_list:\n",
    "                    assert token_ids[\n",
    "                        cls_index] == tokenizer.cls_token_id, \"cls_indexes validation\"\n",
    "                cls_indexes = torch.LongTensor(cls_index_list).to(device)\n",
    "                class_ids = torch.LongTensor(\n",
    "                    [target_cls]).to(device)\n",
    "                target_col_mask = torch.LongTensor(target_col_mask).to(device)\n",
    "                data_list.append(\n",
    "                    [index,\n",
    "                    len(target_table), token_ids, class_ids, cls_indexes, target_col_mask])                \n",
    "        print(split, len(data_list))\n",
    "        self.table_df = pd.DataFrame(data_list,\n",
    "                                     columns=[\n",
    "                                         \"table_id\", \"num_col\", \"data_tensor\",\n",
    "                                         \"label_tensor\", \"cls_indexes\", \"target_col_mask\"\n",
    "                                     ])\n",
    "        \"\"\"\n",
    "        # NOTE: msato contains a small portion of single-col tables. keep it to be consistent.  \n",
    "        if multicol_only:\n",
    "            # Check\n",
    "            num_all_tables = len(self.table_df)\n",
    "            self.table_df = self.table_df[self.table_df[\"num_col\"] > 1]\n",
    "            assert len(self.table_df) == num_all_tables\n",
    "        \"\"\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.table_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"data\": self.table_df.iloc[idx][\"data_tensor\"],\n",
    "            \"label\": self.table_df.iloc[idx][\"label_tensor\"],\n",
    "            \"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"],\n",
    "            \"target_col_mask\": self.table_df.iloc[idx][\"target_col_mask\"],\n",
    "        }\n",
    "        #\"idx\": torch.LongTensor([idx])}\n",
    "        #\"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column[\"class_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok = False\n",
    "for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "    group_df.sort_values(by=[\"col_idx\"], inplace=True)\n",
    "    group_df = group_df.reset_index(drop=True)\n",
    "    labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "    # if len(group_df) > 10:\n",
    "    #     print(i, len(group_df))\n",
    "    for index, target_column in labeled_columns.iterrows():\n",
    "\n",
    "        target_col_idx = target_column[\"col_idx\"]\n",
    "        column_pairs = []\n",
    "        for index in range(len(group_df)):\n",
    "            if group_df.iloc[index][\"col_idx\"] <= target_col_idx:\n",
    "                column_pairs.append((group_df.iloc[index][\"data\"], target_column[\"data\"]))\n",
    "            else:\n",
    "                column_pairs.append((target_column[\"data\"], group_df.iloc[index][\"data\"]))\n",
    "        encoded_pairs = tokenizer.batch_encode_plus(\n",
    "            column_pairs,\n",
    "            return_tensors='pt',  # Return PyTorch tensors\n",
    "            max_length=512,  # Set a maximum length for each pair\n",
    "            truncation=True,  # Enable truncation\n",
    "            padding=True  # Pad to the longest sequence in the batch\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            outputs = next_predictor(**encoded_pairs)\n",
    "        scores = torch.softmax(outputs.logits, dim=1)[:, 0]\n",
    "        selected_idx = scores.topk(min(max_unlabeled, len(group_df))).indices.tolist()\n",
    "        if min(selected_idx) < target_col_idx and max(selected_idx) > target_col_idx and len(group_df) > 10:\n",
    "            ok = True\n",
    "        target_table = group_df.iloc[selected_idx]\n",
    "\n",
    "        target_table.sort_values(by=['col_idx'], inplace=True) \n",
    "    \n",
    "        \n",
    "    #     if target_col_idx != 0 and target_col_idx < len(group_df)-1 and len(group_df) > 10:\n",
    "    #         ok = True\n",
    "    #         break\n",
    "    if ok:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptive_max_length=True\n",
    "global_i = 0 \n",
    "for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "    group_df.sort_values(by=['class_id'], inplace=True)\n",
    "    unlabeled_columns = group_df[group_df['class_id'] == -1]\n",
    "    labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "    unlabeled_columns = unlabeled_columns.drop_duplicates(subset=['data'], keep='last')\n",
    "    group_df = pd.concat([labeled_columns, unlabeled_columns])\n",
    "    group_df.sort_values(by=['col_idx'], inplace=True)\n",
    "    group_df = group_df.reset_index(drop=True)\n",
    "    col_embs = torch.tensor(sb_model.encode(group_df[\"data\"].to_list()))\n",
    "    labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "    for index_i, target_column in labeled_columns.iterrows():\n",
    "        \n",
    "        chosen_columns_idx = F.cosine_similarity(col_embs[index_i].reshape(1,-1), col_embs).argsort(descending=True)[:max_unlabeled+1].tolist()\n",
    "        chosen_columns_idx.remove(index_i)\n",
    "        target_table = group_df.iloc[chosen_columns_idx]\n",
    "        target_table = pd.concat([target_column.to_frame().T, target_table], ignore_index=True)\n",
    "\n",
    "        # other_labeled = labeled_columns.drop(index_i)\n",
    "        # target_table = group_df.iloc[F.cosine_similarity(col_embs[index_i].reshape(1,-1), col_embs).argsort(descending=True)[:max_unlabeled-len(other_labeled)].tolist()]\n",
    "        # target_table = pd.concat([target_table, other_labeled], ignore_index=True)\n",
    "        \n",
    "        target_col_idx = target_table[\"col_idx\"].values[0]\n",
    "        target_cls = target_table[\"class_id\"].values[0]\n",
    "        if target_cls != labels_test_original[global_i]:\n",
    "            print(i, target_cls, labels_test_original[global_i].item())\n",
    "            raise ValueError(\"target_cls != labels_test_original[global_i]\")\n",
    "        \n",
    "        target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "        col_idx_list = target_table[\"col_idx\"].tolist()\n",
    "        # target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "\n",
    "        if max_length <= 128 and adaptive_max_length:\n",
    "            cur_maxlen = min(max_length, 512 // len(target_table) - 1)\n",
    "        else:\n",
    "            cur_maxlen = max_length\n",
    "            \n",
    "        token_ids_list = target_table[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "            tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=cur_maxlen, truncation=True)).tolist(\n",
    "            )\n",
    "        token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                            token_ids_list)).to(device)\n",
    "\n",
    "        target_col_mask = []\n",
    "        cls_index_value = 0\n",
    "        context_id = 1\n",
    "        meet_target = False\n",
    "        for idx, col_i in enumerate(col_idx_list):\n",
    "            if col_i == target_col_idx:\n",
    "                target_col_mask += [0] * len(token_ids_list[idx])\n",
    "                meet_target = True\n",
    "            else:\n",
    "                target_col_mask += [context_id] * len(token_ids_list[idx])\n",
    "                context_id += 1\n",
    "            if not meet_target:\n",
    "                cls_index_value += len(token_ids_list[idx])\n",
    "        cls_index_list = [cls_index_value] \n",
    "        for cls_index in cls_index_list:\n",
    "            assert token_ids[\n",
    "                cls_index] == tokenizer.cls_token_id, \"cls_indexes validation\"\n",
    "        cls_indexes = torch.LongTensor(cls_index_list).to(device)\n",
    "        class_ids = torch.LongTensor(\n",
    "            [target_cls]).to(device)\n",
    "        target_col_mask = torch.LongTensor(target_col_mask).to(device)\n",
    "        global_i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "for index, target_column in labeled_columns.iterrows():\n",
    "    target_col_idx = target_column[\"col_idx\"]\n",
    "    \n",
    "    other_columns = group_df.drop(index).drop_duplicates(subset=['data'], keep='first')\n",
    "    \n",
    "    # other_columns['distance'] = abs(other_columns['col_idx'] - target_col_idx)\n",
    "    # other_columns.sort_values(by='distance', inplace=True)\n",
    "    # nearby_columns = other_columns.head(max_unlabeled-1)\n",
    "    # target_table = pd.concat([target_column.to_frame().T, nearby_columns], ignore_index=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    other_labeled = other_columns[other_columns['class_id'] > -1].head(max_unlabeled-1)\n",
    "    other_unlabeled = other_columns[other_columns['class_id'] == -1]\n",
    "    other_unlabeled['distance'] = abs(other_unlabeled['col_idx'] - target_col_idx)\n",
    "    other_unlabeled.sort_values(by='distance', inplace=True)\n",
    "    nearby_columns = other_unlabeled.head(max_unlabeled-len(other_labeled)-1)\n",
    "    target_table = pd.concat([target_column.to_frame().T, other_labeled, nearby_columns], ignore_index=True)\n",
    "    i += 1\n",
    "    if i == 2:\n",
    "        break\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df= group_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df_reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "for index, target_column in labeled_columns.iterrows():\n",
    "    top_columns = group_df.iloc[F.cosine_similarity(col_embs[index].reshape(1,-1), col_embs).argsort(descending=True)[:8].tolist()]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_unlabeled = 8\n",
    "labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "for index, target_column in labeled_columns.iterrows():\n",
    "    other_labeled = labeled_columns.drop(index)\n",
    "    target_table = group_df.iloc[F.cosine_similarity(col_embs[index].reshape(1,-1), col_embs).argsort(descending=True)[:max_unlabeled-len(other_labeled)].tolist()]\n",
    "    target_table = pd.concat([target_table, other_labeled], ignore_index=True)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "sb_model = SentenceTransformer(\"all-mpnet-base-v2\", cache_folder=\"/data/zhihao/TU/Watchog/sentence_transformers_cache\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "import os\n",
    "# Set the cache directory\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/data/zhihao/TU/Watchog/sentence_transformers_cache'\n",
    "cross_encoder = CrossEncoder(\"cross-encoder/stsb-roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_encoder.predict([\n",
    "    (\"2014;2014;2014;2014;2014;2014;2014;2014;2014\", \"2014R1G1MW;2014R1G2MW;2014R1G3MW;2014R1G4MW;\"),\n",
    "    (\"2014-03-17;2014-03-17;2014-03-17;2014-03-18;\", \"2014;2014;2014;2014;2014;2014;2014;2014;2014\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left right\n",
    "max_unlabeled = 8\n",
    "first_scores = []\n",
    "for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "    group_df.sort_values(by=['col_idx'], inplace=True)\n",
    "    group_df = group_df.reset_index(drop=True)\n",
    "    labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "    labeled_columns.sort_values(by=['col_idx'], inplace=True)\n",
    "    for index, target_column in labeled_columns.iterrows():\n",
    "        other_columns = group_df.drop(index).head(max_unlabeled-1)\n",
    "        target_col_idx = target_column[\"col_idx\"]\n",
    "        left_columns = other_columns[other_columns['col_idx'] < target_col_idx]\n",
    "        right_columns = other_columns[other_columns['col_idx'] > target_col_idx]\n",
    "        left_scores = torch.tensor(left_columns[\"data\"].apply(lambda x: cross_encoder.predict([\n",
    "                (target_column[\"data\"], x)\n",
    "        ])).tolist())\n",
    "        right_scores = torch.tensor(right_columns[\"data\"].apply(lambda x: cross_encoder.predict([\n",
    "                (x, target_column[\"data\"])\n",
    "        ])).tolist())\n",
    "        scores = torch.cat([left_scores,  right_scores], dim=0)\n",
    "        assert len(scores) == len(other_columns)\n",
    "        scores = scores.mean()\n",
    "        first_scores.append(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left right\n",
    "max_unlabeled = 8\n",
    "last_scores = []\n",
    "for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "    group_df.sort_values(by=['col_idx'], inplace=True)\n",
    "    group_df = group_df.reset_index(drop=True)\n",
    "    labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "    labeled_columns.sort_values(by=['col_idx'], inplace=True)\n",
    "    for index, target_column in labeled_columns.iterrows():\n",
    "        other_columns = group_df.drop(index).tail(max_unlabeled-1)\n",
    "        target_col_idx = target_column[\"col_idx\"]\n",
    "        left_columns = other_columns[other_columns['col_idx'] < target_col_idx]\n",
    "        right_columns = other_columns[other_columns['col_idx'] > target_col_idx]\n",
    "        left_scores = torch.tensor(left_columns[\"data\"].apply(lambda x: cross_encoder.predict([\n",
    "                (target_column[\"data\"], x)\n",
    "        ])).tolist())\n",
    "        right_scores = torch.tensor(right_columns[\"data\"].apply(lambda x: cross_encoder.predict([\n",
    "                (x, target_column[\"data\"])\n",
    "        ])).tolist())\n",
    "        scores = torch.cat([left_scores,  right_scores], dim=0)\n",
    "        assert len(scores) == len(other_columns)\n",
    "        scores = scores.mean()\n",
    "        last_scores.append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left right\n",
    "max_unlabeled = 8\n",
    "best_scores = []\n",
    "for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "    group_df.sort_values(by=['col_idx'], inplace=True)\n",
    "    group_df = group_df.reset_index(drop=True)\n",
    "    labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "    labeled_columns.sort_values(by=['col_idx'], inplace=True)\n",
    "    for index, target_column in labeled_columns.iterrows():\n",
    "        other_labeled = labeled_columns.drop(index)\n",
    "        other_columns = group_df.drop(index).head(max_unlabeled-1-len(other_labeled))\n",
    "        target_col_idx = target_column[\"col_idx\"]\n",
    "        target_table = pd.concat([other_labeled, other_columns], ignore_index=True)\n",
    "        target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "        left_columns = target_table[target_table['col_idx'] < target_col_idx]\n",
    "        right_columns = target_table[target_table['col_idx'] > target_col_idx]\n",
    "        left_scores = torch.tensor(left_columns[\"data\"].apply(lambda x: cross_encoder.predict([\n",
    "                (target_column[\"data\"], x)\n",
    "        ])).tolist())\n",
    "        right_scores = torch.tensor(right_columns[\"data\"].apply(lambda x: cross_encoder.predict([\n",
    "                (x, target_column[\"data\"])\n",
    "        ])).tolist())\n",
    "        scores = torch.cat([left_scores, right_scores], dim=0)\n",
    "        assert len(scores) == len(target_table)\n",
    "        scores = scores.mean()\n",
    "        best_scores.append(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_scores.isnan().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_scores = torch.tensor(first_scores)\n",
    "first_scores = first_scores[first_scores.isnan() == False]\n",
    "print(len(first_scores), first_scores.mean(), first_scores.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_scores = torch.tensor(last_scores)\n",
    "last_scores = last_scores[last_scores.isnan() == False]\n",
    "print(len(last_scores), last_scores.mean(), last_scores.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_scores = torch.tensor(best_scores)\n",
    "best_scores = best_scores[best_scores.isnan() == False]\n",
    "print(len(best_scores), best_scores.mean(), best_scores.median())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_unlabeled = 8\n",
    "frist_scores = []\n",
    "for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "    group_df.sort_values(by=['col_idx'], inplace=True)\n",
    "    group_df = group_df.reset_index(drop=True)\n",
    "    labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "    labeled_columns.sort_values(by=['col_idx'], inplace=True)\n",
    "    for index, target_column in labeled_columns.iterrows():\n",
    "        other_columns = group_df.drop(index).head(max_unlabeled-1)\n",
    "        target_col_idx = target_column[\"col_idx\"]\n",
    "        target_table = pd.concat([target_column.to_frame().T, other_columns], ignore_index=True)\n",
    "        target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "        res_i = []\n",
    "        for index in range(len(target_table)-1):\n",
    "            res = cross_encoder.predict([\n",
    "                (target_table.iloc[index][\"data\"], target_table.iloc[index+1][\"data\"])\n",
    "            ])\n",
    "            res_i.append(res)\n",
    "        res_i = torch.tensor(res_i).mean()\n",
    "        frist_scores.append(res_i)\n",
    "frist_scores = torch.tensor(frist_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_unlabeled = 8\n",
    "last_scores = []\n",
    "for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "    group_df.sort_values(by=['col_idx'], inplace=True)\n",
    "    group_df = group_df.reset_index(drop=True)\n",
    "    labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "    labeled_columns.sort_values(by=['col_idx'], inplace=True)\n",
    "    for index, target_column in labeled_columns.iterrows():\n",
    "        other_columns = group_df.drop(index).tail(max_unlabeled-1)\n",
    "        target_col_idx = target_column[\"col_idx\"]\n",
    "        target_table = pd.concat([target_column.to_frame().T, other_columns], ignore_index=True)\n",
    "        target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "        res_i = []\n",
    "        for index in range(len(target_table)-1):\n",
    "            res = cross_encoder.predict([\n",
    "                (target_table.iloc[index][\"data\"], target_table.iloc[index+1][\"data\"])\n",
    "            ])\n",
    "            res_i.append(res)\n",
    "        res_i = torch.tensor(res_i).mean()\n",
    "        last_scores.append(res_i)\n",
    "last_scores = torch.tensor(last_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_unlabeled = 8\n",
    "best_scores = []\n",
    "for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "    group_df.sort_values(by=['col_idx'], inplace=True)\n",
    "    group_df = group_df.reset_index(drop=True)\n",
    "    labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "    labeled_columns.sort_values(by=['col_idx'], inplace=True)\n",
    "    for index, target_column in labeled_columns.iterrows():\n",
    "        other_labeled = labeled_columns.drop(index)\n",
    "        other_columns = group_df.drop(index).head(max_unlabeled-1-len(other_labeled))\n",
    "        target_col_idx = target_column[\"col_idx\"]\n",
    "        target_table = pd.concat([target_column.to_frame().T, other_labeled, other_columns], ignore_index=True)\n",
    "        target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "        res_i = []\n",
    "        for index in range(len(target_table)-1):\n",
    "            res = cross_encoder.predict([\n",
    "                (target_table.iloc[index][\"data\"], target_table.iloc[index+1][\"data\"])\n",
    "            ])\n",
    "            res_i.append(res)\n",
    "        res_i = torch.tensor(res_i).mean()\n",
    "        best_scores.append(res_i)\n",
    "best_scores = torch.tensor(best_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_encoder.predict([\n",
    "                (target_table.iloc[index][\"data\"], target_table.iloc[index+1][\"data\"])\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_table.iloc[1]['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frist_scores = torch.tensor(frist_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frist_scores = frist_scores[frist_scores.isnan() == False]\n",
    "print(frist_scores.mean(), frist_scores.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearby_scores = torch.tensor(nearby_scores)\n",
    "nearby_scores = nearby_scores[nearby_scores.isnan() == False]\n",
    "print(nearby_scores.mean(), nearby_scores.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_scores = torch.tensor(best_scores)\n",
    "best_scores = best_scores[best_scores.isnan() == False]\n",
    "print(best_scores.mean(), best_scores.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_scores = torch.tensor(last_scores)\n",
    "last_scores = last_scores[last_scores.isnan() == False]\n",
    "print(last_scores.mean(), last_scores.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nearby_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(nearby_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearby_scores = []\n",
    "for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "    labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "    for index, target_column in labeled_columns.iterrows():\n",
    "        target_col_idx = target_column[\"col_idx\"]\n",
    "        \n",
    "        other_columns = group_df.drop(index)\n",
    "\n",
    "        other_columns['distance'] = abs(other_columns['col_idx'] - target_col_idx)\n",
    "        other_columns.sort_values(by='distance', inplace=True)\n",
    "        other_columns = other_columns.head(max_unlabeled-1)\n",
    "        other_columns.sort_values(by=['col_idx'], inplace=True)\n",
    "        \n",
    "        target_table = pd.concat([target_column.to_frame().T, other_columns], ignore_index=True)\n",
    "        target_cls = target_table[\"class_id\"].values[0]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearby_scores = []\n",
    "for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "    labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "    for index, target_column in labeled_columns.iterrows():\n",
    "        target_col_idx = target_column[\"col_idx\"]\n",
    "        \n",
    "        other_columns = group_df.drop(index)\n",
    "\n",
    "        other_columns['distance'] = abs(other_columns['col_idx'] - target_col_idx)\n",
    "        other_columns.sort_values(by='distance', inplace=True)\n",
    "        other_columns = other_columns.head(max_unlabeled-1)\n",
    "        target_table = pd.concat([target_column.to_frame().T, other_columns], ignore_index=True)\n",
    "        \n",
    "        target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "        res_i = []\n",
    "        for index in range(len(target_table)-1):\n",
    "            res = cross_encoder.predict([\n",
    "                (target_table.iloc[index][\"data\"], target_table.iloc[index+1][\"data\"])\n",
    "            ])\n",
    "            res_i.append(res)\n",
    "        res_i = torch.tensor(res_i).mean()\n",
    "        nearby_scores.append(res_i)\n",
    "nearby_scores = torch.tensor(nearby_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BertForNextSentencePrediction.from_pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForNextSentencePrediction\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Load the pre-trained model and tokenizer\n",
    "next_predictor = BertForNextSentencePrediction.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Define two sentences\n",
    "sentence_a = \"11.1;12.2;2.0\"\n",
    "sentence_b = \"2014;2002;2001\"\n",
    "\n",
    "# Tokenize and encode the sentences\n",
    "inputs = tokenizer.encode_plus(sentence_a, sentence_b, return_tensors='pt')\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    outputs = next_predictor(**inputs)\n",
    "    logits = outputs.logits\n",
    "\n",
    "# Determine if the second sentence follows the first\n",
    "print(torch.softmax(logits, dim=1)[0][0].item())\n",
    "# print(\"Next Sentence Prediction:\", \"Yes\" if predicted_label == 0 else \"No\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_predictor.load_state_dict(best_state_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define two sentences\n",
    "sentence_a = \"11.1;12.2;2.0\"\n",
    "sentence_b = \"A;B;C\"\n",
    "\n",
    "# Tokenize and encode the sentences\n",
    "inputs = tokenizer.encode_plus(sentence_a, sentence_b, return_tensors='pt')\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    outputs = next_predictor(**inputs)\n",
    "    logits = outputs.logits\n",
    "\n",
    "# Determine if the second sentence follows the first\n",
    "print(torch.softmax(logits, dim=1)[0][0].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define two sentences\n",
    "sentence_a = \"11.1;12.2;2.0\"\n",
    "sentence_b = \"2014;2002;2001\"\n",
    "\n",
    "# Tokenize and encode the sentences\n",
    "inputs = tokenizer.encode_plus(sentence_a, sentence_b, return_tensors='pt')\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    outputs = next_predictor(**inputs)\n",
    "    logits = outputs.logits\n",
    "\n",
    "# Determine if the second sentence follows the first\n",
    "print(torch.softmax(logits, dim=1)[0][0].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define two sentences\n",
    "sentence_a = \"USD; USD; USD\"\n",
    "sentence_b = \"USD; USD; USD\"\n",
    "\n",
    "# Tokenize and encode the sentences\n",
    "inputs = tokenizer.encode_plus(sentence_a, sentence_b, return_tensors='pt')\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    outputs = next_predictor(**inputs)\n",
    "    logits = outputs.logits\n",
    "\n",
    "# Determine if the second sentence follows the first\n",
    "print(torch.softmax(logits, dim=1)[0][0].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.encode_plus(target_table.iloc[index][\"data\"], target_table.iloc[index+1][\"data\"], return_tensors='pt', max_length=256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_unlabeled = 8\n",
    "# best_scores = []\n",
    "# for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "#     group_df.sort_values(by=['col_idx'], inplace=True)\n",
    "#     group_df = group_df.reset_index(drop=True)\n",
    "#     labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "#     labeled_columns.sort_values(by=['col_idx'], inplace=True)\n",
    "#     for index, target_column in labeled_columns.iterrows():\n",
    "#         other_labeled = labeled_columns.drop(index)\n",
    "#         other_columns = group_df.drop(index).head(max_unlabeled-1-len(other_labeled))\n",
    "#         target_col_idx = target_column[\"col_idx\"]\n",
    "#         target_table = pd.concat([target_column.to_frame().T, other_labeled, other_columns], ignore_index=True)\n",
    "#         target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "#         res_i = []\n",
    "#         for index in range(len(target_table)-1):\n",
    "#             # Tokenize and encode the sentences\n",
    "#             inputs = tokenizer.encode_plus(target_table.iloc[index][\"data\"], target_table.iloc[index+1][\"data\"], return_tensors='pt', truncation='longest_first', max_length=512)\n",
    "\n",
    "#             # Make predictions\n",
    "#             with torch.no_grad():\n",
    "#                 outputs = next_predictor(**inputs)\n",
    "#                 logits = outputs.logits\n",
    "\n",
    "#             res = torch.softmax(logits, dim=1)[0][0].item()\n",
    "#             res_i.append(res)\n",
    "#         res_i = torch.tensor(res_i).mean()\n",
    "#         best_scores.append(res_i)\n",
    "# best_scores = torch.tensor(best_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.encode_plus(target_table.iloc[index][\"data\"], target_table.iloc[index+1][\"data\"], return_tensors='pt', truncation='longest_first', max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # left right\n",
    "# max_unlabeled = 8\n",
    "# best_scores = []\n",
    "# for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "#     group_df.sort_values(by=['col_idx'], inplace=True)\n",
    "#     group_df = group_df.reset_index(drop=True)\n",
    "#     labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "#     labeled_columns.sort_values(by=['col_idx'], inplace=True)\n",
    "#     for index, target_column in labeled_columns.iterrows():\n",
    "#         other_labeled = labeled_columns.drop(index)\n",
    "#         other_columns = group_df.drop(index).head(max_unlabeled-1-len(other_labeled))\n",
    "#         target_col_idx = target_column[\"col_idx\"]\n",
    "#         target_table = pd.concat([other_labeled, other_columns], ignore_index=True)\n",
    "#         target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "#         left_columns = target_table[target_table['col_idx'] < target_col_idx]\n",
    "#         right_columns = target_table[target_table['col_idx'] > target_col_idx]\n",
    "#         left_pairs = left_columns[\"data\"].apply(lambda x: tokenizer.encode_plus(x, \n",
    "#                     target_column[\"data\"], return_tensors='pt', truncation='longest_first', max_length=512)).tolist()\n",
    "#         right_pairs = right_columns[\"data\"].apply(lambda x: tokenizer.encode_plus(target_column[\"data\"], x, \n",
    "#                    return_tensors='pt', truncation='longest_first', max_length=512))\n",
    "#         res_i = []\n",
    "#         left_pairs.extend(right_pairs)\n",
    "#         assert len(left_pairs) == len(target_table)\n",
    "#         with torch.no_grad():\n",
    "#             for inputs in left_pairs:\n",
    "#                 outputs = next_predictor(**inputs)\n",
    "#                 logits = outputs.logits\n",
    "#                 res = torch.softmax(logits, dim=1)[0][0].item()\n",
    "#                 res_i.append(res)\n",
    "#         res_i = torch.tensor(res_i).mean()\n",
    "#         best_scores.append(res_i)\n",
    "# best_scores = torch.tensor(best_scores)\n",
    "\n",
    "# last_scores = []\n",
    "# for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "#     group_df.sort_values(by=['col_idx'], inplace=True)\n",
    "#     group_df = group_df.reset_index(drop=True)\n",
    "#     labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "#     labeled_columns.sort_values(by=['col_idx'], inplace=True)\n",
    "#     for index, target_column in labeled_columns.iterrows():\n",
    "#         other_columns = group_df.drop(index).tail(max_unlabeled-1)\n",
    "#         target_col_idx = target_column[\"col_idx\"]\n",
    "#         target_table = other_columns\n",
    "#         target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "#         left_columns = target_table[target_table['col_idx'] < target_col_idx]\n",
    "#         right_columns = target_table[target_table['col_idx'] > target_col_idx]\n",
    "#         left_pairs = left_columns[\"data\"].apply(lambda x: tokenizer.encode_plus(x, \n",
    "#                     target_column[\"data\"], return_tensors='pt', truncation='longest_first', max_length=512)).tolist()\n",
    "#         right_pairs = right_columns[\"data\"].apply(lambda x: tokenizer.encode_plus(target_column[\"data\"], x, \n",
    "#                    return_tensors='pt', truncation='longest_first', max_length=512))\n",
    "#         res_i = []\n",
    "#         left_pairs.extend(right_pairs)\n",
    "#         assert len(left_pairs) == len(target_table)\n",
    "#         with torch.no_grad():\n",
    "#             for inputs in left_pairs:\n",
    "#                 outputs = next_predictor(**inputs)\n",
    "#                 logits = outputs.logits\n",
    "#                 res = torch.softmax(logits, dim=1)[0][0].item()\n",
    "#                 res_i.append(res)\n",
    "#         res_i = torch.tensor(res_i).mean()\n",
    "#         last_scores.append(res_i)\n",
    "# last_scores = torch.tensor(last_scores)           \n",
    "\n",
    "# first_scores = []\n",
    "# for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "#     group_df.sort_values(by=['col_idx'], inplace=True)\n",
    "#     group_df = group_df.reset_index(drop=True)\n",
    "#     labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "#     labeled_columns.sort_values(by=['col_idx'], inplace=True)\n",
    "#     for index, target_column in labeled_columns.iterrows():\n",
    "#         other_columns = group_df.drop(index).head(max_unlabeled-1)\n",
    "#         target_col_idx = target_column[\"col_idx\"]\n",
    "#         target_table = other_columns\n",
    "#         target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "#         left_columns = target_table[target_table['col_idx'] < target_col_idx]\n",
    "#         right_columns = target_table[target_table['col_idx'] > target_col_idx]\n",
    "#         left_pairs = left_columns[\"data\"].apply(lambda x: tokenizer.encode_plus(x, \n",
    "#                     target_column[\"data\"], return_tensors='pt', truncation='longest_first', max_length=512)).tolist()\n",
    "#         right_pairs = right_columns[\"data\"].apply(lambda x: tokenizer.encode_plus(target_column[\"data\"], x, \n",
    "#                    return_tensors='pt', truncation='longest_first', max_length=512))\n",
    "#         res_i = []\n",
    "#         left_pairs.extend(right_pairs)\n",
    "#         assert len(left_pairs) == len(target_table)\n",
    "#         with torch.no_grad():\n",
    "#             for inputs in left_pairs:\n",
    "#                 outputs = next_predictor(**inputs)\n",
    "#                 logits = outputs.logits\n",
    "#                 res = torch.softmax(logits, dim=1)[0][0].item()\n",
    "#                 res_i.append(res)\n",
    "#         res_i = torch.tensor(res_i).mean()\n",
    "#         first_scores.append(res_i)\n",
    "# first_scores = torch.tensor(first_scores)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok = False\n",
    "for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "    group_df.sort_values(by=['col_idx'], inplace=True)\n",
    "    group_df = group_df.reset_index(drop=True)\n",
    "    labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "    labeled_columns.sort_values(by=['col_idx'], inplace=True)\n",
    "    for index, target_column in labeled_columns.iterrows():\n",
    "        target_col_idx = target_column[\"col_idx\"]\n",
    "        if target_col_idx != 0 and target_col_idx < len(group_df)-1:\n",
    "            ok = True\n",
    "            break\n",
    "    if ok:\n",
    "        break\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(column_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_table = pd.concat([target_column.to_frame().T, other_labeled, other_columns], ignore_index=True)\n",
    "column_pairs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.histplot(best_scores[best_scores.isnan() == False])\n",
    "print(best_scores[best_scores.isnan() == False].median(), best_scores[best_scores.isnan() == False].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.histplot(last_scores[last_scores.isnan() == False])\n",
    "print(last_scores[last_scores.isnan() == False].median(), last_scores[last_scores.isnan() == False].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(first_scores[first_scores.isnan() == False].median(), first_scores[first_scores.isnan() == False].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(first_scores[first_scores.isnan() == False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(last_scores[last_scores.isnan() == False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(best_scores[best_scores.isnan() == False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use doduo state_dict\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "# max_unlabeled = 8\n",
    "# frist_scores = []\n",
    "# for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "#     group_df.sort_values(by=['col_idx'], inplace=True)\n",
    "#     group_df = group_df.reset_index(drop=True)\n",
    "#     labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "#     labeled_columns.sort_values(by=['col_idx'], inplace=True)\n",
    "#     for index, target_column in labeled_columns.iterrows():\n",
    "#         other_columns = group_df.drop(index).head(max_unlabeled-1)\n",
    "#         target_col_idx = target_column[\"col_idx\"]\n",
    "#         target_table = pd.concat([target_column.to_frame().T, other_columns], ignore_index=True)\n",
    "#         target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "#         res_i = []\n",
    "#         for index in range(len(target_table)-1):\n",
    "#             # Tokenize and encode the sentences\n",
    "#             inputs = tokenizer.encode_plus(target_table.iloc[index][\"data\"], target_table.iloc[index+1][\"data\"], return_tensors='pt', truncation='longest_first', max_length=512)\n",
    "\n",
    "#             # Make predictions\n",
    "#             with torch.no_grad():\n",
    "#                 outputs = next_predictor(**inputs)\n",
    "#                 logits = outputs.logits\n",
    "\n",
    "#             res = torch.softmax(logits, dim=1)[0][0].item()\n",
    "#             res_i.append(res)\n",
    "#         res_i = torch.tensor(res_i).mean()\n",
    "#         frist_scores.append(res_i)\n",
    "# frist_scores = torch.tensor(frist_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use doduo state_dict\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "# max_unlabeled = 8\n",
    "# last_scores = []\n",
    "# for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "#     group_df.sort_values(by=['col_idx'], inplace=True)\n",
    "#     group_df = group_df.reset_index(drop=True)\n",
    "#     labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "#     labeled_columns.sort_values(by=['col_idx'], inplace=True)\n",
    "#     for index, target_column in labeled_columns.iterrows():\n",
    "#         other_columns = group_df.drop(index).tail(max_unlabeled-1)\n",
    "#         target_col_idx = target_column[\"col_idx\"]\n",
    "#         target_table = pd.concat([target_column.to_frame().T, other_columns], ignore_index=True)\n",
    "#         target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "#         res_i = []\n",
    "#         for index in range(len(target_table)-1):\n",
    "#             # Tokenize and encode the sentences\n",
    "#             inputs = tokenizer.encode_plus(target_table.iloc[index][\"data\"], target_table.iloc[index+1][\"data\"], return_tensors='pt', truncation='longest_first', max_length=512)\n",
    "\n",
    "#             # Make predictions\n",
    "#             with torch.no_grad():\n",
    "#                 outputs = next_predictor(**inputs)\n",
    "#                 logits = outputs.logits\n",
    "\n",
    "#             res = torch.softmax(logits, dim=1)[0][0].item()\n",
    "#             res_i.append(res)\n",
    "#         res_i = torch.tensor(res_i).mean()\n",
    "#         last_scores.append(res_i)\n",
    "# last_scores = torch.tensor(last_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_embs = torch.tensor(sb_model.encode(group_df[\"data\"].to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df.iloc[F.cosine_similarity(col_embs[11].reshape(1,-1), col_embs).argsort(descending=True)[:8].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_scores = group_df[\"data\"].apply(lambda x: classify_column(x)).tolist(\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for index, target_column in labeled_columns.iterrows():\n",
    "    target_col_idx = target_column[\"col_idx\"]\n",
    "    \n",
    "    other_columns = group_df.drop(index).drop_duplicates(subset=['data'], keep='first')\n",
    "    # other_labeled = other_columns[other_columns['class_id'] > -1].head(max_unlabeled-1)\n",
    "    # other_unlabeled = other_columns[other_columns['class_id'] == -1].head(max_unlabeled-len(other_labeled)-1)\n",
    "    other_columns['distance'] = abs(other_columns['col_idx'] - target_col_idx)\n",
    "    other_columns.sort_values(by='distance', inplace=True)\n",
    "    nearby_columns = other_columns.head(max_unlabeled-1)\n",
    "\n",
    "    target_table = pd.concat([target_column.to_frame().T, nearby_columns], ignore_index=True)\n",
    "    i += 1\n",
    "    if i == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column[\"col_idx\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df[\"semantic_scores\"] = semantic_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df.sort_values(by=['semantic_scores'], ascending=False, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(group_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "    labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "    if len(labeled_columns) >= 3 and len(group_df) >= 10:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_unlabeled = 8\n",
    "adaptive_max_length=False\n",
    "data_list = []\n",
    "\n",
    "\n",
    "semantic_scores = torch.tensor(group_df[\"data\"].apply(lambda x: classify_column(x.split(';'))).tolist())\n",
    "group_df[\"semantic_scores\"] = semantic_scores\n",
    "group_df.sort_values(by=['semantic_scores'], ascending=False, inplace=True) \n",
    "labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "row_count = 0\n",
    "for index, target_column in labeled_columns.iterrows():\n",
    "    other_columns = group_df.drop(index)\n",
    "    # Get the top K-1 rows\n",
    "    target_contexts = other_columns.head(max_unlabeled-1)\n",
    "\n",
    "    target_table = pd.concat([target_column.to_frame().T, target_contexts], ignore_index=True)\n",
    "    target_col_idx = target_table[\"col_idx\"].values[0]\n",
    "    target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "    col_idx_list = target_table[\"col_idx\"].tolist()\n",
    "    # target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "\n",
    "    if max_length <= 128 and adaptive_max_length:\n",
    "        cur_maxlen = min(max_length, 512 // len(target_table) - 1)\n",
    "    else:\n",
    "        cur_maxlen = max_length\n",
    "        \n",
    "    token_ids_list = target_table[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "        tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=cur_maxlen, truncation=True)).tolist(\n",
    "        )\n",
    "    token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                        token_ids_list)).to(device)\n",
    "\n",
    "    target_col_mask = []\n",
    "    cls_index_value = 0\n",
    "    context_id = 1\n",
    "    meet_target = False\n",
    "    for idx, col_i in enumerate(col_idx_list):\n",
    "        if col_i == target_col_idx:\n",
    "            target_col_mask += [0] * len(token_ids_list[idx])\n",
    "            meet_target = True\n",
    "        else:\n",
    "            target_col_mask += [context_id] * len(token_ids_list[idx])\n",
    "            context_id += 1\n",
    "        if not meet_target:\n",
    "            cls_index_value += len(token_ids_list[idx])\n",
    "    cls_index_list = [cls_index_value] \n",
    "    for cls_index in cls_index_list:\n",
    "        assert token_ids[\n",
    "            cls_index] == tokenizer.cls_token_id, \"cls_indexes validation\"\n",
    "    cls_indexes = torch.LongTensor(cls_index_list).to(device)\n",
    "    class_ids = torch.LongTensor(\n",
    "        [target_table[\"class_id\"].values[0]]).to(device)\n",
    "    target_col_mask = torch.LongTensor(target_col_mask).to(device)\n",
    "    data_list.append(\n",
    "        [index,\n",
    "        len(target_table), token_ids, class_ids, cls_indexes, target_col_mask])   \n",
    "    row_count += 1\n",
    "    if row_count == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_table[\"col_idx\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_table = target_table.drop_duplicates(subset=['data'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_i in data_list:\n",
    "    print(tokenizer.decode(data_i[2].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(pad_token_id, data_only=True):\n",
    "    '''padder for input batch'''\n",
    "\n",
    "    def padder(samples):    \n",
    "        data = torch.nn.utils.rnn.pad_sequence(\n",
    "            [sample[\"data\"] for sample in samples], padding_value=pad_token_id)\n",
    "        if not data_only:\n",
    "            label = torch.nn.utils.rnn.pad_sequence(\n",
    "                [sample[\"label\"] for sample in samples], padding_value=-1)\n",
    "        else:\n",
    "            label = torch.cat([sample[\"label\"] for sample in samples])\n",
    "        batch = {\"data\": data, \"label\": label}\n",
    "        if \"idx\" in samples[0]:\n",
    "            batch[\"idx\"] = [sample[\"idx\"] for sample in samples]\n",
    "        if \"cls_indexes\" in samples[0]:\n",
    "            cls_indexes = torch.nn.utils.rnn.pad_sequence(\n",
    "                [sample[\"cls_indexes\"] for sample in samples], padding_value=0)\n",
    "            batch[\"cls_indexes\"] = cls_indexes\n",
    "        if \"target_col_mask\" in samples[0]:\n",
    "            target_col_mask = torch.nn.utils.rnn.pad_sequence(\n",
    "                [sample[\"target_col_mask\"] for sample in samples], padding_value=-1)\n",
    "            batch[\"target_col_mask\"] = target_col_mask\n",
    "        if \"table_embedding\" in samples[0]:\n",
    "            table_embeddings = [sample[\"table_embedding\"] for sample in samples]\n",
    "            batch[\"table_embedding\"] = torch.stack(table_embeddings, dim=0)\n",
    "        return batch\n",
    "        \n",
    "    return padder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "test 1085\n"
     ]
    }
   ],
   "source": [
    "src = None\n",
    "test_dataset_iter = GittablesTablewiseIterateDataset(cv=cv,\n",
    "                            split=\"test\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only='all' not in task,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\")\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "test_dataloader_iter = DataLoader(test_dataset_iter,\n",
    "                                batch_size=1,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels_iter = []\n",
    "for batch in test_dataloader_iter:\n",
    "    all_labels_iter += batch[\"label\"].cpu().tolist()\n",
    "all_labels_iter = torch.tensor(all_labels_iter)\n",
    "torch.equal(all_labels_iter, labels_test_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = None\n",
    "test_dataset_lb = GittablesTablewiseIterateLabelDataset(cv=cv,\n",
    "                            split=\"test\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only='all' not in task,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\")\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "test_dataloader_lb = DataLoader(test_dataset_lb,\n",
    "                                batch_size=1,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(test_dataset_lb.correctness_checklist)/len(test_dataset_lb.correctness_checklist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels_lb = []\n",
    "for batch in test_dataloader_iter:\n",
    "    all_labels_lb += batch[\"label\"].cpu().tolist()\n",
    "all_labels_lb = torch.tensor(all_labels_lb)\n",
    "torch.equal(all_labels_lb, labels_test_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_pos_iter = []\n",
    "for batch in test_dataloader_iter:\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    init_permutation_i = get_permutation(target_col_mask)\n",
    "    labeled_pos_iter.append(init_permutation_i.index(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "test 1085\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "src = None\n",
    "test_dataset_first = GittablesTablewiseFirstDataset(cv=cv,\n",
    "                            split=\"test\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only='all' not in task,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\")\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "test_dataloader_first = DataLoader(test_dataset_first,\n",
    "                                batch_size=1,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "test 1085\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "src = None\n",
    "test_dataset_single = GittablesTablewiseFirstDataset(cv=cv,\n",
    "                            split=\"test\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only='all' not in task,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\",\n",
    "                            max_unlabeled=1)\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "test_dataloader_single = DataLoader(test_dataset_single,\n",
    "                                batch_size=1,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "src = None\n",
    "test_dataset_nf = GittablesTablewiseIterateNearbyFirstDataset(cv=cv,\n",
    "                            split=\"test\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only='all' not in task,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\",\n",
    "                            nearby_num=2)\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "test_dataloader_nf = DataLoader(test_dataset_nf,\n",
    "                                batch_size=1,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels_f = []\n",
    "for batch in test_dataloader_first:\n",
    "    all_labels_f += batch[\"label\"].cpu().tolist()\n",
    "all_labels_f = torch.tensor(all_labels_f)\n",
    "torch.equal(all_labels_f, labels_test_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch['cls_indexes'].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    init_permutation_i = get_permutation(target_col_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_columns[\"col_idx\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_col_idx = []\n",
    "for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "    group_df.sort_values(by=[\"col_idx\"], inplace=True)\n",
    "    group_df = group_df.reset_index(drop=True)\n",
    "    labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "    # if len(group_df) > 10:\n",
    "    #     print(i, len(group_df))\n",
    "    labeled_col_idx.extend(labeled_columns[\"col_idx\"].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_col_idx = torch.tensor(labeled_col_idx)\n",
    "(labeled_col_idx<8).sum()/len(labeled_col_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(labeled_pos_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_pos_first = []\n",
    "for batch in test_dataloader_first:\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    init_permutation_i = get_permutation(target_col_mask)\n",
    "    labeled_pos_first.append(init_permutation_i.index(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(labeled_pos).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols_dataset = []\n",
    "for batch in test_dataloader_first:\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    init_permutation_i = get_permutation(target_col_mask)\n",
    "    num_cols_dataset.append(len(init_permutation_i))\n",
    "num_cols_dataset = torch.tensor(num_cols_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_pos_iter = torch.tensor(labeled_pos_iter)\n",
    "sns.histplot(labeled_pos_iter)\n",
    "print((labeled_pos_iter==0).sum()/len(labeled_pos_iter), (labeled_pos_iter==(num_cols_dataset-1)).sum()/len(labeled_pos_iter), 1-(labeled_pos_iter==0).sum()/len(labeled_pos_iter)-(labeled_pos_iter==(num_cols_dataset-1)).sum()/len(labeled_pos_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_pos_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(labeled_pos_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# src = None\n",
    "# test_dataset_cor = GittablesTablewiseCorrelationDataset(cv=cv,\n",
    "#                             split=\"test\", src=src,\n",
    "#                             tokenizer=tokenizer,\n",
    "#                             max_length=max_length,\n",
    "#                             gt_only='all' not in task,\n",
    "#                             device=device,\n",
    "#                             base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "#                             small_tag=\"semi1\")\n",
    "# padder = collate_fn(tokenizer.pad_token_id)\n",
    "# test_dataloader_cor = DataLoader(test_dataset_cor,\n",
    "#                                 batch_size=1,\n",
    "#                             #   collate_fn=collate_fn)\n",
    "#                             collate_fn=padder);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels_c = []\n",
    "for batch in test_dataloader_cor:\n",
    "    all_labels_c += batch[\"label\"].cpu().tolist()\n",
    "all_labels_c = torch.tensor(all_labels_c)\n",
    "torch.equal(all_labels_c, labels_test_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_idx = 0\n",
    "for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "    group_df.sort_values(by=['col_idx'], inplace=True)\n",
    "    group_df = group_df.reset_index(drop=True)\n",
    "    labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "    # if len(group_df) > 10:\n",
    "    #     print(i, len(group_df))\n",
    "    for index, target_column in labeled_columns.iterrows():\n",
    "        other_columns = group_df.drop(index)\n",
    "        target_col_idx = target_column[\"col_idx\"]\n",
    "        \n",
    "        target_cls = target_column[\"class_id\"]\n",
    "        assert target_cls == labels_test_original[label_idx]\n",
    "        label_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test_original[label_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column[\"class_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "src = None\n",
    "test_dataset_last = GittablesTablewiseLabelLastDataset(cv=cv,\n",
    "                            split=\"test\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only='all' not in task,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\")\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "test_dataloader_last = DataLoader(test_dataset_last,\n",
    "                                batch_size=1,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "src = None\n",
    "test_dataset_last_old = GittablesTablewiseLastDataset(cv=cv,\n",
    "                            split=\"test\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only='all' not in task,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\")\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "test_dataloader_last_old = DataLoader(test_dataset_last_old,\n",
    "                                batch_size=1,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data, data_old in zip(test_dataset_last, test_dataset_last_old):\n",
    "    assert torch.equal(torch.tensor(data['col_idx_list']), torch.tensor(data_old['col_idx_list']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['col_idx_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_old['col_idx_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data['data'] == 101).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data_old['data'] == 101).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_old['data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d, d_old in zip(test_dataset_last, test_dataset_last_old):\n",
    "    assert torch.equal(torch.tensor(d['data']), torch.tensor(d_old['data']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['col_idx_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_old['col_idx_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "src = None\n",
    "test_dataset_last = GittablesTablewiseLabelLastDataset(cv=cv,\n",
    "                            split=\"test\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only='all' not in task,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\")\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "test_dataloader_last = DataLoader(test_dataset_last,\n",
    "                                batch_size=1,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "src = None\n",
    "test_dataset_first = GittablesTablewiseLabelFirstDataset(cv=cv,\n",
    "                            split=\"test\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only='all' not in task,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\")\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "test_dataloader_first = DataLoader(test_dataset_first,\n",
    "                                batch_size=1,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels_l = []\n",
    "for batch in test_dataloader_last:\n",
    "    all_labels_l += batch[\"label\"].cpu().tolist()\n",
    "all_labels_l = torch.tensor(all_labels_l)\n",
    "torch.equal(all_labels_l, labels_test_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = None\n",
    "test_dataset_gt = GittablesTablewiseIterateDataset(cv=cv,\n",
    "                            split=\"test\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only=True,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\")\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "test_dataloader_gt = DataLoader(test_dataset_gt,\n",
    "                                batch_size=1,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset_gt[100]['initial_num_col']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 1\n",
      "train 2\n",
      "train 3\n",
      "train 4\n",
      "train 3463\n"
     ]
    }
   ],
   "source": [
    "train_dataset_gt = GittablesTablewiseIterateDataset(cv=cv,\n",
    "                            split=\"train\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only=True,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\")\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "train_dataloader_gt= DataLoader(train_dataset_gt,\n",
    "                                batch_size=1,\n",
    "                                collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(train_dataset_gt[2][\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(test_dataset_gt[0][\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_gt[0][\"label\"].cpu().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_labeled = df_train[df_train[\"class_id\"] > -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_train_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_labeled[\"data\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_labeled_corpus = [train_dataset_gt[i][\"data\"].cpu().tolist() for i in range(len(train_dataset_gt))]\n",
    "training_labeled_class = [train_dataset_gt[i][\"label\"].cpu().item() for i in range(len(train_dataset_gt))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_labeled_corpus_ind = [tokenizer.encode(\n",
    "                tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=max_length, truncation=True) for x in df_train_labeled[\"data\"].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_gt[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(train_dataset_gt[i][\"data\"].cpu().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_corpus_embs = torch.tensor(sb_model.encode([tokenizer.decode(train_dataset_gt[i][\"data\"].cpu().tolist()) for i in range(len(train_dataset_gt))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_corpus_embs_ind = torch.tensor(sb_model.encode(df_train_labeled[\"data\"].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_corpus_embs_ind.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_corpus_embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labeled_data = df_labeled[\"data\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labeled_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_corpus_embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "bm25 = BM25Okapi(training_labeled_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_ind = BM25Okapi(training_labeled_corpus_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(training_labeled_corpus_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 3\n",
    "scores = bm25.get_scores(test_dataset_gt[idx][\"data\"].cpu().tolist())\n",
    "print(tokenizer.decode(test_dataset_gt[idx][\"data\"]))\n",
    "top_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:5]\n",
    "\n",
    "# Fetch the top 5 documents\n",
    "top_documents = [training_labeled_corpus[i] for i in top_indices]\n",
    "for i, doc in enumerate(top_documents):\n",
    "    print(f\"Rank {i+1}: Document: {tokenizer.decode(doc)} => BM25 Score: {scores[top_indices[i]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IND\n",
    "idx = 6\n",
    "scores = bm25_ind.get_scores(tokenizer.encode(tokenizer.encode(\n",
    "                tokenizer.cls_token + \" \" + df_labeled_data[idx], add_special_tokens=False, max_length=max_length, truncation=True)))\n",
    "print(df_labeled_data[idx])\n",
    "top_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:5]\n",
    "\n",
    "# Fetch the top 5 documents\n",
    "top_documents = [training_labeled_corpus_ind[i] for i in top_indices]\n",
    "for i, doc in enumerate(top_documents):\n",
    "    print(f\"Rank {i+1}: Document: {tokenizer.decode(doc)} => BM25 Score: {scores[top_indices[i]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_labeled_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 3\n",
    "scores = F.cosine_similarity(training_corpus_embs, torch.tensor(sb_model.encode([tokenizer.decode(test_dataset_gt[idx][\"data\"])])).cpu().reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IND\n",
    "idx = 21\n",
    "scores = F.cosine_similarity(training_corpus_embs_ind, torch.tensor(sb_model.encode([df_labeled_data[idx]])).cpu().reshape(1,-1))\n",
    "print(df_labeled_data[idx])\n",
    "top_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:5]\n",
    "\n",
    "# Fetch the top 5 documents\n",
    "top_documents = [training_labeled_corpus_ind[i] for i in top_indices]\n",
    "for i, doc in enumerate(top_documents):\n",
    "    print(f\"Rank {i+1}: Document: {tokenizer.decode(doc)} => BM25 Score: {scores[top_indices[i]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_iter = GittablesTablewiseIterateDataset(cv=cv,\n",
    "                            split=\"train\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only='all' not in task,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\",\n",
    "                            random_sample=True)\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "train_dataloader_iter = DataLoader(train_dataset_iter,\n",
    "                                batch_size=1,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_random = GittablesTablewiseIterateRandomDataset(cv=cv,\n",
    "                            split=\"train\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only='all' not in task,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\",\n",
    "                            random_sample=True)\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "train_dataloader_random = DataLoader(train_dataset_random,\n",
    "                                batch_size=1,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "src = None\n",
    "test_dataset_sem = GittablesTablewiseIterateSemanticDataset(cv=cv,\n",
    "                            split=\"test\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only='all' not in task,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\")\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "test_dataloader_sem = DataLoader(test_dataset_sem,\n",
    "                                batch_size=1,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels_sem = []\n",
    "for batch in test_dataloader_sem:\n",
    "    all_labels_sem += batch[\"label\"].cpu().tolist()\n",
    "all_labels_sem = torch.tensor(all_labels_sem)\n",
    "torch.equal(all_labels_sem, labels_test_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(all_labels_sem == labels_test_original).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "test 1085\n"
     ]
    }
   ],
   "source": [
    "src = None\n",
    "test_dataset_all = GittablesTablewiseIterateAllDataset(cv=cv,\n",
    "                            split=\"test\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only='all' not in task,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\")\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "test_dataloader_all = DataLoader(test_dataset_all,\n",
    "                                batch_size=1,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "test 1085\n"
     ]
    }
   ],
   "source": [
    "src = None\n",
    "test_dataset_near = GittablesTablewiseIterateNearbyDataset(cv=cv,\n",
    "                            split=\"test\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only='all' not in task,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\")\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "test_dataloader_near = DataLoader(test_dataset_near,\n",
    "                                batch_size=1,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = None\n",
    "valid_dataset_near = GittablesTablewiseIterateNearbyDataset(cv=cv,\n",
    "                            split=\"valid\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only='all' not in task,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\")\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "valid_dataloader_near = DataLoader(valid_dataset_near,\n",
    "                                batch_size=1,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "test 1085\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "src = None\n",
    "test_dataset_cluster = GittablesTablewiseIterateClusterDataset(cv=cv,\n",
    "                            split=\"test\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only='all' not in task,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\")\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "test_dataloader_cluster = DataLoader(test_dataset_cluster,\n",
    "                                batch_size=1,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "src = None\n",
    "valid_dataset_cluster = GittablesTablewiseIterateClusterDataset(cv=cv,\n",
    "                            split=\"valid\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only='all' not in task,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\")\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "valid_dataloader_cluster = DataLoader(valid_dataset_cluster,\n",
    "                                batch_size=1,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=max_unlabeled-1, random_state=0).fit(training_corpus_embs_doduo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "src = None\n",
    "max_unlabeled = 8\n",
    "test_dataset_extra = GittablesTablewiseIterateClusterExtraDataset(cv=cv,\n",
    "                            split=\"test\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only='all' not in task,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\",\n",
    "                            kmeans=kmeans,\n",
    "                            df_train_labeled=df_train_labeled,\n",
    "                            training_corpus_embs_doduo=training_corpus_embs_doduo)\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "test_dataloader_extra = DataLoader(test_dataset_extra,\n",
    "                                batch_size=1,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "src = None\n",
    "max_unlabeled = 8\n",
    "kmeans = KMeans(n_clusters=max_unlabeled-1, random_state=0).fit(training_corpus_embs_doduo_all)\n",
    "test_dataset_extra = GittablesTablewiseIterateClusterExtraDataset(cv=cv,\n",
    "                            split=\"test\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only='all' not in task,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\",\n",
    "                            kmeans=kmeans,\n",
    "                            df_train_labeled=df_train,\n",
    "                            training_corpus_embs_doduo=training_corpus_embs_doduo_all)\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "test_dataloader_extra = DataLoader(test_dataset_extra,\n",
    "                                batch_size=1,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src = None\n",
    "# test_dataset_dist = GittablesTablewiseIterateDistantDataset(cv=cv,\n",
    "#                             split=\"test\", src=src,\n",
    "#                             tokenizer=tokenizer,\n",
    "#                             max_length=max_length,\n",
    "#                             gt_only='all' not in task,\n",
    "#                             device=device,\n",
    "#                             base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "#                             small_tag=\"semi1\")\n",
    "# padder = collate_fn(tokenizer.pad_token_id)\n",
    "# test_dataloader_dist = DataLoader(test_dataset_dist,\n",
    "#                                 batch_size=1,\n",
    "#                             #   collate_fn=collate_fn)\n",
    "#                             collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels_near = []\n",
    "for batch in test_dataloader_near:\n",
    "    all_labels_near += batch[\"label\"].cpu().tolist()\n",
    "all_labels_near = torch.tensor(all_labels_near)\n",
    "torch.equal(all_labels_near, labels_test_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "src = None\n",
    "test_dataset_nearlast = GittablesTablewiseIterateNearbyLastDataset(cv=cv,\n",
    "                            split=\"test\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only='all' not in task,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\")\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "test_dataloader_nearlast = DataLoader(test_dataset_nearlast,\n",
    "                                batch_size=1,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels_nearlast = []\n",
    "for batch in test_dataloader_nearlast:\n",
    "    all_labels_nearlast += batch[\"label\"].cpu().tolist()\n",
    "all_labels_nearlast = torch.tensor(all_labels_nearlast)\n",
    "torch.equal(all_labels_nearlast, labels_test_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = None\n",
    "test_dataset_hy = GittablesTablewiseIterateHybridDataset(cv=cv,\n",
    "                            split=\"test\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only='all' not in task,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\")\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "test_dataloader_hy = DataLoader(test_dataset_hy,\n",
    "                                batch_size=1,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels_hy = []\n",
    "for batch in test_dataloader_hy:\n",
    "    all_labels_hy += batch[\"label\"].cpu().tolist()\n",
    "all_labels_hy = torch.tensor(all_labels_hy)\n",
    "torch.equal(all_labels_hy, labels_test_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "src = None\n",
    "test_dataset_set = GittablesTablewiseIterateSentenceDataset(cv=cv,\n",
    "                            split=\"test\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only='all' not in task,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\")\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "test_dataloader_set = DataLoader(test_dataset_set,\n",
    "                                batch_size=1,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels_set = []\n",
    "for batch in test_dataloader_set:\n",
    "    all_labels_set += batch[\"label\"].cpu().tolist()\n",
    "all_labels_set = torch.tensor(all_labels_set)\n",
    "torch.equal(all_labels_set, labels_test_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(all_labels_set==labels_test_original).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_set[0][\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_set[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(train_dataloader_iter):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    num_cols.append(batch[\"target_col_mask\"].max().item()+1)\n",
    "num_cols = torch.tensor(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(num_cols.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = None\n",
    "valid_dataset_iter = GittablesTablewiseIterateDataset(cv=cv,\n",
    "                            split=\"valid\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only='all' not in task,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\",\n",
    "                            random_sample=True)\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "valid_dataloader_iter = DataLoader(valid_dataset_iter,\n",
    "                                batch_size=1,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = None\n",
    "valid_dataset_random = GittablesTablewiseIterateRandomDataset(cv=cv,\n",
    "                            split=\"valid\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only='all' not in task,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\",\n",
    "                            random_sample=True)\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "valid_dataloader_random = DataLoader(valid_dataset_random,\n",
    "                                batch_size=1,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_micro_f1=0.5355, ts_macro_f1=0.2745\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test_original = []\n",
    "logits_test = []\n",
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    labels_test_original.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "    num_cols.append(test_dataset_iter[batch_idx]['initial_num_col'])\n",
    "    ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "labels_test_original = torch.cat(labels_test_original, dim=0)\n",
    "logits_test = torch.stack(logits_test, dim=0)\n",
    "preds_test = torch.argmax(logits_test, dim=1)\n",
    "num_cols = torch.tensor(num_cols)\n",
    "ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "mask = num_cols > 0\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "full_f1_init = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=None)\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test_original[num_cols==6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_col in np.arange(1, 10):\n",
    "    if n_col <= 8:\n",
    "        mask = num_cols == n_col\n",
    "    else:\n",
    "        mask = num_cols > 8\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach()[mask].numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    print(\"num_cols={} num_samples={} ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(n_col, sum(mask), ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_unlabeled=2\n",
      "test\n",
      "test 1085\n",
      "ts_micro_f1=0.4959, ts_macro_f1=0.2512\n",
      "max_unlabeled=4\n",
      "test\n",
      "test 1085\n",
      "ts_micro_f1=0.4857, ts_macro_f1=0.2470\n",
      "max_unlabeled=8\n",
      "test\n",
      "test 1085\n",
      "ts_micro_f1=0.4664, ts_macro_f1=0.2221\n"
     ]
    }
   ],
   "source": [
    "for max_unlabeled in [2,4, 8]:\n",
    "    print(\"max_unlabeled={}\".format(max_unlabeled))\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    src = None\n",
    "    test_dataset_cluster = GittablesTablewiseIterateClusterDataset(cv=cv,\n",
    "                                split=\"test\", src=src,\n",
    "                                tokenizer=tokenizer,\n",
    "                                max_length=max_length,\n",
    "                                gt_only='all' not in task,\n",
    "                                device=device,\n",
    "                                base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                                small_tag=\"semi1\",\n",
    "                                max_unlabeled=max_unlabeled)\n",
    "    padder = collate_fn(tokenizer.pad_token_id)\n",
    "    test_dataloader_cluster = DataLoader(test_dataset_cluster,\n",
    "                                    batch_size=1,\n",
    "                                #   collate_fn=collate_fn)\n",
    "                                collate_fn=padder)\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    ft_embs_test = []\n",
    "    labels_test_original = []\n",
    "    logits_test = []\n",
    "    num_cols = []\n",
    "    for batch_idx, batch in enumerate(test_dataloader_cluster):\n",
    "        cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "        # target_col_mask = batch[\"target_col_mask\"].T\n",
    "        logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "        labels_test_original.append(batch[\"label\"].cpu())\n",
    "        logits_test.append(logits.detach().cpu())\n",
    "        num_cols.append(test_dataset_iter[batch_idx]['initial_num_col'])\n",
    "        ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "    labels_test_original = torch.cat(labels_test_original, dim=0)\n",
    "    logits_test = torch.stack(logits_test, dim=0)\n",
    "    preds_test = torch.argmax(logits_test, dim=1)\n",
    "    num_cols = torch.tensor(num_cols)\n",
    "    ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "    from sklearn.metrics import confusion_matrix, f1_score\n",
    "    mask = num_cols > 0\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach().numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test_original = []\n",
    "logits_test = []\n",
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(test_dataloader_cluster):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    # target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    labels_test_original.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "    num_cols.append(test_dataset_iter[batch_idx]['initial_num_col'])\n",
    "    ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "labels_test_original = torch.cat(labels_test_original, dim=0)\n",
    "logits_test = torch.stack(logits_test, dim=0)\n",
    "preds_test = torch.argmax(logits_test, dim=1)\n",
    "num_cols = torch.tensor(num_cols)\n",
    "ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "mask = num_cols < 8\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1)[mask].cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test_original[mask].reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test_original[mask].reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_col in np.arange(1, 10):\n",
    "    if n_col <= 8:\n",
    "        mask = num_cols == n_col\n",
    "    else:\n",
    "        mask = num_cols > 8\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach()[mask].numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test_original.reshape(-1)[mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test_original.reshape(-1)[mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    print(\"num_cols={} num_samples={} ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(n_col, sum(mask), ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test_original = []\n",
    "logits_test = []\n",
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(test_dataloader_extra):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    # target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    labels_test_original.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "    num_cols.append(test_dataset_iter[batch_idx]['initial_num_col'])\n",
    "    ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "labels_test_original = torch.cat(labels_test_original, dim=0)\n",
    "logits_test = torch.stack(logits_test, dim=0)\n",
    "preds_test = torch.argmax(logits_test, dim=1)\n",
    "num_cols = torch.tensor(num_cols)\n",
    "ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "mask = num_cols > 0\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "mask = num_cols < 8\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1)[mask].cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test_original[mask].reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test_original[mask].reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_col in np.arange(1, 10):\n",
    "    if n_col <= 8:\n",
    "        mask = num_cols == n_col\n",
    "    else:\n",
    "        mask = num_cols > 8\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach()[mask].numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test_original.reshape(-1)[mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test_original.reshape(-1)[mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    print(\"num_cols={} num_samples={} ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(n_col, sum(mask), ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for max_unlabeled in [32]:\n",
    "    for n_sample in [1, 2,3,4,5,6]:\n",
    "        print(f\"******************{ max_unlabeled, n_sample}******************\")\n",
    "        src = None\n",
    "        test_dataset_cluster = GittablesTablewiseIterateClusterDataset(cv=cv,\n",
    "                                    split=\"test\", src=src,\n",
    "                                    tokenizer=tokenizer,\n",
    "                                    max_length=max_length,\n",
    "                                    gt_only='all' not in task,\n",
    "                                    device=device,\n",
    "                                    base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                                    small_tag=\"semi1\",\n",
    "                                    max_unlabeled=max_unlabeled,\n",
    "                                    samples_per_cluster=n_sample)\n",
    "        padder = collate_fn(tokenizer.pad_token_id)\n",
    "        test_dataloader_cluster = DataLoader(test_dataset_cluster,\n",
    "                                        batch_size=1,\n",
    "                                    #   collate_fn=collate_fn)\n",
    "                                    collate_fn=padder)\n",
    "        model.eval()\n",
    "        model = model.to(device)\n",
    "        ft_embs_test = []\n",
    "        labels_test_original = []\n",
    "        logits_test = []\n",
    "        num_cols = []\n",
    "        for batch_idx, batch in enumerate(test_dataloader_cluster):\n",
    "            cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "            # target_col_mask = batch[\"target_col_mask\"].T\n",
    "            logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "            labels_test_original.append(batch[\"label\"].cpu())\n",
    "            logits_test.append(logits.detach().cpu())\n",
    "            num_cols.append(test_dataset_iter[batch_idx]['initial_num_col'])\n",
    "            ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "        labels_test_original = torch.cat(labels_test_original, dim=0)\n",
    "        logits_test = torch.stack(logits_test, dim=0)\n",
    "        preds_test = torch.argmax(logits_test, dim=1)\n",
    "        num_cols = torch.tensor(num_cols)\n",
    "        ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "        from sklearn.metrics import confusion_matrix, f1_score\n",
    "        mask = num_cols > 0\n",
    "        ts_pred_list = logits_test.argmax(\n",
    "                                    1).cpu().detach().numpy().tolist()\n",
    "        ts_micro_f1 = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                            ts_pred_list,\n",
    "                            average=\"micro\")\n",
    "        ts_macro_f1 = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                            ts_pred_list,\n",
    "                            average=\"macro\")\n",
    "        print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_col in np.arange(1, 10):\n",
    "    if n_col <= 8:\n",
    "        mask = num_cols == n_col\n",
    "    else:\n",
    "        mask = num_cols > 8\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach()[mask].numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test_original.reshape(-1)[mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test_original.reshape(-1)[mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    print(\"num_cols={} num_samples={} ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(n_col, sum(mask), ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine distance to all labeled training columns\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test = []\n",
    "logits_test_eu = []\n",
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(test_dataloader_lb):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    # target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    labels_test.append(batch[\"label\"].cpu())\n",
    "    logits_test_eu.append(logits.detach().cpu())\n",
    "    num_cols.append(test_dataset_iter[batch_idx]['initial_num_col'])\n",
    "    ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "labels_test = torch.cat(labels_test, dim=0)\n",
    "logits_test_eu = torch.stack(logits_test_eu, dim=0)\n",
    "preds_test_eu = torch.argmax(logits_test_eu, dim=1)\n",
    "num_cols = torch.tensor(num_cols)\n",
    "ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "mask = num_cols > 0\n",
    "ts_pred_list_eu = logits_test_eu.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list_eu,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list_eu,\n",
    "                    average=\"macro\")\n",
    "full_f1_eu = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list_eu,\n",
    "                    average=None)\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_unlabeled=2\n",
      "test\n",
      "test 1085\n",
      "ts_micro_f1=0.5346, ts_macro_f1=0.2734\n",
      "max_unlabeled=4\n",
      "test\n",
      "test 1085\n",
      "ts_micro_f1=0.5171, ts_macro_f1=0.2538\n",
      "max_unlabeled=8\n",
      "test\n",
      "test 1085\n",
      "ts_micro_f1=0.4922, ts_macro_f1=0.2192\n"
     ]
    }
   ],
   "source": [
    "# EU distance to all labeled training columns\n",
    "for max_unlabeled in [2,4, 8]:\n",
    "    print(\"max_unlabeled={}\".format(max_unlabeled))\n",
    "    src = None\n",
    "    test_dataset_lb = GittablesTablewiseIterateLabelDataset(cv=cv,\n",
    "                                split=\"test\", src=src,\n",
    "                                tokenizer=tokenizer,\n",
    "                                max_length=max_length,\n",
    "                                gt_only='all' not in task,\n",
    "                                device=device,\n",
    "                                base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                                small_tag=\"semi1\",\n",
    "                                max_unlabeled=max_unlabeled)\n",
    "    padder = collate_fn(tokenizer.pad_token_id)\n",
    "    test_dataloader_lb = DataLoader(test_dataset_lb,\n",
    "                                    batch_size=1,\n",
    "                                #   collate_fn=collate_fn)\n",
    "                                collate_fn=padder)\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    ft_embs_test = []\n",
    "    labels_test_original = []\n",
    "    logits_test = []\n",
    "    num_cols = []\n",
    "    for batch_idx, batch in enumerate(test_dataloader_lb):\n",
    "        cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "        # target_col_mask = batch[\"target_col_mask\"].T\n",
    "        logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "        labels_test_original.append(batch[\"label\"].cpu())\n",
    "        logits_test.append(logits.detach().cpu())\n",
    "        num_cols.append(test_dataset_iter[batch_idx]['initial_num_col'])\n",
    "        ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "    labels_test_original = torch.cat(labels_test_original, dim=0)\n",
    "    logits_test = torch.stack(logits_test, dim=0)\n",
    "    preds_test = torch.argmax(logits_test, dim=1)\n",
    "    num_cols = torch.tensor(num_cols)\n",
    "    ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "    from sklearn.metrics import confusion_matrix, f1_score\n",
    "    mask = num_cols > 0\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach().numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    full_f1_init = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=None)\n",
    "    print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EU distance to class center\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test_original = []\n",
    "logits_test = []\n",
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(test_dataloader_lb):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    # target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    labels_test_original.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "    num_cols.append(test_dataset_iter[batch_idx]['initial_num_col'])\n",
    "    ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "labels_test_original = torch.cat(labels_test_original, dim=0)\n",
    "logits_test = torch.stack(logits_test, dim=0)\n",
    "preds_test = torch.argmax(logits_test, dim=1)\n",
    "num_cols = torch.tensor(num_cols)\n",
    "ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "mask = num_cols > 0\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "full_f1_init = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=None)\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COS distance to class center\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test_original = []\n",
    "logits_test = []\n",
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(test_dataloader_lb):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    # target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    labels_test_original.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "    num_cols.append(test_dataset_iter[batch_idx]['initial_num_col'])\n",
    "    ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "labels_test_original = torch.cat(labels_test_original, dim=0)\n",
    "logits_test = torch.stack(logits_test, dim=0)\n",
    "preds_test = torch.argmax(logits_test, dim=1)\n",
    "num_cols = torch.tensor(num_cols)\n",
    "ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "mask = num_cols > 0\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "full_f1_init = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=None)\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MD distance\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test_original = []\n",
    "logits_test = []\n",
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(test_dataloader_lb):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    # target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    labels_test_original.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "    num_cols.append(test_dataset_iter[batch_idx]['initial_num_col'])\n",
    "    ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "labels_test_original = torch.cat(labels_test_original, dim=0)\n",
    "logits_test = torch.stack(logits_test, dim=0)\n",
    "preds_test = torch.argmax(logits_test, dim=1)\n",
    "num_cols = torch.tensor(num_cols)\n",
    "ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "mask = num_cols > 0\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "full_f1_init = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=None)\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_col in np.arange(1, 10):\n",
    "    if n_col <= 8:\n",
    "        mask = num_cols == n_col\n",
    "    else:\n",
    "        mask = num_cols > 8\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach()[mask].numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    print(\"num_cols={} num_samples={} ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(n_col, sum(mask), ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test_dataset_single)):\n",
    "    assert test_dataset_single[i][\"num_col\"] == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols_labeled = []\n",
    "for i in range(len(test_dataset_gt)):\n",
    "    num_cols_labeled.append(test_dataset_gt[i][\"target_col_mask\"].max().item())\n",
    "    if test_dataset_gt[i][\"target_col_mask\"].max().item() == 6:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 6])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(num_cols_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': tensor([  101,  1015,  1025,  1016,  1025,  1017,  1025,  1018,  1025,  1019,\n",
       "          1025,  1020,  1025,  1021,  1025,  1022,  1025,  1023,  1025,  2184,\n",
       "           101,  3287,  1025,  2931,  1025,  2931,  1025,  3287,  1025,  2931,\n",
       "          1025,  2931,  1025,  2931,  1025,  3287,  1025,  3287,  1025,  2931,\n",
       "           101, 28557,  9286, 12691,  1025, 16364,  1025,  6243, 15951,  1025,\n",
       "          9774,  1025,  2882, 12775,  1025, 15302, 12801,  1025, 19243,  4674,\n",
       "          3077,  1025, 12403, 14343,  6767,  7295,  1037,  1012,  1042,  1012,\n",
       "          1055,  1012,  1025,  3387,  3077,  1025,  9530, 10532,  2015,   101,\n",
       "         23523,  2487,  1025, 24368, 24096,  1025,  6109, 14142,  2487,  1025,\n",
       "         29335, 10790,  1025, 29302,  2692,  2620,  1025,  3963, 17914,  2475,\n",
       "          1025,  5824, 19841,  2487,  1025,  5585, 12376,  2575,  1025, 17222,\n",
       "         10790,  1025, 22060,  2692,  2581,   101,  2149,  1025,  2149,  1025,\n",
       "          2149,  1025,  2149,  1025,  2149,  1025,  2149,  1025,  2149,  1025,\n",
       "          2149,  1025,  2149,  1025,  2149,   101,  4840,  2707,  1025,  3477,\n",
       "          1005,  1050,  2202,  4183,  1025, 22794,  2140, 14341,  2545,  1025,\n",
       "          1996,  3407,  4562,  1025, 12831, 12614,  1025,  8379,  4827,  2015,\n",
       "          1025, 12256, 13767,  2015,  1025,  2430,  8051,  1025,  2259, 21475,\n",
       "          2160,  1025,  7723,  1047, 10524,  2121,  1004,  4124,   101,  5527,\n",
       "         15338,  5397,  1012,  4012,  1025, 28516,  8445, 25128,  1012,  4012,\n",
       "          1025,  2987, 10760,  2906,  1012,  4012,  1025,  3026,  7076,  5051,\n",
       "         16761,  1012,  4012,  1025,  2919, 21572, 26557,  3508,  1012,  4012,\n",
       "          1025,  5451,  7442, 16761,  2100,  1012,  4012,  1025,  8028, 22231,\n",
       "          2860,  1012,  4012,  1025,  7262,  2638, 18377, 12821,  9021,  1012,\n",
       "          4012,  1025, 10373, 15975,  2015,  1012,  4012,  1025,  9004,  4305,\n",
       "          5339,  1012], device='cuda:1'),\n",
       " 'label': tensor([60], device='cuda:1'),\n",
       " 'cls_indexes': tensor([0], device='cuda:1'),\n",
       " 'target_col_mask': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "         3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
       "         4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "         5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "         5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "         6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "         6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "         6, 6], device='cuda:1'),\n",
       " 'initial_num_col': 7,\n",
       " 'col_idx': array([ 0,  1,  7,  9, 10, 26, 28])}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset_gt[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 6])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(num_cols_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset_gt[i]['initial_num_col']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_micro_f1=0.5401, ts_macro_f1=0.2674\n",
      "ts_micro_f1=0.5061, ts_macro_f1=0.2464\n",
      "ts_micro_f1=0.5787, ts_macro_f1=0.2439\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(test_dataloader_gt):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    labels_test.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "    num_cols.append(batch[\"target_col_mask\"].max().item())\n",
    "    ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "labels_test = torch.cat(labels_test, dim=0)\n",
    "logits_test = torch.stack(logits_test, dim=0)\n",
    "preds_test = torch.argmax(logits_test, dim=1)\n",
    "num_cols = torch.tensor(num_cols)\n",
    "ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "mask = num_cols > 0\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "full_f1_init = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=None)\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach()[mask].numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach()[~mask].numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_micro_f1=0.5336, ts_macro_f1=0.2414\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(test_dataloader_single):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    labels_test.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "    num_cols.append(batch[\"target_col_mask\"].max().item())\n",
    "    ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "labels_test = torch.cat(labels_test, dim=0)\n",
    "logits_test = torch.stack(logits_test, dim=0)\n",
    "preds_test = torch.argmax(logits_test, dim=1)\n",
    "num_cols = torch.tensor(num_cols)\n",
    "ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "mask = num_cols > 0\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "full_f1_init = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=None)\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_col in np.arange(1, 10):\n",
    "    if n_col <= 8:\n",
    "        mask = num_cols == n_col\n",
    "    else:\n",
    "        mask = num_cols > 8\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach()[mask].numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    print(\"num_cols={} num_samples={} ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(n_col, sum(mask), ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_micro_f1=0.5355, ts_macro_f1=0.2683\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(test_dataloader_first):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    labels_test.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "    num_cols.append(test_dataset_iter[batch_idx]['initial_num_col'])\n",
    "    ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "labels_test = torch.cat(labels_test, dim=0)\n",
    "logits_test_first = torch.stack(logits_test, dim=0)\n",
    "preds_test_first = torch.argmax(logits_test_first, dim=1)\n",
    "num_cols = torch.tensor(num_cols)\n",
    "ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "mask = num_cols > 0\n",
    "ts_pred_list_first = logits_test_first.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list_first,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list_first,\n",
    "                    average=\"macro\")\n",
    "full_f1_init = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list_first,\n",
    "                    average=None)\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************2******************\n",
      "test\n",
      "test 1085\n",
      "ts_micro_f1=0.4885, ts_macro_f1=0.2359\n",
      "******************4******************\n",
      "test\n",
      "test 1085\n",
      "ts_micro_f1=0.4903, ts_macro_f1=0.2469\n",
      "******************8******************\n",
      "test\n",
      "test 1085\n",
      "ts_micro_f1=0.4608, ts_macro_f1=0.2259\n",
      "******************16******************\n",
      "test\n",
      "test 1085\n",
      "ts_micro_f1=0.4396, ts_macro_f1=0.1986\n"
     ]
    }
   ],
   "source": [
    "for max_unlabeled in [2, 4, 8, 16]:\n",
    "    print(f\"******************{ max_unlabeled}******************\")\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    src = None\n",
    "    test_dataset_first = GittablesTablewiseFirstDataset(cv=cv,\n",
    "                                split=\"test\", src=src,\n",
    "                                tokenizer=tokenizer,\n",
    "                                max_length=max_length,\n",
    "                                gt_only='all' not in task,\n",
    "                                device=device,\n",
    "                                base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                                small_tag=\"semi1\",\n",
    "                                max_unlabeled=max_unlabeled)\n",
    "    padder = collate_fn(tokenizer.pad_token_id)\n",
    "    test_dataloader_first = DataLoader(test_dataset_first,\n",
    "                                    batch_size=1,\n",
    "                                #   collate_fn=collate_fn)\n",
    "                                collate_fn=padder)\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    num_cols = []\n",
    "    for batch_idx, batch in enumerate(test_dataloader_first):\n",
    "        cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "        target_col_mask = batch[\"target_col_mask\"].T\n",
    "        logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "        labels_test.append(batch[\"label\"].cpu())\n",
    "        logits_test.append(logits.detach().cpu())\n",
    "        num_cols.append(test_dataset_iter[batch_idx]['initial_num_col'])\n",
    "        ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "    labels_test = torch.cat(labels_test, dim=0)\n",
    "    logits_test_first = torch.stack(logits_test, dim=0)\n",
    "    preds_test_first = torch.argmax(logits_test_first, dim=1)\n",
    "    num_cols = torch.tensor(num_cols)\n",
    "    ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "    from sklearn.metrics import confusion_matrix, f1_score\n",
    "    mask = num_cols > 0\n",
    "    ts_pred_list_first = logits_test_first.argmax(\n",
    "                                1).cpu().detach().numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list_first,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list_first,\n",
    "                        average=\"macro\")\n",
    "    full_f1_init = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list_first,\n",
    "                        average=None)\n",
    "    print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4348"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_corpus_labels = []\n",
    "for label, x in zip(df_train_labeled[\"class_id\"], df_train_labeled[\"data\"]):\n",
    "    training_corpus_labels.append(label)\n",
    "training_corpus_labels = torch.tensor(training_corpus_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "training_corpus_embs_doduo = []\n",
    "\n",
    "for label, x in zip(df_train_labeled[\"class_id\"], df_train_labeled[\"data\"]):\n",
    "    cls_indexes = torch.LongTensor([[0, 0]]).to(device)\n",
    "    x = torch.LongTensor( tokenizer.encode(\n",
    "                tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=max_length, truncation=True)).to(device).reshape(1, -1)\n",
    "    logits, embs = model(x, cls_indexes=cls_indexes, get_enc=True)\n",
    "    training_corpus_embs_doduo.append(embs.detach().cpu().reshape(1, -1))\n",
    "training_corpus_embs_doduo = torch.cat(training_corpus_embs_doduo, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "training_corpus_embs_doduo_all = []\n",
    "\n",
    "for label, x in zip(df_train[\"class_id\"], df_train[\"data\"]):\n",
    "    cls_indexes = torch.LongTensor([[0, 0]]).to(device)\n",
    "    x = torch.LongTensor( tokenizer.encode(\n",
    "                tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=max_length, truncation=True)).to(device).reshape(1, -1)\n",
    "    logits, embs = model(x, cls_indexes=cls_indexes, get_enc=True)\n",
    "    training_corpus_embs_doduo_all.append(embs.detach().cpu().reshape(1, -1))\n",
    "training_corpus_embs_doduo_all = torch.cat(training_corpus_embs_doduo_all, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_corpus_labels.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_corpus_embs_doduo[training_corpus_labels==0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model = model.to(device)\n",
    "training_corpus_embs_doduo_center = []\n",
    "for label in training_corpus_labels.unique():\n",
    "    class_center = training_corpus_embs_doduo[training_corpus_labels==label].mean(dim=0, keepdim=True)\n",
    "    training_corpus_embs_doduo_center.append(class_center)\n",
    "training_corpus_embs_doduo_center = torch.cat(training_corpus_embs_doduo_center, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "training_corpus_embs_doduo_all = []\n",
    "\n",
    "for label, x in zip(df_train[\"class_id\"], df_train[\"data\"]):\n",
    "    cls_indexes = torch.LongTensor([[0, 0]]).to(device)\n",
    "    x = torch.LongTensor( tokenizer.encode(\n",
    "                tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=max_length, truncation=True)).to(device).reshape(1, -1)\n",
    "    logits, embs = model(x, cls_indexes=cls_indexes, get_enc=True)\n",
    "    training_corpus_embs_doduo_all.append(embs.detach().cpu().reshape(1, -1))\n",
    "training_corpus_embs_doduo_all = torch.cat(training_corpus_embs_doduo_all, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(training_corpus_embs_doduo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(training_corpus_embs_doduo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[\"data\"].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(test_dataset_lb):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T.reshape(1,-1), cls_indexes=cls_indexes, get_enc=True)\n",
    "    labels_test.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "    num_cols.append(test_dataset_iter[batch_idx]['initial_num_col'])\n",
    "    ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "labels_test = torch.cat(labels_test, dim=0)\n",
    "logits_test_first = torch.stack(logits_test, dim=0)\n",
    "preds_test_first = torch.argmax(logits_test_first, dim=1)\n",
    "num_cols = torch.tensor(num_cols)\n",
    "ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "mask = num_cols > 0\n",
    "ts_pred_list_first = logits_test_first.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list_first,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list_first,\n",
    "                    average=\"macro\")\n",
    "full_f1_init = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list_first,\n",
    "                    average=None)\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[\"data\"].T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get first columns, put target column at the head\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(test_dataloader_first):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    labels_test.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "    num_cols.append(test_dataset_iter[batch_idx]['initial_num_col'])\n",
    "    ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "labels_test = torch.cat(labels_test, dim=0)\n",
    "logits_test_first = torch.stack(logits_test, dim=0)\n",
    "preds_test_first = torch.argmax(logits_test_first, dim=1)\n",
    "num_cols = torch.tensor(num_cols)\n",
    "ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "mask = num_cols > 0\n",
    "ts_pred_list_first = logits_test_first.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list_first,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list_first,\n",
    "                    average=\"macro\")\n",
    "full_f1_init = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list_first,\n",
    "                    average=None)\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nearby_num in [1,2,4,8]:\n",
    "    print(\"nearby_num={}\".format(nearby_num))\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    src = None\n",
    "    test_dataset_nf = GittablesTablewiseIterateNearbyFirstDataset(cv=cv,\n",
    "                                split=\"test\", src=src,\n",
    "                                tokenizer=tokenizer,\n",
    "                                max_length=max_length,\n",
    "                                gt_only='all' not in task,\n",
    "                                device=device,\n",
    "                                base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                                small_tag=\"semi1\",\n",
    "                                nearby_num=nearby_num)\n",
    "    padder = collate_fn(tokenizer.pad_token_id)\n",
    "    test_dataloader_nf = DataLoader(test_dataset_nf,\n",
    "                                    batch_size=1,\n",
    "                                #   collate_fn=collate_fn)\n",
    "                                collate_fn=padder)\n",
    "\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    num_cols = []\n",
    "    for batch_idx, batch in enumerate(test_dataloader_nf):\n",
    "        cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "        # target_col_mask = batch[\"target_col_mask\"].T\n",
    "        logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "        labels_test.append(batch[\"label\"].cpu())\n",
    "        logits_test.append(logits.detach().cpu())\n",
    "        num_cols.append(test_dataset_iter[batch_idx]['initial_num_col'])\n",
    "        ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "    labels_test = torch.cat(labels_test, dim=0)\n",
    "    logits_test_first = torch.stack(logits_test, dim=0)\n",
    "    preds_test_first = torch.argmax(logits_test_first, dim=1)\n",
    "    num_cols = torch.tensor(num_cols)\n",
    "    ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "    from sklearn.metrics import confusion_matrix, f1_score\n",
    "    mask = num_cols > 0\n",
    "    ts_pred_list_first = logits_test_first.argmax(\n",
    "                                1).cpu().detach().numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list_first,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list_first,\n",
    "                        average=\"macro\")\n",
    "    full_f1_init = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list_first,\n",
    "                        average=None)\n",
    "    print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(test_dataloader_last):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    labels_test.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "    num_cols.append(len(target_col_mask.unique()))\n",
    "    ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "labels_test = torch.cat(labels_test, dim=0)\n",
    "logits_test_first = torch.stack(logits_test, dim=0)\n",
    "preds_test_first = torch.argmax(logits_test_first, dim=1)\n",
    "num_cols = torch.tensor(num_cols)\n",
    "ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "mask = num_cols > 0\n",
    "ts_pred_list_first = logits_test_first.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list_first,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list_first,\n",
    "                    average=\"macro\")\n",
    "full_f1_init = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list_first,\n",
    "                    average=None)\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[\"data\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_num_cols = []\n",
    "for i, (batch_old, batch) in enumerate(zip(test_dataloader_last_old, test_dataloader_last)):\n",
    "    if not torch.equal(batch_old[\"data\"], batch[\"data\"]):\n",
    "        bad_num_cols.append(num_cols[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(bad_num_cols).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bad_num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(num_cols==8).sum() - 93"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.equal(num_cols, num_cols_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "num_cols_old = []\n",
    "for batch_idx, batch in enumerate(test_dataloader_last_old):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    # target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    labels_test.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "    # num_cols_old.append(len(target_col_mask.unique()))\n",
    "    ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "labels_test = torch.cat(labels_test, dim=0)\n",
    "logits_test_first = torch.stack(logits_test, dim=0)\n",
    "preds_test_first = torch.argmax(logits_test_first, dim=1)\n",
    "# num_cols_old = torch.tensor(num_cols_old)\n",
    "ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "mask = num_cols > 0\n",
    "ts_pred_list_first = logits_test_first.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list_first,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list_first,\n",
    "                    average=\"macro\")\n",
    "full_f1_init = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list_first,\n",
    "                    average=None)\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(preds_test_first == labels_test).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(preds_test_near == labels_test).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(((preds_test_near != labels_test)&(preds_test_first == labels_test)).nonzero()))\n",
    "print(((preds_test_near != labels_test)&(preds_test_first == labels_test)).nonzero())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 820\n",
    "print(types[test_dataset_near[idx]['label'].item()], tokenizer.decode(test_dataset_near[idx][\"data\"][test_dataset_near[idx]['target_col_mask']==0]))\n",
    "tokenizer.decode(test_dataset_near[idx][\"data\"]).split('[CLS]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 820\n",
    "print(types[test_dataset_first[idx]['label'].item()], tokenizer.decode(test_dataset_first[idx][\"data\"][test_dataset_first[idx]['target_col_mask']==0]))\n",
    "tokenizer.decode(test_dataset_first[idx][\"data\"]).split('[CLS]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(((preds_test_near == labels_test)&(preds_test_first != labels_test)).nonzero()))\n",
    "((preds_test_near == labels_test)&(preds_test_first != labels_test)).nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 152\n",
    "print(types[test_dataset_near[idx]['label'].item()], tokenizer.decode(test_dataset_near[idx][\"data\"][test_dataset_near[idx]['target_col_mask']==0]))\n",
    "tokenizer.decode(test_dataset_near[idx][\"data\"]).split('[CLS]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 152\n",
    "print(types[test_dataset_first[idx]['label'].item()], tokenizer.decode(test_dataset_first[idx][\"data\"][test_dataset_first[idx]['target_col_mask']==0]))\n",
    "tokenizer.decode(test_dataset_first[idx][\"data\"]).split('[CLS]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_col in np.arange(1, 10):\n",
    "    if n_col <= 8:\n",
    "        mask = num_cols == n_col\n",
    "    else:\n",
    "        mask = num_cols > 8\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach()[mask].numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    print(\"num_cols={} num_samples={} ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(n_col, sum(mask), ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(test_dataloader_sem):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    labels_test.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "    num_cols.append(test_dataset_iter[batch_idx]['initial_num_col'])\n",
    "    ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "labels_test = torch.cat(labels_test, dim=0)\n",
    "logits_test = torch.stack(logits_test, dim=0)\n",
    "preds_test = torch.argmax(logits_test, dim=1)\n",
    "num_cols = torch.tensor(num_cols)\n",
    "ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "mask = num_cols > 0\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "full_f1_init = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=None)\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach()[mask].numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach()[~mask].numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "preds_test_sem = preds_test.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(preds_test == labels_test).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_acc_origin = []\n",
    "for class_i in range(args.num_classes):\n",
    "    mask = labels_test == class_i\n",
    "    class_acc_origin.append((preds_test[mask] == labels_test[mask]).sum().item() / mask.sum().item())\n",
    "class_acc_origin = torch.tensor(class_acc_origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_acc_sem = []\n",
    "for class_i in range(args.num_classes):\n",
    "    mask = labels_test == class_i\n",
    "    class_acc_sem.append((preds_test_sem[mask] == labels_test[mask]).sum().item() / mask.sum().item())\n",
    "class_acc_sem = torch.tensor(class_acc_sem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((class_acc_origin > class_acc_sem).sum())\n",
    "print((class_acc_origin < class_acc_sem).sum())\n",
    "print((class_acc_origin == class_acc_sem).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coltypes[(class_acc_origin > class_acc_sem)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((class_acc_origin == 0).sum())\n",
    "print((class_acc_sem == 0).sum())\n",
    "print(((class_acc_sem == 0)&(class_acc_origin == 0)).sum())\n",
    "print(((class_acc_sem == 0)&(class_acc_origin != 0)).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(coltypes[((class_acc_sem == 0)&(class_acc_origin != 0))])\n",
    "print(class_acc_origin[((class_acc_sem == 0)&(class_acc_origin != 0))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(is_numerical[(class_acc_origin > class_acc_sem)].sum())\n",
    "print(is_categorical[(class_acc_origin > class_acc_sem)].sum())\n",
    "print(is_datetime[(class_acc_origin > class_acc_sem)].sum())\n",
    "print(is_other[(class_acc_origin > class_acc_sem)].sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coltypes[(class_acc_origin < class_acc_sem)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(is_numerical[(class_acc_origin < class_acc_sem)].sum())\n",
    "print(is_categorical[(class_acc_origin < class_acc_sem)].sum())\n",
    "print(is_datetime[(class_acc_origin < class_acc_sem)].sum())\n",
    "print(is_other[(class_acc_origin < class_acc_sem)].sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = coltypes\n",
    "type2id = {t: i for i, t in enumerate(types)}\n",
    "id2type = {i: t for i, t in enumerate(types)}\n",
    "column_categories = {\n",
    "    \"Numerical\": ['start', 'duration', 'frequency', 'age', 'value', 'price', 'weight', 'score', 'rank', 'height', 'population', 'order', 'length', 'max', 'min', 'number', 'cost', 'elevation', 'depth', 'width', 'percentage'],\n",
    "    \"Categorical\": ['project', 'id', 'name', 'description', 'type', 'title', 'state', 'status', 'code', 'city', 'source', 'country', 'county', 'comment', 'notes', 'category', 'address', 'gender', 'location', 'version', 'sex', 'class', 'field', 'region', 'note', 'race', 'species', 'position', 'language', 'filename', 'model', 'role', 'series', 'family', 'currency', 'definition', 'format', 'author', 'area', 'domain', 'rating', 'parent', 'alias', 'postalCode', 'reference', 'publisher', 'treatment', 'company', 'district', 'project', 'scientificName', 'abbreviation', 'part', 'countryCode', 'topic', 'road', 'prefix', 'route', 'department', 'zipCode', 'abstract', 'event', 'creator', 'genus', 'tag', 'owner', 'party', 'result'],\n",
    "    \"Datetime\": ['date', 'time', 'startDate', 'endDate', 'birthDate', 'created', 'day', 'end', 'month', 'period', 'releaseDate', 'season'],\n",
    "    # \"Other\": ['start', 'duration', 'project', 'frequency']\n",
    "}\n",
    "is_numerical = np.array([t in column_categories[\"Numerical\"] for t in types])\n",
    "is_categorical = np.array([t in column_categories[\"Categorical\"] for t in types])\n",
    "is_datetime = np.array([t in column_categories[\"Datetime\"] for t in types])\n",
    "# is_other = np.array([t in column_categories[\"Other\"] for t in types])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(class_acc_origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Example class-wise accuracy for two models\n",
    "classes = [f'Class {i}' for i in range(101)]  # 101 class labels\n",
    "acc_model_1 = class_acc_origin  # Random accuracy values for model 1 (replace with actual data)\n",
    "acc_model_2 = class_acc_sem  # Random accuracy values for model 2 (replace with actual data)\n",
    "\n",
    "# Define the number of classes and the width of the bars\n",
    "num_classes = len(classes)\n",
    "bar_width = 0.35\n",
    "\n",
    "# Set positions for the bars on the x-axis\n",
    "index = np.arange(num_classes)\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(20, 8))  # Increase figure size for better visualization of 101 classes\n",
    "\n",
    "# Plot the bars for each model\n",
    "bar1 = ax.bar(index, acc_model_1, bar_width, label='Model 1')\n",
    "bar2 = ax.bar(index + bar_width, acc_model_2, bar_width, label='Model 2')\n",
    "\n",
    "# Add labels and title\n",
    "ax.set_xlabel('Class')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Class-wise Accuracy Comparison')\n",
    "ax.set_xticks(index + bar_width / 2)\n",
    "\n",
    "# To prevent cluttering, only show some x-tick labels (adjust as needed)\n",
    "ax.set_xticklabels(classes, rotation=90, fontsize=8)\n",
    "\n",
    "# Add legend\n",
    "ax.legend()\n",
    "\n",
    "# Adjust the layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(preds_test_sem == labels_test).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = preds_test == labels_test\n",
    "(preds_test_sem[mask] == labels_test[mask]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_col in np.arange(1, 10):\n",
    "    if n_col <= 8:\n",
    "        mask = num_cols == n_col\n",
    "    else:\n",
    "        mask = num_cols > 8\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach()[mask].numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    print(\"num_cols={} num_samples={} ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(n_col, sum(mask), ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_micro_f1=0.4415, ts_macro_f1=0.1832\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(test_dataloader_all):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    labels_test.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "    num_cols.append(test_dataset_iter[batch_idx]['initial_num_col'])\n",
    "    ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "labels_test = torch.cat(labels_test, dim=0)\n",
    "logits_test = torch.stack(logits_test, dim=0)\n",
    "preds_test = torch.argmax(logits_test, dim=1)\n",
    "num_cols = torch.tensor(num_cols)\n",
    "ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "mask = num_cols > 0\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "full_f1_init = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=None)\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_unlabeled=2\n",
      "test\n",
      "test 1085\n",
      "ts_micro_f1=0.5198, ts_macro_f1=0.2494\n",
      "max_unlabeled=4\n",
      "test\n",
      "test 1085\n",
      "ts_micro_f1=0.5078, ts_macro_f1=0.2436\n",
      "max_unlabeled=8\n",
      "test\n",
      "test 1085\n",
      "ts_micro_f1=0.4857, ts_macro_f1=0.2291\n"
     ]
    }
   ],
   "source": [
    "for max_unlabeled in [2, 4, 8]:\n",
    "    print(\"max_unlabeled={}\".format(max_unlabeled))\n",
    "    src = None\n",
    "    test_dataset_near = GittablesTablewiseIterateNearbyDataset(cv=cv,\n",
    "                                split=\"test\", src=src,\n",
    "                                tokenizer=tokenizer,\n",
    "                                max_length=max_length,\n",
    "                                gt_only='all' not in task,\n",
    "                                device=device,\n",
    "                                base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                                small_tag=\"semi1\", \n",
    "                                max_unlabeled=max_unlabeled)\n",
    "    padder = collate_fn(tokenizer.pad_token_id)\n",
    "    test_dataloader_near = DataLoader(test_dataset_near,\n",
    "                                    batch_size=1,\n",
    "                                #   collate_fn=collate_fn)\n",
    "                                collate_fn=padder)\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    num_cols = []\n",
    "    for batch_idx, batch in enumerate(test_dataloader_near):\n",
    "        cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "        target_col_mask = batch[\"target_col_mask\"].T\n",
    "        logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "        labels_test.append(batch[\"label\"].cpu())\n",
    "        logits_test.append(logits.detach().cpu())\n",
    "        num_cols.append(test_dataset_iter[batch_idx]['initial_num_col'])\n",
    "        ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "    labels_test = torch.cat(labels_test, dim=0)\n",
    "    logits_test = torch.stack(logits_test, dim=0)\n",
    "    preds_test = torch.argmax(logits_test, dim=1)\n",
    "    num_cols = torch.tensor(num_cols)\n",
    "    ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "    from sklearn.metrics import confusion_matrix, f1_score\n",
    "    mask = num_cols > 0\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach().numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    full_f1_init = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=None)\n",
    "    print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_micro_f1=0.5300, ts_macro_f1=0.2442\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(test_dataloader_near):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    labels_test.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "    num_cols.append(test_dataset_iter[batch_idx]['initial_num_col'])\n",
    "    ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "labels_test = torch.cat(labels_test, dim=0)\n",
    "logits_test = torch.stack(logits_test, dim=0)\n",
    "preds_test = torch.argmax(logits_test, dim=1)\n",
    "num_cols = torch.tensor(num_cols)\n",
    "ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "mask = num_cols > 0\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "full_f1_init = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=None)\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(test_dataloader_near):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    labels_test.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "    num_cols.append(test_dataset_iter[batch_idx]['initial_num_col'])\n",
    "    ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "labels_test = torch.cat(labels_test, dim=0)\n",
    "logits_test = torch.stack(logits_test, dim=0)\n",
    "preds_test = torch.argmax(logits_test, dim=1)\n",
    "num_cols = torch.tensor(num_cols)\n",
    "ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "mask = num_cols > 0\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "full_f1_init = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=None)\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(test_dataloader_dist):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    labels_test.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "    num_cols.append(test_dataset_iter[batch_idx]['initial_num_col'])\n",
    "    ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "labels_test = torch.cat(labels_test, dim=0)\n",
    "logits_test = torch.stack(logits_test, dim=0)\n",
    "preds_test = torch.argmax(logits_test, dim=1)\n",
    "num_cols = torch.tensor(num_cols)\n",
    "ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "mask = num_cols > 0\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "full_f1_init = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=None)\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nearby + labeled\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test = []\n",
    "logits_test_near = []\n",
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(test_dataloader_near):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    labels_test.append(batch[\"label\"].cpu())\n",
    "    logits_test_near.append(logits.detach().cpu())\n",
    "    num_cols.append(test_dataset_iter[batch_idx]['initial_num_col'])\n",
    "    ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "labels_test = torch.cat(labels_test, dim=0)\n",
    "logits_test_near = torch.stack(logits_test_near, dim=0)\n",
    "preds_test_near = torch.argmax(logits_test_near, dim=1)\n",
    "num_cols = torch.tensor(num_cols)\n",
    "ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "mask = num_cols > 0\n",
    "ts_pred_list_near = logits_test_near.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list_near,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list_near,\n",
    "                    average=\"macro\")\n",
    "full_f1_near = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list_near,\n",
    "                    average=None)\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_col in np.arange(1, 10):\n",
    "    if n_col <= 8:\n",
    "        mask = num_cols == n_col\n",
    "    else:\n",
    "        mask = num_cols > 8\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach()[mask].numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    print(\"num_cols={} num_samples={} ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(n_col, sum(mask), ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(test_dataloader_nearlast):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    labels_test.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "    num_cols.append(test_dataset_iter[batch_idx]['initial_num_col'])\n",
    "    ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "labels_test = torch.cat(labels_test, dim=0)\n",
    "logits_test = torch.stack(logits_test, dim=0)\n",
    "preds_test = torch.argmax(logits_test, dim=1)\n",
    "num_cols = torch.tensor(num_cols)\n",
    "ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "mask = num_cols > 0\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "full_f1_init = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=None)\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "# ts_pred_list = logits_test.argmax(\n",
    "#                             1).cpu().detach()[mask].numpy().tolist()\n",
    "# ts_micro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "#                     ts_pred_list,\n",
    "#                     average=\"micro\")\n",
    "# ts_macro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "#                     ts_pred_list,\n",
    "#                     average=\"macro\")\n",
    "# print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "# ts_pred_list = logits_test.argmax(\n",
    "#                             1).cpu().detach()[~mask].numpy().tolist()\n",
    "# ts_micro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "#                     ts_pred_list,\n",
    "#                     average=\"micro\")\n",
    "# ts_macro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "#                     ts_pred_list,\n",
    "#                     average=\"macro\")\n",
    "# print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(test_dataloader_near):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    labels_test.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "    num_cols.append(batch[\"target_col_mask\"].max().item())\n",
    "    ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "labels_test = torch.cat(labels_test, dim=0)\n",
    "logits_test_near = torch.stack(logits_test, dim=0)\n",
    "preds_test_near = torch.argmax(logits_test_near, dim=1)\n",
    "num_cols = torch.tensor(num_cols)\n",
    "ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "mask = num_cols > 0\n",
    "ts_pred_list_near = logits_test_near.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list_near,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list_near,\n",
    "                    average=\"macro\")\n",
    "full_f1_init = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list_near,\n",
    "                    average=None)\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(test_dataloader_hy):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    labels_test.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "    num_cols.append(test_dataset_iter[batch_idx]['initial_num_col'])\n",
    "    ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "labels_test = torch.cat(labels_test, dim=0)\n",
    "logits_test = torch.stack(logits_test, dim=0)\n",
    "preds_test = torch.argmax(logits_test, dim=1)\n",
    "num_cols = torch.tensor(num_cols)\n",
    "ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "mask = num_cols > 0\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "full_f1_init = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=None)\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(test_dataloader_cor):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    # target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    labels_test.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "    num_cols.append(test_dataset_iter[batch_idx]['initial_num_col'])\n",
    "    ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "labels_test = torch.cat(labels_test, dim=0)\n",
    "logits_test = torch.stack(logits_test, dim=0)\n",
    "preds_test = torch.argmax(logits_test, dim=1)\n",
    "num_cols = torch.tensor(num_cols)\n",
    "ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "mask = num_cols > 0\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "full_f1_init = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=None)\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "16/58"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_micro_f1=0.5198, ts_macro_f1=0.2426 # first 5\n",
    "ts_micro_f1=0.5198, ts_macro_f1=0.2450 # first 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_col in np.arange(1, 10):\n",
    "    if n_col <= 8:\n",
    "        mask = num_cols == n_col\n",
    "    else:\n",
    "        mask = num_cols > 8\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach()[mask].numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    print(\"num_cols={} num_samples={} ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(n_col, sum(mask), ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_unlabeled=2\n",
      "test\n",
      "test 1085\n",
      "ts_micro_f1=0.4857, ts_macro_f1=0.2260\n",
      "max_unlabeled=4\n",
      "test\n",
      "test 1085\n",
      "ts_micro_f1=0.4959, ts_macro_f1=0.2428\n",
      "max_unlabeled=8\n",
      "test\n",
      "test 1085\n",
      "ts_micro_f1=0.4848, ts_macro_f1=0.2472\n"
     ]
    }
   ],
   "source": [
    "for max_unlabeled in [2, 4, 8]:\n",
    "    print(\"max_unlabeled={}\".format(max_unlabeled))\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    src = None\n",
    "    test_dataset_set = GittablesTablewiseIterateSentenceDataset(cv=cv,\n",
    "                                split=\"test\", src=src,\n",
    "                                tokenizer=tokenizer,\n",
    "                                max_length=max_length,\n",
    "                                gt_only='all' not in task,\n",
    "                                device=device,\n",
    "                                base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                                small_tag=\"semi1\",\n",
    "                                max_unlabeled=max_unlabeled)\n",
    "    padder = collate_fn(tokenizer.pad_token_id)\n",
    "    test_dataloader_set = DataLoader(test_dataset_set,\n",
    "                                    batch_size=1,\n",
    "                                #   collate_fn=collate_fn)\n",
    "                                collate_fn=padder)\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    num_cols = []\n",
    "    for batch_idx, batch in enumerate(test_dataloader_set):\n",
    "        cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "        target_col_mask = batch[\"target_col_mask\"].T\n",
    "        logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "        labels_test.append(batch[\"label\"].cpu())\n",
    "        logits_test.append(logits.detach().cpu())\n",
    "        num_cols.append(test_dataset_iter[batch_idx]['initial_num_col'])\n",
    "        ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "    labels_test = torch.cat(labels_test, dim=0)\n",
    "    logits_test = torch.stack(logits_test, dim=0)\n",
    "    preds_test = torch.argmax(logits_test, dim=1)\n",
    "    num_cols = torch.tensor(num_cols)\n",
    "    ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "    from sklearn.metrics import confusion_matrix, f1_score\n",
    "    mask = num_cols > 0\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach().numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    full_f1_init = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=None)\n",
    "    print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(labels_test == labels_test_original).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test_original.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.equal(labels_test, labels_test_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_col in np.arange(1, 10):\n",
    "    if n_col <= 8:\n",
    "        mask = num_cols == n_col\n",
    "    else:\n",
    "        mask = num_cols > 8\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach()[mask].numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    print(\"num_cols={} num_samples={} ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(n_col, sum(mask), ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_macro = []\n",
    "results_micro = []\n",
    "for seed in range(5):\n",
    "    print(\"**********************************seed={}***************************\".format(seed))\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    src = None\n",
    "    test_dataset_rd = GittablesTablewiseLabelRandomDataset(cv=cv,\n",
    "                                split=\"test\", src=src,\n",
    "                                tokenizer=tokenizer,\n",
    "                                max_length=max_length,\n",
    "                                gt_only='all' not in task,\n",
    "                                device=device,\n",
    "                                base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                                small_tag=\"semi1\",\n",
    "                                seed=seed)\n",
    "    padder = collate_fn(tokenizer.pad_token_id)\n",
    "    test_dataloader_rd = DataLoader(test_dataset_rd,\n",
    "                                    batch_size=1,\n",
    "                                #   collate_fn=collate_fn)\n",
    "                                collate_fn=padder)\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    num_cols = []\n",
    "    for batch_idx, batch in enumerate(test_dataloader_rd):\n",
    "        cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "        target_col_mask = batch[\"target_col_mask\"].T\n",
    "        logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "        labels_test.append(batch[\"label\"].cpu())\n",
    "        logits_test.append(logits.detach().cpu())\n",
    "        num_cols.append(test_dataset_iter[batch_idx]['initial_num_col'])\n",
    "        ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "    labels_test = torch.cat(labels_test, dim=0)\n",
    "    logits_test = torch.stack(logits_test, dim=0)\n",
    "    preds_test = torch.argmax(logits_test, dim=1)\n",
    "    num_cols = torch.tensor(num_cols)\n",
    "    ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "    from sklearn.metrics import confusion_matrix, f1_score\n",
    "    mask = num_cols > 0\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach().numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    full_f1_init = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=None)\n",
    "    print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "    results_micro.append(ts_micro_f1)\n",
    "    results_macro.append(ts_macro_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(results_micro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(results_macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_macro = []\n",
    "results_micro = []\n",
    "for seed in range(20):\n",
    "    print(\"**********************************seed={}***************************\".format(seed))\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    src = None\n",
    "    test_dataset_rd = GittablesTablewiseRandomDataset(cv=cv,\n",
    "                                split=\"test\", src=src,\n",
    "                                tokenizer=tokenizer,\n",
    "                                max_length=max_length,\n",
    "                                gt_only='all' not in task,\n",
    "                                device=device,\n",
    "                                base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                                small_tag=\"semi1\",\n",
    "                                seed=seed)\n",
    "    padder = collate_fn(tokenizer.pad_token_id)\n",
    "    test_dataloader_rd = DataLoader(test_dataset_rd,\n",
    "                                    batch_size=1,\n",
    "                                #   collate_fn=collate_fn)\n",
    "                                collate_fn=padder)\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    num_cols = []\n",
    "    for batch_idx, batch in enumerate(test_dataloader_rd):\n",
    "        cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "        target_col_mask = batch[\"target_col_mask\"].T\n",
    "        logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "        labels_test.append(batch[\"label\"].cpu())\n",
    "        logits_test.append(logits.detach().cpu())\n",
    "        num_cols.append(test_dataset_iter[batch_idx]['initial_num_col'])\n",
    "        ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "    labels_test = torch.cat(labels_test, dim=0)\n",
    "    logits_test = torch.stack(logits_test, dim=0)\n",
    "    preds_test = torch.argmax(logits_test, dim=1)\n",
    "    num_cols = torch.tensor(num_cols)\n",
    "    ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "    from sklearn.metrics import confusion_matrix, f1_score\n",
    "    mask = num_cols > 0\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach().numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    full_f1_init = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=None)\n",
    "    print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "    results_micro.append(ts_micro_f1)\n",
    "    results_macro.append(ts_macro_f1)\n",
    "print(np.mean(results_micro))\n",
    "print(np.mean(results_macro))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brute force perumate in validation TODO: restrict mamimus length of permutation\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "\n",
    "ft_embs_test = []\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "log = defaultdict(list)\n",
    "num_cols = []\n",
    "corrected = 0\n",
    "total_mistakes = 0\n",
    "num_permutations = {}\n",
    "init_permutation = {}\n",
    "init_correctness = {}\n",
    "score_init = {}\n",
    "score_permutation = defaultdict(list)\n",
    "permutation_correctness = defaultdict(list)\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in enumerate(test_dataloader_sem):\n",
    "        cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "        target_col_mask = batch[\"target_col_mask\"].T\n",
    "        init_permutation_i = get_permutation(target_col_mask)\n",
    "        init_permutation[batch_idx] = init_permutation_i\n",
    "\n",
    "\n",
    "        num_cols.append(len(init_permutation_i))\n",
    "        col_idx_set = target_col_mask.unique().tolist()\n",
    "        \n",
    "        max_score = -float(\"inf\")\n",
    "        assert -1 not in col_idx_set\n",
    "        for r in range(len(init_permutation_i), max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "            for x in itertools.combinations(init_permutation_i, r):\n",
    "                if 0 not in x:\n",
    "                    continue\n",
    "\n",
    "                new_batch_data = []\n",
    "                if len(x) != len(init_permutation_i):\n",
    "                    drop_idx = (set(init_permutation_i)-set(x)).pop()\n",
    "                else:\n",
    "                    drop_idx = -1\n",
    "                for col_i in x:\n",
    "                    if col_i == 0:\n",
    "                        if len(new_batch_data) == 0:\n",
    "                            cls_indexes_value = 0\n",
    "                        else:\n",
    "                            cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                    new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                scores_temp = verifier(embs_temp.reshape(1,-1)).item()\n",
    "                predict_temp = logits_temp.argmax().item()\n",
    "\n",
    "                if scores_temp > max_score:\n",
    "                    max_score = scores_temp\n",
    "                    logits = logits_temp.clone()\n",
    "        labels_test.append(batch[\"label\"].cpu())\n",
    "        logits_test.append(logits.detach().cpu())\n",
    "    labels_test = torch.cat(labels_test, dim=0)\n",
    "    logits_test = torch.stack(logits_test, dim=0)\n",
    "    preds_test = torch.argmax(logits_test, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "ts_f1_full = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=None)\n",
    "# full_f1_init\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brute force perumate in validation TODO: restrict mamimus length of permutation\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brute force perumate in validation TODO: restrict mamimus length of permutation\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "verifier.load_state_dict(veri_state_dict)\n",
    "verifier.eval()\n",
    "verifier = verifier.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "\n",
    "ft_embs_test = []\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "log = defaultdict(list)\n",
    "num_cols = []\n",
    "corrected = 0\n",
    "total_mistakes = 0\n",
    "num_permutations = {}\n",
    "init_permutation = {}\n",
    "init_correctness = {}\n",
    "score_init = {}\n",
    "score_permutation = defaultdict(list)\n",
    "permutation_correctness = defaultdict(list)\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in enumerate(test_dataloader_near):\n",
    "        cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "        target_col_mask = batch[\"target_col_mask\"].T\n",
    "        init_permutation_i = get_permutation(target_col_mask)\n",
    "        init_permutation[batch_idx] = init_permutation_i\n",
    "\n",
    "\n",
    "        num_cols.append(len(init_permutation_i))\n",
    "        col_idx_set = target_col_mask.unique().tolist()\n",
    "        \n",
    "        max_score = -float(\"inf\")\n",
    "        assert -1 not in col_idx_set\n",
    "        for r in range(len(init_permutation_i), max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "            for x in itertools.combinations(init_permutation_i, r):\n",
    "                if 0 not in x:\n",
    "                    continue\n",
    "\n",
    "                new_batch_data = []\n",
    "                if len(x) != len(init_permutation_i):\n",
    "                    drop_idx = (set(init_permutation_i)-set(x)).pop()\n",
    "                else:\n",
    "                    drop_idx = -1\n",
    "                for col_i in x:\n",
    "                    if col_i == 0:\n",
    "                        if len(new_batch_data) == 0:\n",
    "                            cls_indexes_value = 0\n",
    "                        else:\n",
    "                            cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                    new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                scores_temp = verifier(embs_temp.reshape(1,-1)).item()\n",
    "                predict_temp = logits_temp.argmax().item()\n",
    "\n",
    "                if scores_temp > max_score:\n",
    "                    max_score = scores_temp\n",
    "                    logits = logits_temp.clone()\n",
    "        labels_test.append(batch[\"label\"].cpu())\n",
    "        logits_test.append(logits.detach().cpu())\n",
    "    labels_test = torch.cat(labels_test, dim=0)\n",
    "    logits_test = torch.stack(logits_test, dim=0)\n",
    "    preds_test = torch.argmax(logits_test, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "ts_f1_full = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=None)\n",
    "# full_f1_init\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "\n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "verifier.load_state_dict(veri_state_dict)\n",
    "verifier.eval()\n",
    "verifier = verifier.to(device)\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "init_scores = []\n",
    "init_correctness = []\n",
    "final_scores = []\n",
    "final_correctness = []\n",
    "num_cols = []\n",
    "total_steps = []\n",
    "final_steps = []\n",
    "correct_scores = defaultdict(list)\n",
    "correct_steps = defaultdict(list)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "        target_col_mask = batch[\"target_col_mask\"].T\n",
    "        embs = test_embs[batch_idx][0].reshape(1,-1).to(device)\n",
    "        logits = test_logits[batch_idx][0].reshape(-1).to(device)\n",
    "        scores_init = verifier(embs)\n",
    "        max_score = -float(\"inf\")\n",
    "\n",
    "        init_scores.append(scores_init.item())\n",
    "        init_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "        init_permutation_i = get_permutation(target_col_mask)\n",
    "        col_idx_set = target_col_mask.unique().tolist()\n",
    "        early_stop = False\n",
    "        i = 0\n",
    "        final_step = 0\n",
    "        total_steps.append(len(init_permutation_i) - max(len(init_permutation_i)//2, len(init_permutation_i)-3) -1)\n",
    "        num_cols.append(len(init_permutation_i))\n",
    "        for r in range(len(init_permutation_i), max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "            for x in itertools.combinations(init_permutation_i, r):\n",
    "                if 0 not in x:\n",
    "                    continue\n",
    "                logits_temp = test_logits[batch_idx][i].reshape(-1).to(device)\n",
    "                embs_temp = test_embs[batch_idx][i].reshape(1,-1).to(device)\n",
    "                scores_temp = verifier(embs_temp).item()\n",
    "                predict_temp = logits_temp.argmax().item()\n",
    "                i += 1\n",
    "                if scores_temp > max_score:\n",
    "                    max_score = scores_temp\n",
    "                    logits = logits_temp.clone()\n",
    "                    final_step = len(init_permutation_i) - r\n",
    "                if logits_temp.argmax().item() == batch[\"label\"].item():\n",
    "                    correct_scores[batch_idx].append(scores_temp)\n",
    "                    correct_steps[batch_idx].append(len(init_permutation_i) - r)\n",
    "                    \n",
    "        final_scores.append(max_score)\n",
    "        final_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "        final_steps.append(final_step)\n",
    "        labels_test.append(batch[\"label\"].cpu())\n",
    "        logits_test.append(logits.detach().cpu())\n",
    "    labels_test = torch.cat(labels_test, dim=0)\n",
    "    logits_test = torch.stack(logits_test, dim=0)\n",
    "    preds_test = torch.argmax(logits_test, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "ts_f1_full = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=None)\n",
    "# full_f1_init\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_embedding = nn.Embedding(2, 768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_embedding(torch.ones(32).long()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_f1_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(valid_dataloader_iter):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    labels_test.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "    num_cols.append(batch[\"target_col_mask\"].max().item())\n",
    "    ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "labels_test = torch.cat(labels_test, dim=0)\n",
    "logits_test = torch.stack(logits_test, dim=0)\n",
    "preds_test = torch.argmax(logits_test, dim=1)\n",
    "num_cols = torch.tensor(num_cols)\n",
    "ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "mask = num_cols > 0\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach()[mask].numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach()[~mask].numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_freq = torch.zeros(args.num_classes)\n",
    "for batch_idx, batch in enumerate(train_dataloader_iter):\n",
    "    class_freq[batch[\"label\"].item()] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def reweight_logits(logits, class_weights):\n",
    "#     # Reweight the logits by multiplying with class weights\n",
    "#     reweighted_logits = logits * torch.sqrt(class_weights)\n",
    "    \n",
    "#     # Apply softmax to the reweighted logits\n",
    "#     reweighted_probs = F.softmax(reweighted_logits, dim=-1)\n",
    "    \n",
    "#     return reweighted_probs\n",
    "def reweight_logits(logits, class_weights):\n",
    "    # Step 1: Apply exp(logits)\n",
    "    exp_logits = torch.exp(logits)\n",
    "    \n",
    "    # Step 2: Multiply by class weights\n",
    "    # reweighted_exp = exp_logits * torch.sqrt(class_weights)\n",
    "    reweighted_exp = exp_logits * class_weights\n",
    "    # Step 3: Normalize to get valid probabilities (like softmax)\n",
    "    reweighted_probs = reweighted_exp / reweighted_exp.sum(dim=-1, keepdim=True)\n",
    "    \n",
    "    return reweighted_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# brute force perumate, find uncertain init prediction, weighted msp\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "idx_list = []\n",
    "uncertain_init_mask = []\n",
    "uncertain_target_mask = []\n",
    "correct_init_mask = []\n",
    "correct_target_mask = []\n",
    "correct_permutation_mask = []\n",
    "correct_permutation_confident_mask = []\n",
    "correct_permutation_confident_scores = []\n",
    "correct_msp_mask = []\n",
    "init_target_mask = []\n",
    "ood_score_init_list = []\n",
    "ood_score_target_list = []\n",
    "ood_score_final_list = []\n",
    "msp_predicts = []\n",
    "max_col_length = 3\n",
    "\n",
    "alpha = 0\n",
    "# class_weights = (1.0 / class_freq) ** alpha\n",
    "# debias_threshold = 1.0\n",
    "# # Normalize the weights\n",
    "# class_weights /= class_weights.sum()\n",
    "for threshold in [0.9]:\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    log = defaultdict(list)\n",
    "    num_cols = []\n",
    "    corrected = 0\n",
    "    total_mistakes = 0\n",
    "\n",
    "    for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "        target_col_mask = batch[\"target_col_mask\"].T\n",
    "        if 1 in target_col_mask:\n",
    "            idx_list.append(batch_idx)\n",
    "\n",
    "            cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "            logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "            # logits = reweight_logits(logits.detach().cpu(), class_weights)\n",
    "            logits = F.softmax(logits, dim=-1)\n",
    "            num_cols.append(batch[\"target_col_mask\"].max().item())         \n",
    "            ood_score_init = logits.max().item()\n",
    "            ood_score_init_list.append(ood_score_init)\n",
    "            uncertain_init_mask.append(ood_score_init < threshold)\n",
    "            predict_init = logits.argmax().item()\n",
    "            correct_init_mask.append(predict_init == batch[\"label\"].item())\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            \n",
    "            correct_permutation = False\n",
    "            correct_permutation_ood_score = 0.0\n",
    "            correct_permutation_confident = False\n",
    "            ood_score_max = max_msp = 0\n",
    "            max_msp_debiased = 0\n",
    "            debias_class = []\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            assert -1 not in col_idx_set\n",
    "            for r in range(len(col_idx_set)-1, len(col_idx_set)//2, -1):\n",
    "                for subset in itertools.combinations(col_idx_set, r):\n",
    "                    if 0 not in subset and r != 1:\n",
    "                        continue\n",
    "                    for x in itertools.permutations(subset):\n",
    "                        if not is_sublist(x, init_permutation_i):\n",
    "                            continue\n",
    "                        new_batch_data = []\n",
    "                        for col_i in x:\n",
    "                            if col_i == 0:\n",
    "                                if len(new_batch_data) == 0:\n",
    "                                    cls_indexes_value = 0\n",
    "                                else:\n",
    "                                    cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                            new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                        if 0 not in x:\n",
    "                            cls_indexes_value = 0\n",
    "                        new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                        cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                        logits_temp = model(new_batch_data, cls_indexes=cls_indexes,)\n",
    "                        logits_temp = F.softmax(logits_temp, dim=-1)\n",
    "                        # logits_temp = reweight_logits(logits_temp.detach().cpu(), class_weights)\n",
    "                        msp_temp = logits_temp.max().item()\n",
    "                        predict_temp = logits_temp.argmax().item()\n",
    "                        # if 0 not in x and msp_temp > debias_threshold and (predict_temp!=predict_target or predict_temp!=predict_init):\n",
    "                        #     debias_class.append(predict_temp)\n",
    "                        #     continue\n",
    "                        # print(x, msp_temp, predict_temp)\n",
    "                        # if msp_temp > max_msp and 0 in x and predict_temp not in debias_class:\n",
    "                        if msp_temp > max_msp and 0 in x:\n",
    "                            max_msp = msp_temp\n",
    "                            msp_predict = predict_temp\n",
    "                        if predict_temp == batch[\"label\"].item():\n",
    "                            correct_permutation = True\n",
    "                            if msp_temp > correct_permutation_ood_score:\n",
    "                                correct_permutation_ood_score = msp_temp\n",
    "            msp_predicts.append(msp_predict)\n",
    "            ood_score_final_list.append(max_msp)\n",
    "            correct_permutation_mask.append(correct_permutation)\n",
    "            correct_permutation_confident_scores.append(correct_permutation_ood_score)\n",
    "            correct_msp_mask.append(msp_predict == batch[\"label\"].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "idx_list = torch.tensor(idx_list).reshape(-1)\n",
    "uncertain_init_mask = torch.tensor(uncertain_init_mask).reshape(-1)\n",
    "uncertain_target_mask = torch.tensor(uncertain_target_mask).reshape(-1)\n",
    "correct_init_mask = torch.tensor(correct_init_mask).reshape(-1)\n",
    "correct_target_mask = torch.tensor(correct_target_mask).reshape(-1)\n",
    "correct_permutation_mask = torch.tensor(correct_permutation_mask).reshape(-1)\n",
    "correct_permutation_confident_scores = torch.tensor(correct_permutation_confident_scores).reshape(-1)\n",
    "correct_msp_mask = torch.tensor(correct_msp_mask).reshape(-1)\n",
    "init_target_mask = torch.tensor(init_target_mask).reshape(-1)\n",
    "ood_score_init_list = torch.tensor(ood_score_init_list).reshape(-1)\n",
    "ood_score_target_list = torch.tensor(ood_score_target_list).reshape(-1)\n",
    "ood_score_final_list = torch.tensor(ood_score_final_list).reshape(-1)\n",
    "msp_predicts = torch.tensor(msp_predicts).reshape(-1)\n",
    "print(len(idx_list), len(init_target_mask), len(correct_init_mask), len(correct_target_mask), len(correct_permutation_mask))\n",
    "torch.save({\"idx_list\": idx_list, \"uncertain_init_mask\": uncertain_init_mask, \"uncertain_target_mask\": uncertain_target_mask, \"correct_init_mask\": correct_init_mask, \"correct_target_mask\": correct_target_mask, \"correct_permutation_mask\": correct_permutation_mask, \"correct_msp_mask\": correct_msp_mask, \"init_target_mask\": init_target_mask, \"ood_score_init_list\": ood_score_init_list, \"ood_score_target_list\": ood_score_target_list, \"ood_score_final_list\": ood_score_final_list}, f\"./results/brute_force_permutation_alpha@{alpha}_drop.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# brute force perumate, find uncertain init prediction, weighted msp\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "idx_list = []\n",
    "uncertain_init_mask = []\n",
    "uncertain_target_mask = []\n",
    "correct_init_mask = []\n",
    "correct_target_mask = []\n",
    "correct_permutation_mask = []\n",
    "correct_permutation_confident_mask = []\n",
    "correct_permutation_confident_scores = []\n",
    "correct_msp_mask = []\n",
    "init_target_mask = []\n",
    "ood_score_init_list = []\n",
    "ood_score_target_list = []\n",
    "ood_score_final_list = []\n",
    "msp_predicts = []\n",
    "max_col_length = 3\n",
    "\n",
    "alpha = 0.25\n",
    "class_weights = (1.0 / class_freq) ** alpha\n",
    "debias_threshold = 1.0\n",
    "# Normalize the weights\n",
    "class_weights /= class_weights.sum()\n",
    "for threshold in [0.9]:\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    log = defaultdict(list)\n",
    "    num_cols = []\n",
    "    corrected = 0\n",
    "    total_mistakes = 0\n",
    "\n",
    "    for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "        target_col_mask = batch[\"target_col_mask\"].T\n",
    "        if 1 in target_col_mask:\n",
    "            idx_list.append(batch_idx)\n",
    "\n",
    "            cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "            logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "            logits = reweight_logits(logits.detach().cpu(), class_weights)\n",
    "            num_cols.append(batch[\"target_col_mask\"].max().item())         \n",
    "            ood_score_init = logits.max().item()\n",
    "            ood_score_init_list.append(ood_score_init)\n",
    "            uncertain_init_mask.append(ood_score_init < threshold)\n",
    "            predict_init = logits.argmax().item()\n",
    "            correct_init_mask.append(predict_init == batch[\"label\"].item())\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            \n",
    "            correct_permutation = False\n",
    "            correct_permutation_ood_score = 0.0\n",
    "            correct_permutation_confident = False\n",
    "            ood_score_max = max_msp = 0\n",
    "            max_msp_debiased = 0\n",
    "            debias_class = []\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            assert -1 not in col_idx_set\n",
    "            for r in range(len(col_idx_set)-1, len(col_idx_set)//2, -1):\n",
    "                for subset in itertools.combinations(col_idx_set, r):\n",
    "                    if 0 not in subset and r != 1:\n",
    "                        continue\n",
    "                    for x in itertools.permutations(subset):\n",
    "                        if not is_sublist(x, init_permutation_i):\n",
    "                            continue\n",
    "                        new_batch_data = []\n",
    "                        for col_i in x:\n",
    "                            if col_i == 0:\n",
    "                                if len(new_batch_data) == 0:\n",
    "                                    cls_indexes_value = 0\n",
    "                                else:\n",
    "                                    cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                            new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                        if 0 not in x:\n",
    "                            cls_indexes_value = 0\n",
    "                        new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                        cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                        logits_temp = model(new_batch_data, cls_indexes=cls_indexes,)\n",
    "                        logits_temp = reweight_logits(logits_temp.detach().cpu(), class_weights)\n",
    "                        msp_temp = logits_temp.max().item()\n",
    "                        predict_temp = logits_temp.argmax().item()\n",
    "                        # if 0 not in x and msp_temp > debias_threshold and (predict_temp!=predict_target or predict_temp!=predict_init):\n",
    "                        #     debias_class.append(predict_temp)\n",
    "                        #     continue\n",
    "                        # print(x, msp_temp, predict_temp)\n",
    "                        # if msp_temp > max_msp and 0 in x and predict_temp not in debias_class:\n",
    "                        if msp_temp > max_msp and 0 in x:\n",
    "                            max_msp = msp_temp\n",
    "                            msp_predict = predict_temp\n",
    "                        if predict_temp == batch[\"label\"].item():\n",
    "                            correct_permutation = True\n",
    "                            if msp_temp > correct_permutation_ood_score:\n",
    "                                correct_permutation_ood_score = msp_temp\n",
    "            msp_predicts.append(msp_predict)\n",
    "            ood_score_final_list.append(max_msp)\n",
    "            correct_permutation_mask.append(correct_permutation)\n",
    "            correct_permutation_confident_scores.append(correct_permutation_ood_score)\n",
    "            correct_msp_mask.append(msp_predict == batch[\"label\"].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "idx_list = torch.tensor(idx_list).reshape(-1)\n",
    "uncertain_init_mask = torch.tensor(uncertain_init_mask).reshape(-1)\n",
    "uncertain_target_mask = torch.tensor(uncertain_target_mask).reshape(-1)\n",
    "correct_init_mask = torch.tensor(correct_init_mask).reshape(-1)\n",
    "correct_target_mask = torch.tensor(correct_target_mask).reshape(-1)\n",
    "correct_permutation_mask = torch.tensor(correct_permutation_mask).reshape(-1)\n",
    "correct_permutation_confident_scores = torch.tensor(correct_permutation_confident_scores).reshape(-1)\n",
    "correct_msp_mask = torch.tensor(correct_msp_mask).reshape(-1)\n",
    "init_target_mask = torch.tensor(init_target_mask).reshape(-1)\n",
    "ood_score_init_list = torch.tensor(ood_score_init_list).reshape(-1)\n",
    "ood_score_target_list = torch.tensor(ood_score_target_list).reshape(-1)\n",
    "ood_score_final_list = torch.tensor(ood_score_final_list).reshape(-1)\n",
    "msp_predicts = torch.tensor(msp_predicts).reshape(-1)\n",
    "print(len(idx_list), len(init_target_mask), len(correct_init_mask), len(correct_target_mask), len(correct_permutation_mask))\n",
    "torch.save({\"idx_list\": idx_list, \"uncertain_init_mask\": uncertain_init_mask, \"uncertain_target_mask\": uncertain_target_mask, \"correct_init_mask\": correct_init_mask, \"correct_target_mask\": correct_target_mask, \"correct_permutation_mask\": correct_permutation_mask, \"correct_msp_mask\": correct_msp_mask, \"init_target_mask\": init_target_mask, \"ood_score_init_list\": ood_score_init_list, \"ood_score_target_list\": ood_score_target_list, \"ood_score_final_list\": ood_score_final_list}, f\"./results/brute_force_permutation_alpha@{alpha}_drop.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weighted, only uncertain init\n",
    "\n",
    "for threshold in [0.8, 0.9, 0.99]:\n",
    "    correct_permutation_confident_mask = correct_permutation_confident_scores>threshold\n",
    "    uncertain_init_mask = ood_score_init_list < threshold\n",
    "    uncertain_target_mask = ood_score_target_list < threshold\n",
    "    condition_mask = ~uncertain_init_mask\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    print(\"Init\")\n",
    "    # init prediction\n",
    "    print((condition_mask&correct_init_mask).sum().item(), \n",
    "        (condition_mask).sum().item(), \n",
    "        (condition_mask&correct_init_mask).sum().item()/(condition_mask).sum().item())\n",
    "    # init prediction\n",
    "    print((~condition_mask&correct_init_mask).sum().item(), \n",
    "        (~condition_mask).sum().item(), \n",
    "       (~condition_mask&correct_init_mask).sum().item()/(~condition_mask).sum().item())\n",
    "    print(\"MSP\")\n",
    "    # msp prediction\n",
    "    print((condition_mask&correct_msp_mask).sum().item(), \n",
    "        (condition_mask).sum().item(), \n",
    "        (condition_mask&correct_msp_mask).sum().item()/(condition_mask).sum().item())\n",
    "    # msp prediction\n",
    "    print((~condition_mask&correct_msp_mask).sum().item(), \n",
    "        (~condition_mask).sum().item(), \n",
    "        (~condition_mask&correct_msp_mask).sum().item()/(~condition_mask).sum().item())\n",
    "    print(\"MSP & Init\")\n",
    "    print(((condition_mask&correct_init_mask)&(condition_mask&correct_msp_mask)).sum().item())\n",
    "    # print(((~(init_target_mask&(~uncertain_init_mask & ~uncertain_target_mask))& correct_msp_mask)&(~(init_target_mask&(~uncertain_init_mask & ~uncertain_target_mask))& correct_init_mask)).sum().item())\n",
    "    print(((condition_mask&correct_init_mask)|(condition_mask&correct_msp_mask)).sum().item(),\n",
    "          (condition_mask).sum().item(), \n",
    "          ((condition_mask&correct_init_mask)|(condition_mask&correct_msp_mask)).sum().item()/(condition_mask).sum().item())\n",
    "    print(((~condition_mask&correct_init_mask)|(~condition_mask&correct_msp_mask)).sum().item(),\n",
    "          (~condition_mask).sum().item(), \n",
    "          ((~condition_mask&correct_init_mask)|(~condition_mask&correct_msp_mask)).sum().item()/(~condition_mask).sum().item())\n",
    "    print(\"Permutation\")\n",
    "    print((condition_mask&correct_permutation_mask).sum().item(), \n",
    "        (condition_mask).sum().item(), \n",
    "        (condition_mask&correct_permutation_mask).sum().item()/(condition_mask).sum().item())\n",
    "    print((~condition_mask&correct_permutation_mask).sum().item(), \n",
    "         (~condition_mask).sum().item(), \n",
    "        (~condition_mask&correct_permutation_mask).sum().item()/(~condition_mask).sum().item())\n",
    "    print(\"Permutation Confident\")\n",
    "    print((condition_mask&correct_permutation_confident_mask).sum().item(), \n",
    "        (condition_mask).sum().item(), \n",
    "        (condition_mask&correct_permutation_confident_mask).sum().item()/(condition_mask).sum().item())\n",
    "    print((~condition_mask&correct_permutation_confident_mask).sum().item(),\n",
    "            (~condition_mask).sum().item(), \n",
    "            (~condition_mask&correct_permutation_confident_mask).sum().item()/(~condition_mask).sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weighted, only uncertain init\n",
    "\n",
    "for threshold in [0.82]:\n",
    "    correct_permutation_confident_mask = correct_permutation_confident_scores>threshold\n",
    "    uncertain_init_mask = ood_score_init_list < threshold\n",
    "    uncertain_target_mask = ood_score_target_list < threshold\n",
    "    condition_mask = ~uncertain_init_mask\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    print(\"Init\")\n",
    "    # init prediction\n",
    "    print((condition_mask&correct_init_mask).sum().item(), \n",
    "        (condition_mask).sum().item(), \n",
    "        (condition_mask&correct_init_mask).sum().item()/(condition_mask).sum().item())\n",
    "    # init prediction\n",
    "    print((~condition_mask&correct_init_mask).sum().item(), \n",
    "        (~condition_mask).sum().item(), \n",
    "       (~condition_mask&correct_init_mask).sum().item()/(~condition_mask).sum().item())\n",
    "    print(\"MSP\")\n",
    "    # msp prediction\n",
    "    print((condition_mask&correct_msp_mask).sum().item(), \n",
    "        (condition_mask).sum().item(), \n",
    "        (condition_mask&correct_msp_mask).sum().item()/(condition_mask).sum().item())\n",
    "    # msp prediction\n",
    "    print((~condition_mask&correct_msp_mask).sum().item(), \n",
    "        (~condition_mask).sum().item(), \n",
    "        (~condition_mask&correct_msp_mask).sum().item()/(~condition_mask).sum().item())\n",
    "    print(\"MSP & Init\")\n",
    "    print(((condition_mask&correct_init_mask)&(condition_mask&correct_msp_mask)).sum().item())\n",
    "    # print(((~(init_target_mask&(~uncertain_init_mask & ~uncertain_target_mask))& correct_msp_mask)&(~(init_target_mask&(~uncertain_init_mask & ~uncertain_target_mask))& correct_init_mask)).sum().item())\n",
    "    print(((condition_mask&correct_init_mask)|(condition_mask&correct_msp_mask)).sum().item(),\n",
    "          (condition_mask).sum().item(), \n",
    "          ((condition_mask&correct_init_mask)|(condition_mask&correct_msp_mask)).sum().item()/(condition_mask).sum().item())\n",
    "    print(((~condition_mask&correct_init_mask)|(~condition_mask&correct_msp_mask)).sum().item(),\n",
    "          (~condition_mask).sum().item(), \n",
    "          ((~condition_mask&correct_init_mask)|(~condition_mask&correct_msp_mask)).sum().item()/(~condition_mask).sum().item())\n",
    "    print(\"Permutation\")\n",
    "    print((condition_mask&correct_permutation_mask).sum().item(), \n",
    "        (condition_mask).sum().item(), \n",
    "        (condition_mask&correct_permutation_mask).sum().item()/(condition_mask).sum().item())\n",
    "    print((~condition_mask&correct_permutation_mask).sum().item(), \n",
    "         (~condition_mask).sum().item(), \n",
    "        (~condition_mask&correct_permutation_mask).sum().item()/(~condition_mask).sum().item())\n",
    "    print(\"Permutation Confident\")\n",
    "    print((condition_mask&correct_permutation_confident_mask).sum().item(), \n",
    "        (condition_mask).sum().item(), \n",
    "        (condition_mask&correct_permutation_confident_mask).sum().item()/(condition_mask).sum().item())\n",
    "    print((~condition_mask&correct_permutation_confident_mask).sum().item(),\n",
    "            (~condition_mask).sum().item(), \n",
    "            (~condition_mask&correct_permutation_confident_mask).sum().item()/(~condition_mask).sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSP is wrong, but init is correct\n",
    "target_col_idx_msp_init = idx_list[~condition_mask&correct_msp_mask&correct_init_mask]\n",
    "target_col_idx_msp =  idx_list[~condition_mask&correct_msp_mask&~correct_init_mask]\n",
    "target_col_idx_init =  idx_list[~condition_mask&~correct_msp_mask&correct_init_mask]\n",
    "target_col_idx_permutation = idx_list[~condition_mask&correct_permutation_confident_mask&~correct_msp_mask&~correct_init_mask]\n",
    "target_col_idx_permutation_msp =  idx_list[~condition_mask&correct_permutation_confident_mask&~correct_msp_mask]\n",
    "target_col_idx_permutation_init =  idx_list[~condition_mask&correct_permutation_confident_mask&~correct_init_mask]\n",
    "\n",
    "print(\"Both correct\", (~condition_mask&correct_msp_mask&correct_init_mask).sum(), \n",
    "      ood_score_init_list[~condition_mask&correct_msp_mask&correct_init_mask].mean(), \n",
    "      # ood_score_target_list[~condition_mask&correct_msp_mask&correct_init_mask].mean(),\n",
    "      ood_score_final_list[~condition_mask&correct_msp_mask&correct_init_mask].mean())\n",
    "print(\"MSP correct \", (~condition_mask&correct_msp_mask&~correct_init_mask).sum(), \n",
    "      ood_score_init_list[~condition_mask&correct_msp_mask&~correct_init_mask].mean(),\n",
    "      #   ood_score_target_list[~condition_mask&correct_msp_mask&~correct_init_mask].mean(),\n",
    "        ood_score_final_list[~condition_mask&correct_msp_mask&~correct_init_mask].mean())\n",
    "print(\"Init correct\", (~condition_mask&~correct_msp_mask&correct_init_mask).sum(), \n",
    "      ood_score_init_list[~condition_mask&~correct_msp_mask&correct_init_mask].mean(),\n",
    "      #   ood_score_target_list[~condition_mask&~correct_msp_mask&correct_init_mask].mean(),\n",
    "        ood_score_final_list[~condition_mask&~correct_msp_mask&correct_init_mask].mean())\n",
    "print(\"Permutation correct\",(~condition_mask&correct_permutation_confident_mask&~correct_msp_mask&~correct_init_mask).sum(), \n",
    "      ood_score_init_list[~condition_mask&correct_permutation_confident_mask&~correct_msp_mask&~correct_init_mask].mean(),\n",
    "      #   ood_score_target_list[~condition_mask&correct_permutation_confident_mask&~correct_msp_mask&~correct_init_mask].mean(),\n",
    "        ood_score_final_list[~condition_mask&correct_permutation_confident_mask&~correct_msp_mask&~correct_init_mask].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col_idx_permutation_msp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use target as head, the MSP context\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "log = defaultdict(list)\n",
    "num_cols = []\n",
    "threshold = 0.8\n",
    "corrected = 0\n",
    "total_mistakes = 0\n",
    "init_permutation = defaultdict(list)\n",
    "corrected_permutation = defaultdict(list)\n",
    "init_logits = defaultdict(list)\n",
    "corrected_logits = defaultdict(list)\n",
    "max_col_length = 3\n",
    "msp_threshold = 0.9\n",
    "\n",
    "\n",
    "alpha = 0.25\n",
    "\n",
    "class_weights = (1.0 / class_freq) ** alpha\n",
    "\n",
    "# Normalize the weights\n",
    "class_weights /= class_weights.sum()\n",
    "\n",
    "for batch_idx, batch in enumerate(test_dataset_iter):\n",
    "    if batch_idx == 19:\n",
    "        break\n",
    "cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "target_col_mask = batch[\"target_col_mask\"].T\n",
    "col_idx_set = target_col_mask.unique().tolist()\n",
    "init_permutation_i = get_permutation(target_col_mask)\n",
    "successs = False\n",
    "# logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,).detach().cpu()\n",
    "# logits = reweight_logits(logits, class_weights)\n",
    "# logits_init = logits.clone()\n",
    "# num_cols.append(batch[\"target_col_mask\"].max().item())\n",
    "\n",
    "\n",
    "# col_idx_set = target_col_mask.unique().tolist()\n",
    "# successs = False\n",
    "# init_permutation_i = get_permutation(target_col_mask)\n",
    "# init_permutation[batch_idx].append(get_permutation(target_col_mask))\n",
    "# init_logits[batch_idx].append(logits_init.detach().cpu())     \n",
    "# init_msp = logits_init.max().item()\n",
    "# print(batch[\"label\"].item())\n",
    "# print(get_permutation(target_col_mask), init_msp, init_logits[batch_idx][0].argmax().item()) \n",
    "print(batch[\"label\"].item())  \n",
    "print(batch[\"target_col_mask\"].max().item(), get_permutation(target_col_mask))\n",
    "print(\"********************************************************\")\n",
    "assert -1 not in col_idx_set\n",
    "max_msp = 0 \n",
    "# for r in range(1, min(len(col_idx_set), max_col_length) + 1):\n",
    "enough = False\n",
    "# for r in range(len(col_idx_set)-1, 0, -1):\n",
    "for r in range(len(col_idx_set)-1, len(col_idx_set)//2, -1):\n",
    "    for subset in itertools.combinations(col_idx_set, r):\n",
    "        if 0 not in subset and r != 1:\n",
    "            continue\n",
    "        for x in itertools.permutations(subset):\n",
    "            if not is_sublist(x, init_permutation_i):\n",
    "                continue\n",
    "            new_batch_data = []\n",
    "            for col_i in x:\n",
    "                if col_i == 0:\n",
    "                    if len(new_batch_data) == 0:\n",
    "                        cls_indexes_value = 0\n",
    "                    else:\n",
    "                        cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "            if 0 not in x:\n",
    "                cls_indexes_value = 0\n",
    "            new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "            cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "            logits_temp = model(new_batch_data, cls_indexes=cls_indexes,).detach().cpu()\n",
    "            logits_temp = reweight_logits(logits_temp, class_weights)\n",
    "            msp_temp = logits_temp.max()\n",
    "            predict_temp = logits_temp.argmax()\n",
    "            # msp_temp = F.softmax(logits_temp).max().item()\n",
    "            # predict_temp = F.softmax(logits_temp).argmax().item()\n",
    "\n",
    "            print(x, msp_temp,predict_temp)\n",
    "            if msp_temp > max_msp and 0 in x:\n",
    "                max_msp = msp_temp\n",
    "                best_msp_perm = x\n",
    "                msp_predict = predict_temp\n",
    "        \n",
    "print(\"********************************************************\")\n",
    "print(best_msp_perm, max_msp, msp_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# brute force perumate, early stop\n",
    "import itertools\n",
    "\n",
    "\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "\n",
    "max_col_length = 3\n",
    "for alpha in [0.25]:\n",
    "    class_weights = (1.0 / class_freq) ** alpha\n",
    "    # Normalize the weights\n",
    "    class_weights /= class_weights.sum()\n",
    "    for uncertainty_threshold in [ 0.8]:\n",
    "        for msp_threshold in [ 0.8, 0.9, 0.99]:\n",
    "            for debias_threshold in [1.0]:\n",
    "                print(f\"*********************alpha: {alpha}; uncertain: {uncertainty_threshold}; debias: {debias_threshold}; msp: {msp_threshold}****************************\")\n",
    "                ft_embs_test = []\n",
    "                labels_test = []\n",
    "                logits_test = []\n",
    "                log = defaultdict(list)\n",
    "                num_cols = []\n",
    "                corrected = 0\n",
    "                total_mistakes = 0\n",
    "\n",
    "                for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "                    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "                    target_col_mask = batch[\"target_col_mask\"].T\n",
    "                    logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "                    logits = reweight_logits(logits.detach().cpu(), class_weights) # Here !!!!!!!!!!\n",
    "                    msp_init = logits.max().item()\n",
    "                    num_cols.append(batch[\"target_col_mask\"].max().item())\n",
    "                    predict_init = logits.argmax().item()\n",
    "                    max_msp = 0\n",
    "                    \n",
    "                    if 1 in target_col_mask and msp_init < uncertainty_threshold:\n",
    "                        init_permutation_i = get_permutation(target_col_mask)\n",
    "                        col_idx_set = target_col_mask.unique().tolist()\n",
    "                        debias_classes = []\n",
    "                        early_stop = False\n",
    "                        assert -1 not in col_idx_set\n",
    "                        for r in range(len(col_idx_set)-1, len(col_idx_set)//2, -1):\n",
    "                            round_classes = set()\n",
    "                            for subset in itertools.combinations(col_idx_set, r):\n",
    "                                if 0 not in subset and r != 1:\n",
    "                                    continue\n",
    "                                for x in itertools.permutations(subset):\n",
    "                                    if not is_sublist(x, init_permutation_i):\n",
    "                                        continue\n",
    "                                    new_batch_data = []\n",
    "                                    for col_i in x:\n",
    "                                        if col_i == 0:\n",
    "                                            if len(new_batch_data) == 0:\n",
    "                                                cls_indexes_value = 0\n",
    "                                            else:\n",
    "                                                cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                                        new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                                    if 0 not in x:\n",
    "                                        cls_indexes_value = 0\n",
    "                                    new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                                    cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                                    logits_temp = model(new_batch_data, cls_indexes=cls_indexes,)\n",
    "                                    logits_temp = reweight_logits(logits_temp.detach().cpu(), class_weights)\n",
    "                                    msp_temp = logits_temp.max().item()\n",
    "                                    predict_temp = logits_temp.argmax().item()\n",
    "                                    round_classes.add(predict_temp)\n",
    "                                    # if len(x) == 1 and 0 in x:\n",
    "                                    #     predict_target = predict_temp\n",
    "                                    #     msp_target = msp_temp\n",
    "                                    # # print(x, msp_temp, predict_temp)\n",
    "                                    # if 0 not in x and msp_temp > debias_threshold and (predict_temp != predict_target):\n",
    "                                    #     debias_classes.append(predict_temp)\n",
    "                                    #     continue\n",
    "                                    if msp_temp > max_msp and 0 in x and predict_temp not in debias_classes:\n",
    "                                        max_msp = msp_temp\n",
    "                                        best_msp_perm = x\n",
    "                                        msp_predict = predict_temp\n",
    "                                        logits_msp = logits_temp.clone()\n",
    "                                        if max_msp > msp_threshold and 0 in x and len(round_classes) > 1: # make sure the classes in one round is not homogenous \n",
    "                                            early_stop = True\n",
    "                            if early_stop:\n",
    "                                break\n",
    "                    if max_msp > msp_threshold:\n",
    "                        logits = logits_msp.clone()\n",
    "                    labels_test.append(batch[\"label\"].cpu())\n",
    "                    logits_test.append(logits.detach().cpu())\n",
    "                labels_test = torch.cat(labels_test, dim=0)\n",
    "                logits_test = torch.stack(logits_test, dim=0)\n",
    "                preds_test = torch.argmax(logits_test, dim=1)\n",
    "                num_cols = torch.tensor(num_cols)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                from sklearn.metrics import confusion_matrix, f1_score\n",
    "                mask = num_cols > 0\n",
    "                ts_pred_list = logits_test.argmax(\n",
    "                                            1).cpu().detach().numpy().tolist()\n",
    "                ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"micro\")\n",
    "                ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"macro\")\n",
    "                print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "                ts_pred_list = logits_test.argmax(\n",
    "                                            1).cpu().detach()[mask].numpy().tolist()\n",
    "                ts_micro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"micro\")\n",
    "                ts_macro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"macro\")\n",
    "                print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "                ts_pred_list = logits_test.argmax(\n",
    "                                            1).cpu().detach()[~mask].numpy().tolist()\n",
    "                ts_micro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"micro\")\n",
    "                ts_macro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"macro\")\n",
    "                print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# brute force perumate, early stop\n",
    "import itertools\n",
    "\n",
    "\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "\n",
    "max_col_length = 3\n",
    "for alpha in [0.25]:\n",
    "    class_weights = (1.0 / class_freq) ** alpha\n",
    "    # Normalize the weights\n",
    "    class_weights /= class_weights.sum()\n",
    "    for uncertainty_threshold in [ 0.8]:\n",
    "        for msp_threshold in [0.0]:\n",
    "            for debias_threshold in [1.0]:\n",
    "                print(f\"*********************alpha: {alpha}; uncertain: {uncertainty_threshold}; debias: {debias_threshold}; msp: {msp_threshold}****************************\")\n",
    "                ft_embs_test = []\n",
    "                labels_test = []\n",
    "                logits_test = []\n",
    "                log = defaultdict(list)\n",
    "                num_cols = []\n",
    "                corrected = 0\n",
    "                total_mistakes = 0\n",
    "\n",
    "                for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "                    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "                    target_col_mask = batch[\"target_col_mask\"].T\n",
    "                    logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "                    logits = reweight_logits(logits.detach().cpu(), class_weights) # Here !!!!!!!!!!\n",
    "                    msp_init = logits.max().item()\n",
    "                    num_cols.append(batch[\"target_col_mask\"].max().item())\n",
    "                    predict_init = logits.argmax().item()\n",
    "                    max_msp = 0\n",
    "                    \n",
    "                    if 1 in target_col_mask and msp_init < uncertainty_threshold:\n",
    "                        init_permutation_i = get_permutation(target_col_mask)\n",
    "                        col_idx_set = target_col_mask.unique().tolist()\n",
    "                        debias_classes = []\n",
    "                        early_stop = False\n",
    "                        assert -1 not in col_idx_set\n",
    "                        for r in range(len(col_idx_set)-1, len(col_idx_set)//2, -1):\n",
    "                            round_classes = set()\n",
    "                            for subset in itertools.combinations(col_idx_set, r):\n",
    "                                if 0 not in subset and r != 1:\n",
    "                                    continue\n",
    "                                for x in itertools.permutations(subset):\n",
    "                                    if not is_sublist(x, init_permutation_i):\n",
    "                                        continue\n",
    "                                    new_batch_data = []\n",
    "                                    for col_i in x:\n",
    "                                        if col_i == 0:\n",
    "                                            if len(new_batch_data) == 0:\n",
    "                                                cls_indexes_value = 0\n",
    "                                            else:\n",
    "                                                cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                                        new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                                    if 0 not in x:\n",
    "                                        cls_indexes_value = 0\n",
    "                                    new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                                    cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                                    logits_temp = model(new_batch_data, cls_indexes=cls_indexes,)\n",
    "                                    logits_temp = reweight_logits(logits_temp.detach().cpu(), class_weights)\n",
    "                                    msp_temp = logits_temp.max().item()\n",
    "                                    predict_temp = logits_temp.argmax().item()\n",
    "                                    round_classes.add(predict_temp)\n",
    "                                    # if len(x) == 1 and 0 in x:\n",
    "                                    #     predict_target = predict_temp\n",
    "                                    #     msp_target = msp_temp\n",
    "                                    # # print(x, msp_temp, predict_temp)\n",
    "                                    # if 0 not in x and msp_temp > debias_threshold and (predict_temp != predict_target):\n",
    "                                    #     debias_classes.append(predict_temp)\n",
    "                                    #     continue\n",
    "                                    if msp_temp > max_msp and 0 in x and predict_temp not in debias_classes:\n",
    "                                        max_msp = msp_temp\n",
    "                                        best_msp_perm = x\n",
    "                                        msp_predict = predict_temp\n",
    "                                        logits_msp = logits_temp.clone()\n",
    "                                        if max_msp > msp_threshold and 0 in x and len(round_classes) > 1: # make sure the classes in one round is not homogenous \n",
    "                                            early_stop = True\n",
    "                            if early_stop:\n",
    "                                break\n",
    "                    if max_msp > msp_threshold:\n",
    "                        logits = logits_msp.clone()\n",
    "                    labels_test.append(batch[\"label\"].cpu())\n",
    "                    logits_test.append(logits.detach().cpu())\n",
    "                labels_test = torch.cat(labels_test, dim=0)\n",
    "                logits_test = torch.stack(logits_test, dim=0)\n",
    "                preds_test = torch.argmax(logits_test, dim=1)\n",
    "                num_cols = torch.tensor(num_cols)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                from sklearn.metrics import confusion_matrix, f1_score\n",
    "                mask = num_cols > 0\n",
    "                ts_pred_list = logits_test.argmax(\n",
    "                                            1).cpu().detach().numpy().tolist()\n",
    "                ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"micro\")\n",
    "                ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"macro\")\n",
    "                print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "                ts_pred_list = logits_test.argmax(\n",
    "                                            1).cpu().detach()[mask].numpy().tolist()\n",
    "                ts_micro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"micro\")\n",
    "                ts_macro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"macro\")\n",
    "                print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "                ts_pred_list = logits_test.argmax(\n",
    "                                            1).cpu().detach()[~mask].numpy().tolist()\n",
    "                ts_micro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"micro\")\n",
    "                ts_macro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"macro\")\n",
    "                print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# brute force perumate, early stop\n",
    "import itertools\n",
    "\n",
    "\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "\n",
    "max_col_length = 3\n",
    "for alpha in [0.25]:\n",
    "    class_weights = (1.0 / class_freq) ** alpha\n",
    "    # Normalize the weights\n",
    "    class_weights /= class_weights.sum()\n",
    "    for uncertainty_threshold in [ 0.85]:\n",
    "        for msp_threshold in [0.9]:\n",
    "            for debias_threshold in [1.0]:\n",
    "                print(f\"*********************alpha: {alpha}; uncertain: {uncertainty_threshold}; debias: {debias_threshold}; msp: {msp_threshold}****************************\")\n",
    "                ft_embs_test = []\n",
    "                labels_test = []\n",
    "                logits_test = []\n",
    "                log = defaultdict(list)\n",
    "                num_cols = []\n",
    "                corrected = 0\n",
    "                total_mistakes = 0\n",
    "\n",
    "                for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "                    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "                    target_col_mask = batch[\"target_col_mask\"].T\n",
    "                    logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "                    logits = reweight_logits(logits.detach().cpu(), class_weights) # Here !!!!!!!!!!\n",
    "                    msp_init = logits.max().item()\n",
    "                    num_cols.append(batch[\"target_col_mask\"].max().item())\n",
    "                    predict_init = logits.argmax().item()\n",
    "                    max_msp = 0\n",
    "                    \n",
    "                    if 1 in target_col_mask and msp_init < uncertainty_threshold:\n",
    "                        init_permutation_i = get_permutation(target_col_mask)\n",
    "                        col_idx_set = target_col_mask.unique().tolist()\n",
    "                        debias_classes = []\n",
    "                        early_stop = False\n",
    "                        assert -1 not in col_idx_set\n",
    "                        for r in range(len(col_idx_set)-1, len(col_idx_set)//2, -1):\n",
    "                            round_classes = set()\n",
    "                            for subset in itertools.combinations(col_idx_set, r):\n",
    "                                if 0 not in subset and r != 1:\n",
    "                                    continue\n",
    "                                for x in itertools.permutations(subset):\n",
    "                                    if not is_sublist(x, init_permutation_i):\n",
    "                                        continue\n",
    "                                    new_batch_data = []\n",
    "                                    for col_i in x:\n",
    "                                        if col_i == 0:\n",
    "                                            if len(new_batch_data) == 0:\n",
    "                                                cls_indexes_value = 0\n",
    "                                            else:\n",
    "                                                cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                                        new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                                    if 0 not in x:\n",
    "                                        cls_indexes_value = 0\n",
    "                                    new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                                    cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                                    logits_temp = model(new_batch_data, cls_indexes=cls_indexes,)\n",
    "                                    logits_temp = reweight_logits(logits_temp.detach().cpu(), class_weights)\n",
    "                                    msp_temp = logits_temp.max().item()\n",
    "                                    predict_temp = logits_temp.argmax().item()\n",
    "                                    round_classes.add(predict_temp)\n",
    "                                    # if len(x) == 1 and 0 in x:\n",
    "                                    #     predict_target = predict_temp\n",
    "                                    #     msp_target = msp_temp\n",
    "                                    # # print(x, msp_temp, predict_temp)\n",
    "                                    # if 0 not in x and msp_temp > debias_threshold and (predict_temp != predict_target):\n",
    "                                    #     debias_classes.append(predict_temp)\n",
    "                                    #     continue\n",
    "                                    if msp_temp > max_msp and 0 in x and predict_temp not in debias_classes:\n",
    "                                        max_msp = msp_temp\n",
    "                                        best_msp_perm = x\n",
    "                                        msp_predict = predict_temp\n",
    "                                        logits_msp = logits_temp.clone()\n",
    "                                        if max_msp > msp_threshold and 0 in x and len(round_classes) > 1: # make sure the classes in one round is not homogenous \n",
    "                                            early_stop = True\n",
    "                            if early_stop:\n",
    "                                break\n",
    "                    if max_msp > msp_threshold:\n",
    "                        logits = logits_msp.clone()\n",
    "                    labels_test.append(batch[\"label\"].cpu())\n",
    "                    logits_test.append(logits.detach().cpu())\n",
    "                labels_test = torch.cat(labels_test, dim=0)\n",
    "                logits_test = torch.stack(logits_test, dim=0)\n",
    "                preds_test = torch.argmax(logits_test, dim=1)\n",
    "                num_cols = torch.tensor(num_cols)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                from sklearn.metrics import confusion_matrix, f1_score\n",
    "                mask = num_cols > 0\n",
    "                ts_pred_list = logits_test.argmax(\n",
    "                                            1).cpu().detach().numpy().tolist()\n",
    "                ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"micro\")\n",
    "                ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"macro\")\n",
    "                print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "                ts_pred_list = logits_test.argmax(\n",
    "                                            1).cpu().detach()[mask].numpy().tolist()\n",
    "                ts_micro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"micro\")\n",
    "                ts_macro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"macro\")\n",
    "                print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "                ts_pred_list = logits_test.argmax(\n",
    "                                            1).cpu().detach()[~mask].numpy().tolist()\n",
    "                ts_micro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"micro\")\n",
    "                ts_macro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"macro\")\n",
    "                print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# brute force perumate, early stop\n",
    "import itertools\n",
    "\n",
    "\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "\n",
    "max_col_length = 3\n",
    "for alpha in [0.25]:\n",
    "    class_weights = (1.0 / class_freq) ** alpha\n",
    "    # Normalize the weights\n",
    "    class_weights /= class_weights.sum()\n",
    "    for uncertainty_threshold in [ 0.85, 0.8]:\n",
    "        for msp_threshold in [0.0, 0.8, 0.85, 0.9]:\n",
    "            for debias_threshold in [1.0]:\n",
    "                print(f\"*********************alpha: {alpha}; uncertain: {uncertainty_threshold}; debias: {debias_threshold}; msp: {msp_threshold}****************************\")\n",
    "                ft_embs_test = []\n",
    "                labels_test = []\n",
    "                logits_test = []\n",
    "                log = defaultdict(list)\n",
    "                num_cols = []\n",
    "                corrected = 0\n",
    "                total_mistakes = 0\n",
    "\n",
    "                for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "                    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "                    target_col_mask = batch[\"target_col_mask\"].T\n",
    "                    logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "                    logits = reweight_logits(logits.detach().cpu(), class_weights) # Here !!!!!!!!!!\n",
    "                    msp_init = logits.max().item()\n",
    "                    num_cols.append(batch[\"target_col_mask\"].max().item())\n",
    "                    predict_init = logits.argmax().item()\n",
    "                    max_msp = 0\n",
    "                    \n",
    "                    if 1 in target_col_mask and msp_init < uncertainty_threshold:\n",
    "                        init_permutation_i = get_permutation(target_col_mask)\n",
    "                        col_idx_set = target_col_mask.unique().tolist()\n",
    "                        debias_classes = []\n",
    "                        early_stop = False\n",
    "                        assert -1 not in col_idx_set\n",
    "                        for r in range(len(col_idx_set)-1, len(col_idx_set)//2, -1):\n",
    "                            round_classes = set()\n",
    "                            for subset in itertools.combinations(col_idx_set, r):\n",
    "                                if 0 not in subset and r != 1:\n",
    "                                    continue\n",
    "                                for x in itertools.permutations(subset):\n",
    "                                    if not is_sublist(x, init_permutation_i):\n",
    "                                        continue\n",
    "                                    new_batch_data = []\n",
    "                                    for col_i in x:\n",
    "                                        if col_i == 0:\n",
    "                                            if len(new_batch_data) == 0:\n",
    "                                                cls_indexes_value = 0\n",
    "                                            else:\n",
    "                                                cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                                        new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                                    if 0 not in x:\n",
    "                                        cls_indexes_value = 0\n",
    "                                    new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                                    cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                                    logits_temp = model(new_batch_data, cls_indexes=cls_indexes,)\n",
    "                                    logits_temp = reweight_logits(logits_temp.detach().cpu(), class_weights)\n",
    "                                    msp_temp = logits_temp.max().item()\n",
    "                                    predict_temp = logits_temp.argmax().item()\n",
    "                                    round_classes.add(predict_temp)\n",
    "                                    # if len(x) == 1 and 0 in x:\n",
    "                                    #     predict_target = predict_temp\n",
    "                                    #     msp_target = msp_temp\n",
    "                                    # # print(x, msp_temp, predict_temp)\n",
    "                                    # if 0 not in x and msp_temp > debias_threshold and (predict_temp != predict_target):\n",
    "                                    #     debias_classes.append(predict_temp)\n",
    "                                    #     continue\n",
    "                                    if msp_temp > max_msp and 0 in x and predict_temp not in debias_classes:\n",
    "                                        max_msp = msp_temp\n",
    "                                        best_msp_perm = x\n",
    "                                        msp_predict = predict_temp\n",
    "                                        logits_msp = logits_temp.clone()\n",
    "                                        if max_msp > msp_threshold and 0 in x: # make sure the classes in one round is not homogenous \n",
    "                                            early_stop = True\n",
    "                            if early_stop:\n",
    "                                break\n",
    "                    if max_msp > msp_threshold:\n",
    "                        logits = logits_msp.clone()\n",
    "                    labels_test.append(batch[\"label\"].cpu())\n",
    "                    logits_test.append(logits.detach().cpu())\n",
    "                labels_test = torch.cat(labels_test, dim=0)\n",
    "                logits_test = torch.stack(logits_test, dim=0)\n",
    "                preds_test = torch.argmax(logits_test, dim=1)\n",
    "                num_cols = torch.tensor(num_cols)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                from sklearn.metrics import confusion_matrix, f1_score\n",
    "                mask = num_cols > 0\n",
    "                ts_pred_list = logits_test.argmax(\n",
    "                                            1).cpu().detach().numpy().tolist()\n",
    "                ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"micro\")\n",
    "                ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"macro\")\n",
    "                print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "                ts_pred_list = logits_test.argmax(\n",
    "                                            1).cpu().detach()[mask].numpy().tolist()\n",
    "                ts_micro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"micro\")\n",
    "                ts_macro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"macro\")\n",
    "                print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "                ts_pred_list = logits_test.argmax(\n",
    "                                            1).cpu().detach()[~mask].numpy().tolist()\n",
    "                ts_micro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"micro\")\n",
    "                ts_macro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"macro\")\n",
    "                print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *********************alpha: 0.25; uncertain: 0.85; debias: 1.0; msp: 0.9****************************\n",
    "# ts_micro_f1=0.5456, ts_macro_f1=0.2627\n",
    "# ts_micro_f1=0.5452, ts_macro_f1=0.2626\n",
    "# ts_micro_f1=1.0000, ts_macro_f1=1.0000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# brute force perumate, early stop\n",
    "import itertools\n",
    "\n",
    "\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "\n",
    "max_col_length = 3\n",
    "for alpha in [0.0]:\n",
    "    # class_weights = (1.0 / class_freq) ** alpha\n",
    "    # # Normalize the weights\n",
    "    # class_weights /= class_weights.sum()\n",
    "    for uncertainty_threshold in [ 0.85, 0.8, 0.9]:\n",
    "        for msp_threshold in [0.0, 0.8, 0.85, 0.9]:\n",
    "            for debias_threshold in [1.0]:\n",
    "                print(f\"*********************alpha: {alpha}; uncertain: {uncertainty_threshold}; debias: {debias_threshold}; msp: {msp_threshold}****************************\")\n",
    "                ft_embs_test = []\n",
    "                labels_test = []\n",
    "                logits_test = []\n",
    "                log = defaultdict(list)\n",
    "                num_cols = []\n",
    "                corrected = 0\n",
    "                total_mistakes = 0\n",
    "\n",
    "                for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "                    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "                    target_col_mask = batch[\"target_col_mask\"].T\n",
    "                    logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "                    # logits = reweight_logits(logits.detach().cpu(), class_weights) # Here !!!!!!!!!!\n",
    "                    logits = F.softmax(logits, dim=-1)\n",
    "                    msp_init = logits.max().item()\n",
    "                    num_cols.append(batch[\"target_col_mask\"].max().item())\n",
    "                    predict_init = logits.argmax().item()\n",
    "                    max_msp = 0\n",
    "                    \n",
    "                    if 1 in target_col_mask and msp_init < uncertainty_threshold:\n",
    "                        init_permutation_i = get_permutation(target_col_mask)\n",
    "                        col_idx_set = target_col_mask.unique().tolist()\n",
    "                        debias_classes = []\n",
    "                        early_stop = False\n",
    "                        assert -1 not in col_idx_set\n",
    "                        for r in range(len(col_idx_set)-1, len(col_idx_set)//2, -1):\n",
    "                            round_classes = set()\n",
    "                            for subset in itertools.combinations(col_idx_set, r):\n",
    "                                if 0 not in subset and r != 1:\n",
    "                                    continue\n",
    "                                for x in itertools.permutations(subset):\n",
    "                                    if not is_sublist(x, init_permutation_i):\n",
    "                                        continue\n",
    "                                    new_batch_data = []\n",
    "                                    for col_i in x:\n",
    "                                        if col_i == 0:\n",
    "                                            if len(new_batch_data) == 0:\n",
    "                                                cls_indexes_value = 0\n",
    "                                            else:\n",
    "                                                cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                                        new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                                    if 0 not in x:\n",
    "                                        cls_indexes_value = 0\n",
    "                                    new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                                    cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                                    logits_temp = model(new_batch_data, cls_indexes=cls_indexes,)\n",
    "                                    # logits_temp = reweight_logits(logits_temp.detach().cpu(), class_weights)\n",
    "                                    logits_temp = F.softmax(logits_temp, dim=-1)\n",
    "                                    msp_temp = logits_temp.max().item()\n",
    "                                    predict_temp = logits_temp.argmax().item()\n",
    "                                    round_classes.add(predict_temp)\n",
    "                                    # if len(x) == 1 and 0 in x:\n",
    "                                    #     predict_target = predict_temp\n",
    "                                    #     msp_target = msp_temp\n",
    "                                    # # print(x, msp_temp, predict_temp)\n",
    "                                    # if 0 not in x and msp_temp > debias_threshold and (predict_temp != predict_target):\n",
    "                                    #     debias_classes.append(predict_temp)\n",
    "                                    #     continue\n",
    "                                    if msp_temp > max_msp and 0 in x and predict_temp not in debias_classes:\n",
    "                                        max_msp = msp_temp\n",
    "                                        best_msp_perm = x\n",
    "                                        msp_predict = predict_temp\n",
    "                                        logits_msp = logits_temp.clone()\n",
    "                                        if max_msp > msp_threshold and 0 in x: # make sure the classes in one round is not homogenous \n",
    "                                            early_stop = True\n",
    "                            if early_stop:\n",
    "                                break\n",
    "                    if max_msp > msp_threshold:\n",
    "                        logits = logits_msp.clone()\n",
    "                    labels_test.append(batch[\"label\"].cpu())\n",
    "                    logits_test.append(logits.detach().cpu())\n",
    "                labels_test = torch.cat(labels_test, dim=0)\n",
    "                logits_test = torch.stack(logits_test, dim=0)\n",
    "                preds_test = torch.argmax(logits_test, dim=1)\n",
    "                num_cols = torch.tensor(num_cols)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                from sklearn.metrics import confusion_matrix, f1_score\n",
    "                mask = num_cols > 0\n",
    "                ts_pred_list = logits_test.argmax(\n",
    "                                            1).cpu().detach().numpy().tolist()\n",
    "                ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"micro\")\n",
    "                ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"macro\")\n",
    "                print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "                ts_pred_list = logits_test.argmax(\n",
    "                                            1).cpu().detach()[mask].numpy().tolist()\n",
    "                ts_micro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"micro\")\n",
    "                ts_macro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"macro\")\n",
    "                print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "                ts_pred_list = logits_test.argmax(\n",
    "                                            1).cpu().detach()[~mask].numpy().tolist()\n",
    "                ts_micro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"micro\")\n",
    "                ts_macro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"macro\")\n",
    "                print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brute force perumate in training TODO: restrict mamimus length of permutation\n",
    "import itertools\n",
    "import torch.nn.functional as F\n",
    "\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "for threshold in [1.5]:\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    log = defaultdict(list)\n",
    "    num_cols = []\n",
    "    corrected = 0\n",
    "    total_mistakes = 0\n",
    "    num_permutations = {}\n",
    "    init_permutation = {}\n",
    "    init_correctness = {}\n",
    "    score_init = {}\n",
    "    score_permutation = defaultdict(list)\n",
    "    permutation_correctness = defaultdict(list)\n",
    "    for batch_idx, batch in enumerate(train_dataloader_iter):\n",
    "        cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "        target_col_mask = batch[\"target_col_mask\"].T\n",
    "        logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "        score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
    "        label_i = batch[\"label\"].item()\n",
    "        predict_init = logits.argmax().item()\n",
    "        init_permutation_i = get_permutation(target_col_mask)\n",
    "        init_permutation[batch_idx] = init_permutation_i\n",
    "        if predict_init == label_i:\n",
    "            init_correctness[batch_idx] = True\n",
    "        else:\n",
    "            init_correctness[batch_idx] = False\n",
    "        num_permutations[batch_idx] = 0\n",
    "        if 1 in target_col_mask:\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            assert -1 not in col_idx_set\n",
    "            for r in range(len(init_permutation_i)-1, len(init_permutation_i)//2, -1): # not \n",
    "                for x in itertools.combinations(init_permutation_i, r):\n",
    "                    if 0 not in x:\n",
    "                        continue\n",
    "\n",
    "                    num_permutations[batch_idx] += 1\n",
    "                    new_batch_data = []\n",
    "                    for col_i in x:\n",
    "                        if col_i == 0:\n",
    "                            if len(new_batch_data) == 0:\n",
    "                                cls_indexes_value = 0\n",
    "                            else:\n",
    "                                cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                        new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                    new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                    cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                    logits_temp = model(new_batch_data, cls_indexes=cls_indexes,)\n",
    "                    ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n",
    "                    score_permutation[batch_idx].append(ood_score_temp)\n",
    "                    predict_temp = logits_temp.argmax().item()\n",
    "                    permutation_correctness[batch_idx].append(predict_temp == label_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation_correctness_ratio = []\n",
    "score_permutation_avg = []\n",
    "for i in score_init:\n",
    "    permutation_correctness_ratio.append(np.mean(permutation_correctness[i]))\n",
    "    score_permutation_avg.append(np.mean(score_permutation[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(score_permutation_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(permutation_correctness_ratio)\n",
    "permutation_correctness_ratio = np.array(permutation_correctness_ratio)\n",
    "print(np.mean(permutation_correctness_ratio[~np.isnan(permutation_correctness_ratio)]), sum(permutation_correctness_ratio==1)/len(permutation_correctness_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation_correctness[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(permutation_correctness[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in score_init:\n",
    "    print(score_init[i], init_correctness[i], num_permutations[i], init_permutation[i])\n",
    "    for score, correct in zip(score_permutation[i], permutation_correctness[i], ):\n",
    "        print(score, correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(i, score_init[i], init_correctness[i], num_permutations[i], init_permutation[i])\n",
    "    print(np.mean(score_permutation[i]), np.mean(permutation_correctness[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation_correctness[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_valid = []\n",
    "for batch_idx, batch in enumerate(valid_dataloader_iter):\n",
    "    labels_valid.append(batch[\"label\"].cpu())\n",
    "labels_valid = torch.tensor(labels_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(labels_valid.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, batch in enumerate(valid_dataloader_iter):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[\"target_col_mask\"].T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " batch[\"cls_indexes\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brute force perumate in validation TODO: restrict mamimus length of permutation\n",
    "import itertools\n",
    "import torch.nn.functional as F\n",
    "\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "for threshold in [1.5]:\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    log = defaultdict(list)\n",
    "    num_cols = []\n",
    "    corrected = 0\n",
    "    total_mistakes = 0\n",
    "    num_permutations = {}\n",
    "    init_permutation = {}\n",
    "    init_correctness = {}\n",
    "    score_init = {}\n",
    "    score_permutation = defaultdict(list)\n",
    "    permutation_correctness = defaultdict(list)\n",
    "    for batch_idx, batch in enumerate(valid_dataloader_iter):\n",
    "        cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "        target_col_mask = batch[\"target_col_mask\"].T\n",
    "        logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "        score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
    "        label_i = batch[\"label\"].item()\n",
    "        predict_init = logits.argmax().item()\n",
    "        init_permutation_i = get_permutation(target_col_mask)\n",
    "        init_permutation[batch_idx] = init_permutation_i\n",
    "        if predict_init == label_i:\n",
    "            init_correctness[batch_idx] = True\n",
    "        else:\n",
    "            init_correctness[batch_idx] = False\n",
    "        num_permutations[batch_idx] = 0\n",
    "        if 1 in target_col_mask:\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            assert -1 not in col_idx_set\n",
    "            for r in range(len(init_permutation_i), max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "                for subset in itertools.combinations(init_permutation_i, r):\n",
    "                    if 0 not in subset and r != 1:\n",
    "                        continue\n",
    "                    for x in itertools.permutations(subset):\n",
    "                    num_permutations[batch_idx] += 1\n",
    "                    new_batch_data = []\n",
    "                    for col_i in x:\n",
    "                        if col_i == 0:\n",
    "                            if len(new_batch_data) == 0:\n",
    "                                cls_indexes_value = 0\n",
    "                            else:\n",
    "                                cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                        new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                    new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                    cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                    logits_temp = model(new_batch_data, cls_indexes=cls_indexes,)\n",
    "                    ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n",
    "                    score_permutation[batch_idx].append(ood_score_temp)\n",
    "                    predict_temp = logits_temp.argmax().item()\n",
    "                    permutation_correctness[batch_idx].append(predict_temp == label_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brute force perumate in validation TODO: restrict mamimus length of permutation\n",
    "import itertools\n",
    "import torch.nn.functional as F\n",
    "\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "for threshold in [1.5]:\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    log = defaultdict(list)\n",
    "    num_cols = []\n",
    "    corrected = 0\n",
    "    total_mistakes = 0\n",
    "    num_permutations = {}\n",
    "    init_permutation = {}\n",
    "    init_correctness = {}\n",
    "    score_init = {}\n",
    "    score_permutation = defaultdict(list)\n",
    "    permutation_correctness = defaultdict(list)\n",
    "    for batch_idx, batch in enumerate(valid_dataloader_iter):\n",
    "        cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "        target_col_mask = batch[\"target_col_mask\"].T\n",
    "        logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "        score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
    "        label_i = batch[\"label\"].item()\n",
    "        predict_init = logits.argmax().item()\n",
    "        init_permutation_i = get_permutation(target_col_mask)\n",
    "        init_permutation[batch_idx] = init_permutation_i\n",
    "        if predict_init == label_i:\n",
    "            init_correctness[batch_idx] = True\n",
    "        else:\n",
    "            init_correctness[batch_idx] = False\n",
    "        num_permutations[batch_idx] = 0\n",
    "        if 1 in target_col_mask:\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            assert -1 not in col_idx_set\n",
    "            for r in range(len(init_permutation_i), max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "                for x in itertools.combinations(init_permutation_i, r):\n",
    "                    if 0 not in x:\n",
    "                        continue\n",
    "\n",
    "                    num_permutations[batch_idx] += 1\n",
    "                    new_batch_data = []\n",
    "                    for col_i in x:\n",
    "                        if col_i == 0:\n",
    "                            if len(new_batch_data) == 0:\n",
    "                                cls_indexes_value = 0\n",
    "                            else:\n",
    "                                cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                        new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                    new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                    cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                    logits_temp = model(new_batch_data, cls_indexes=cls_indexes,)\n",
    "                    ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n",
    "                    score_permutation[batch_idx].append(ood_score_temp)\n",
    "                    predict_temp = logits_temp.argmax().item()\n",
    "                    permutation_correctness[batch_idx].append(predict_temp == label_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation_correctness_ratio = []\n",
    "score_permutation_avg = []\n",
    "for i in score_init:\n",
    "    permutation_correctness_ratio.append(np.mean(permutation_correctness[i]))\n",
    "    score_permutation_avg.append(np.mean(score_permutation[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(permutation_correctness_ratio)\n",
    "permutation_correctness_ratio = np.array(permutation_correctness_ratio)\n",
    "print(np.mean(permutation_correctness_ratio[~np.isnan(permutation_correctness_ratio)]), sum(permutation_correctness_ratio==1)/len(permutation_correctness_ratio), sum(permutation_correctness_ratio==0)/len(permutation_correctness_ratio), (sum(permutation_correctness_ratio==0)+sum(permutation_correctness_ratio==1))/len(permutation_correctness_ratio))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(labels_valid[permutation_correctness_ratio==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(labels_valid[permutation_correctness_ratio==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(labels_valid[(permutation_correctness_ratio==1)|(permutation_correctness_ratio==0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation_correctness_ratio.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_init = torch.tensor(list(score_init.values()))\n",
    "score_init.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation_correctness_ratio = torch.tensor(permutation_correctness_ratio)\n",
    "print(score_init[permutation_correctness_ratio==1].mean())\n",
    "False in torch.tensor(list(init_correctness.values()))[permutation_correctness_ratio==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(score_init[permutation_correctness_ratio==0].mean())\n",
    "True in torch.tensor(list(init_correctness.values()))[permutation_correctness_ratio==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_permutations_all = num_permutations.values()\n",
    "sns.histplot(num_permutations_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_permutations.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(num_permutations[i], len(init_permutation[i]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_correct_permutations = [sum(permutation_correctness[i]) for i in permutation_correctness]\n",
    "num_wrong_permutations = [len(permutation_correctness[i])-sum(permutation_correctness[i]) for i in permutation_correctness]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.median(num_correct_permutations))\n",
    "print(torch.tensor(num_correct_permutations).unique())\n",
    "sns.histplot(num_correct_permutations )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.median(num_wrong_permutations))\n",
    "sns.histplot(num_wrong_permutations )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(num_wrong_permutations).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, batch in enumerate(valid_dataloader_iter):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "            veri_data[batch_idx].append(new_batch_data.cpu())\n",
    "            veri_label[batch_idx].append(torch.tensor(predict_temp == label_i).long())\n",
    "            veri_cls_indexes[batch_idx].append(cls_indexes_value)\n",
    "            veri_embs[batch_idx].append(embs_temp.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1 in target_col_mask:\n",
    "    col_idx_set = target_col_mask.unique().tolist()\n",
    "    assert -1 not in col_idx_set\n",
    "    for r in range(len(init_permutation_i), max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "        for x in itertools.combinations(init_permutation_i, r):\n",
    "            if 0 not in x:\n",
    "                continue\n",
    "\n",
    "            num_permutations[batch_idx] += 1\n",
    "            new_batch_data = []\n",
    "            for col_i in x:\n",
    "                if col_i == 0:\n",
    "                    if len(new_batch_data) == 0:\n",
    "                        cls_indexes_value = 0\n",
    "                    else:\n",
    "                        cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "            new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "            cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "            logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "            logits_temp = logits_temp.detach().cpu()\n",
    "            ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n",
    "            score_permutation[batch_idx].append(ood_score_temp)\n",
    "            predict_temp = logits_temp.argmax().item()\n",
    "            permutation_correctness[batch_idx].append(predict_temp == label_i)\n",
    "            \n",
    "            # veri_data[batch_idx].append(new_batch_data.cpu())\n",
    "            # veri_label[batch_idx].append(torch.tensor(predict_temp == label_i).long())\n",
    "            # veri_cls_indexes[batch_idx].append(cls_indexes_value)\n",
    "            # veri_embs[batch_idx].append(embs_temp.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_iter[batch_idx][\"col_idx\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_iter[batch_idx][\"col_idx\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "train_dataset_iter = GittablesTablewiseIterateDataset(cv=cv,\n",
    "                            split=\"train\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only='all' not in task,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\",\n",
    "                            random_sample=True)\n",
    "\n",
    "for batch_idx, batch in enumerate(train_dataloader_iter):\n",
    "    \n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    init_permutation_i = get_permutation(target_col_mask)\n",
    "    if len(init_permutation_i) > 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0, 64]], device='cuda:1')"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([229, 1])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# brute force perumate in validation TODO: restrict mamimus length of permutation\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "import torch.nn.functional as F\n",
    "train_data = defaultdict(list)\n",
    "train_logits = defaultdict(list)\n",
    "train_cls_indexes = defaultdict(list)\n",
    "train_target_col_mask = defaultdict(list)\n",
    "train_embs = defaultdict(list)\n",
    "train_col_num = defaultdict(list)\n",
    "train_label = defaultdict(list)\n",
    "train_class = defaultdict(list)\n",
    "train_target_embs = defaultdict(list)\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "for threshold in [1.5]:\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    log = defaultdict(list)\n",
    "    num_cols = []\n",
    "    corrected = 0\n",
    "    total_mistakes = 0\n",
    "    num_permutations = {}\n",
    "    init_permutation = {}\n",
    "    init_correctness = {}\n",
    "    score_init = {}\n",
    "    score_permutation = defaultdict(list)\n",
    "    permutation_correctness = defaultdict(list)\n",
    "    with torch.no_grad():\n",
    "        # for batch_idx, batch in enumerate(train_dataloader_iter):\n",
    "        for batch_idx, batch in enumerate(train_dataloader_gt):\n",
    "            cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "            target_col_mask = batch[\"target_col_mask\"].T\n",
    "            logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "            score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
    "            label_i = batch[\"label\"].item()\n",
    "            predict_init = logits.argmax().item()\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            init_permutation[batch_idx] = init_permutation_i\n",
    "            if predict_init == label_i:\n",
    "                init_correctness[batch_idx] = True\n",
    "            else:\n",
    "                init_correctness[batch_idx] = False\n",
    "            num_permutations[batch_idx] = 0\n",
    "\n",
    "            train_data[batch_idx].append(batch[\"data\"].T.cpu())\n",
    "            train_logits[batch_idx].append(logits.detach().cpu())\n",
    "            train_cls_indexes[batch_idx].append(batch[\"cls_indexes\"].cpu().item())\n",
    "            train_embs[batch_idx].append(embs.cpu())\n",
    "            train_col_num[batch_idx].append(len(init_permutation_i))\n",
    "            train_label[batch_idx].append(torch.tensor(predict_init == label_i).long()) # indicate whether the permutation is correct or not\n",
    "            train_class[batch_idx].append(label_i)\n",
    "\n",
    "\n",
    "            x = [0]\n",
    "            new_batch_data = []\n",
    "            for col_i in x:\n",
    "                if col_i == 0:\n",
    "                    if len(new_batch_data) == 0:\n",
    "                        cls_indexes_value = 0\n",
    "                    else:\n",
    "                        cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "            new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "            cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "            logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "            train_target_embs[batch_idx].append(embs_temp.cpu())\n",
    "\n",
    "            num_cols.append(len(init_permutation_i))\n",
    "            labels_test.append(batch[\"label\"].cpu().item())\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            assert -1 not in col_idx_set\n",
    "            for r in range(len(init_permutation_i)-1,  0, -1): # not \n",
    "                for x in itertools.combinations(init_permutation_i, r):\n",
    "                    if 0 not in x:\n",
    "                        continue\n",
    "\n",
    "                    num_permutations[batch_idx] += 1\n",
    "                    new_batch_data = []\n",
    "                    for col_i in x:\n",
    "                        if col_i == 0:\n",
    "                            if len(new_batch_data) == 0:\n",
    "                                cls_indexes_value = 0\n",
    "                            else:\n",
    "                                cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                        new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                    new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                    cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                    logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                    ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n",
    "                    score_permutation[batch_idx].append(ood_score_temp)\n",
    "                    predict_temp = logits_temp.argmax().item()\n",
    "                    permutation_correctness[batch_idx].append(predict_temp == label_i)\n",
    "                    \n",
    "                    \n",
    "                    train_data[batch_idx].append(new_batch_data.cpu())\n",
    "                    train_logits[batch_idx].append(logits_temp.detach().cpu())\n",
    "                    train_cls_indexes[batch_idx].append(cls_indexes_value)\n",
    "                    train_embs[batch_idx].append(embs_temp.cpu())\n",
    "                    train_col_num[batch_idx].append(len(x))\n",
    "                    train_label[batch_idx].append(torch.tensor(predict_temp == label_i).long()) # indicate whether the permutation is correct or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Threshold: 1.5****************************\n"
     ]
    }
   ],
   "source": [
    "# brute force perumate in validation TODO: restrict mamimus length of permutation\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "\n",
    "# train_dataset_lb = GittablesTablewiseIterateLabelDataset(cv=cv,\n",
    "#                             split=\"valid\", src=src,\n",
    "#                             tokenizer=tokenizer,\n",
    "#                             max_length=max_length,\n",
    "#                             gt_only='all' not in task,\n",
    "#                             device=device,\n",
    "#                             base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "#                             small_tag=\"semi1\",\n",
    "#                             max_unlabeled=4)\n",
    "# padder = collate_fn(tokenizer.pad_token_id)\n",
    "# train_dataloader_lb = DataLoader(valid_dataset_lb,\n",
    "#                                 batch_size=1,\n",
    "#                             #   collate_fn=collate_fn)\n",
    "#                             collate_fn=padder)\n",
    "\n",
    "import torch.nn.functional as F\n",
    "train_data = defaultdict(list)\n",
    "train_logits = defaultdict(list)\n",
    "train_cls_indexes = defaultdict(list)\n",
    "train_target_col_mask = defaultdict(list)\n",
    "train_embs = defaultdict(list)\n",
    "train_col_num = defaultdict(list)\n",
    "train_label = defaultdict(list)\n",
    "train_class = defaultdict(list)\n",
    "train_target_embs = defaultdict(list)\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "for threshold in [1.5]:\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    log = defaultdict(list)\n",
    "    num_cols = []\n",
    "    corrected = 0\n",
    "    total_mistakes = 0\n",
    "    num_permutations = {}\n",
    "    init_permutation = {}\n",
    "    init_correctness = {}\n",
    "    score_init = {}\n",
    "    score_permutation = defaultdict(list)\n",
    "    permutation_correctness = defaultdict(list)\n",
    "    with torch.no_grad():\n",
    "        # for batch_idx, batch in enumerate(train_dataloader_iter):\n",
    "        for batch_idx, batch in enumerate(train_dataloader_lb):\n",
    "            cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "            target_col_mask = batch[\"target_col_mask\"].T\n",
    "            logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "            score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
    "            label_i = batch[\"label\"].item()\n",
    "            predict_init = logits.argmax().item()\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            init_permutation[batch_idx] = init_permutation_i\n",
    "            if predict_init == label_i:\n",
    "                init_correctness[batch_idx] = True\n",
    "            else:\n",
    "                init_correctness[batch_idx] = False\n",
    "            num_permutations[batch_idx] = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            x = [0]\n",
    "            new_batch_data = []\n",
    "            for col_i in x:\n",
    "                if col_i == 0:\n",
    "                    if len(new_batch_data) == 0:\n",
    "                        cls_indexes_value = 0\n",
    "                    else:\n",
    "                        cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "            new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "            cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "            logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "            train_target_embs[batch_idx].append(embs_temp.cpu())\n",
    "\n",
    "            num_cols.append(len(init_permutation_i))\n",
    "            labels_test.append(batch[\"label\"].cpu().item())\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            assert -1 not in col_idx_set\n",
    "            for r in range(0,  len(init_permutation_i)+1): # not \n",
    "                for x in itertools.combinations(init_permutation_i, r):\n",
    "                    if 0 not in x:\n",
    "                        continue\n",
    "\n",
    "                    num_permutations[batch_idx] += 1\n",
    "                    new_batch_data = []\n",
    "                    for col_i in x:\n",
    "                        if col_i == 0:\n",
    "                            if len(new_batch_data) == 0:\n",
    "                                cls_indexes_value = 0\n",
    "                            else:\n",
    "                                cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                        new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                    new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                    cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                    logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                    ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n",
    "                    score_permutation[batch_idx].append(ood_score_temp)\n",
    "                    predict_temp = logits_temp.argmax().item()\n",
    "                    permutation_correctness[batch_idx].append(predict_temp == label_i)\n",
    "                    \n",
    "                    \n",
    "                    train_data[batch_idx].append(new_batch_data.cpu())\n",
    "                    train_logits[batch_idx].append(logits_temp.detach().cpu())\n",
    "                    train_cls_indexes[batch_idx].append(cls_indexes_value)\n",
    "                    train_embs[batch_idx].append(embs_temp.cpu())\n",
    "                    train_col_num[batch_idx].append(len(x))\n",
    "                    train_label[batch_idx].append(torch.tensor(predict_temp == label_i).long()) # indicate whether the permutation is correct or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gt loader 4\n",
    "import os\n",
    "os.makedirs(\"/data/zhihao/TU/Watchog/trainfication\", exist_ok=True)\n",
    "torch.save({\"data\": train_data, \"label\": train_label, \"logits\": train_logits, \"cls_indexes\": train_cls_indexes, \"embs\": train_embs, \"target_embs\":train_target_embs , \"col_num\": train_col_num}, f\"/data/zhihao/TU/Watchog/trainfication/{args.task}_train_data_gt_1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80478\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.5104)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gt loader 4\n",
    "train_labels_all = torch.cat([torch.tensor(train_label[i]) for i in train_label], dim=0)\n",
    "print(len(train_labels_all))\n",
    "train_labels_all.sum()/len(train_labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80478\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.5104)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gt loader 4\n",
    "train_labels_all = torch.cat([torch.tensor(train_label[i]) for i in train_label], dim=0)\n",
    "print(len(train_labels_all))\n",
    "train_labels_all.sum()/len(train_labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9525\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.8631)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_all = torch.cat([torch.tensor(train_label[i]) for i in train_label], dim=0)\n",
    "print(len(train_labels_all))\n",
    "train_labels_all.sum()/len(train_labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80478\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.5104)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_all = torch.cat([torch.tensor(train_label[i]) for i in train_label], dim=0)\n",
    "print(len(train_labels_all))\n",
    "train_labels_all.sum()/len(train_labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141808\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.4443)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_all = torch.cat([torch.tensor(train_label[i]) for i in train_label], dim=0)\n",
    "print(len(train_labels_all))\n",
    "train_labels_all.sum()/len(train_labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61330"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "141808 - 80478"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7687\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.8903)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_all = torch.cat([torch.tensor(train_label[i]) for i in train_label], dim=0)\n",
    "print(len(train_labels_all))\n",
    "train_labels_all.sum()/len(train_labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for threshold in [1.5]:\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    log = defaultdict(list)\n",
    "    num_cols = []\n",
    "    corrected = 0\n",
    "    total_mistakes = 0\n",
    "    num_permutations = {}\n",
    "    init_permutation = {}\n",
    "    init_correctness = {}\n",
    "    score_init = {}\n",
    "    score_permutation = defaultdict(list)\n",
    "    permutation_correctness = defaultdict(list)\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(train_dataloader_iter):\n",
    "            cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "            target_col_mask = batch[\"target_col_mask\"].T\n",
    "            logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "            score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
    "            label_i = batch[\"label\"].item()\n",
    "            predict_init = logits.argmax().item()\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            init_permutation[batch_idx] = init_permutation_i\n",
    "            if predict_init == label_i:\n",
    "                init_correctness[batch_idx] = True\n",
    "            else:\n",
    "                init_correctness[batch_idx] = False\n",
    "            num_permutations[batch_idx] = 0\n",
    "\n",
    "            train_data[batch_idx].append(batch[\"data\"].T.cpu())\n",
    "            train_logits[batch_idx].append(logits.detach().cpu())\n",
    "            train_cls_indexes[batch_idx].append(batch[\"cls_indexes\"].cpu().item())\n",
    "            train_embs[batch_idx].append(embs.cpu())\n",
    "            train_col_num[batch_idx].append(len(init_permutation_i))\n",
    "            train_label[batch_idx].append(torch.tensor(predict_init == label_i).long()) # indicate whether the permutation is correct or not\n",
    "            train_class[batch_idx].append(label_i)\n",
    "\n",
    "\n",
    "            x = [0]\n",
    "            new_batch_data = []\n",
    "            for col_i in x:\n",
    "                if col_i == 0:\n",
    "                    if len(new_batch_data) == 0:\n",
    "                        cls_indexes_value = 0\n",
    "                    else:\n",
    "                        cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "            new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "            cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "            logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "            train_target_embs[batch_idx].append(embs_temp.cpu())\n",
    "\n",
    "            num_cols.append(len(init_permutation_i))\n",
    "            labels_test.append(batch[\"label\"].cpu().item())\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            assert -1 not in col_idx_set\n",
    "            for r in range(max(len(init_permutation_i)//2, len(init_permutation_i)-2) -1, 1, -1): # not \n",
    "                for x in itertools.combinations(init_permutation_i, r):\n",
    "                    if 0 not in x:\n",
    "                        continue\n",
    "\n",
    "                    num_permutations[batch_idx] += 1\n",
    "                    new_batch_data = []\n",
    "                    for col_i in x:\n",
    "                        if col_i == 0:\n",
    "                            if len(new_batch_data) == 0:\n",
    "                                cls_indexes_value = 0\n",
    "                            else:\n",
    "                                cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                        new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                    new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                    cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                    logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                    ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n",
    "                    score_permutation[batch_idx].append(ood_score_temp)\n",
    "                    predict_temp = logits_temp.argmax().item()\n",
    "                    permutation_correctness[batch_idx].append(predict_temp == label_i)\n",
    "                    if predict_temp == label_i:\n",
    "                        continue\n",
    "                    \n",
    "                    train_data[batch_idx].append(new_batch_data.cpu())\n",
    "                    train_logits[batch_idx].append(logits_temp.detach().cpu())\n",
    "                    train_cls_indexes[batch_idx].append(cls_indexes_value)\n",
    "                    train_embs[batch_idx].append(embs_temp.cpu())\n",
    "                    train_col_num[batch_idx].append(len(x))\n",
    "                    train_label[batch_idx].append(torch.tensor(predict_temp == label_i).long()) # indicate whether the permutation is correct or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_all = torch.cat([torch.tensor(train_label[i]) for i in train_label], dim=0)\n",
    "print(len(train_labels_all))\n",
    "train_labels_all.sum()/len(train_labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_columns.iloc[:len(other_columns)//2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_columns.iloc[:len(other_columns)//2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v1: random once\n",
    "# v2: random all\n",
    "import os\n",
    "os.makedirs(\"/data/zhihao/TU/Watchog/trainfication\", exist_ok=True)\n",
    "torch.save({\"data\": train_data, \"label\": train_label, \"logits\": train_logits, \"cls_indexes\": train_cls_indexes, \"embs\": train_embs, \"target_embs\":train_target_embs , \"col_num\": train_col_num}, f\"/data/zhihao/TU/Watchog/trainfication/{args.task}_train_data_gt.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataloader_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_dataloader_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"/data/zhihao/TU/Watchog/trainfication\", exist_ok=True)\n",
    "torch.save({\"data\": train_data, \"label\": train_label, \"logits\": train_logits, \"cls_indexes\": train_cls_indexes, \"embs\": train_embs, \"target_embs\":train_target_embs , \"col_num\": train_col_num}, f\"/data/zhihao/TU/Watchog/trainfication/{args.task}_train_data_8.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = torch.load(f\"/data/zhihao/TU/Watchog/trainfication/{args.task}_train_data_gt.pth\")\n",
    "train_data = res[\"data\"]\n",
    "train_label = res[\"label\"]\n",
    "train_logits = res[\"logits\"]\n",
    "train_cls_indexes = res[\"cls_indexes\"]\n",
    "train_embs = res[\"embs\"]\n",
    "train_target_embs = res[\"target_embs\"]\n",
    "train_col_num = res[\"col_num\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7687\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.8903)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GT only\n",
    "train_labels_all = torch.cat([torch.tensor(train_label[i]) for i in train_label], dim=0)\n",
    "print(len(train_labels_all))\n",
    "train_labels_all.sum()/len(train_labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"/data/zhihao/TU/Watchog/verification\", exist_ok=True)\n",
    "# {args.task}_veri_data: min length: max(len(init_permutation_i)//2, len(init_permutation_i)-3)\n",
    "# {args.task}_veri_data_1: min length: for those without correct permutation, \n",
    "veri_results = torch.load(f\"/data/zhihao/TU/Watchog/verification/{args.task}/GT_4_veri_data_3.pth\")\n",
    "veri_data = veri_results[\"data\"]\n",
    "veri_label = veri_results[\"label\"]\n",
    "veri_logits = veri_results[\"logits\"]\n",
    "veri_cls_indexes = veri_results[\"cls_indexes\"]\n",
    "veri_embs = veri_results[\"embs\"]\n",
    "veri_target_embs = veri_results[\"target_embs\"]\n",
    "veri_col_num = veri_results[\"col_num\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13672\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.7266)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "veri_labels_all = torch.cat([torch.tensor(veri_label[i]) for i in veri_label], dim=0)\n",
    "print(len(veri_labels_all))\n",
    "veri_labels_all.sum()/len(veri_labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = len(train_data)\n",
    "for i in veri_data:\n",
    "    train_data[num_train+i] = veri_data[i]\n",
    "    train_label[num_train+i] = veri_label[i]\n",
    "    train_logits[num_train+i] = veri_logits[i]\n",
    "    train_cls_indexes[num_train+i] = veri_cls_indexes[i]\n",
    "    train_embs[num_train+i] = veri_embs[i]\n",
    "    train_target_embs[num_train+i] = veri_target_embs[i]\n",
    "    train_col_num[num_train+i] = veri_col_num[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "883"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(veri_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141808\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.4443)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train + veri gt loader 4\n",
    "train_labels_all = torch.cat([torch.tensor(train_label[i]) for i in train_label], dim=0)\n",
    "print(len(train_labels_all))\n",
    "train_labels_all.sum()/len(train_labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21359\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.7855)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4\n",
    "train_labels_all = torch.cat([torch.tensor(train_label[i]) for i in train_label], dim=0)\n",
    "print(len(train_labels_all))\n",
    "train_labels_all.sum()/len(train_labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68132\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.4154)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4 + 8neg\n",
    "train_labels_all = torch.cat([torch.tensor(train_label[i]) for i in train_label], dim=0)\n",
    "print(len(train_labels_all))\n",
    "train_labels_all.sum()/len(train_labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141808\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.4443)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train4 + veri4 + 8neg\n",
    "train_labels_all = torch.cat([torch.tensor(train_label[i]) for i in train_label], dim=0)\n",
    "print(len(train_labels_all))\n",
    "train_labels_all.sum()/len(train_labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87280\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.5436)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8\n",
    "train_labels_all = torch.cat([torch.tensor(train_label[i]) for i in train_label], dim=0)\n",
    "print(len(train_labels_all))\n",
    "train_labels_all.sum()/len(train_labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_init_mask = []\n",
    "for i in train_label:\n",
    "    k = 0\n",
    "    for j in train_label[i]:\n",
    "        if k == 0:\n",
    "            train_init_mask.append(True)\n",
    "        else:\n",
    "            train_init_mask.append(False)\n",
    "        k += 1\n",
    "train_init_mask = torch.tensor(train_init_mask)\n",
    "train_labels_all[train_init_mask] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_init_idx = train_init_mask.nonzero().reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((train_labels_all==2).sum(), (train_labels_all==2).sum()/len(train_labels_all))\n",
    "print((train_labels_all==1).sum(), (train_labels_all==1).sum()/len(train_labels_all))\n",
    "print((train_labels_all==0).sum(), (train_labels_all==0).sum()/len(train_labels_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# veri V5\n",
    "train_embs_all = torch.cat([torch.stack(train_embs[i], dim=0) for i in train_embs], dim=0)\n",
    "print(train_embs_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4348"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_idx = torch.randperm(len(train_embs_all))[:1000]\n",
    "chosen_embs = train_embs_all[chosen_idx]\n",
    "chosen_labels = train_labels_all[chosen_idx]\n",
    "# umap \n",
    "import umap\n",
    "reducer = umap.UMAP()\n",
    "embedding = reducer.fit_transform(chosen_embs)\n",
    "chosen_colors = []\n",
    "for label in chosen_labels:\n",
    "    if label == 0:\n",
    "        chosen_colors.append(\"red\")\n",
    "    elif label == 1:\n",
    "        chosen_colors.append(\"blue\")\n",
    "    else:\n",
    "        chosen_colors.append(\"green\")\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1], c=chosen_colors, s=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_init_mask.nonzero().reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_idx = torch.randperm(len(train_embs_all))[:1000]\n",
    "chosen_init_idx = torch.randperm(len(train_init_idx))[:500]\n",
    "chosen_idx = torch.cat([chosen_idx, train_init_idx[chosen_init_idx]])\n",
    "chosen_embs = train_embs_all[chosen_idx]\n",
    "chosen_labels = train_labels_all[chosen_idx]\n",
    "# umap \n",
    "import umap\n",
    "reducer = umap.UMAP()\n",
    "embedding = reducer.fit_transform(chosen_embs)\n",
    "chosen_colors = []\n",
    "for label in chosen_labels:\n",
    "    if label == 0:\n",
    "        chosen_colors.append(\"red\")\n",
    "    elif label == 1:\n",
    "        chosen_colors.append(\"blue\")\n",
    "    else:\n",
    "        chosen_colors.append(\"green\")\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1], c=chosen_colors, s=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.makedirs(\"/data/zhihao/TU/Watchog/trainfication\", exist_ok=True)\n",
    "veri_results = torch.load( f\"/data/zhihao/TU/Watchog/verification/{args.task}_veri_data_4.pth\")\n",
    "veri_embs_4 = veri_results[\"embs\"]\n",
    "veri_label_4 = veri_results[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# veri V4\n",
    "veri_labels_all_4 = torch.cat([torch.tensor(veri_label_4[i]) for i in veri_label_4], dim=0)\n",
    "print(len(veri_labels_all_4))\n",
    "veri_labels_all_4.sum()/len(veri_labels_all_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# veri V4\n",
    "veri_embs_all_4 = torch.cat([torch.stack(veri_embs_4[i], dim=0) for i in veri_embs_4], dim=0)\n",
    "print(veri_embs_all_4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_idx = torch.randperm(len(veri_embs_all_4))[:1000]\n",
    "chosen_embs = veri_embs_all_4[chosen_idx]\n",
    "chosen_labels = veri_labels_all_4[chosen_idx]\n",
    "# umap \n",
    "import umap\n",
    "reducer = umap.UMAP()\n",
    "embedding = reducer.fit_transform(chosen_embs)\n",
    "chosen_colors = ['red' if label == 0 else 'blue' for label in chosen_labels]\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1], c=chosen_colors, s=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3463"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_2\n",
    "import os\n",
    "os.makedirs(f\"/data/zhihao/TU/Watchog/verification/{args.task}\", exist_ok=True)\n",
    "torch.save({\"data\": veri_data, \"label\": veri_label, \"logits\": veri_logits, \"cls_indexes\": veri_cls_indexes, \"embs\": veri_embs, \"target_embs\":veri_target_embs , \"col_num\": veri_col_num}, f\"/data/zhihao/TU/Watchog/verification/{args.task}/GT_4_veri_data_2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_3\n",
    "import os\n",
    "os.makedirs(f\"/data/zhihao/TU/Watchog/verification/{args.task}\", exist_ok=True)\n",
    "torch.save({\"data\": veri_data, \"label\": veri_label, \"logits\": veri_logits, \"cls_indexes\": veri_cls_indexes, \"embs\": veri_embs, \"target_embs\":veri_target_embs , \"col_num\": veri_col_num}, f\"/data/zhihao/TU/Watchog/verification/{args.task}/GT_4_veri_data_3.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_4\n",
    "import os\n",
    "os.makedirs(f\"/data/zhihao/TU/Watchog/verification/{args.task}\", exist_ok=True)\n",
    "torch.save({\"data\": train_data, \"label\": train_label, \"logits\": train_logits, \"cls_indexes\": train_cls_indexes, \"embs\": train_embs, \"target_embs\":train_target_embs , \"col_num\": train_col_num}, f\"/data/zhihao/TU/Watchog/verification/{args.task}/GT_4_veri_data_4.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4\n",
    "import os\n",
    "os.makedirs(f\"/data/zhihao/TU/Watchog/verification/{args.task}\", exist_ok=True)\n",
    "torch.save({\"data\": train_data, \"label\": train_label, \"logits\": train_logits, \"cls_indexes\": train_cls_indexes, \"embs\": train_embs, \"target_embs\":train_target_embs , \"col_num\": train_col_num}, f\"/data/zhihao/TU/Watchog/verification/{args.task}/GT_4_veri_data.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 + 8neg\n",
    "import os\n",
    "os.makedirs(f\"/data/zhihao/TU/Watchog/verification/{args.task}\", exist_ok=True)\n",
    "torch.save({\"data\": train_data, \"label\": train_label, \"logits\": train_logits, \"cls_indexes\": train_cls_indexes, \"embs\": train_embs, \"target_embs\":train_target_embs , \"col_num\": train_col_num}, f\"/data/zhihao/TU/Watchog/verification/{args.task}/GT_4_veri_data_1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# veri_data_5: train + veri gt_loader col=4\n",
    "import os\n",
    "os.makedirs(f\"/data/zhihao/TU/Watchog/verification/{args.task}\", exist_ok=True)\n",
    "torch.save({\"data\": train_data, \"label\": train_label, \"logits\": train_logits, \"cls_indexes\": train_cls_indexes, \"embs\": train_embs, \"target_embs\":train_target_embs , \"col_num\": train_col_num}, f\"/data/zhihao/TU/Watchog/verification/{args.task}/GT_4_veri_data_5.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_unlabeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid 1\n",
      "valid 2\n",
      "valid 3\n",
      "valid 4\n",
      "valid 885\n",
      "*********************Threshold: 1.5****************************\n"
     ]
    }
   ],
   "source": [
    "valid_dataset_lb = GittablesTablewiseIterateLabelDataset(cv=cv,\n",
    "                            split=\"valid\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only='all' not in task,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\",\n",
    "                            max_unlabeled=8)\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "valid_dataloader_lb = DataLoader(valid_dataset_lb,\n",
    "                                batch_size=1,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)\n",
    "\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "import torch.nn.functional as F\n",
    "veri_data = defaultdict(list)\n",
    "veri_logits = defaultdict(list)\n",
    "veri_cls_indexes = defaultdict(list)\n",
    "veri_target_col_mask = defaultdict(list)\n",
    "veri_embs = defaultdict(list)\n",
    "veri_target_embs = defaultdict(list)\n",
    "veri_col_num = defaultdict(list)\n",
    "veri_label = defaultdict(list)\n",
    "veri_class = defaultdict(list)\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "for threshold in [1.5]:\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    log = defaultdict(list)\n",
    "    num_cols = []\n",
    "    corrected = 0\n",
    "    total_mistakes = 0\n",
    "    num_permutations = {}\n",
    "    init_permutation = {}\n",
    "    init_correctness = {}\n",
    "    score_init = {}\n",
    "    score_permutation = defaultdict(list)\n",
    "    permutation_correctness = defaultdict(list)\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(valid_dataloader_lb):\n",
    "            cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "            target_col_mask = batch[\"target_col_mask\"].T\n",
    "            logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "            score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
    "            label_i = batch[\"label\"].item()\n",
    "            predict_init = logits.argmax().item()\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            init_permutation[batch_idx] = init_permutation_i\n",
    "            if predict_init == label_i:\n",
    "                init_correctness[batch_idx] = True\n",
    "            else:\n",
    "                init_correctness[batch_idx] = False\n",
    "            num_permutations[batch_idx] = 0\n",
    "            \n",
    "            x = [0]\n",
    "            new_batch_data = []\n",
    "            for col_i in x:\n",
    "                if col_i == 0:\n",
    "                    if len(new_batch_data) == 0:\n",
    "                        cls_indexes_value = 0\n",
    "                    else:\n",
    "                        cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "            new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "            cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "            logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "            veri_target_embs[batch_idx].append(embs_temp.cpu())\n",
    "\n",
    "\n",
    "            num_cols.append(len(init_permutation_i))\n",
    "            labels_test.append(batch[\"label\"].cpu().item())\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            assert -1 not in col_idx_set\n",
    "            for r in range(len(init_permutation_i), 0, -1): # not \n",
    "                for x in itertools.combinations(init_permutation_i, r):\n",
    "                    if 0 not in x:\n",
    "                        continue\n",
    "\n",
    "                    num_permutations[batch_idx] += 1\n",
    "                    new_batch_data = []\n",
    "                    for col_i in x:\n",
    "                        if col_i == 0:\n",
    "                            if len(new_batch_data) == 0:\n",
    "                                cls_indexes_value = 0\n",
    "                            else:\n",
    "                                cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                        new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                    new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                    cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                    logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                    ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n",
    "                    score_permutation[batch_idx].append(ood_score_temp)\n",
    "                    predict_temp = logits_temp.argmax().item()\n",
    "                    permutation_correctness[batch_idx].append(predict_temp == label_i)\n",
    "\n",
    "                    if predict_temp == label_i and len(x) > 4:\n",
    "                        continue\n",
    "                    \n",
    "                    veri_data[batch_idx].append(new_batch_data.cpu())\n",
    "                    veri_logits[batch_idx].append(logits_temp.detach().cpu())\n",
    "                    veri_cls_indexes[batch_idx].append(cls_indexes_value)\n",
    "                    veri_embs[batch_idx].append(embs_temp.cpu())\n",
    "                    veri_col_num[batch_idx].append(len(x))\n",
    "                    veri_label[batch_idx].append(torch.tensor(predict_temp == label_i).long()) # indicate whether the permutation is correct or not\n",
    "                    veri_class[batch_idx].append(label_i)\n",
    "\n",
    "import os\n",
    "os.makedirs(f\"/data/zhihao/TU/Watchog/verification/{args.task}\", exist_ok=True)\n",
    "torch.save({\"data\": veri_data, \"label\": veri_label, \"logits\": veri_logits, \"cls_indexes\": veri_cls_indexes, \"embs\": veri_embs, \"target_embs\":veri_target_embs , \"col_num\": veri_col_num}, f\"/data/zhihao/TU/Watchog/verification/{args.task}/GT_4_veri_data_3.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(f\"/data/zhihao/TU/Watchog/verification/{args.task}\", exist_ok=True)\n",
    "torch.save({\"data\":train_data, \"label\": train_label, \"logits\": train_logits, \"cls_indexes\": train_cls_indexes, \"embs\": train_embs, \"target_embs\":train_target_embs , \"col_num\": train_col_num}, f\"/data/zhihao/TU/Watchog/verification/{args.task}/GT_4_veri_data.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid 1\n",
      "valid 2\n",
      "valid 3\n",
      "valid 4\n",
      "valid 885\n",
      "*********************Threshold: 1.5****************************\n"
     ]
    }
   ],
   "source": [
    "valid_dataset_lb = GittablesTablewiseIterateLabelDataset(cv=cv,\n",
    "                            split=\"valid\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only='all' not in task,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\",\n",
    "                            max_unlabeled=4)\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "valid_dataloader_lb = DataLoader(valid_dataset_lb,\n",
    "                                batch_size=1,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)\n",
    "\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "import torch.nn.functional as F\n",
    "veri_data = defaultdict(list)\n",
    "veri_logits = defaultdict(list)\n",
    "veri_cls_indexes = defaultdict(list)\n",
    "veri_target_col_mask = defaultdict(list)\n",
    "veri_embs = defaultdict(list)\n",
    "veri_target_embs = defaultdict(list)\n",
    "veri_col_num = defaultdict(list)\n",
    "veri_label = defaultdict(list)\n",
    "veri_class = defaultdict(list)\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "for threshold in [1.5]:\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    log = defaultdict(list)\n",
    "    num_cols = []\n",
    "    corrected = 0\n",
    "    total_mistakes = 0\n",
    "    num_permutations = {}\n",
    "    init_permutation = {}\n",
    "    init_correctness = {}\n",
    "    score_init = {}\n",
    "    score_permutation = defaultdict(list)\n",
    "    permutation_correctness = defaultdict(list)\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(valid_dataloader_lb):\n",
    "            cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "            target_col_mask = batch[\"target_col_mask\"].T\n",
    "            logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "            score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
    "            label_i = batch[\"label\"].item()\n",
    "            predict_init = logits.argmax().item()\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            init_permutation[batch_idx] = init_permutation_i\n",
    "            if predict_init == label_i:\n",
    "                init_correctness[batch_idx] = True\n",
    "            else:\n",
    "                init_correctness[batch_idx] = False\n",
    "            num_permutations[batch_idx] = 0\n",
    "            \n",
    "            x = [0]\n",
    "            new_batch_data = []\n",
    "            for col_i in x:\n",
    "                if col_i == 0:\n",
    "                    if len(new_batch_data) == 0:\n",
    "                        cls_indexes_value = 0\n",
    "                    else:\n",
    "                        cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "            new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "            cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "            logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "            veri_target_embs[batch_idx].append(embs_temp.cpu())\n",
    "\n",
    "\n",
    "            num_cols.append(len(init_permutation_i))\n",
    "            labels_test.append(batch[\"label\"].cpu().item())\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            assert -1 not in col_idx_set\n",
    "            for r in range(len(init_permutation_i), 0, -1): # not \n",
    "                for x in itertools.combinations(init_permutation_i, r):\n",
    "                    if 0 not in x:\n",
    "                        continue\n",
    "\n",
    "                    num_permutations[batch_idx] += 1\n",
    "                    new_batch_data = []\n",
    "                    for col_i in x:\n",
    "                        if col_i == 0:\n",
    "                            if len(new_batch_data) == 0:\n",
    "                                cls_indexes_value = 0\n",
    "                            else:\n",
    "                                cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                        new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                    new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                    cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                    logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                    ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n",
    "                    score_permutation[batch_idx].append(ood_score_temp)\n",
    "                    predict_temp = logits_temp.argmax().item()\n",
    "                    permutation_correctness[batch_idx].append(predict_temp == label_i)\n",
    "\n",
    "                    # if predict_temp == label_i and len(x) < max(len(init_permutation_i)//2, len(init_permutation_i)-2):\n",
    "                    #     continue\n",
    "                    \n",
    "                    veri_data[batch_idx].append(new_batch_data.cpu())\n",
    "                    veri_logits[batch_idx].append(logits_temp.detach().cpu())\n",
    "                    veri_cls_indexes[batch_idx].append(cls_indexes_value)\n",
    "                    veri_embs[batch_idx].append(embs_temp.cpu())\n",
    "                    veri_col_num[batch_idx].append(len(x))\n",
    "                    veri_label[batch_idx].append(torch.tensor(predict_temp == label_i).long()) # indicate whether the permutation is correct or not\n",
    "                    veri_class[batch_idx].append(label_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_ratio = []\n",
    "for i in range(len(veri_label)):\n",
    "    pos_ratio.append(torch.tensor(veri_label[i]).sum().item()/len(veri_label[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(pos_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2129)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pos_ratio = []\n",
    "for i in range(len(test_label)):\n",
    "    pos_ratio.append(torch.tensor(test_label[i]).sum().item()/len(test_label[i]))\n",
    "import seaborn as sns\n",
    "sns.histplot(pos_ratio)\n",
    "pos_ratio = torch.tensor(pos_ratio)\n",
    "print((pos_ratio[pos_ratio<1]>0).sum()/len(pos_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save({\"data\": test_data, \"logits\": test_logits, \"cls_indexes\": test_cls_indexes, \n",
    "#             \"embs\": test_embs, \"target_embs\":test_target_embs, \"col_num\": test_col_num, \"label\": test_label, \"class\": test_class}, f\"/data/zhihao/TU/Watchog/verification/{args.task}/GT_8_test_data.pth\")\n",
    "res = torch.load( f\"/data/zhihao/TU/Watchog/verification/{args.task}/GT_4_test_data.pth\")\n",
    "test_label = res[\"label\"]\n",
    "test_col_num = res[\"col_num\"]\n",
    "col_correct_ratio = defaultdict(list)\n",
    "for i in range(len(test_label)):\n",
    "    col_num = torch.tensor(test_col_num[i]).reshape(-1)\n",
    "    label = torch.tensor(test_label[i]).reshape(-1)\n",
    "    for j in col_num.unique():\n",
    "        col_correct_ratio[j.item()].append(label[col_num==j].sum().item()/len(label[col_num==j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.5336405634880066\n",
      "2 0.5189114212989807\n",
      "3 0.5196802616119385\n",
      "4 0.5108054876327515\n"
     ]
    }
   ],
   "source": [
    "for i in col_correct_ratio:\n",
    "    print(i, torch.tensor(col_correct_ratio[i]).mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 2, 2, 1]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_col_num[i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(1), tensor(1), tensor(1), tensor(1)]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3373)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.makedirs(\"/data/zhihao/TU/Watchog/verification\", exist_ok=True)\n",
    "res = torch.load( f\"/data/zhihao/TU/Watchog/verification/{args.task}/GT_8_test_data.pth\")\n",
    "test_label = res[\"label\"]\n",
    "pos_ratio = []\n",
    "for i in range(len(test_label)):\n",
    "    pos_ratio.append(torch.tensor(test_label[i]).sum().item()/len(test_label[i]))\n",
    "import seaborn as sns\n",
    "sns.histplot(pos_ratio)\n",
    "pos_ratio = torch.tensor(pos_ratio)\n",
    "print((pos_ratio[pos_ratio<1]>0).sum()/len(pos_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9994431138038635,\n",
       " 0.995649516582489,\n",
       " 0.9986926913261414,\n",
       " 0.9993484616279602,\n",
       " 0.5446780323982239,\n",
       " 0.9180978536605835,\n",
       " 0.9985690116882324]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_permutation[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, False, False, False, False, False, False]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permutation_correctness[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.5163)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4\n",
    "veri_labels_all = torch.cat([torch.tensor(veri_label[i]) for i in veri_label], dim=0)\n",
    "print(len(veri_labels_all))\n",
    "veri_labels_all.sum()/len(veri_labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6870\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.5194)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4 data_2\n",
    "veri_labels_all = torch.cat([torch.tensor(veri_label[i]) for i in veri_label], dim=0)\n",
    "print(len(veri_labels_all))\n",
    "veri_labels_all.sum()/len(veri_labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61330\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.3576)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4 data_3 4+ 8neg\n",
    "veri_labels_all = torch.cat([torch.tensor(veri_label[i]) for i in veri_label], dim=0)\n",
    "print(len(veri_labels_all))\n",
    "veri_labels_all.sum()/len(veri_labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61330\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.3576)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4 data_3 4+ 8neg\n",
    "veri_labels_all = torch.cat([torch.tensor(veri_label[i]) for i in veri_label], dim=0)\n",
    "print(len(veri_labels_all))\n",
    "veri_labels_all.sum()/len(veri_labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60445\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.3550)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4 + 8neg\n",
    "veri_labels_all = torch.cat([torch.tensor(veri_label[i]) for i in veri_label], dim=0)\n",
    "print(len(veri_labels_all))\n",
    "veri_labels_all.sum()/len(veri_labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols_valid = []\n",
    "for i in range(len(valid_dataset_iter)):\n",
    "    num_cols_valid.append(valid_dataset_iter[i]['initial_num_col'])\n",
    "num_cols_valid = torch.tensor(num_cols_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(num_cols_valid>16).sum()/len(num_cols_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(num_cols_valid>12).sum()/len(num_cols_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(num_cols_valid>8).sum()/len(num_cols_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(num_cols_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop one column for column correlation\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "import torch.nn.functional as F\n",
    "veri_data = defaultdict(list)\n",
    "veri_logits = defaultdict(list)\n",
    "veri_cls_indexes = defaultdict(list)\n",
    "veri_target_col_mask = defaultdict(list)\n",
    "veri_embs = defaultdict(list)\n",
    "veri_col_num = defaultdict(list)\n",
    "veri_label = defaultdict(list)\n",
    "veri_class = defaultdict(list)\n",
    "veri_target_embs = defaultdict(list)\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "for threshold in [1.5]:\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    log = defaultdict(list)\n",
    "    num_cols = []\n",
    "    corrected = 0\n",
    "    total_mistakes = 0\n",
    "    num_permutations = {}\n",
    "    init_permutation = {}\n",
    "    init_correctness = {}\n",
    "    score_init = {}\n",
    "    score_permutation = defaultdict(list)\n",
    "    permutation_correctness = defaultdict(list)\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(valid_dataloader_iter):\n",
    "            cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "            target_col_mask = batch[\"target_col_mask\"].T\n",
    "            logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "            score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
    "            label_i = batch[\"label\"].item()\n",
    "            predict_init = logits.argmax().item()\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            init_permutation[batch_idx] = init_permutation_i\n",
    "            if predict_init == label_i:\n",
    "                init_correctness[batch_idx] = True\n",
    "            else:\n",
    "                init_correctness[batch_idx] = False\n",
    "            num_permutations[batch_idx] = 0\n",
    "\n",
    "            x = [0]\n",
    "            new_batch_data = []\n",
    "            for col_i in x:\n",
    "                if col_i == 0:\n",
    "                    if len(new_batch_data) == 0:\n",
    "                        cls_indexes_value = 0\n",
    "                    else:\n",
    "                        cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "            new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "            cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "            logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "            veri_target_embs[batch_idx].append(embs_temp.cpu())\n",
    "\n",
    "            num_cols.append(len(init_permutation_i))\n",
    "            labels_test.append(batch[\"label\"].cpu().item())\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            assert -1 not in col_idx_set\n",
    "            for r in range(len(init_permutation_i), len(init_permutation_i)-2, -1): # not \n",
    "                for x in itertools.combinations(init_permutation_i, r):\n",
    "                    if 0 not in x:\n",
    "                        continue\n",
    "\n",
    "                    num_permutations[batch_idx] += 1\n",
    "                    new_batch_data = []\n",
    "                    for col_i in x:\n",
    "                        if col_i == 0:\n",
    "                            if len(new_batch_data) == 0:\n",
    "                                cls_indexes_value = 0\n",
    "                            else:\n",
    "                                cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                        new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                    new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                    cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                    logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                    ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n",
    "                    score_permutation[batch_idx].append(ood_score_temp)\n",
    "                    predict_temp = logits_temp.argmax().item()\n",
    "                    permutation_correctness[batch_idx].append(predict_temp == label_i)\n",
    "                    \n",
    "                    veri_data[batch_idx].append(new_batch_data.cpu())\n",
    "                    veri_logits[batch_idx].append(logits_temp.detach().cpu())\n",
    "                    veri_cls_indexes[batch_idx].append(cls_indexes_value)\n",
    "                    veri_embs[batch_idx].append(embs_temp.cpu())\n",
    "                    veri_col_num[batch_idx].append(len(x))\n",
    "                    if predict_init != label_i and predict_temp == label_i:\n",
    "                        veri_label[batch_idx].append(torch.tensor(1).long())\n",
    "                    elif predict_init == label_i and predict_temp != label_i:\n",
    "                        veri_label[batch_idx].append(torch.tensor(0).long())\n",
    "                    elif predict_init == label_i and predict_temp == label_i:\n",
    "                        veri_label[batch_idx].append(torch.tensor(2).long())\n",
    "                    else:\n",
    "                        veri_label[batch_idx].append(torch.tensor(3).long())\n",
    "                    veri_class[batch_idx].append(label_i)\n",
    "            assert len(veri_label[batch_idx]) == len(init_permutation_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for veri_i in veri_label:\n",
    "    context_embs = veri_embs[veri_i][0].reshape(-1)\n",
    "    for veri_j in range(1, len(veri_label[veri_i])):\n",
    "        if label_version == 0:\n",
    "            if veri_label[veri_i][veri_j] != 0 or veri_label[veri_i][veri_j-1] != 1:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "veri_labels_all = torch.cat([torch.tensor(veri_label[i]) for i in veri_label], dim=0)\n",
    "print(len(veri_labels_all))\n",
    "for i in range(4):\n",
    "    print((veri_labels_all==i).sum(), (veri_labels_all==i).sum()/len(veri_labels_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "veri_labels_all = torch.cat([torch.tensor(veri_label[i])[1:] for i in veri_label], dim=0)\n",
    "print(len(veri_labels_all))\n",
    "for i in range(4):\n",
    "    print((veri_labels_all==i).sum(), (veri_labels_all==i).sum()/len(veri_labels_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "        self.pos_iter[anchor_idx] = iter(self.veri_pos_embs[anchor_idx])\n",
    "        self.neg_iter[anchor_idx] = iter(self.veri_neg_embs[anchor_idx])\n",
    "        # Shuffle for randomness\n",
    "        random.shuffle(self.pos_embeddings[anchor_idx])\n",
    "        random.shuffle(self.neg_embeddings[anchor_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"/data/zhihao/TU/Watchog/verification\", exist_ok=True)\n",
    "torch.save({\"data\": veri_data, \"label\": veri_label, \"logits\": veri_logits, \"cls_indexes\": veri_cls_indexes, \"embs\": veri_embs, \"target_embs\":veri_target_embs , \"col_num\": veri_col_num}, f\"/data/zhihao/TU/Watchog/verification/{args.task}_veri_data.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = torch.load(f\"/data/zhihao/TU/Watchog/verification/SOTAB_veri_data.pth\")\n",
    "veri_label_sotab = res[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "veri_label_sotab_all = []\n",
    "for i in veri_label_sotab:\n",
    "    veri_label_sotab_all += veri_label_sotab[i]\n",
    "veri_label_sotab_all = torch.tensor(veri_label_sotab_all).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(veri_label_sotab_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veri_label_sotab_all.sum()/len(veri_label_sotab_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = torch.load(f\"/data/zhihao/TU/Watchog/verification/{args.task}_veri_data.pth\")\n",
    "veri_label_old = res[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = torch.load(f\"/data/zhihao/TU/Watchog/verification/{args.task}_veri_data_1.pth\")\n",
    "veri_label_1 = res1[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "veri_label_old_all = []\n",
    "for i in veri_label_old:\n",
    "    veri_label_old_all += veri_label_old[i]\n",
    "veri_label_old_all = torch.tensor(veri_label_old_all).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "veri_label_1_all = []\n",
    "for i in veri_label_1:\n",
    "    veri_label_1_all += veri_label_1[i]\n",
    "veri_label_1_all = torch.tensor(veri_label_1_all).reshape(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(veri_label_old_all))\n",
    "print(veri_label_old_all.sum()/len(veri_label_old_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(veri_label_1_all))\n",
    "print(veri_label_1_all.sum()/len(veri_label_1_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def veri_collate_fn(pad_token_id, binary=False):\n",
    "    '''padder for input batch'''\n",
    "    \n",
    "    def padder(samples):    \n",
    "        batch = {}\n",
    "        if \"embs\" in samples[0]:\n",
    "            embs = torch.stack([sample[\"embs\"] for sample in samples], dim=0)\n",
    "            batch[\"embs\"] = embs\n",
    "        \n",
    "        if \"data\" in samples[0]:\n",
    "            data = []\n",
    "            for sample in samples:\n",
    "                data.extend(sample[\"data\"])\n",
    "            data =torch.nn.utils.rnn.pad_sequence(\n",
    "                data, padding_value=pad_token_id)\n",
    "            batch[\"data\"] = data\n",
    "        if \"label\" in samples[0]:\n",
    "            label = torch.cat([sample[\"label\"] for sample in samples], dim=-1)\n",
    "            batch[\"label\"] = label\n",
    "        if \"cls_indexes\" in samples[0]:\n",
    "            i = 0\n",
    "            cls_indexes = []\n",
    "            for sample in samples:\n",
    "                for value in sample[\"cls_indexes\"]:\n",
    "                    cls_indexes.append(torch.tensor([i, value]))\n",
    "                    i += 1\n",
    "            cls_indexes = torch.stack(cls_indexes, dim=0).long()\n",
    "            batch[\"cls_indexes\"] = cls_indexes\n",
    "        return batch\n",
    "    \n",
    "    def padder_binary(samples):   \n",
    "\n",
    "        label = torch.cat([sample[\"label\"] for sample in samples], dim=-1)\n",
    "        batch = {\"label\": label}\n",
    "        if  \"data\" in samples[0]:\n",
    "            data = torch.nn.utils.rnn.pad_sequence(\n",
    "                [sample[\"data\"] for sample in samples], padding_value=pad_token_id)\n",
    "            batch[\"data\"] = data\n",
    "        if \"cls_indexes\" in samples[0]:\n",
    "            i = 0\n",
    "            cls_indexes = []\n",
    "            for sample in samples:\n",
    "                value =  sample[\"cls_indexes\"]\n",
    "                cls_indexes.append(torch.tensor([i, value]))\n",
    "                i += 1\n",
    "            cls_indexes = torch.stack(cls_indexes, dim=0).long()\n",
    "            batch[\"cls_indexes\"] = cls_indexes\n",
    "        if \"embs\" in samples[0]:\n",
    "            embs = torch.stack([sample[\"embs\"] for sample in samples], dim=0)\n",
    "            batch[\"embs\"] = embs\n",
    "        if \"logits\" in samples[0]:\n",
    "            logits = torch.stack([sample[\"logits\"] for sample in samples], dim=0)\n",
    "            batch[\"logits\"] = logits\n",
    "        return batch\n",
    "    if binary:\n",
    "        return padder_binary\n",
    "    else:\n",
    "        return padder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VerificationCompareDataset(data.Dataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            data_path: str = \"/data/zhihao/TU/Watchog/verification/gt-semtab22-dbpedia-all0_veri_data.pth\",\n",
    "            pos_ratio = None, # clone the negative samples\n",
    "            context = None,\n",
    "            ): \n",
    "        \n",
    "        self.num_neg = int((1-pos_ratio)/pos_ratio)\n",
    "        self.context = context\n",
    "        \n",
    "        data_raw = torch.load(data_path)\n",
    "        veri_label = data_raw[\"label\"]\n",
    "        veri_data = data_raw[\"data\"]\n",
    "        veri_cls_indexes = data_raw[\"cls_indexes\"]\n",
    "        veri_embs = data_raw[\"embs\"]\n",
    "        veri_target_embs = data_raw[\"target_embs\"]\n",
    "        veri_logits = data_raw[\"logits\"]\n",
    "        \n",
    "        \n",
    "        self.veri_pos_embs = defaultdict(list)\n",
    "        self.veri_neg_embs = defaultdict(list)\n",
    "        self.veri_anchor_embs = defaultdict(list)\n",
    "        \n",
    "        # self.veri_label = {}\n",
    "        # self.veri_logits = {}\n",
    "        # self.veri_cls_indexes = {}\n",
    "        # self.veri_logits = {}\n",
    "        i = 0\n",
    "        for veri_i in veri_label:\n",
    "            if 1 not in veri_label[veri_i] or 0 not in veri_label[veri_i]:\n",
    "                continue\n",
    "            # save anchor emb\n",
    "            if context is None or context == \"None\" or context == \"init\":\n",
    "                self.veri_anchor_embs[i].append(veri_embs[veri_i][0])\n",
    "            elif context == \"target\":\n",
    "                self.veri_anchor_embs[i].append(veri_target_embs[veri_i][0])        \n",
    "            else:\n",
    "                raise ValueError(\"context {} is not supported\".format(context))\n",
    "            # save pos and neg embs\n",
    "            for veri_j in range(len(veri_label[veri_i])):\n",
    "                if veri_label[veri_i][veri_j] == 1:\n",
    "                    self.veri_pos_embs[i].append(veri_embs[veri_i][veri_j])\n",
    "                else:\n",
    "                    self.veri_neg_embs[i].append(veri_embs[veri_i][veri_j])\n",
    "            i += 1\n",
    "\n",
    "        # Maintain the iteration state for each anchor\n",
    "        self.pos_iter = {anchor_idx: iter(pos_embs) for anchor_idx, pos_embs in self.veri_pos_embs.items()}\n",
    "        self.neg_iter = {anchor_idx: iter(neg_embs) for anchor_idx, neg_embs in self.veri_neg_embs.items()}\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.veri_anchor_embs)\n",
    "\n",
    "    def reset_iterators(self, anchor_idx, type=\"pos\"):\n",
    "        \"\"\"Reset the iterator for the given anchor when all positives or negatives are iterated through.\"\"\"\n",
    "        if type == \"pos\":\n",
    "            self.pos_iter[anchor_idx] = iter(self.veri_pos_embs[anchor_idx])\n",
    "            random.shuffle(self.veri_pos_embs[anchor_idx])\n",
    "        else:\n",
    "            self.neg_iter[anchor_idx] = iter(self.veri_neg_embs[anchor_idx])\n",
    "            random.shuffle(self.veri_neg_embs[anchor_idx])\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        anchor_emb = self.veri_anchor_embs[idx]\n",
    "\n",
    "        # Get one positive embedding\n",
    "        try:\n",
    "            pos_emb = next(self.pos_iter[idx])\n",
    "        except StopIteration:\n",
    "            # If we've exhausted all positives, reset and shuffle\n",
    "            self.reset_iterators(idx, type=\"pos\")\n",
    "            pos_emb = next(self.pos_iter[idx])\n",
    "\n",
    "        # Get N negative embeddings\n",
    "        neg_embs = []\n",
    "        for _ in range(self.num_neg):\n",
    "            try:\n",
    "                neg_emb = next(self.neg_iter[idx])\n",
    "                neg_embs.append(neg_emb)\n",
    "            except StopIteration:\n",
    "                # If we've exhausted all negatives, reset and shuffle\n",
    "                self.reset_iterators(idx, type=\"neg\")\n",
    "                neg_emb = next(self.neg_iter[idx])\n",
    "                neg_embs.append(neg_emb)\n",
    "        if self.context is None or self.context == \"None\":\n",
    "            embs = [pos_emb] + neg_embs\n",
    "        else:\n",
    "            embs = [anchor_emb, pos_emb] + neg_embs\n",
    "        embs = torch.stack(embs, dim=0)\n",
    "        \n",
    "        \n",
    "        \n",
    "        return {\n",
    "            # \"data\": self.veri_data[idx].reshape(-1),\n",
    "            \"embs\": embs,\n",
    "            # \"label\": self.veri_label[idx],\n",
    "            # \"logits\": self.veri_logits[idx],\n",
    "            # \"cls_indexes\": self.veri_cls_indexes[idx], \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_comp = VerificationCompareDataset(pos_ratio=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "veri_comp_padder = veri_collate_fn(0)\n",
    "veri_comp_dataloader = data.DataLoader(\n",
    "    dataset_comp, batch_size=5, shuffle=True, num_workers=4, collate_fn=veri_comp_padder\n",
    ")\n",
    "num = 0\n",
    "for batch_idx, batch in enumerate(veri_comp_dataloader):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[\"embs\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = nn.MultiheadAttention(embed_dim=128, num_heads=2, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = torch.randn(32, 2, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = torch.randn(32, 1, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = attention(q, embs, embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = ffn(batch[\"embs\"])\n",
    "pos_scores, neg_scores = scores[:, 0], scores[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "margin = 0.1\n",
    "loss = torch.clamp(pos_scores - neg_scores + margin, min=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_comp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "labels_test = []\n",
    "for batch in veri_class:\n",
    "    labels_test.append(batch[0])\n",
    "sns.histplot(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, test_counts = np.unique(labels_test, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, veri_counts = np.unique(labels_all, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max(test_counts)/min(test_counts), )\n",
    "veri_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "labels_all = []\n",
    "for batch in veri_class:\n",
    "    for label in veri_class[batch]:\n",
    "        labels_all.append(label)\n",
    "sns.histplot(labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs_temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_batch_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_indexes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[\"data\"].T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in veri_data:\n",
    "    assert len(veri_data[i]) == len(veri_label[i]) == len(veri_cls_indexes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_drop_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "test 1085\n",
      "*********************Threshold: 1.5****************************\n"
     ]
    }
   ],
   "source": [
    "# brute force perumate in validation TODO: restrict mamimus length of permutation\n",
    "src = None\n",
    "test_dataset_lb = GittablesTablewiseIterateLabelDataset(cv=cv,\n",
    "                            split=\"test\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only='all' not in task,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\",\n",
    "                            max_unlabeled=4)\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "test_dataloader_lb = DataLoader(test_dataset_lb,\n",
    "                                batch_size=1,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)\n",
    "\n",
    "\n",
    "\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "import torch.nn.functional as F\n",
    "test_data = defaultdict(list)\n",
    "test_logits = defaultdict(list)\n",
    "test_cls_indexes = defaultdict(list)\n",
    "test_target_col_mask = defaultdict(list)\n",
    "test_embs = defaultdict(list)\n",
    "test_col_num = defaultdict(list)\n",
    "test_label = defaultdict(list)\n",
    "test_class = defaultdict(list)\n",
    "test_target_embs = defaultdict(list)\n",
    "test_drop_idx = defaultdict(list)\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "for threshold in [1.5]:\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    log = defaultdict(list)\n",
    "    num_cols = []\n",
    "    corrected = 0\n",
    "    total_mistakes = 0\n",
    "    num_permutations = {}\n",
    "    init_permutation = {}\n",
    "    init_correctness = {}\n",
    "    score_init = {}\n",
    "    score_permutation = defaultdict(list)\n",
    "    permutation_correctness = defaultdict(list)\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(test_dataloader_lb):\n",
    "            cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "            target_col_mask = batch[\"target_col_mask\"].T\n",
    "            logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "            score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
    "            label_i = batch[\"label\"].item()\n",
    "            predict_init = logits.argmax().item()\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            init_permutation[batch_idx] = init_permutation_i\n",
    "            if predict_init == label_i:\n",
    "                init_correctness[batch_idx] = True\n",
    "            else:\n",
    "                init_correctness[batch_idx] = False\n",
    "            num_permutations[batch_idx] = 0\n",
    "\n",
    "\n",
    "            x = [0]\n",
    "            new_batch_data = []\n",
    "            for col_i in x:\n",
    "                if col_i == 0:\n",
    "                    if len(new_batch_data) == 0:\n",
    "                        cls_indexes_value = 0\n",
    "                    else:\n",
    "                        cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "            new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "            cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "            logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "            test_target_embs[batch_idx].append(embs_temp.cpu())\n",
    "\n",
    "\n",
    "            num_cols.append(len(init_permutation_i))\n",
    "            labels_test.append(batch[\"label\"].cpu())\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            assert -1 not in col_idx_set\n",
    "            for r in range(len(init_permutation_i), 0, -1): # not \n",
    "                for x in itertools.combinations(init_permutation_i, r):\n",
    "                    if 0 not in x:\n",
    "                        continue\n",
    "\n",
    "                    num_permutations[batch_idx] += 1\n",
    "                    new_batch_data = []\n",
    "                    if len(x) != len(init_permutation_i):\n",
    "                        drop_idx = (set(init_permutation_i)-set(x)).pop()\n",
    "                    else:\n",
    "                        drop_idx = -1\n",
    "                    for col_i in x:\n",
    "                        if col_i == 0:\n",
    "                            if len(new_batch_data) == 0:\n",
    "                                cls_indexes_value = 0\n",
    "                            else:\n",
    "                                cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                        new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                    new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                    cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                    logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                    ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n",
    "                    score_permutation[batch_idx].append(ood_score_temp)\n",
    "                    predict_temp = logits_temp.argmax().item()\n",
    "                    permutation_correctness[batch_idx].append(predict_temp == label_i)\n",
    "                    \n",
    "                    test_data[batch_idx].append(new_batch_data.cpu())\n",
    "                    test_logits[batch_idx].append(logits_temp.detach().cpu())\n",
    "                    test_cls_indexes[batch_idx].append(cls_indexes_value)\n",
    "                    test_embs[batch_idx].append(embs_temp.cpu())\n",
    "                    test_col_num[batch_idx].append(len(x))\n",
    "                    test_label[batch_idx].append(torch.tensor(predict_temp == label_i).long()) # indicate whether the permutation is correct or not\n",
    "                    test_class[batch_idx].append(label_i)\n",
    "                    test_drop_idx[batch_idx].append(drop_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"/data/zhihao/TU/Watchog/verification\", exist_ok=True)\n",
    "torch.save({\"data\": test_data, \"logits\": test_logits, \"cls_indexes\": test_cls_indexes, \n",
    "            \"embs\": test_embs, \"target_embs\":test_target_embs, \"col_num\": test_col_num, \"label\": test_label, \"class\": test_class}, f\"/data/zhihao/TU/Watchog/verification/{args.task}/GT_4_test_data.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_micro_f1=0.5171, ts_macro_f1=0.2538\n"
     ]
    }
   ],
   "source": [
    "labels_test = []\n",
    "logits_test = []\n",
    "col_scores = defaultdict(list)\n",
    "verifier = Verifier(norm=\"batch_norm\").to(device)\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in enumerate(test_dataloader_lb):\n",
    "        embs = test_embs[batch_idx][0].reshape(-1).to(device)\n",
    "        logits = test_logits[batch_idx][0].reshape(-1).to(device)\n",
    "        # ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "        logits_test.append(logits.detach().cpu())\n",
    "        labels_test.append(batch[\"label\"].cpu())\n",
    "    labels_test = torch.cat(labels_test, dim=0)\n",
    "    logits_test = torch.stack(logits_test, dim=0)\n",
    "    preds_test = torch.argmax(logits_test, dim=1)\n",
    "    num_cols = torch.tensor(num_cols)\n",
    "    # ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "    from sklearn.metrics import confusion_matrix, f1_score\n",
    "    mask = num_cols > 0\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach().numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    full_f1_init = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=None)\n",
    "    print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_unlabeled=2\n",
      "test\n",
      "test 1085\n",
      "ts_micro_f1=0.5346, ts_macro_f1=0.2734\n",
      "max_unlabeled=4\n",
      "test\n",
      "test 1085\n",
      "ts_micro_f1=0.5171, ts_macro_f1=0.2538\n",
      "max_unlabeled=8\n",
      "test\n",
      "test 1085\n",
      "ts_micro_f1=0.4922, ts_macro_f1=0.2192\n"
     ]
    }
   ],
   "source": [
    "# EU distance to all labeled training columns\n",
    "for max_unlabeled in [2,4, 8]:\n",
    "    print(\"max_unlabeled={}\".format(max_unlabeled))\n",
    "    src = None\n",
    "    test_dataset_lb = GittablesTablewiseIterateLabelDataset(cv=cv,\n",
    "                                split=\"test\", src=src,\n",
    "                                tokenizer=tokenizer,\n",
    "                                max_length=max_length,\n",
    "                                gt_only='all' not in task,\n",
    "                                device=device,\n",
    "                                base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                                small_tag=\"semi1\",\n",
    "                                max_unlabeled=max_unlabeled,)\n",
    "    padder = collate_fn(tokenizer.pad_token_id)\n",
    "    test_dataloader_lb = DataLoader(test_dataset_lb,\n",
    "                                    batch_size=1,\n",
    "                                #   collate_fn=collate_fn)\n",
    "                                collate_fn=padder)\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    ft_embs_test = []\n",
    "    labels_test_original = []\n",
    "    logits_test = []\n",
    "    num_cols = []\n",
    "    for batch_idx, batch in enumerate(test_dataloader_lb):\n",
    "        cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "        # target_col_mask = batch[\"target_col_mask\"].T\n",
    "        logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "        labels_test_original.append(batch[\"label\"].cpu())\n",
    "        logits_test.append(logits.detach().cpu())\n",
    "        num_cols.append(test_dataset_iter[batch_idx]['initial_num_col'])\n",
    "        ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "    labels_test_original = torch.cat(labels_test_original, dim=0)\n",
    "    logits_test = torch.stack(logits_test, dim=0)\n",
    "    preds_test = torch.argmax(logits_test, dim=1)\n",
    "    num_cols = torch.tensor(num_cols)\n",
    "    ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "    from sklearn.metrics import confusion_matrix, f1_score\n",
    "    mask = num_cols > 0\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach().numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    full_f1_init = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=None)\n",
    "    print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_unlabeled=2\n",
      "test\n",
      "test 1085\n",
      "ts_micro_f1=0.5346, ts_macro_f1=0.2734\n",
      "max_unlabeled=4\n",
      "test\n",
      "test 1085\n",
      "ts_micro_f1=0.5171, ts_macro_f1=0.2538\n",
      "max_unlabeled=8\n",
      "test\n",
      "test 1085\n",
      "ts_micro_f1=0.4866, ts_macro_f1=0.2146\n"
     ]
    }
   ],
   "source": [
    "# EU distance to all labeled training columns\n",
    "for max_unlabeled in [2,4, 8]:\n",
    "    print(\"max_unlabeled={}\".format(max_unlabeled))\n",
    "    src = None\n",
    "    test_dataset_lb = GittablesTablewiseIterateLabelDataset(cv=cv,\n",
    "                                split=\"test\", src=src,\n",
    "                                tokenizer=tokenizer,\n",
    "                                max_length=max_length,\n",
    "                                gt_only='all' not in task,\n",
    "                                device=device,\n",
    "                                base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                                small_tag=\"semi1\",\n",
    "                                max_unlabeled=max_unlabeled,\n",
    "                                adaptive_max_length=False)\n",
    "    padder = collate_fn(tokenizer.pad_token_id)\n",
    "    test_dataloader_lb = DataLoader(test_dataset_lb,\n",
    "                                    batch_size=1,\n",
    "                                #   collate_fn=collate_fn)\n",
    "                                collate_fn=padder)\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    ft_embs_test = []\n",
    "    labels_test_original = []\n",
    "    logits_test = []\n",
    "    num_cols = []\n",
    "    for batch_idx, batch in enumerate(test_dataloader_lb):\n",
    "        cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "        # target_col_mask = batch[\"target_col_mask\"].T\n",
    "        logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "        labels_test_original.append(batch[\"label\"].cpu())\n",
    "        logits_test.append(logits.detach().cpu())\n",
    "        num_cols.append(test_dataset_iter[batch_idx]['initial_num_col'])\n",
    "        ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "    labels_test_original = torch.cat(labels_test_original, dim=0)\n",
    "    logits_test = torch.stack(logits_test, dim=0)\n",
    "    preds_test = torch.argmax(logits_test, dim=1)\n",
    "    num_cols = torch.tensor(num_cols)\n",
    "    ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "    from sklearn.metrics import confusion_matrix, f1_score\n",
    "    mask = num_cols > 0\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach().numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    full_f1_init = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=None)\n",
    "    print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_unlabeled=2\n",
      "test\n",
      "test 1085\n",
      "ts_micro_f1=0.5346, ts_macro_f1=0.2734\n",
      "max_unlabeled=4\n",
      "test\n",
      "test 1085\n",
      "ts_micro_f1=0.5060, ts_macro_f1=0.2479\n",
      "max_unlabeled=8\n",
      "test\n",
      "test 1085\n",
      "ts_micro_f1=0.4747, ts_macro_f1=0.2173\n"
     ]
    }
   ],
   "source": [
    "# other columns sort by col_idx\n",
    "for max_unlabeled in [2,4, 8]:\n",
    "    print(\"max_unlabeled={}\".format(max_unlabeled))\n",
    "    src = None\n",
    "    test_dataset_lb = GittablesTablewiseIterateLabelDataset(cv=cv,\n",
    "                                split=\"test\", src=src,\n",
    "                                tokenizer=tokenizer,\n",
    "                                max_length=max_length,\n",
    "                                gt_only='all' not in task,\n",
    "                                device=device,\n",
    "                                base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                                small_tag=\"semi1\",\n",
    "                                max_unlabeled=max_unlabeled,\n",
    "                                adaptive_max_length=False)\n",
    "    padder = collate_fn(tokenizer.pad_token_id)\n",
    "    test_dataloader_lb = DataLoader(test_dataset_lb,\n",
    "                                    batch_size=1,\n",
    "                                #   collate_fn=collate_fn)\n",
    "                                collate_fn=padder)\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    ft_embs_test = []\n",
    "    labels_test_original = []\n",
    "    logits_test = []\n",
    "    num_cols = []\n",
    "    for batch_idx, batch in enumerate(test_dataloader_lb):\n",
    "        cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "        # target_col_mask = batch[\"target_col_mask\"].T\n",
    "        logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "        labels_test_original.append(batch[\"label\"].cpu())\n",
    "        logits_test.append(logits.detach().cpu())\n",
    "        num_cols.append(test_dataset_iter[batch_idx]['initial_num_col'])\n",
    "        ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "    labels_test_original = torch.cat(labels_test_original, dim=0)\n",
    "    logits_test = torch.stack(logits_test, dim=0)\n",
    "    preds_test = torch.argmax(logits_test, dim=1)\n",
    "    num_cols = torch.tensor(num_cols)\n",
    "    ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "    from sklearn.metrics import confusion_matrix, f1_score\n",
    "    mask = num_cols > 0\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach().numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    full_f1_init = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=None)\n",
    "    print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "        for batch_idx, batch in enumerate(test_dataloader_lb):\n",
    "            cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "            target_col_mask = batch[\"target_col_mask\"].T\n",
    "            logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "            score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
    "            label_i = batch[\"label\"].item()\n",
    "            predict_init = logits.argmax().item()\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            init_permutation[batch_idx] = init_permutation_i\n",
    "            if len(init_permutation[batch_idx]) > 3:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "test 1085\n",
      "*********************Threshold: 1.5****************************\n",
      "ts_micro_f1=0.5788, ts_macro_f1=0.2968\n"
     ]
    }
   ],
   "source": [
    "# brute force perumate in validation TODO: restrict mamimus length of permutation\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "src = None\n",
    "test_dataset_lb = GittablesTablewiseIterateLabelDataset(cv=cv,\n",
    "                            split=\"test\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only='all' not in task,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\",\n",
    "                            max_unlabeled=2)\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "test_dataloader_lb = DataLoader(test_dataset_lb,\n",
    "                                batch_size=1,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)\n",
    "\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "import torch.nn.functional as F\n",
    "test_data = defaultdict(list)\n",
    "test_logits = defaultdict(list)\n",
    "test_cls_indexes = defaultdict(list)\n",
    "test_target_col_mask = defaultdict(list)\n",
    "test_embs = defaultdict(list)\n",
    "test_col_num = defaultdict(list)\n",
    "test_label = defaultdict(list)\n",
    "test_class = defaultdict(list)\n",
    "test_target_embs = defaultdict(list)\n",
    "test_drop_idx = defaultdict(list)\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "for threshold in [1.5]:\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    log = defaultdict(list)\n",
    "    num_cols = []\n",
    "    corrected = 0\n",
    "    total_mistakes = 0\n",
    "    num_permutations = {}\n",
    "    init_permutation = {}\n",
    "    init_correctness = {}\n",
    "    score_init = {}\n",
    "    score_permutation = defaultdict(list)\n",
    "    permutation_correctness = defaultdict(list)\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(test_dataloader_lb):\n",
    "            cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "            target_col_mask = batch[\"target_col_mask\"].T\n",
    "            logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "            score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
    "            label_i = batch[\"label\"].item()\n",
    "            predict_init = logits.argmax().item()\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            init_permutation[batch_idx] = init_permutation_i\n",
    "            if predict_init == label_i:\n",
    "                init_correctness[batch_idx] = True\n",
    "            else:\n",
    "                init_correctness[batch_idx] = False\n",
    "            num_permutations[batch_idx] = 0\n",
    "\n",
    "\n",
    "\n",
    "            num_cols.append(len(init_permutation_i))\n",
    "            labels_test.append(batch[\"label\"].cpu())\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            assert -1 not in col_idx_set\n",
    "            found = False\n",
    "            for r in range(len(init_permutation_i), 0, -1): # not \n",
    "                for x in itertools.combinations(init_permutation_i, r):\n",
    "                    if 0 not in x:\n",
    "                        continue\n",
    "\n",
    "                    num_permutations[batch_idx] += 1\n",
    "                    new_batch_data = []\n",
    "                    if len(x) != len(init_permutation_i):\n",
    "                        drop_idx = (set(init_permutation_i)-set(x)).pop()\n",
    "                    else:\n",
    "                        drop_idx = -1\n",
    "                    for col_i in x:\n",
    "                        if col_i == 0:\n",
    "                            if len(new_batch_data) == 0:\n",
    "                                cls_indexes_value = 0\n",
    "                            else:\n",
    "                                cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                        new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                    new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                    cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                    logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                    ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n",
    "                    score_permutation[batch_idx].append(ood_score_temp)\n",
    "                    predict_temp = logits_temp.argmax().item()\n",
    "                    permutation_correctness[batch_idx].append(predict_temp == label_i)\n",
    "                    \n",
    "                    if predict_temp == label_i:\n",
    "                        found = True\n",
    "                        break\n",
    "                if found:\n",
    "                    break\n",
    "            logits_test.append(logits_temp.detach().cpu())\n",
    "    labels_test = torch.cat(labels_test, dim=0)\n",
    "    logits_test = torch.stack(logits_test, dim=0)\n",
    "    preds_test = torch.argmax(logits_test, dim=1)\n",
    "    num_cols = torch.tensor(num_cols)\n",
    "    from sklearn.metrics import confusion_matrix, f1_score\n",
    "    mask = num_cols > 0\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach().numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_micro_f1=0.4922, ts_macro_f1=0.2192\n"
     ]
    }
   ],
   "source": [
    "# 2\n",
    "# ts_micro_f1=0.5788, ts_macro_f1=0.2968\n",
    "# 4\n",
    "# *********************Threshold: 1.5****************************\n",
    "# ts_micro_f1=0.6240, ts_macro_f1=0.3520\n",
    "\n",
    "# 8\n",
    "# *********************Threshold: 1.5****************************\n",
    "# ts_micro_f1=0.6571, ts_macro_f1=0.3995\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"/data/zhihao/TU/Watchog/verification\", exist_ok=True)\n",
    "torch.save({\"data\": test_data, \"logits\": test_logits, \"cls_indexes\": test_cls_indexes, \n",
    "            \"embs\": test_embs, \"target_embs\":test_target_embs, \"col_num\": test_col_num, \"label\": test_label, \"class\": test_class}, f\"/data/zhihao/TU/Watchog/verification/{args.task}/GT_8_test_data.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_veri = torch.load(f\"/data/zhihao/TU/Watchog/verification/{args.task}_test_data.pth\")\n",
    "test_data = test_veri[\"data\"]\n",
    "test_logits = test_veri[\"logits\"]\n",
    "test_cls_indexes = test_veri[\"cls_indexes\"]\n",
    "test_embs = test_veri[\"embs\"]\n",
    "test_col_num = test_veri[\"col_num\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_micro_f1=0.5171, ts_macro_f1=0.2538\n"
     ]
    }
   ],
   "source": [
    "labels_test = []\n",
    "logits_test = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in enumerate(test_embs):\n",
    "        embs = test_embs[batch_idx][0].reshape(-1).to(device)\n",
    "        logits = test_logits[batch_idx][0].reshape(-1).to(device)\n",
    "\n",
    "\n",
    "        labels_test.append(torch.tensor(test_class[batch_idx][0]).reshape([-1,1]))\n",
    "        logits_test.append(logits.detach().cpu())\n",
    "    labels_test = torch.cat(labels_test, dim=0)\n",
    "    logits_test = torch.stack(logits_test, dim=0)\n",
    "    preds_test = torch.argmax(logits_test, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_col_num[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test = []\n",
    "logits_test = []\n",
    "col_scores = defaultdict(list)\n",
    "verifier = Verifier(norm=\"batch_norm\").to(device)\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "        embs = test_embs[batch_idx][0].reshape(-1).to(device)\n",
    "        logits = test_logits[batch_idx][0].reshape(-1).to(device)\n",
    "        # scores_init = verifier(embs)\n",
    "        max_score = -float(\"inf\")\n",
    "        target_col_mask = batch[\"target_col_mask\"].T\n",
    "        init_permutation_i = get_permutation(target_col_mask)\n",
    "        num_cols_to_drop = min(2, len(init_permutation_i)//2)\n",
    "        if len(init_permutation_i) ==1:\n",
    "            labels_test.append(batch[\"label\"].cpu())\n",
    "            logits_test.append(logits.detach().cpu())\n",
    "            continue\n",
    "        \n",
    "        for i in range(1, len(test_embs[batch_idx])):\n",
    "            logits_temp = test_logits[batch_idx][i].reshape(-1).to(device)\n",
    "            embs_temp = test_embs[batch_idx][i].reshape(-1).to(device)\n",
    "\n",
    "            scores_temp = np.random.rand()\n",
    "            predict_temp = logits_temp.argmax().item()\n",
    "            col_scores[batch_idx].append(scores_temp)\n",
    "            \n",
    "            \n",
    "        cols_to_drop = torch.tensor(col_scores[batch_idx]).argsort()[:num_cols_to_drop]\n",
    "        x = deepcopy(init_permutation_i)\n",
    "        for col_i in cols_to_drop:\n",
    "            x.remove(col_i)\n",
    "        new_batch_data = []\n",
    "        if len(x) != len(init_permutation_i):\n",
    "            drop_idx = (set(init_permutation_i)-set(x)).pop()\n",
    "        else:\n",
    "            drop_idx = -1\n",
    "        for col_i in x:\n",
    "            if col_i == 0:\n",
    "                if len(new_batch_data) == 0:\n",
    "                    cls_indexes_value = 0\n",
    "                else:\n",
    "                    cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "            new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "        new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "        cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "        logits_topk, embs_topk = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "        if len(init_permutation_i) > 4: \n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_micro_f1=0.4922, ts_macro_f1=0.2192\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_permutation_i = torch.tensor(init_permutation_i)\n",
    "init_permutation_i[init_permutation_i!=0][:num_cols_to_drop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(col_scores[batch_idx]).argsort(descending=True)[: ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(col_scores[batch_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(init_permutation_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_idx = (set(init_permutation_i)-set(x)).pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"/data/zhihao/TU/Watchog/verification\", exist_ok=True)\n",
    "torch.save({\"data\": test_data, \"logits\": test_logits, \"cls_indexes\": test_cls_indexes, \n",
    "            \"embs\": test_embs, \"target_embs\":test_target_embs, \"col_num\": test_col_num, \"label\": test_label, \"class\": test_class}, f\"/data/zhihao/TU/Watchog/verification/{args.task}_test_data_2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, r in enumerate(test_dataloader_iter):\n",
    "    try:\n",
    "        res = test_embs[i][0]\n",
    "    except:\n",
    "        print(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = torch.load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = []\n",
    "for i in veri_label:\n",
    "    all_labels.extend(veri_label[i])\n",
    "all_labels = torch.tensor(all_labels).reshape(-1)\n",
    "all_labels.sum()/len(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veri_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VerificationDataset(data.Dataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            data_path: str = \"/data/zhihao/TU/Watchog/verification/veri_data.pth\",\n",
    "            max_list_length: int = 10,\n",
    "            pos_ratio : int = 0.5, # None: only control pos_ratio to be less than 0.5\n",
    "            label_padding_value: int = -1,\n",
    "            data_padding_value: int = 0,\n",
    "            ): \n",
    "        data_raw = torch.load(data_path)\n",
    "        veri_label = data_raw[\"label\"]\n",
    "        veri_data = data_raw[\"data\"]\n",
    "        veri_cls_indexes = data_raw[\"cls_indexes\"]\n",
    "        self.label_padding_value = label_padding_value\n",
    "        self.data_padding_value = data_padding_value\n",
    "        self.max_list_length = max_list_length\n",
    "        self.pos_ratio = pos_ratio\n",
    "        self.veri_label = {}\n",
    "        self.veri_data = {}\n",
    "        self.veri_cls_indexes = {}\n",
    "        i = 0\n",
    "        for veri_i in veri_label:\n",
    "            labels_i = torch.tensor(veri_label[veri_i]).reshape(-1)\n",
    "            \n",
    "            if 0 not in labels_i or 1 not in labels_i:\n",
    "                continue\n",
    "            self.veri_data[i] = veri_data[veri_i]\n",
    "            self.veri_label[i] = labels_i\n",
    "            self.veri_cls_indexes[i] = veri_cls_indexes[veri_i]\n",
    "            i += 1\n",
    "    def sample(self, labels):\n",
    "        labels = labels.tolist()  # Convert tensor to list for easier manipulation\n",
    "        positive_indices = [i for i, label in enumerate(labels) if label == 1]\n",
    "        negative_indices = [i for i, label in enumerate(labels) if label == 0]\n",
    "\n",
    "        # Determine how many positives we can sample, respecting the ratio requirement\n",
    "        max_num_positives = max_num_negatives = min(len(positive_indices), len(negative_indices), self.max_list_length // 2)\n",
    "        \n",
    "        # Randomly sample the positives and negatives\n",
    "        sampled_positives = random.sample(positive_indices, max_num_positives)\n",
    "        sampled_negatives = random.sample(negative_indices, max_num_negatives)\n",
    "\n",
    "        # Combine and shuffle the indices\n",
    "        sampled_indices = sampled_positives + sampled_negatives\n",
    "\n",
    "        return sampled_indices\n",
    "        # {\"data\": veri_data, \"label\": veri_label, \"cls_indexes\": veri_cls_indexes}\n",
    "    def __len__(self):\n",
    "        return len(self.veri_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        labels = self.veri_label[idx]\n",
    "        sampled_indices = self.sample(labels)\n",
    "        sampled_labels = torch.tensor([labels[i] for i in sampled_indices]).reshape(-1)\n",
    "        sampled_data = [self.veri_data[idx][i].reshape(-1) for i in sampled_indices]\n",
    "        sampled_cls_indexes = torch.tensor([self.veri_cls_indexes[idx][i] for i in sampled_indices], dtype=torch.long)\n",
    "        if len(sampled_indices) < self.max_list_length:\n",
    "            sampled_labels = torch.cat([sampled_labels, torch.ones(self.max_list_length - len(sampled_labels))*self.label_padding_value])\n",
    "            sampled_data.extend([torch.tensor([self.data_padding_value]) for _ in range(self.max_list_length - len(sampled_data))])\n",
    "            sampled_cls_indexes = torch.cat([sampled_cls_indexes, torch.zeros(self.max_list_length - len(sampled_cls_indexes))])\n",
    "        return {\n",
    "            \"data\": sampled_data,\n",
    "            \"label\": sampled_labels,\n",
    "            \"cls_indexes\": sampled_cls_indexes, \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VerificationBinaryDataset(data.Dataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            data_path: str = \"/data/zhihao/TU/Watchog/verification/veri_data.pth\",\n",
    "            pos_ratio = None, # clone the negative samples\n",
    "            ): \n",
    "        data_raw = torch.load(data_path)\n",
    "        veri_label = data_raw[\"label\"]\n",
    "        veri_data = data_raw[\"data\"]\n",
    "        veri_cls_indexes = data_raw[\"cls_indexes\"]\n",
    "        veri_embs = data_raw[\"embs\"]\n",
    "        veri_logits = data_raw[\"logits\"]\n",
    "        self.neg_expand = int(1/pos_ratio)-1 if pos_ratio is not None else 1\n",
    "        self.veri_label = {}\n",
    "        self.veri_data = {}\n",
    "        self.veri_embs = {}\n",
    "        self.veri_cls_indexes = {}\n",
    "        self.veri_logits = {}\n",
    "        i = 0\n",
    "        for veri_i in veri_label:\n",
    "            for veri_j in range(len(veri_label[veri_i])):\n",
    "                if veri_label[veri_i][veri_j] == 1:\n",
    "                    labels_i = torch.tensor([1]).reshape(-1)\n",
    "                    self.veri_data[i] = veri_data[veri_i][veri_j]\n",
    "                    self.veri_label[i] = labels_i\n",
    "                    self.veri_cls_indexes[i] = veri_cls_indexes[veri_i][veri_j]\n",
    "                    self.veri_embs[i] = veri_embs[veri_i][veri_j]\n",
    "                    self.veri_logits[i] = veri_logits[veri_i][veri_j]\n",
    "                    i += 1\n",
    "                else:\n",
    "                    for _ in range(self.neg_expand):\n",
    "                        labels_i = torch.tensor([0]).reshape(-1)\n",
    "                        self.veri_data[i] = veri_data[veri_i][veri_j]\n",
    "                        self.veri_label[i] = labels_i\n",
    "                        self.veri_cls_indexes[i] = veri_cls_indexes[veri_i][veri_j]\n",
    "                        self.veri_embs[i] = veri_embs[veri_i][veri_j]\n",
    "                        self.veri_logits[i] = veri_logits[veri_i][veri_j]\n",
    "                        i += 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.veri_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            # \"data\": self.veri_data[idx].reshape(-1),\n",
    "            \"embs\": self.veri_embs[idx].reshape(-1),\n",
    "            \"label\": self.veri_label[idx],\n",
    "            \"logits\": self.veri_logits[idx],\n",
    "            # \"cls_indexes\": self.veri_cls_indexes[idx], \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(veri_dataset), len(veri_dataset.veri_data), len(veri_dataset.veri_label), len(veri_dataset.veri_cls_indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verit_binary_dataset = VerificationBinaryDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(verit_binary_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.nn.utils.rnn.pad_sequence(\n",
    "            [verit_binary_dataset[i][\"data\"] for i in range(10)], padding_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verit_binary_dataset[0][\"embs\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "verit_labels = []\n",
    "for i in range(len(verit_binary_dataset)):\n",
    "    verit_labels.append(verit_binary_dataset[i][\"label\"].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(verit_labels).sum()/len(verit_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(veri_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veri_dataset = VerificationDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(veri_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = veri_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(res[\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[\"data\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[\"label\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = []\n",
    "for i in range(len(veri_dataset)):\n",
    "    data_test.extend(veri_dataset[i][\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def veri_collate_fn(pad_token_id, binary=False):\n",
    "    '''padder for input batch'''\n",
    "    \n",
    "    def padder(samples):    \n",
    "        data = []\n",
    "        for sample in samples:\n",
    "            data.extend(sample[\"data\"])\n",
    "        data =torch.nn.utils.rnn.pad_sequence(\n",
    "            data, padding_value=pad_token_id)\n",
    "\n",
    "        label = torch.cat([sample[\"label\"] for sample in samples], dim=-1)\n",
    "        batch = {\"data\": data, \"label\": label}\n",
    "        if \"cls_indexes\" in samples[0]:\n",
    "            i = 0\n",
    "            cls_indexes = []\n",
    "            for sample in samples:\n",
    "                for value in sample[\"cls_indexes\"]:\n",
    "                    cls_indexes.append(torch.tensor([i, value]))\n",
    "                    i += 1\n",
    "            cls_indexes = torch.stack(cls_indexes, dim=0).long()\n",
    "            batch[\"cls_indexes\"] = cls_indexes\n",
    "        return batch\n",
    "    \n",
    "    def padder_binary(samples):   \n",
    "\n",
    "        label = torch.cat([sample[\"label\"] for sample in samples], dim=-1)\n",
    "        batch = {\"label\": label}\n",
    "        if  \"data\" in samples[0]:\n",
    "            data = torch.nn.utils.rnn.pad_sequence(\n",
    "                [sample[\"data\"] for sample in samples], padding_value=pad_token_id)\n",
    "            batch[\"data\"] = data\n",
    "        if \"cls_indexes\" in samples[0]:\n",
    "            i = 0\n",
    "            cls_indexes = []\n",
    "            for sample in samples:\n",
    "                value =  sample[\"cls_indexes\"]\n",
    "                cls_indexes.append(torch.tensor([i, value]))\n",
    "                i += 1\n",
    "            cls_indexes = torch.stack(cls_indexes, dim=0).long()\n",
    "            batch[\"cls_indexes\"] = cls_indexes\n",
    "        if \"embs\" in samples[0]:\n",
    "            embs = torch.stack([sample[\"embs\"] for sample in samples], dim=0)\n",
    "            batch[\"embs\"] = embs\n",
    "        if \"logits\" in samples[0]:\n",
    "            logits = torch.stack([sample[\"logits\"] for sample in samples], dim=0)\n",
    "            batch[\"logits\"] = logits\n",
    "        return batch\n",
    "    if binary:\n",
    "        return padder_binary\n",
    "    else:\n",
    "        return padder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veri_padder = veri_collate_fn(0)\n",
    "veri_dataloader = data.DataLoader(\n",
    "    veri_dataset, batch_size=args.batch_size, shuffle=True, num_workers=4, collate_fn=veri_padder\n",
    ")\n",
    "for batch in veri_dataloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "veri_binary_padder = veri_collate_fn(0, binary=True)\n",
    "veri_binary_dataloader = data.DataLoader(\n",
    "    verit_binary_dataset, batch_size=args.batch_size, shuffle=True, num_workers=4, collate_fn=veri_binary_padder\n",
    ")\n",
    "for batch_idx, batch in enumerate(veri_binary_dataloader):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[\"embs\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[\"logits\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[\"label\"].to(device).squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model = model.to(device)\n",
    "verifier.train()\n",
    "verifier = verifier.to(device)\n",
    "pos_ratio = 0.1\n",
    "pos_weight = torch.tensor([(1-pos_ratio)/pos_ratio]).to(device)\n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "for batch_idx, batch in enumerate(veri_binary_dataloader ):\n",
    "    cls_indexes = batch[\"cls_indexes\"].to(device)\n",
    "    input_data = batch[\"data\"].T.to(device)\n",
    "    logits, embs = model(input_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "    scores = verifier(embs).squeeze()\n",
    "    loss = loss_fn(scores, batch[\"label\"].to(device).squeeze().float())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " batch[\"label\"].to(device).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[\"data\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[\"data\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[\"label\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[\"cls_indexes\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "verifier = Verifier(norm=\"batch_norm\", num_layers=None).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# veri_state_dict = torch.load(\"/data/zhihao/TU/Watchog/outputs/gt-semtab22-dbpedia-all0/bert-base-uncased-fromscratch-semi1-mode@ffn-context@None-data@5-lr@5e-05-warmup@0.0-dp@0.0-norm@batch_norm-pos@0.1-poolv0-unlabeled8-randFalse-bs64-ml128-ne200-do0.0_verifier_binary_best_f1_macro.pt\")\n",
    "# veri_state_dict = torch.load(\"/data/zhihao/TU/Watchog/outputs/gt-semtab22-dbpedia-all0/bert-base-uncased-fromscratch-semi1-mode@ffn-context@None-data@5-lr@5e-05-warmup@0.0-dp@0.0-norm@batch_norm-pos@0.2-poolv0-unlabeled8-randFalse-bs64-ml128-ne200-do0.0_verifier_binary_best_f1_micro.pt\")\n",
    "# veri_state_dict = torch.load(\"/data/zhihao/TU/Watchog/outputs/gt-semtab22-dbpedia-all0/bert-base-uncased-fromscratch-semi1-mode@ffn-context@None-data@5-lr@5e-05-warmup@0.0-dp@0.0-norm@batch_norm-pos@0.1-poolv0-unlabeled8-randFalse-bs64-ml128-ne200-do0.0_verifier_binary_best_f1_micro.pt\")\n",
    "veri_state_dict = torch.load(\"/data/zhihao/TU/Watchog/outputs/gt-semtab22-dbpedia-all0/bert-base-uncased-fromscratch-semi1-mode@ffn-context@None-data@5-lr@5e-05-warmup@0.0-dp@0.0-norm@batch_norm-pos@0.2-poolv0-unlabeled8-randFalse-bs64-ml128-ne200-do0.0_verifier_binary_best_f1_micro.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verifier.load_state_dict(veri_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verifier.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(verifier.parameters(), lr=args.lr, eps=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.to(device)\n",
    "verifier.train()\n",
    "tr_loss = 0.0\n",
    "for batch_idx, batch in enumerate(veri_dataloader):\n",
    "    cls_indexes = batch[\"cls_indexes\"].to(device)\n",
    "    input_data = batch[\"data\"].T.to(device)\n",
    "    logits, embs = model(input_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "    scores = verifier(embs)\n",
    "    loss = listMLE(scores.reshape(args.batch_size, -1), batch[\"label\"].to(device).reshape(args.batch_size, -1))\n",
    "\n",
    "    accelerator.backward(loss)\n",
    "    # loss.backward()\n",
    "    tr_loss += loss.cpu().detach().item()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def listMLE(y_pred, y_true, eps=1e-10, padded_value_indicator=-1):\n",
    "    \"\"\"\n",
    "    ListMLE loss introduced in \"Listwise Approach to Learning to Rank - Theory and Algorithm\".\n",
    "    :param y_pred: predictions from the model, shape [batch_size, slate_length]\n",
    "    :param y_true: ground truth labels, shape [batch_size, slate_length]\n",
    "    :param eps: epsilon value, used for numerical stability\n",
    "    :param padded_value_indicator: an indicator of the y_true index containing a padded item, e.g. -1\n",
    "    :return: loss value, a torch.Tensor\n",
    "    \"\"\"\n",
    "    # shuffle for randomised tie resolution\n",
    "    random_indices = torch.randperm(y_pred.shape[-1])\n",
    "    y_pred_shuffled = y_pred[:, random_indices]\n",
    "    y_true_shuffled = y_true[:, random_indices]\n",
    "\n",
    "    y_true_sorted, indices = y_true_shuffled.sort(descending=True, dim=-1)\n",
    "\n",
    "    mask = y_true_sorted == padded_value_indicator\n",
    "\n",
    "    preds_sorted_by_true = torch.gather(y_pred_shuffled, dim=1, index=indices)\n",
    "    preds_sorted_by_true[mask] = float(\"-inf\")\n",
    "\n",
    "    max_pred_values, _ = preds_sorted_by_true.max(dim=1, keepdim=True)\n",
    "\n",
    "    preds_sorted_by_true_minus_max = preds_sorted_by_true - max_pred_values\n",
    "\n",
    "    cumsums = torch.cumsum(preds_sorted_by_true_minus_max.exp().flip(dims=[1]), dim=1).flip(dims=[1])\n",
    "\n",
    "    observation_loss = torch.log(cumsums + eps) - preds_sorted_by_true_minus_max\n",
    "\n",
    "    observation_loss[mask] = 0.0\n",
    "\n",
    "    return torch.mean(torch.sum(observation_loss, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "\n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "verifier.eval()\n",
    "verifier = verifier.to(device)\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "init_scores = []\n",
    "init_correctness = []\n",
    "final_scores = []\n",
    "final_correctness = []\n",
    "\n",
    "for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    scores_init = verifier(embs)\n",
    "    max_score = -float(\"inf\")\n",
    "    if 1 in target_col_mask:\n",
    "        init_scores.append(scores_init.item())\n",
    "        init_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "        init_permutation_i = get_permutation(target_col_mask)\n",
    "        col_idx_set = target_col_mask.unique().tolist()\n",
    "        early_stop = False\n",
    "        assert -1 not in col_idx_set\n",
    "        for r in range(len(init_permutation_i), max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "            for x in itertools.combinations(init_permutation_i, r):\n",
    "                if 0 not in x:\n",
    "                    continue\n",
    "                new_batch_data = []\n",
    "                for col_i in x:\n",
    "                    if col_i == 0:\n",
    "                        if len(new_batch_data) == 0:\n",
    "                            cls_indexes_value = 0\n",
    "                        else:\n",
    "                            cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                    new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                if 0 not in x:\n",
    "                    cls_indexes_value = 0\n",
    "                new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                logits_temp, embs = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                scores_temp = verifier(embs).item()\n",
    "                predict_temp = logits_temp.argmax().item()\n",
    "                    # if len(x) == 1 and 0 in x:\n",
    "                    #     predict_target = predict_temp\n",
    "                    #     msp_target = msp_temp\n",
    "                    # # print(x, msp_temp, predict_temp)\n",
    "                    # if 0 not in x and msp_temp > debias_threshold and (predict_temp != predict_target):\n",
    "                    #     debias_classes.append(predict_temp)\n",
    "                    #     continue\n",
    "                if scores_temp > max_score:\n",
    "                    max_score = scores_temp\n",
    "                    logits = logits_temp.clone()\n",
    "        final_scores.append(max_score)\n",
    "        final_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "    labels_test.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "labels_test = torch.cat(labels_test, dim=0)\n",
    "logits_test = torch.stack(logits_test, dim=0)\n",
    "preds_test = torch.argmax(logits_test, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_correctness = torch.tensor(init_correctness)\n",
    "final_correctness = torch.tensor(final_correctness)\n",
    "init_scores = torch.tensor(init_scores)\n",
    "final_scores = torch.tensor(final_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(init_correctness | final_correctness).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(init_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(F.sigmoid(init_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.sigmoid(init_scores)[init_correctness].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.sigmoid(init_scores)[~init_correctness].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.sigmoid(final_scores)[init_correctness].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.sigmoid(final_scores)[~init_correctness].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(final_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(F.sigmoid(final_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_macro_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_init_mask = init_correctness\n",
    "correct_msp_mask = final_correctness\n",
    "for threshold in [ 0.9, 0.99, 0.999]:\n",
    "    uncertain_init_mask = F.sigmoid(init_scores) < threshold\n",
    "    condition_mask = ~uncertain_init_mask\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    print(\"Init\")\n",
    "    # init prediction\n",
    "    print((condition_mask&correct_init_mask).sum().item(), \n",
    "        (condition_mask).sum().item(), \n",
    "        (condition_mask&correct_init_mask).sum().item()/(condition_mask).sum().item())\n",
    "    # init prediction\n",
    "    print((~condition_mask&correct_init_mask).sum().item(), \n",
    "        (~condition_mask).sum().item(), \n",
    "       (~condition_mask&correct_init_mask).sum().item()/(~condition_mask).sum().item())\n",
    "    print(\"MSP\")\n",
    "    # msp prediction\n",
    "    print((condition_mask&correct_msp_mask).sum().item(), \n",
    "        (condition_mask).sum().item(), \n",
    "        (condition_mask&correct_msp_mask).sum().item()/(condition_mask).sum().item())\n",
    "    # msp prediction\n",
    "    print((~condition_mask&correct_msp_mask).sum().item(), \n",
    "        (~condition_mask).sum().item(), \n",
    "        (~condition_mask&correct_msp_mask).sum().item()/(~condition_mask).sum().item())\n",
    "    print(\"MSP & Init\")\n",
    "    print(((condition_mask&correct_init_mask)&(condition_mask&correct_msp_mask)).sum().item())\n",
    "    # print(((~(init_target_mask&(~uncertain_init_mask & ~uncertain_target_mask))& correct_msp_mask)&(~(init_target_mask&(~uncertain_init_mask & ~uncertain_target_mask))& correct_init_mask)).sum().item())\n",
    "    print(((condition_mask&correct_init_mask)|(condition_mask&correct_msp_mask)).sum().item(),\n",
    "          (condition_mask).sum().item(), \n",
    "          ((condition_mask&correct_init_mask)|(condition_mask&correct_msp_mask)).sum().item()/(condition_mask).sum().item())\n",
    "    print(((~condition_mask&correct_init_mask)|(~condition_mask&correct_msp_mask)).sum().item(),\n",
    "          (~condition_mask).sum().item(), \n",
    "          ((~condition_mask&correct_init_mask)|(~condition_mask&correct_msp_mask)).sum().item()/(~condition_mask).sum().item())\n",
    "    # print(\"Permutation\")\n",
    "    # print((condition_mask&correct_permutation_mask).sum().item(), \n",
    "    #     (condition_mask).sum().item(), \n",
    "    #     (condition_mask&correct_permutation_mask).sum().item()/(condition_mask).sum().item())\n",
    "    # print((~condition_mask&correct_permutation_mask).sum().item(), \n",
    "    #      (~condition_mask).sum().item(), \n",
    "    #     (~condition_mask&correct_permutation_mask).sum().item()/(~condition_mask).sum().item())\n",
    "    # print(\"Permutation Confident\")\n",
    "    # print((condition_mask&correct_permutation_confident_mask).sum().item(), \n",
    "    #     (condition_mask).sum().item(), \n",
    "    #     (condition_mask&correct_permutation_confident_mask).sum().item()/(condition_mask).sum().item())\n",
    "    # print((~condition_mask&correct_permutation_confident_mask).sum().item(),\n",
    "    #         (~condition_mask).sum().item(), \n",
    "    #         (~condition_mask&correct_permutation_confident_mask).sum().item()/(~condition_mask).sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_micro_f1=0.5309, ts_macro_f1=0.2573\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "\n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "verifier.load_state_dict(veri_state_dict)\n",
    "verifier.eval()\n",
    "verifier = verifier.to(device)\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "init_scores = []\n",
    "init_correctness = []\n",
    "final_scores = []\n",
    "final_correctness = []\n",
    "num_cols = []\n",
    "total_steps = []\n",
    "final_steps = []\n",
    "correct_scores = defaultdict(list)\n",
    "correct_steps = defaultdict(list)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in enumerate(test_embs):\n",
    "        # target_col_mask = batch[\"target_col_mask\"].T\n",
    "        embs = test_embs[batch_idx][0].reshape(1,-1).to(device)\n",
    "        logits = test_logits[batch_idx][0].reshape(-1).to(device)\n",
    "        scores_init = verifier(embs)\n",
    "        max_score = -float(\"inf\")\n",
    "\n",
    "        for i in range(1, len(test_embs[batch_idx])):\n",
    "            logits_temp = test_logits[batch_idx][i].reshape(-1).to(device)\n",
    "            embs_temp = test_embs[batch_idx][i].reshape(1,-1).to(device)\n",
    "            scores_temp = verifier(embs_temp).item()\n",
    "            predict_temp = logits_temp.argmax().item()\n",
    "            i += 1\n",
    "            if scores_temp > max_score:\n",
    "                max_score = scores_temp\n",
    "                logits = logits_temp.clone()\n",
    "            # if logits_temp.argmax().item() == batch[\"label\"].item():\n",
    "            #     correct_scores[batch_idx].append(scores_temp)\n",
    "            #     correct_steps[batch_idx].append(len(init_permutation_i) - r)\n",
    "                    \n",
    "        labels_test.append(torch.tensor([test_class[batch_idx][0]]))\n",
    "        logits_test.append(logits.detach().cpu())\n",
    "    labels_test = torch.cat(labels_test, dim=0)\n",
    "    logits_test = torch.stack(logits_test, dim=0)\n",
    "    preds_test = torch.argmax(logits_test, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "ts_f1_full = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=None)\n",
    "# full_f1_init\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_class[batch_idx][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.2916e+01,  2.4383e+00,  9.3054e-01,  1.1832e+00,  3.8163e-01,\n",
       "        -4.1304e-01,  2.5061e-01,  2.9922e-01,  2.1219e+00, -1.5456e+00,\n",
       "         1.0486e+00,  1.7135e-01,  5.8479e-01,  5.6031e-01,  7.9119e-01,\n",
       "        -1.9345e+00,  6.0354e-01, -5.2155e-01, -2.9209e-01, -6.2590e-01,\n",
       "         1.5675e+00, -8.2818e-01,  6.8346e-01, -1.2816e+00, -1.2873e+00,\n",
       "        -1.0300e-01,  2.3035e-01, -4.3228e-01, -6.3182e-01, -8.1665e-02,\n",
       "         1.5359e-01, -7.0446e-01, -3.0784e-03, -2.7170e-01,  1.6831e+00,\n",
       "         2.9460e-02,  5.0607e-01,  1.7261e+00,  1.0552e+00, -2.2262e+00,\n",
       "         2.6121e+00, -1.1065e+00,  1.2613e+00, -8.3482e-01, -5.2512e-01,\n",
       "         9.5436e-01,  8.1357e-01, -1.0823e+00, -1.7021e+00, -1.8044e+00,\n",
       "        -2.5944e+00, -1.6346e+00, -1.9973e+00, -2.5277e+00, -3.1694e+00,\n",
       "        -2.2490e+00, -6.9584e-01, -1.6117e+00, -1.3453e+00, -8.2781e-01,\n",
       "         7.2658e-01, -1.0802e+00, -2.9322e+00,  2.9278e-01, -1.6854e+00,\n",
       "        -2.7928e+00, -2.6941e+00, -1.2854e+00, -1.5073e+00,  1.9946e-01,\n",
       "        -2.4417e+00, -1.4837e+00,  1.7400e+00, -1.3023e+00, -1.9670e+00,\n",
       "        -2.4743e+00, -5.2934e-01, -1.7398e+00, -1.3267e+00, -2.1675e+00,\n",
       "        -2.9491e-01, -1.2110e+00, -3.2133e+00, -2.7684e+00, -1.2789e+00,\n",
       "        -1.2847e+00, -1.0048e+00, -2.2948e+00, -3.8275e+00, -2.5167e+00,\n",
       "        -2.5429e+00, -2.6081e+00, -2.1808e+00, -2.4966e+00, -2.4830e+00,\n",
       "        -2.8086e+00, -2.6541e-01, -1.4356e+00, -3.6130e+00, -1.5748e+00,\n",
       "        -2.7960e+00], device='cuda:0')"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [147]\u001b[0m, in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m     max_score \u001b[38;5;241m=\u001b[39m scores_temp\n\u001b[1;32m     63\u001b[0m     logits \u001b[38;5;241m=\u001b[39m logits_temp\u001b[38;5;241m.\u001b[39mclone()\n\u001b[0;32m---> 64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logits_temp\u001b[38;5;241m.\u001b[39margmax()\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m==\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mitem():\n\u001b[1;32m     65\u001b[0m     correct_scores[batch_idx]\u001b[38;5;241m.\u001b[39mappend(scores_temp)\n\u001b[1;32m     66\u001b[0m     correct_steps[batch_idx]\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mlen\u001b[39m(init_permutation_i) \u001b[38;5;241m-\u001b[39m r)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "\n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "verifier.load_state_dict(veri_state_dict)\n",
    "verifier.eval()\n",
    "verifier = verifier.to(device)\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "init_scores = []\n",
    "init_correctness = []\n",
    "final_scores = []\n",
    "final_correctness = []\n",
    "num_cols = []\n",
    "total_steps = []\n",
    "final_steps = []\n",
    "correct_scores = defaultdict(list)\n",
    "correct_steps = defaultdict(list)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in enumerate(test_embs):\n",
    "        # target_col_mask = batch[\"target_col_mask\"].T\n",
    "        embs = test_embs[batch_idx][0].reshape(1,-1).to(device)\n",
    "        logits = test_logits[batch_idx][0].reshape(-1).to(device)\n",
    "        scores_init = verifier(embs)\n",
    "        max_score = -float(\"inf\")\n",
    "\n",
    "        init_scores.append(scores_init.item())\n",
    "        # init_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "        # init_permutation_i = get_permutation(target_col_mask)\n",
    "        # col_idx_set = target_col_mask.unique().tolist()\n",
    "        early_stop = False\n",
    "        i = 0\n",
    "        final_step = 0\n",
    "        total_steps.append(len(init_permutation_i) - max(len(init_permutation_i)//2, len(init_permutation_i)-3) -1)\n",
    "        num_cols.append(test_dataset_iter[batch_idx][\"initial_num_col\"].item())\n",
    "        for r in range(len(init_permutation_i), max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "            for x in itertools.combinations(init_permutation_i, r):\n",
    "                if 0 not in x:\n",
    "                    continue\n",
    "                logits_temp = test_logits[batch_idx][i].reshape(-1).to(device)\n",
    "                embs_temp = test_embs[batch_idx][i].reshape(1,-1).to(device)\n",
    "                scores_temp = verifier(embs_temp).item()\n",
    "                predict_temp = logits_temp.argmax().item()\n",
    "                i += 1\n",
    "                if scores_temp > max_score:\n",
    "                    max_score = scores_temp\n",
    "                    logits = logits_temp.clone()\n",
    "                if logits_temp.argmax().item() == batch[\"label\"].item():\n",
    "                    correct_scores[batch_idx].append(scores_temp)\n",
    "                    correct_steps[batch_idx].append(len(init_permutation_i) - r)\n",
    "                    \n",
    "        labels_test.append(batch[\"label\"].cpu())\n",
    "        logits_test.append(logits.detach().cpu())\n",
    "    labels_test = torch.cat(labels_test, dim=0)\n",
    "    logits_test = torch.stack(logits_test, dim=0)\n",
    "    preds_test = torch.argmax(logits_test, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "ts_f1_full = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=None)\n",
    "# full_f1_init\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "\n",
    "final_correctness = torch.tensor(final_correctness)\n",
    "init_correctness = torch.tensor(init_correctness)\n",
    "init_scores = torch.tensor(init_scores)\n",
    "final_scores = torch.tensor(final_scores)\n",
    "final_steps = torch.tensor(final_steps)\n",
    "total_steps = torch.tensor(total_steps)\n",
    "final_scores_origin = F.sigmoid(torch.tensor(final_scores))\n",
    "init_scores = F.sigmoid(torch.tensor(init_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_final_scores_avg = []\n",
    "for i in range(args.num_classes):\n",
    "    class_final_scores_avg.append(final_scores_origin[labels_test==i].mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=torch.arange(len(class_final_scores_avg)), y=class_final_scores_avg)\n",
    "plt.xlabel('Class Label')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Class Frequency Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_f1_near.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_f1_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_near = (preds_test_near == labels_test).float().mean().item()\n",
    "acc_eu = (preds_test_eu == labels_test).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_near"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_f1_near.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mask in [is_numerical, is_categorical, is_datetime]:\n",
    "    mask = torch.tensor(mask)\n",
    "    print(mask.sum(), full_f1_near[mask].mean(), full_f1_eu[mask].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "f1_diff = full_f1_near - full_f1_eu\n",
    "data = pd.DataFrame({\n",
    "    'Class': np.arange(args.num_classes),\n",
    "    'F1 Difference (Model 1 - Model 3)': f1_diff\n",
    "})\n",
    "# Plot using seaborn\n",
    "plt.figure(figsize=(18, 8))\n",
    "sns.barplot(x='Class', y='F1 Difference (Model 1 - Model 3)', data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for threshold in [0.2, 0.5, 0.8, 0.9, 0.99]:\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    print(len(final_correctness[final_scores>threshold]), final_correctness[final_scores>threshold].sum().item()/len(final_correctness[final_scores>threshold]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_correctness[final_scores>threshold])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_scores.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(final_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = torch.tensor(num_cols)\n",
    "for n_col in np.arange(1, 10):\n",
    "    if n_col <= 8:\n",
    "        mask = num_cols == n_col\n",
    "    else:\n",
    "        mask = num_cols > 8\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach()[mask].numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    print(\"num_cols={} counts={} ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(n_col, mask.sum().item(), ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "for K in [1, 3, 5]:\n",
    "    print(f\"*********************K: {K}****************************\")\n",
    "    model.load_state_dict(best_state_dict, strict=False)\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    verifier.load_state_dict(veri_state_dict)\n",
    "    verifier.eval()\n",
    "    verifier = verifier.to(device)\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    init_scores = []\n",
    "    init_correctness = []\n",
    "    final_scores = []\n",
    "    final_correctness = []\n",
    "    num_cols = []\n",
    "    total_steps = []\n",
    "    final_steps = []\n",
    "    correct_scores = defaultdict(list)\n",
    "    correct_steps = defaultdict(list)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "            target_col_mask = batch[\"target_col_mask\"].T\n",
    "            embs = test_embs[batch_idx][0].reshape(1,-1).to(device)\n",
    "            logits = test_logits[batch_idx][0].reshape(-1).to(device)\n",
    "            scores_init = verifier(embs)\n",
    "            \n",
    "            scores = []\n",
    "            predictions = []\n",
    "\n",
    "            init_scores.append(scores_init.item())\n",
    "            init_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            early_stop = False\n",
    "            i = 0\n",
    "            final_step = 0\n",
    "            total_steps.append(len(init_permutation_i) - max(len(init_permutation_i)//2, len(init_permutation_i)-3) -1)\n",
    "            num_cols.append(test_dataset_iter[batch_idx][\"initial_num_col\"].item())\n",
    "            for r in range(len(init_permutation_i), max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "                for x in itertools.combinations(init_permutation_i, r):\n",
    "                    if 0 not in x:\n",
    "                        continue\n",
    "                    logits_temp = test_logits[batch_idx][i].reshape(-1).to(device)\n",
    "                    embs_temp = test_embs[batch_idx][i].reshape(1,-1).to(device)\n",
    "                    scores_temp = verifier(embs_temp).item()\n",
    "                    predict_temp = torch.zeros(args.num_classes)\n",
    "                    predict_temp[logits_temp.argmax().item()] = 1\n",
    "                    \n",
    "                    i += 1\n",
    "                    scores.append(scores_temp)\n",
    "                    predictions.append(predict_temp)\n",
    "\n",
    "            topk = torch.tensor(scores).topk(min(K, len(scores)))\n",
    "            logits = 0\n",
    "            for value, index in zip(*topk):\n",
    "                logits += torch.sigmoid(torch.tensor(value)) * predictions[index]\n",
    "            # final_scores.append(final_score)\n",
    "            final_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "            labels_test.append(batch[\"label\"].cpu())\n",
    "            logits_test.append(logits.detach().cpu())\n",
    "        labels_test = torch.cat(labels_test, dim=0)\n",
    "        logits_test = torch.stack(logits_test, dim=0)\n",
    "        preds_test = torch.argmax(logits_test, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix, f1_score\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach().numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    ts_f1_full = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=None)\n",
    "    # full_f1_init\n",
    "    print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "\n",
    "    final_correctness = torch.tensor(final_correctness)\n",
    "    init_correctness = torch.tensor(init_correctness)\n",
    "    init_scores = torch.tensor(init_scores)\n",
    "    # final_steps = torch.tensor(final_steps)\n",
    "    total_steps = torch.tensor(total_steps)\n",
    "    # final_scores_topk = F.sigmoid(torch.tensor(final_scores))\n",
    "    # init_scores = F.sigmoid(torch.tensor(init_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.equal(final_scores_origin, final_scores_topk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "coltypes = np.array(['id', 'name', 'description', 'type', 'title', 'state', 'status',\n",
    "       'date', 'code', 'city', 'value', 'source', 'year', 'time',\n",
    "       'country', 'county', 'comment', 'notes', 'category', 'address',\n",
    "       'age', 'gender', 'location', 'version', 'price', 'sex',\n",
    "       'startDate', 'weight', 'class', 'endDate', 'field', 'region',\n",
    "       'note', 'race', 'duration', 'species', 'score', 'position',\n",
    "       'start', 'language', 'rank', 'height', 'population', 'order',\n",
    "       'length', 'filename', 'model', 'role', 'series', 'max', 'min',\n",
    "       'family', 'currency', 'definition', 'format', 'author', 'area',\n",
    "       'domain', 'rating', 'parent', 'number', 'birthDate', 'alias',\n",
    "       'postalCode', 'reference', 'cost', 'publisher', 'treatment',\n",
    "       'created', 'company', 'district', 'elevation', 'project', 'day',\n",
    "       'end', 'scientificName', 'abbreviation', 'part', 'countryCode',\n",
    "       'season', 'topic', 'depth', 'road', 'prefix', 'month', 'route',\n",
    "       'width', 'department', 'percentage', 'zipCode', 'abstract',\n",
    "       'event', 'creator', 'frequency', 'releaseDate', 'genus', 'tag',\n",
    "       'owner', 'party', 'period', 'result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(coltypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_temp = torch.zeros(1, args.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topk = torch.rand(10).topk(5)\n",
    "for value, index in zip(*topk):\n",
    "    print(value, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "sb_model = SentenceTransformer(\"all-mpnet-base-v2\", cache_folder=\"/data/zhihao/TU/Watchog/sentence_transformers_cache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(training_aug_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_aug_embs_sb[0].device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "res0 = tokenizer.decode(batch[\"data\"].T[target_col_mask==0][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\";\".join(set([i.strip() for i in res0.split(\";\")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_sb = torch.tensor(sb_model.encode([res0, \n",
    "                                       res0.replace(\";\", \",\"),\n",
    "                                       res0.replace(\"female\", \"male\"), \n",
    "                                       \";\".join(set([i.strip() for i in res0.split(\";\")])), \n",
    "                                       res0.replace(\"female\", \"F\").replace(\"male\", \"M\"),\n",
    "                                       \"gender; gender; gender;\",\n",
    "                                       \"1997;2005\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_sb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.cosine_similarity(res_sb[0], res_sb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_sb = torch.tensor(sb_model.encode([\"2017; 2022; 1997\", \n",
    "                                       \"2007-11-04; 2007-11-04; 2007-11-04\",\n",
    "                                       \"100; 200; 300\",\n",
    "                                       \"23; 52; 48; 11\", \n",
    "                                       \"2017.11; 2022.54; 1997.54\", \n",
    "                                       \"11.11; 12.11; 0.124\"]))\n",
    "F.cosine_similarity(res_embs[0], res_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_data = [\"2017; 2022; 1997\", \n",
    "                                       \"2007-11-04; 2007-11-04; 2007-11-04\",\n",
    "                                       \"100; 200; 300\",\n",
    "                                       \"23; 52; 48; 11\", \n",
    "                                       \"2017.11; 2022.54; 1997.54\", \n",
    "                                       \"11.11; 12.11; 0.124\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids_list = [tokenizer.encode(\n",
    "    i, add_special_tokens=True) for i in res_data]\n",
    "\n",
    "\n",
    "# group_df[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "#     tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=cur_maxlen, truncation=True)).tolist(\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_embs = []\n",
    "for i in range(len(res_data)):\n",
    "    logits, embs = model(torch.tensor(token_ids_list[i]).reshape(1, -1).to(device), cls_indexes=torch.LongTensor([[0, 0]]).to(device), get_enc=True)\n",
    "    res_embs.append(embs.cpu())\n",
    "res_embs = torch.stack(res_embs, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.cosine_similarity(res_sb[0], res_sb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, batch in enumerate(train_dataloader_iter):\n",
    "    break\n",
    "cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "target_col_mask = batch[\"target_col_mask\"].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save good context\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "sb_model = SentenceTransformer(\"all-mpnet-base-v2\", cache_folder=\"/data/zhihao/TU/Watchog/sentence_transformers_cache\")\n",
    "\n",
    "\n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "num_single_fail = 0\n",
    "num_good_context = 0\n",
    "class_context = defaultdict(list)\n",
    "training_aug_embs = []\n",
    "training_aug_embs_target = []\n",
    "training_aug_embs_sb = []\n",
    "training_aug_labels = []\n",
    "training_aug_col_num = []\n",
    "training_aug_data = []\n",
    "training_aug_col_mask = []\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in enumerate(train_dataloader_iter):\n",
    "        cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "        target_col_mask = batch[\"target_col_mask\"].T\n",
    "        if 1 not in target_col_mask:\n",
    "            continue\n",
    "        init_permutation_i = get_permutation(target_col_mask)\n",
    "        training_aug_col_num.append(len(init_permutation_i))\n",
    "        \n",
    "        label_i = batch[\"label\"].item()\n",
    "        training_aug_labels.append(label_i)\n",
    "        \n",
    "        logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "        training_aug_embs.append(embs.detach().cpu())\n",
    "        \n",
    "        logits, embs = model(batch[\"data\"].T[target_col_mask==0].reshape(1, -1), cls_indexes=torch.LongTensor([[0, 0]]).to(device), get_enc=True)\n",
    "        training_aug_embs_target.append(embs.detach().cpu())\n",
    "        \n",
    "        string_data = tokenizer.decode(batch[\"data\"].T[target_col_mask==0][1:]).split(\";\")\n",
    "        string_data = \";\".join(set([i.strip() for i in string_data]))\n",
    "        sb_embs = torch.tensor(sb_model.encode([string_data]))\n",
    "        training_aug_embs_sb.append(sb_embs)\n",
    "        \n",
    "        training_aug_data.append(batch[\"data\"].T[target_col_mask!=0])\n",
    "        training_aug_col_mask.append(target_col_mask[target_col_mask!=0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_aug_embs = torch.stack(training_aug_embs, dim=0)\n",
    "training_aug_embs_sb = torch.stack(training_aug_embs_sb, dim=0).squeeze()\n",
    "training_aug_embs_target = torch.stack(training_aug_embs_target, dim=0)\n",
    "training_aug_labels = torch.tensor(training_aug_labels)\n",
    "training_aug_col_num = torch.tensor(training_aug_col_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "        for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "            target_col_mask = batch[\"target_col_mask\"].T\n",
    "            embs = test_embs[batch_idx][0].reshape(1,-1).to(device)\n",
    "            logits = test_logits[batch_idx][0].reshape(-1).to(device)\n",
    "            scores_init = verifier(embs)\n",
    "            max_score = -float(\"inf\")\n",
    "\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, indices = F.cosine_similarity(test_aug_embs_sb[batch_idx], training_aug_embs_sb).topk(K)\n",
    "for aug_idx in indices:\n",
    "    aug_data = training_aug_data[aug_idx]\n",
    "    aug_col_mask = training_aug_col_mask[aug_idx]\n",
    "    \n",
    "    aug_permutation_i = torch.tensor(get_permutation(aug_col_mask)) + len(init_permutation_i) -1\n",
    "    permutation_i = init_permutation_i + aug_permutation_i.tolist()\n",
    "    max_num_cols_i = min(len(permutation_i), args.max_num_col)\n",
    "    aug_data = torch.cat([batch[\"data\"].T, aug_data.reshape(1, -1)], dim=-1)\n",
    "    aug_target_col_mask = torch.cat([target_col_mask, aug_col_mask.reshape(1, -1)], dim=-1)\n",
    "    for r in range(max_num_cols_i, max(max_num_cols_i//2, max_num_cols_i-3), -1): # not \n",
    "        for x in itertools.combinations(permutation_i, r):\n",
    "            if 0 not in x:\n",
    "                continue\n",
    "\n",
    "            \n",
    "            new_batch_data = []\n",
    "            for col_i in x:\n",
    "                if col_i == 0:\n",
    "                    if len(new_batch_data) == 0:\n",
    "                        cls_indexes_value = 0\n",
    "                    else:\n",
    "                        cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                new_batch_data.append(aug_data[aug_target_col_mask==col_i])\n",
    "            new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "            cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "            logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "            ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n",
    "            score_permutation[batch_idx].append(ood_score_temp)\n",
    "            predict_temp = logits_temp.argmax().item()\n",
    "            permutation_correctness[batch_idx].append(predict_temp == label_i)\n",
    "            num_permutations[batch_idx] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_col_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, indices = F.cosine_similarity(test_aug_embs_sb[batch_idx], training_aug_embs_sb).topk(K)\n",
    "for aug_idx in indices:\n",
    "    aug_data = training_aug_data[aug_idx]\n",
    "    aug_col_mask = training_aug_col_mask[aug_idx]\n",
    "    \n",
    "    aug_permutation_i = torch.tensor(get_permutation(aug_col_mask)) + len(init_permutation_i) -1\n",
    "    permutation_i = init_permutation_i + aug_permutation_i.tolist()\n",
    "    max_num_cols_i = min(len(permutation_i), args.max_num_col)\n",
    "    aug_data = torch.cat([batch[\"data\"].T, aug_data.reshape(1, -1)], dim=-1)\n",
    "    aug_target_col_mask = torch.cat([target_col_mask, aug_col_mask.reshape(1, -1)], dim=-1)\n",
    "    for r in range(max_num_cols_i, max(max_num_cols_i//2, max_num_cols_i-3), -1): # not \n",
    "        for x in itertools.combinations(permutation_i, r):\n",
    "            if 0 not in x:\n",
    "                continue\n",
    "\n",
    "            \n",
    "            new_batch_data = []\n",
    "            for col_i in x:\n",
    "                if col_i == 0:\n",
    "                    if len(new_batch_data) == 0:\n",
    "                        cls_indexes_value = 0\n",
    "                    else:\n",
    "                        cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                new_batch_data.append(aug_data[aug_target_col_mask==col_i])\n",
    "            new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "            cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "            logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "            scores_temp = verifier(embs_temp).item()\n",
    "            predict_temp = logits_temp.argmax().item()\n",
    "            num_permutations[batch_idx] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save good context\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "sb_model = SentenceTransformer(\"all-mpnet-base-v2\", cache_folder=\"/data/zhihao/TU/Watchog/sentence_transformers_cache\")\n",
    "\n",
    "\n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "num_single_fail = 0\n",
    "num_good_context = 0\n",
    "class_context = defaultdict(list)\n",
    "test_aug_embs = []\n",
    "test_aug_embs_target = []\n",
    "test_aug_embs_sb = []\n",
    "test_aug_labels = []\n",
    "test_aug_col_num = []\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "        cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "        target_col_mask = batch[\"target_col_mask\"].T\n",
    "\n",
    "        init_permutation_i = get_permutation(target_col_mask)\n",
    "        test_aug_col_num.append(len(init_permutation_i))\n",
    "        \n",
    "        label_i = batch[\"label\"].item()\n",
    "        test_aug_labels.append(label_i)\n",
    "        \n",
    "        logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "        test_aug_embs.append(embs.detach().cpu())\n",
    "        \n",
    "        logits, embs = model(batch[\"data\"].T[target_col_mask==0].reshape(1, -1), cls_indexes=torch.LongTensor([[0, 0]]).to(device), get_enc=True)\n",
    "        test_aug_embs_target.append(embs.detach().cpu())\n",
    "        \n",
    "        string_data = tokenizer.decode(batch[\"data\"].T[target_col_mask==0][1:]).split(\";\")\n",
    "        string_data = \";\".join(set([i.strip() for i in string_data]))\n",
    "        sb_embs = torch.tensor(sb_model.encode([string_data]))\n",
    "        test_aug_embs_sb.append(sb_embs)\n",
    "        \n",
    "test_aug_embs = torch.stack(test_aug_embs, dim=0)\n",
    "test_aug_embs_sb = torch.stack(test_aug_embs_sb, dim=0)\n",
    "test_aug_embs_target = torch.stack(test_aug_embs_target, dim=0)\n",
    "test_aug_labels = torch.tensor(test_aug_labels)\n",
    "test_aug_col_num = torch.tensor(test_aug_col_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs_correctness = []\n",
    "embs_sim_scores = []\n",
    "embs_sb_correctness = []\n",
    "embs_sb_sim_scores = []\n",
    "embs_target_correctness = []\n",
    "embs_target_sim_scores = []\n",
    "for idx in (test_aug_col_num<8).nonzero().reshape(-1):\n",
    "    embs_correctness.append(training_aug_labels[F.cosine_similarity(test_aug_embs[idx], training_aug_embs).argmax()] == test_aug_labels[idx])\n",
    "    embs_sim_scores.append(F.cosine_similarity(test_aug_embs[idx], training_aug_embs).max().item())\n",
    "    embs_sb_correctness.append(training_aug_labels[F.cosine_similarity(test_aug_embs_sb[idx], training_aug_embs_sb).argmax()] == test_aug_labels[idx])\n",
    "    embs_sb_sim_scores.append(F.cosine_similarity(test_aug_embs_sb[idx], training_aug_embs_sb).max().item())\n",
    "    embs_target_correctness.append(training_aug_labels[F.cosine_similarity(test_aug_embs_target[idx], training_aug_embs_target).argmax()] == test_aug_labels[idx])\n",
    "    embs_target_sim_scores.append(F.cosine_similarity(test_aug_embs_target[idx], training_aug_embs_target).max().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_correctness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs_correctness = torch.tensor(embs_correctness).reshape(-1)\n",
    "embs_sb_correctness = torch.tensor(embs_sb_correctness).reshape(-1)\n",
    "embs_target_correctness = torch.tensor(embs_target_correctness).reshape(-1)\n",
    "embs_sim_scores = torch.tensor(embs_sim_scores).reshape(-1)\n",
    "embs_sb_sim_scores = torch.tensor(embs_sb_sim_scores).reshape(-1)\n",
    "embs_target_sim_scores = torch.tensor(embs_target_sim_scores).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embs_correctness.sum(), embs_correctness.shape[0], embs_correctness.sum()/embs_correctness.shape[0], embs_sim_scores[embs_correctness].mean(), embs_sim_scores[~embs_correctness].mean())\n",
    "print(embs_sb_correctness.sum(), embs_sb_correctness.shape[0], embs_sb_correctness.sum()/embs_sb_correctness.shape[0], embs_sb_sim_scores[embs_sb_correctness].mean(), embs_sb_sim_scores[~embs_sb_correctness].mean())\n",
    "print(embs_target_correctness.sum(), embs_target_correctness.shape[0], embs_target_correctness.sum()/embs_target_correctness.shape[0], embs_target_sim_scores[embs_target_correctness].mean(), embs_target_sim_scores[~embs_target_correctness].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_correctness_tocheck = final_correctness[test_aug_col_num<8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embs_correctness.sum(), final_correctness_tocheck.sum(), (embs_correctness&final_correctness_tocheck).sum(), (embs_correctness&final_correctness_tocheck).sum()/len(embs_correctness))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_aug_col_num<8).sum()/len(test_aug_col_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs_correctness = []\n",
    "embs_sim_scores = []\n",
    "embs_sb_correctness = []\n",
    "embs_sb_sim_scores = []\n",
    "embs_target_correctness = []\n",
    "embs_target_sim_scores = []\n",
    "K = 1\n",
    "for idx in (test_aug_col_num<8).nonzero().reshape(-1):\n",
    "    values, indices = F.cosine_similarity(test_aug_embs[idx], training_aug_embs).topk(K)\n",
    "    if test_aug_labels[idx].item() in training_aug_labels[indices]:\n",
    "        embs_correctness.append(True)\n",
    "    else:\n",
    "        embs_correctness.append(False)\n",
    "    values, indices = F.cosine_similarity(test_aug_embs_sb[idx], training_aug_embs_sb).topk(K)\n",
    "    if test_aug_labels[idx].item() in training_aug_labels[indices]:\n",
    "        embs_sb_correctness.append(True)\n",
    "    else:\n",
    "        embs_sb_correctness.append(False)\n",
    "    values, indices = F.cosine_similarity(test_aug_embs_target[idx], training_aug_embs_target).topk(K)\n",
    "    if test_aug_labels[idx].item() in training_aug_labels[indices]:\n",
    "        embs_target_correctness.append(True)\n",
    "    else:\n",
    "        embs_target_correctness.append(False)\n",
    "embs_correctness = torch.tensor(embs_correctness).reshape(-1)\n",
    "embs_sb_correctness = torch.tensor(embs_sb_correctness).reshape(-1)\n",
    "embs_target_correctness = torch.tensor(embs_target_correctness).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K = 1\n",
    "print(embs_correctness.sum(), embs_correctness.shape[0], embs_correctness.sum()/embs_correctness.shape[0],)\n",
    "print(embs_sb_correctness.sum(), embs_sb_correctness.shape[0], embs_sb_correctness.sum()/embs_sb_correctness.shape[0])\n",
    "print(embs_target_correctness.sum(), embs_target_correctness.shape[0], embs_target_correctness.sum()/embs_target_correctness.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K = 3\n",
    "print(embs_correctness.sum(), embs_correctness.shape[0], embs_correctness.sum()/embs_correctness.shape[0],)\n",
    "print(embs_sb_correctness.sum(), embs_sb_correctness.shape[0], embs_sb_correctness.sum()/embs_sb_correctness.shape[0])\n",
    "print(embs_target_correctness.sum(), embs_target_correctness.shape[0], embs_target_correctness.sum()/embs_target_correctness.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K = 5\n",
    "print(embs_correctness.sum(), embs_correctness.shape[0], embs_correctness.sum()/embs_correctness.shape[0],)\n",
    "print(embs_sb_correctness.sum(), embs_sb_correctness.shape[0], embs_sb_correctness.sum()/embs_sb_correctness.shape[0])\n",
    "print(embs_target_correctness.sum(), embs_target_correctness.shape[0], embs_target_correctness.sum()/embs_target_correctness.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K = 10\n",
    "print(embs_correctness.sum(), embs_correctness.shape[0], embs_correctness.sum()/embs_correctness.shape[0],)\n",
    "print(embs_sb_correctness.sum(), embs_sb_correctness.shape[0], embs_sb_correctness.sum()/embs_sb_correctness.shape[0])\n",
    "print(embs_target_correctness.sum(), embs_target_correctness.shape[0], embs_target_correctness.sum()/embs_target_correctness.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K = 20\n",
    "print(embs_correctness.sum(), embs_correctness.shape[0], embs_correctness.sum()/embs_correctness.shape[0],)\n",
    "print(embs_sb_correctness.sum(), embs_sb_correctness.shape[0], embs_sb_correctness.sum()/embs_sb_correctness.shape[0])\n",
    "print(embs_target_correctness.sum(), embs_target_correctness.shape[0], embs_target_correctness.sum()/embs_target_correctness.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "max_tokens_per_col = 512//args.max_num_col\n",
    "\n",
    "before_aug_results = []\n",
    "after_aug_results = []\n",
    "best_aug_label = []\n",
    "gt_lable = []\n",
    "import time \n",
    "for K in [1, 3, 5, 10]:\n",
    "    \n",
    "    before_aug_results.append({})\n",
    "    after_aug_results.append({})\n",
    "    best_aug_label.append({})\n",
    "    gt_lable.append({})\n",
    "    \n",
    "    ts = time.time()\n",
    "    print(f\"============================K={K}=============================\")\n",
    "    model.load_state_dict(best_state_dict, strict=False)\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    verifier.load_state_dict(veri_state_dict)\n",
    "    verifier.eval()\n",
    "    verifier = verifier.to(device)\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    init_scores = []\n",
    "    init_correctness = []\n",
    "    final_scores = []\n",
    "    final_correctness = []\n",
    "    num_cols = []\n",
    "    total_steps = []\n",
    "    final_steps = []\n",
    "    correct_scores = defaultdict(list)\n",
    "    correct_steps = defaultdict(list)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "            target_col_mask = batch[\"target_col_mask\"].T\n",
    "            embs = test_embs[batch_idx][0].reshape(1,-1).to(device)\n",
    "            logits = test_logits[batch_idx][0].reshape(-1).to(device)\n",
    "            scores_init = verifier(embs)\n",
    "            max_score = -float(\"inf\")\n",
    "\n",
    "            init_scores.append(scores_init.item())\n",
    "            init_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            \n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            early_stop = False\n",
    "            i = 0\n",
    "            final_step = 0\n",
    "            total_steps.append(len(init_permutation_i) - max(len(init_permutation_i)//2, len(init_permutation_i)-3) -1)\n",
    "            num_cols.append(len(init_permutation_i))\n",
    "\n",
    "            for r in range(len(init_permutation_i), max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "                for x in itertools.combinations(init_permutation_i, r):\n",
    "                    if 0 not in x:\n",
    "                        continue\n",
    "                    logits_temp = test_logits[batch_idx][i].reshape(-1).to(device)\n",
    "                    embs_temp = test_embs[batch_idx][i].reshape(1,-1).to(device)\n",
    "                    scores_temp = verifier(embs_temp).item()\n",
    "                    predict_temp = logits_temp.argmax().item()\n",
    "                    i += 1\n",
    "                    if scores_temp > max_score:\n",
    "                        max_score = scores_temp\n",
    "                        logits = logits_temp.clone()\n",
    "                        final_step = len(init_permutation_i) - r\n",
    "                    if logits_temp.argmax().item() == batch[\"label\"].item():\n",
    "                        correct_scores[batch_idx].append(scores_temp)\n",
    "                        correct_steps[batch_idx].append(len(init_permutation_i) - r)\n",
    "            \n",
    "            # extra columns for those with less than max_num_col columns\n",
    "            if len(init_permutation_i) < args.max_num_col:\n",
    "                before_aug_results[-1][batch_idx] = logits.argmax().item()\n",
    "                gt_lable[-1][batch_idx] = batch[\"label\"].item()\n",
    "                \n",
    "                values, indices = F.cosine_similarity(test_aug_embs_sb[batch_idx], training_aug_embs_sb).topk(K)\n",
    "                for aug_idx in indices:\n",
    "                    aug_data = training_aug_data[aug_idx]\n",
    "                    aug_col_mask = training_aug_col_mask[aug_idx]\n",
    "                    aug_permutation_i = get_permutation(aug_col_mask)[: args.max_num_col - len(init_permutation_i)]\n",
    "                    aug_col_mask, aug_data = aug_col_mask[aug_col_mask<=max(aug_permutation_i)], aug_data[aug_col_mask<=max(aug_permutation_i)]\n",
    "                    assert len(aug_col_mask.unique()) == len(aug_permutation_i) and len(aug_col_mask) == len(aug_data)\n",
    "                    \n",
    "                    \n",
    "                    aug_permutation_i = torch.tensor(get_permutation(aug_col_mask)) + len(init_permutation_i) -1\n",
    "                    permutation_i = init_permutation_i + aug_permutation_i.tolist()\n",
    "                    max_num_cols_i = min(len(permutation_i), args.max_num_col)\n",
    "                    aug_data = torch.cat([batch[\"data\"].T, aug_data.reshape(1, -1)], dim=-1)\n",
    "                    aug_target_col_mask = torch.cat([target_col_mask, aug_col_mask.reshape(1, -1)], dim=-1)\n",
    "                    for r in range(max_num_cols_i, max(max_num_cols_i//2, max_num_cols_i-3), -1): # not \n",
    "                        for x in itertools.combinations(permutation_i, r):\n",
    "                            if 0 not in x:\n",
    "                                continue\n",
    "\n",
    "                            \n",
    "                            new_batch_data = []\n",
    "                            for col_i in x:\n",
    "                                if col_i == 0:\n",
    "                                    if len(new_batch_data) == 0:\n",
    "                                        cls_indexes_value = 0\n",
    "                                    else:\n",
    "                                        cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                                new_batch_data.append(aug_data[aug_target_col_mask==col_i][:max_tokens_per_col])\n",
    "                            new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                            cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                            logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                            scores_temp = verifier(embs_temp.reshape(1,-1)).item()\n",
    "                            predict_temp = logits_temp.argmax().item()\n",
    "                            if scores_temp > max_score:\n",
    "                                max_score = scores_temp\n",
    "                                logits = logits_temp.clone()\n",
    "                                final_step = len(init_permutation_i) - r\n",
    "                                after_aug_results[-1][batch_idx] = logits.argmax().item()\n",
    "                                best_aug_label[-1][batch_idx] = training_aug_labels[aug_idx]\n",
    "                            # if logits_temp.argmax().item() == batch[\"label\"].item():\n",
    "                            #     correct_scores[batch_idx].append(scores_temp)\n",
    "                            #     correct_steps[batch_idx].append(len(init_permutation_i) - r)\n",
    "\n",
    "\n",
    "            final_scores.append(max_score)\n",
    "            final_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "            final_steps.append(final_step)\n",
    "            labels_test.append(batch[\"label\"].cpu())\n",
    "            logits_test.append(logits.detach().cpu())\n",
    "        labels_test = torch.cat(labels_test, dim=0)\n",
    "        logits_test = torch.stack(logits_test, dim=0)\n",
    "        preds_test = torch.argmax(logits_test, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix, f1_score\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach().numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    ts_f1_full = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=None)\n",
    "    # full_f1_init\n",
    "    print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "    print(f\"time={time.time()-ts}\")\n",
    "\n",
    "    final_correctness = torch.tensor(final_correctness)\n",
    "    init_correctness = torch.tensor(init_correctness)\n",
    "    init_scores = torch.tensor(init_scores)\n",
    "    final_scores = torch.tensor(final_scores)\n",
    "    final_steps = torch.tensor(final_steps)\n",
    "    total_steps = torch.tensor(total_steps)\n",
    "    final_scores = F.sigmoid(torch.tensor(final_scores))\n",
    "    init_scores = F.sigmoid(torch.tensor(init_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "max_tokens_per_col = 512//args.max_num_col\n",
    "\n",
    "before_aug_results = []\n",
    "after_aug_results = []\n",
    "best_aug_label = []\n",
    "gt_lable = []\n",
    "import time \n",
    "for K in [1, 5, 10]:\n",
    "    \n",
    "    before_aug_results.append({})\n",
    "    after_aug_results.append({})\n",
    "    best_aug_label.append({})\n",
    "    gt_lable.append({})\n",
    "    \n",
    "    ts = time.time()\n",
    "    print(f\"============================K={K}=============================\")\n",
    "    model.load_state_dict(best_state_dict, strict=False)\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    verifier.load_state_dict(veri_state_dict)\n",
    "    verifier.eval()\n",
    "    verifier = verifier.to(device)\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    init_scores = []\n",
    "    init_correctness = []\n",
    "    final_scores = []\n",
    "    final_correctness = []\n",
    "    num_cols = []\n",
    "    total_steps = []\n",
    "    final_steps = []\n",
    "    correct_scores = defaultdict(list)\n",
    "    correct_steps = defaultdict(list)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "            target_col_mask = batch[\"target_col_mask\"].T\n",
    "            embs = test_embs[batch_idx][0].reshape(1,-1).to(device)\n",
    "            logits = test_logits[batch_idx][0].reshape(-1).to(device)\n",
    "            scores_init = verifier(embs)\n",
    "            max_score = -float(\"inf\")\n",
    "\n",
    "            init_scores.append(scores_init.item())\n",
    "            init_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            \n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            early_stop = False\n",
    "            i = 0\n",
    "            final_step = 0\n",
    "            total_steps.append(len(init_permutation_i) - max(len(init_permutation_i)//2, len(init_permutation_i)-3) -1)\n",
    "            num_cols.append(len(init_permutation_i))\n",
    "\n",
    "            for r in range(len(init_permutation_i), max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "                for x in itertools.combinations(init_permutation_i, r):\n",
    "                    if 0 not in x:\n",
    "                        continue\n",
    "                    logits_temp = test_logits[batch_idx][i].reshape(-1).to(device)\n",
    "                    embs_temp = test_embs[batch_idx][i].reshape(1,-1).to(device)\n",
    "                    scores_temp = verifier(embs_temp).item()\n",
    "                    predict_temp = logits_temp.argmax().item()\n",
    "                    i += 1\n",
    "                    if scores_temp > max_score:\n",
    "                        max_score = scores_temp\n",
    "                        logits = logits_temp.clone()\n",
    "                        final_step = len(init_permutation_i) - r\n",
    "                    if logits_temp.argmax().item() == batch[\"label\"].item():\n",
    "                        correct_scores[batch_idx].append(scores_temp)\n",
    "                        correct_steps[batch_idx].append(len(init_permutation_i) - r)\n",
    "            \n",
    "            # extra columns for those with less than max_num_col columns\n",
    "            if len(init_permutation_i) in [3,4,5]:\n",
    "                before_aug_results[-1][batch_idx] = logits.argmax().item()\n",
    "                gt_lable[-1][batch_idx] = batch[\"label\"].item()\n",
    "                after_aug_results[-1][batch_idx] = -1\n",
    "                best_aug_label[-1][batch_idx] = -1\n",
    "                \n",
    "                values, indices = F.cosine_similarity(test_aug_embs_sb[batch_idx], training_aug_embs_sb).topk(K)\n",
    "                for aug_idx in indices:\n",
    "                    aug_data = training_aug_data[aug_idx]\n",
    "                    aug_col_mask = training_aug_col_mask[aug_idx]\n",
    "                    aug_permutation_i = get_permutation(aug_col_mask)[: args.max_num_col - len(init_permutation_i)]\n",
    "                    aug_col_mask, aug_data = aug_col_mask[aug_col_mask<=max(aug_permutation_i)], aug_data[aug_col_mask<=max(aug_permutation_i)]\n",
    "                    assert len(aug_col_mask.unique()) == len(aug_permutation_i) and len(aug_col_mask) == len(aug_data)\n",
    "                    \n",
    "                    \n",
    "                    aug_permutation_i = torch.tensor(get_permutation(aug_col_mask)) + len(init_permutation_i) -1\n",
    "                    permutation_i = init_permutation_i + aug_permutation_i.tolist()\n",
    "                    max_num_cols_i = min(len(permutation_i), args.max_num_col)\n",
    "                    aug_data = torch.cat([batch[\"data\"].T, aug_data.reshape(1, -1)], dim=-1)\n",
    "                    aug_target_col_mask = torch.cat([target_col_mask, aug_col_mask.reshape(1, -1)], dim=-1)\n",
    "                    for r in range(max_num_cols_i, max(max_num_cols_i//2, max_num_cols_i-3), -1): # not \n",
    "                        for x in itertools.combinations(permutation_i, r):\n",
    "                            if 0 not in x:\n",
    "                                continue\n",
    "\n",
    "                            \n",
    "                            new_batch_data = []\n",
    "                            for col_i in x:\n",
    "                                if col_i == 0:\n",
    "                                    if len(new_batch_data) == 0:\n",
    "                                        cls_indexes_value = 0\n",
    "                                    else:\n",
    "                                        cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                                new_batch_data.append(aug_data[aug_target_col_mask==col_i][:max_tokens_per_col])\n",
    "                            new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                            cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                            logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                            scores_temp = verifier(embs_temp.reshape(1,-1)).item()\n",
    "                            predict_temp = logits_temp.argmax().item()\n",
    "                            \n",
    "                            if scores_temp > max_score:\n",
    "                                max_score = scores_temp\n",
    "                                logits = logits_temp.clone()\n",
    "                                final_step = len(init_permutation_i) - r\n",
    "                                after_aug_results[-1][batch_idx] = logits.argmax().item()\n",
    "                                best_aug_label[-1][batch_idx] = training_aug_labels[aug_idx]\n",
    "                            # if logits_temp.argmax().item() == batch[\"label\"].item():\n",
    "                            #     correct_scores[batch_idx].append(scores_temp)\n",
    "                            #     correct_steps[batch_idx].append(len(init_permutation_i) - r)\n",
    "\n",
    "\n",
    "            final_scores.append(max_score)\n",
    "            final_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "            final_steps.append(final_step)\n",
    "            labels_test.append(batch[\"label\"].cpu())\n",
    "            logits_test.append(logits.detach().cpu())\n",
    "        labels_test = torch.cat(labels_test, dim=0)\n",
    "        logits_test = torch.stack(logits_test, dim=0)\n",
    "        preds_test = torch.argmax(logits_test, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix, f1_score\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach().numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    ts_f1_full = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=None)\n",
    "    # full_f1_init\n",
    "    print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "    print(f\"time={time.time()-ts}\")\n",
    "\n",
    "    final_correctness = torch.tensor(final_correctness)\n",
    "    init_correctness = torch.tensor(init_correctness)\n",
    "    init_scores = torch.tensor(init_scores)\n",
    "    final_scores = torch.tensor(final_scores)\n",
    "    final_steps = torch.tensor(final_steps)\n",
    "    total_steps = torch.tensor(total_steps)\n",
    "    final_scores = F.sigmoid(torch.tensor(final_scores))\n",
    "    init_scores = F.sigmoid(torch.tensor(init_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "max_tokens_per_col = 512//args.max_num_col\n",
    "\n",
    "before_aug_results = []\n",
    "after_aug_results = []\n",
    "best_aug_label = []\n",
    "gt_lable = []\n",
    "import time \n",
    "for K in [1]:\n",
    "    \n",
    "    before_aug_results.append({})\n",
    "    after_aug_results.append({})\n",
    "    best_aug_label.append({})\n",
    "    gt_lable.append({})\n",
    "    \n",
    "    ts = time.time()\n",
    "    print(f\"============================K={K}=============================\")\n",
    "    model.load_state_dict(best_state_dict, strict=False)\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    verifier.load_state_dict(veri_state_dict)\n",
    "    verifier.eval()\n",
    "    verifier = verifier.to(device)\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    init_scores = []\n",
    "    init_correctness = []\n",
    "    final_scores = []\n",
    "    final_correctness = []\n",
    "    num_cols = []\n",
    "    total_steps = []\n",
    "    final_steps = []\n",
    "    correct_scores = defaultdict(list)\n",
    "    correct_steps = defaultdict(list)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "            target_col_mask = batch[\"target_col_mask\"].T\n",
    "            embs = test_embs[batch_idx][0].reshape(1,-1).to(device)\n",
    "            logits = test_logits[batch_idx][0].reshape(-1).to(device)\n",
    "            scores_init = verifier(embs)\n",
    "            max_score = -float(\"inf\")\n",
    "\n",
    "            init_scores.append(scores_init.item())\n",
    "            init_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            \n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            early_stop = False\n",
    "            i = 0\n",
    "            final_step = 0\n",
    "            total_steps.append(len(init_permutation_i) - max(len(init_permutation_i)//2, len(init_permutation_i)-3) -1)\n",
    "            num_cols.append(len(init_permutation_i))\n",
    "\n",
    "            for r in range(len(init_permutation_i), max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "                for x in itertools.combinations(init_permutation_i, r):\n",
    "                    if 0 not in x:\n",
    "                        continue\n",
    "                    logits_temp = test_logits[batch_idx][i].reshape(-1).to(device)\n",
    "                    embs_temp = test_embs[batch_idx][i].reshape(1,-1).to(device)\n",
    "                    scores_temp = verifier(embs_temp).item()\n",
    "                    predict_temp = logits_temp.argmax().item()\n",
    "                    i += 1\n",
    "                    if scores_temp > max_score:\n",
    "                        max_score = scores_temp\n",
    "                        logits = logits_temp.clone()\n",
    "                        final_step = len(init_permutation_i) - r\n",
    "                    if logits_temp.argmax().item() == batch[\"label\"].item():\n",
    "                        correct_scores[batch_idx].append(scores_temp)\n",
    "                        correct_steps[batch_idx].append(len(init_permutation_i) - r)\n",
    "            \n",
    "            # extra columns for those with less than max_num_col columns\n",
    "            if len(init_permutation_i) in [4, 6]:\n",
    "                before_aug_results[-1][batch_idx] = logits.argmax().item()\n",
    "                gt_lable[-1][batch_idx] = batch[\"label\"].item()\n",
    "                after_aug_results[-1][batch_idx] = -1\n",
    "                best_aug_label[-1][batch_idx] = -1\n",
    "                \n",
    "                values, indices = F.cosine_similarity(test_aug_embs_sb[batch_idx], training_aug_embs_sb).topk(K)\n",
    "                for aug_idx in indices:\n",
    "                    aug_data = training_aug_data[aug_idx]\n",
    "                    aug_col_mask = training_aug_col_mask[aug_idx]\n",
    "                    aug_permutation_i = get_permutation(aug_col_mask)[: args.max_num_col - len(init_permutation_i)]\n",
    "                    aug_col_mask, aug_data = aug_col_mask[aug_col_mask<=max(aug_permutation_i)], aug_data[aug_col_mask<=max(aug_permutation_i)]\n",
    "                    assert len(aug_col_mask.unique()) == len(aug_permutation_i) and len(aug_col_mask) == len(aug_data)\n",
    "                    \n",
    "                    \n",
    "                    aug_permutation_i = torch.tensor(get_permutation(aug_col_mask)) + len(init_permutation_i) -1\n",
    "                    permutation_i = init_permutation_i + aug_permutation_i.tolist()\n",
    "                    max_num_cols_i = min(len(permutation_i), args.max_num_col)\n",
    "                    aug_data = torch.cat([batch[\"data\"].T, aug_data.reshape(1, -1)], dim=-1)\n",
    "                    aug_target_col_mask = torch.cat([target_col_mask, aug_col_mask.reshape(1, -1)], dim=-1)\n",
    "                    for r in range(max_num_cols_i, max(max_num_cols_i//2, max_num_cols_i-3), -1): # not \n",
    "                        for x in itertools.combinations(permutation_i, r):\n",
    "                            if 0 not in x:\n",
    "                                continue\n",
    "\n",
    "                            \n",
    "                            new_batch_data = []\n",
    "                            for col_i in x:\n",
    "                                if col_i == 0:\n",
    "                                    if len(new_batch_data) == 0:\n",
    "                                        cls_indexes_value = 0\n",
    "                                    else:\n",
    "                                        cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                                new_batch_data.append(aug_data[aug_target_col_mask==col_i][:max_tokens_per_col])\n",
    "                            new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                            cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                            logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                            scores_temp = verifier(embs_temp.reshape(1,-1)).item()\n",
    "                            predict_temp = logits_temp.argmax().item()\n",
    "                            \n",
    "                            if scores_temp > max_score:\n",
    "                                max_score = scores_temp\n",
    "                                logits = logits_temp.clone()\n",
    "                                final_step = len(init_permutation_i) - r\n",
    "                                after_aug_results[-1][batch_idx] = logits.argmax().item()\n",
    "                                best_aug_label[-1][batch_idx] = training_aug_labels[aug_idx]\n",
    "                            # if logits_temp.argmax().item() == batch[\"label\"].item():\n",
    "                            #     correct_scores[batch_idx].append(scores_temp)\n",
    "                            #     correct_steps[batch_idx].append(len(init_permutation_i) - r)\n",
    "\n",
    "\n",
    "            final_scores.append(max_score)\n",
    "            final_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "            final_steps.append(final_step)\n",
    "            labels_test.append(batch[\"label\"].cpu())\n",
    "            logits_test.append(logits.detach().cpu())\n",
    "        labels_test = torch.cat(labels_test, dim=0)\n",
    "        logits_test = torch.stack(logits_test, dim=0)\n",
    "        preds_test = torch.argmax(logits_test, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix, f1_score\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach().numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    ts_f1_full = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=None)\n",
    "    # full_f1_init\n",
    "    print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "    print(f\"time={time.time()-ts}\")\n",
    "\n",
    "    final_correctness = torch.tensor(final_correctness)\n",
    "    init_correctness = torch.tensor(init_correctness)\n",
    "    init_scores = torch.tensor(init_scores)\n",
    "    final_scores = torch.tensor(final_scores)\n",
    "    final_steps = torch.tensor(final_steps)\n",
    "    total_steps = torch.tensor(total_steps)\n",
    "    final_scores = F.sigmoid(torch.tensor(final_scores))\n",
    "    init_scores = F.sigmoid(torch.tensor(init_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(torch.tensor(list(before_aug_results[0].values())))/len(test_dataloader_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_aug_results_1 = torch.tensor(list(before_aug_results[0].values()))\n",
    "after_aug_results_1 = torch.tensor(list(after_aug_results[0].values()))\n",
    "gt_lable_1 = torch.tensor(list(gt_lable[0].values()))\n",
    "best_aug_label_1 = torch.tensor(list(best_aug_label[0].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "after_aug_results_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(before_aug_results_1 == gt_lable_1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(after_aug_results_1 == gt_lable_1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((after_aug_results_1 == gt_lable_1)|((after_aug_results_1==-1) & (before_aug_results_1 == gt_lable_1))).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((after_aug_results_1==-1) & (before_aug_results_1 == gt_lable_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((best_aug_label_1 == gt_lable_1).sum(), (best_aug_label_1 == gt_lable_1).sum()/len(best_aug_label_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "max_tokens_per_col = 512//args.max_num_col\n",
    "\n",
    "for K in [1, 3, 5, 10]:\n",
    "    ts = time.time()\n",
    "    print(f\"============================K={K}=============================\")\n",
    "    model.load_state_dict(best_state_dict, strict=False)\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    verifier.load_state_dict(veri_state_dict)\n",
    "    verifier.eval()\n",
    "    verifier = verifier.to(device)\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    init_scores = []\n",
    "    init_correctness = []\n",
    "    final_scores = []\n",
    "    final_correctness = []\n",
    "    num_cols = []\n",
    "    total_steps = []\n",
    "    final_steps = []\n",
    "    correct_scores = defaultdict(list)\n",
    "    correct_steps = defaultdict(list)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "            target_col_mask = batch[\"target_col_mask\"].T\n",
    "            embs = test_embs[batch_idx][0].reshape(1,-1).to(device)\n",
    "            logits = test_logits[batch_idx][0].reshape(-1).to(device)\n",
    "            scores_init = verifier(embs)\n",
    "            max_score = -float(\"inf\")\n",
    "\n",
    "            init_scores.append(scores_init.item())\n",
    "            init_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            \n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            early_stop = False\n",
    "            i = 0\n",
    "            final_step = 0\n",
    "            total_steps.append(len(init_permutation_i) - max(len(init_permutation_i)//2, len(init_permutation_i)-3) -1)\n",
    "            num_cols.append(len(init_permutation_i))\n",
    "\n",
    "            for r in range(len(init_permutation_i), max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "                for x in itertools.combinations(init_permutation_i, r):\n",
    "                    if 0 not in x:\n",
    "                        continue\n",
    "                    logits_temp = test_logits[batch_idx][i].reshape(-1).to(device)\n",
    "                    embs_temp = test_embs[batch_idx][i].reshape(1,-1).to(device)\n",
    "                    scores_temp = verifier(embs_temp).item()\n",
    "                    predict_temp = logits_temp.argmax().item()\n",
    "                    i += 1\n",
    "                    if scores_temp > max_score:\n",
    "                        max_score = scores_temp\n",
    "                        logits = logits_temp.clone()\n",
    "                        final_step = len(init_permutation_i) - r\n",
    "                    if logits_temp.argmax().item() == batch[\"label\"].item():\n",
    "                        correct_scores[batch_idx].append(scores_temp)\n",
    "                        correct_steps[batch_idx].append(len(init_permutation_i) - r)\n",
    "            \n",
    "            # extra columns for those with less than max_num_col columns\n",
    "            if len(init_permutation_i) < args.max_num_col:\n",
    "                values, indices = F.cosine_similarity(test_aug_embs_sb[batch_idx], training_aug_embs_sb).topk(K)\n",
    "                for aug_idx in indices:\n",
    "                    aug_data = training_aug_data[aug_idx]\n",
    "                    aug_col_mask = training_aug_col_mask[aug_idx]\n",
    "                    # aug_permutation_i = get_permutation(aug_col_mask)[: args.max_num_col - len(init_permutation_i)]\n",
    "                    aug_permutation_all = get_permutation(aug_col_mask)\n",
    "                    \n",
    "                    aug_col_mask, aug_data = aug_col_mask[aug_col_mask<=max(aug_permutation_i)], aug_data[aug_col_mask<=max(aug_permutation_i)]\n",
    "                    assert len(aug_col_mask.unique()) == len(aug_permutation_i) and len(aug_col_mask) == len(aug_data)\n",
    "                    \n",
    "                    \n",
    "                    aug_permutation_i = torch.tensor(get_permutation(aug_col_mask)) + len(init_permutation_i) -1\n",
    "                    permutation_i = init_permutation_i + aug_permutation_i.tolist()\n",
    "                    max_num_cols_i = min(len(permutation_i), args.max_num_col)\n",
    "                    aug_data = torch.cat([batch[\"data\"].T, aug_data.reshape(1, -1)], dim=-1)\n",
    "                    aug_target_col_mask = torch.cat([target_col_mask, aug_col_mask.reshape(1, -1)], dim=-1)\n",
    "                    for r in range(max_num_cols_i, max(max_num_cols_i//2, max_num_cols_i-3), -1): # not \n",
    "                        for x in itertools.combinations(permutation_i, r):\n",
    "                            if 0 not in x:\n",
    "                                continue\n",
    "\n",
    "                            \n",
    "                            new_batch_data = []\n",
    "                            for col_i in x:\n",
    "                                if col_i == 0:\n",
    "                                    if len(new_batch_data) == 0:\n",
    "                                        cls_indexes_value = 0\n",
    "                                    else:\n",
    "                                        cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                                new_batch_data.append(aug_data[aug_target_col_mask==col_i][:max_tokens_per_col])\n",
    "                            new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                            cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                            logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                            scores_temp = verifier(embs_temp.reshape(1,-1)).item()\n",
    "                            predict_temp = logits_temp.argmax().item()\n",
    "                            if scores_temp > max_score:\n",
    "                                max_score = scores_temp\n",
    "                                logits = logits_temp.clone()\n",
    "                                final_step = len(init_permutation_i) - r\n",
    "                            # if logits_temp.argmax().item() == batch[\"label\"].item():\n",
    "                            #     correct_scores[batch_idx].append(scores_temp)\n",
    "                            #     correct_steps[batch_idx].append(len(init_permutation_i) - r)\n",
    "\n",
    "\n",
    "            final_scores.append(max_score)\n",
    "            final_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "            final_steps.append(final_step)\n",
    "            labels_test.append(batch[\"label\"].cpu())\n",
    "            logits_test.append(logits.detach().cpu())\n",
    "        labels_test = torch.cat(labels_test, dim=0)\n",
    "        logits_test = torch.stack(logits_test, dim=0)\n",
    "        preds_test = torch.argmax(logits_test, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix, f1_score\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach().numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    ts_f1_full = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=None)\n",
    "    # full_f1_init\n",
    "    print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "    print(f\"time={time.time()-ts}\")\n",
    "\n",
    "    final_correctness = torch.tensor(final_correctness)\n",
    "    init_correctness = torch.tensor(init_correctness)\n",
    "    init_scores = torch.tensor(init_scores)\n",
    "    final_scores = torch.tensor(final_scores)\n",
    "    final_steps = torch.tensor(final_steps)\n",
    "    total_steps = torch.tensor(total_steps)\n",
    "    final_scores = F.sigmoid(torch.tensor(final_scores))\n",
    "    init_scores = F.sigmoid(torch.tensor(init_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_permutation_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_col_mask.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_permutation_i[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_cols=0 ts_micro_f1=1.0000, ts_macro_f1=1.0000\n",
    "# num_cols=2 ts_micro_f1=0.6364, ts_macro_f1=0.3241\n",
    "# num_cols=3 ts_micro_f1=0.5181, ts_macro_f1=0.1611\n",
    "# num_cols=4 ts_micro_f1=0.5909, ts_macro_f1=0.2328\n",
    "# num_cols=5 ts_micro_f1=0.5455, ts_macro_f1=0.2550\n",
    "# num_cols=6 ts_micro_f1=0.5733, ts_macro_f1=0.2734\n",
    "# num_cols=7 ts_micro_f1=0.5146, ts_macro_f1=0.2800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = torch.tensor(num_cols)\n",
    "for n_col in num_cols.unique().tolist():\n",
    "    mask = num_cols == n_col\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach()[mask].numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    \n",
    "    print(\"num_cols={} ts_micro_f1={:.4f}, ts_macro_f1={:.4f}, average_final_score={:.4f}\".format(n_col, ts_micro_f1, ts_macro_f1, final_scores[mask].mean().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_check_idx = []\n",
    "for i in (torch.tensor(final_correctness) == False).nonzero().reshape(-1).tolist():\n",
    "    if len(correct_scores[i])>0:\n",
    "        to_check_idx.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_check_idx[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_check_idx_init = []\n",
    "for i in (torch.tensor(final_correctness) == False).nonzero().reshape(-1).tolist():\n",
    "    if init_correctness[i] == True:\n",
    "        to_check_idx_init.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_check_idx_init[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[34, 52] in to_check_idx_init[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set([34, 52]).issubset(set(to_check_idx_init[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(to_check_idx_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_idx = 53\n",
    "print(final_scores[target_idx], final_correctness[target_idx], init_correctness[target_idx], init_scores[target_idx], num_cols[target_idx], \n",
    "      final_steps[target_idx], total_steps[target_idx], labels_test[target_idx], preds_test[target_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.sigmoid(torch.tensor(correct_scores[target_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(final_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(np.array(final_steps)/np.array(total_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(correct_scores), len(test_dataloader_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(torch.tensor(final_steps)[final_correctness==True]/torch.tensor(total_steps)[final_correctness==True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(torch.tensor(num_cols)[final_scores>0.999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = torch.tensor(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_col in num_cols.unique():\n",
    "    print(num_col, ((final_scores>0.999)&(num_cols==num_col)).sum()/(num_cols==num_col).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(torch.tensor(num_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(torch.tensor(num_cols)<8).sum()/len(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(torch.tensor(final_steps)[final_scores>0.999]/torch.tensor(total_steps)[final_scores>0.999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(final_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(F.sigmoid(final_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_f1_full - full_f1_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_init_mask = torch.tensor(init_correctness)\n",
    "correct_msp_mask = torch.tensor(final_correctness)\n",
    "init_scores = torch.tensor(init_scores)\n",
    "final_scores = torch.tensor(final_scores)\n",
    "for threshold in [0.9, 0.99, 0.999, 0.9999]:\n",
    "    uncertain_init_mask = init_scores < threshold\n",
    "    condition_mask = ~uncertain_init_mask\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    print(\"Init\")\n",
    "    # init prediction\n",
    "    print((condition_mask&correct_init_mask).sum().item(), \n",
    "        (condition_mask).sum().item(), \n",
    "        (condition_mask&correct_init_mask).sum().item()/(condition_mask).sum().item())\n",
    "    # init prediction\n",
    "    print((~condition_mask&correct_init_mask).sum().item(), \n",
    "        (~condition_mask).sum().item(), \n",
    "       (~condition_mask&correct_init_mask).sum().item()/(~condition_mask).sum().item())\n",
    "    print(\"MSP\")\n",
    "    # msp prediction\n",
    "    print((condition_mask&correct_msp_mask).sum().item(), \n",
    "        (condition_mask).sum().item(), \n",
    "        (condition_mask&correct_msp_mask).sum().item()/(condition_mask).sum().item())\n",
    "    # msp prediction\n",
    "    print((~condition_mask&correct_msp_mask).sum().item(), \n",
    "        (~condition_mask).sum().item(), \n",
    "        (~condition_mask&correct_msp_mask).sum().item()/(~condition_mask).sum().item())\n",
    "    print(\"MSP & Init\")\n",
    "    print(((condition_mask&correct_init_mask)&(condition_mask&correct_msp_mask)).sum().item())\n",
    "    # print(((~(init_target_mask&(~uncertain_init_mask & ~uncertain_target_mask))& correct_msp_mask)&(~(init_target_mask&(~uncertain_init_mask & ~uncertain_target_mask))& correct_init_mask)).sum().item())\n",
    "    print(((condition_mask&correct_init_mask)|(condition_mask&correct_msp_mask)).sum().item(),\n",
    "          (condition_mask).sum().item(), \n",
    "          ((condition_mask&correct_init_mask)|(condition_mask&correct_msp_mask)).sum().item()/(condition_mask).sum().item())\n",
    "    print(((~condition_mask&correct_init_mask)|(~condition_mask&correct_msp_mask)).sum().item(),\n",
    "          (~condition_mask).sum().item(), \n",
    "          ((~condition_mask&correct_init_mask)|(~condition_mask&correct_msp_mask)).sum().item()/(~condition_mask).sum().item())\n",
    "    # print(\"Permutation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((final_scores>0.999).sum(), (final_scores>0.999).sum()/len(final_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((final_scores>0.999).sum(), len(final_scores), (final_scores>0.999).sum()/len(final_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = None\n",
    "init_max_col_length = 8\n",
    "test_dataset_iter_extra = GittablesTablewiseIterateDataset(cv=cv,\n",
    "                            split=\"test\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only='all' not in task,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\",\n",
    "                            max_unlabeled=16,\n",
    "                            adaptive_max_length=False,)\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "# test_dataloader_iter_extra = DataLoader(test_dataset_iter_extra,\n",
    "#                                 batch_size=1,\n",
    "#                             #   collate_fn=collate_fn)\n",
    "#                             collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_iter_extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols_extra = []\n",
    "for i in range(len(test_dataset_iter_extra)):\n",
    "    init_permutation_i = get_permutation(test_dataset_iter_extra[i][\"target_col_mask\"].T)\n",
    "    num_cols_extra.append(len(init_permutation_i))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_permutation_i, init_permutation_i_extra = init_permutation_i[:8], init_permutation_i[8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(num_cols_extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "\n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "verifier.load_state_dict(veri_state_dict)\n",
    "verifier.eval()\n",
    "verifier = verifier.to(device)\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "init_scores = []\n",
    "init_correctness = []\n",
    "final_scores = []\n",
    "final_correctness = []\n",
    "num_cols = []\n",
    "total_steps = []\n",
    "final_steps = []\n",
    "correct_scores = defaultdict(list)\n",
    "correct_steps = defaultdict(list)\n",
    "init_max_col_length = 8\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in enumerate(test_dataset_iter_extra):\n",
    "        target_col_mask = batch[\"target_col_mask\"].T\n",
    "        embs = test_embs[batch_idx][0].reshape(1,-1).to(device)\n",
    "        logits = test_logits[batch_idx][0].reshape(-1).to(device)\n",
    "        scores_init = verifier(embs)\n",
    "        max_score = -float(\"inf\")\n",
    "\n",
    "        init_scores.append(scores_init.item())\n",
    "        init_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "        init_permutation_i = get_permutation(target_col_mask)\n",
    "        init_permutation_i, init_permutation_i_extra = init_permutation_i[:init_max_col_length], init_permutation_i[init_max_col_length:]\n",
    "        \n",
    "        col_idx_set = target_col_mask.unique().tolist()\n",
    "        early_stop = False\n",
    "        i = 0\n",
    "        final_step = 0\n",
    "        total_steps.append(len(init_permutation_i) - max(len(init_permutation_i)//2, len(init_permutation_i)-3) -1)\n",
    "        num_cols.append(len(init_permutation_i))\n",
    "        enough = False\n",
    "        for r in range(len(init_permutation_i),  max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "            for x in itertools.combinations(init_permutation_i, r):\n",
    "                if 0 not in x:\n",
    "                    continue\n",
    "                logits_temp = test_logits[batch_idx][i].reshape(-1).to(device)\n",
    "                embs_temp = test_embs[batch_idx][i].reshape(1,-1).to(device)\n",
    "                scores_temp = verifier(embs_temp).item()\n",
    "                predict_temp = logits_temp.argmax().item()\n",
    "                i += 1\n",
    "                if scores_temp > max_score:\n",
    "                    max_score = scores_temp\n",
    "                    logits = logits_temp.clone()\n",
    "                    final_step = len(init_permutation_i) - r\n",
    "                if logits_temp.argmax().item() == batch[\"label\"].item():\n",
    "                    correct_scores[batch_idx].append(scores_temp)\n",
    "                    correct_steps[batch_idx].append(len(init_permutation_i) - r)\n",
    "                if F.sigmoid(torch.tensor(max_score)).item() > 0.999:\n",
    "                    enough = True\n",
    "            if enough:\n",
    "                break  \n",
    "        if not enough and len(init_permutation_i_extra)>0:\n",
    "            for new_col_idx in init_permutation_i_extra:\n",
    "                init_permutation_i_new = init_permutation_i + [new_col_idx]\n",
    "                for r in range(len(init_permutation_i),  max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "                    for x in itertools.combinations(init_permutation_i_new, r):\n",
    "                        if 0 not in x or new_col_idx not in x:\n",
    "                            continue\n",
    "                        new_batch_data = []\n",
    "                        for col_i in x:\n",
    "                            if col_i == 0:\n",
    "                                if len(new_batch_data) == 0:\n",
    "                                    cls_indexes_value = 0\n",
    "                                else:\n",
    "                                    cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                            new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                        new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                        cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                        logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                        scores_temp = verifier(embs_temp.reshape(1,-1)).item()\n",
    "                        predict_temp = logits_temp.argmax().item()\n",
    "                        \n",
    "                        if scores_temp > max_score:\n",
    "                            max_score = scores_temp\n",
    "                            logits = logits_temp.clone()\n",
    "                            final_step = len(init_permutation_i) - r\n",
    "                        if logits_temp.argmax().item() == batch[\"label\"].item():\n",
    "                            correct_scores[batch_idx].append(scores_temp)\n",
    "                            correct_steps[batch_idx].append(len(init_permutation_i) - r)\n",
    "                        if F.sigmoid(torch.tensor(max_score)).item() > 0.999:\n",
    "                            enough = True\n",
    "                    if enough:\n",
    "                        break\n",
    "                if enough:\n",
    "                    break\n",
    "                \n",
    "                \n",
    "        final_scores.append(max_score)\n",
    "        final_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "        final_steps.append(final_step)\n",
    "        labels_test.append(batch[\"label\"].cpu())\n",
    "        logits_test.append(logits.detach().cpu())\n",
    "    labels_test = torch.cat(labels_test, dim=0)\n",
    "    logits_test = torch.stack(logits_test, dim=0)\n",
    "    preds_test = torch.argmax(logits_test, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "ts_f1_full = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=None)\n",
    "# full_f1_init\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "final_correctness = torch.tensor(final_correctness)\n",
    "init_correctness = torch.tensor(init_correctness)\n",
    "init_scores = torch.tensor(init_scores)\n",
    "final_scores = torch.tensor(final_scores)\n",
    "final_steps = torch.tensor(final_steps)\n",
    "total_steps = torch.tensor(total_steps)\n",
    "final_scores = F.sigmoid(torch.tensor(final_scores))\n",
    "init_scores = F.sigmoid(torch.tensor(init_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "\n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "verifier.load_state_dict(veri_state_dict)\n",
    "verifier.eval()\n",
    "verifier = verifier.to(device)\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "init_scores = []\n",
    "init_correctness = []\n",
    "final_scores = []\n",
    "final_correctness = []\n",
    "num_cols = []\n",
    "total_steps = []\n",
    "final_steps = []\n",
    "correct_scores = defaultdict(list)\n",
    "correct_steps = defaultdict(list)\n",
    "init_max_col_length = 8\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in enumerate(test_dataset_iter_extra):\n",
    "        target_col_mask = batch[\"target_col_mask\"].T\n",
    "        embs = test_embs[batch_idx][0].reshape(1,-1).to(device)\n",
    "        logits = test_logits[batch_idx][0].reshape(-1).to(device)\n",
    "        scores_init = verifier(embs)\n",
    "        max_score = -float(\"inf\")\n",
    "\n",
    "        init_scores.append(scores_init.item())\n",
    "        init_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "        init_permutation_i = get_permutation(target_col_mask)\n",
    "        init_permutation_i, init_permutation_i_extra = init_permutation_i[:init_max_col_length], init_permutation_i[init_max_col_length:]\n",
    "        \n",
    "        col_idx_set = target_col_mask.unique().tolist()\n",
    "        early_stop = False\n",
    "        i = 0\n",
    "        final_step = 0\n",
    "        total_steps.append(len(init_permutation_i) - max(len(init_permutation_i)//2, len(init_permutation_i)-3) -1)\n",
    "        num_cols.append(len(init_permutation_i))\n",
    "        enough = False\n",
    "        for r in range(len(init_permutation_i),  max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "            for x in itertools.combinations(init_permutation_i, r):\n",
    "                if 0 not in x:\n",
    "                    continue\n",
    "                logits_temp = test_logits[batch_idx][i].reshape(-1).to(device)\n",
    "                embs_temp = test_embs[batch_idx][i].reshape(1,-1).to(device)\n",
    "                scores_temp = verifier(embs_temp).item()\n",
    "                predict_temp = logits_temp.argmax().item()\n",
    "                i += 1\n",
    "                if scores_temp > max_score:\n",
    "                    max_score = scores_temp\n",
    "                    logits = logits_temp.clone()\n",
    "                    final_step = len(init_permutation_i) - r\n",
    "                if logits_temp.argmax().item() == batch[\"label\"].item():\n",
    "                    correct_scores[batch_idx].append(scores_temp)\n",
    "                    correct_steps[batch_idx].append(len(init_permutation_i) - r)\n",
    "\n",
    "        if len(init_permutation_i_extra)>0:\n",
    "            for new_col_idx in init_permutation_i_extra:\n",
    "                init_permutation_i_new = init_permutation_i + [new_col_idx]\n",
    "                for r in range(len(init_permutation_i),  max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "                    for x in itertools.combinations(init_permutation_i_new, r):\n",
    "                        if 0 not in x or new_col_idx not in x:\n",
    "                            continue\n",
    "                        new_batch_data = []\n",
    "                        for col_i in x:\n",
    "                            if col_i == 0:\n",
    "                                if len(new_batch_data) == 0:\n",
    "                                    cls_indexes_value = 0\n",
    "                                else:\n",
    "                                    cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                            new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                        new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                        cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                        logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                        scores_temp = verifier(embs_temp.reshape(1,-1)).item()\n",
    "                        predict_temp = logits_temp.argmax().item()\n",
    "                        \n",
    "                        if scores_temp > max_score:\n",
    "                            max_score = scores_temp\n",
    "                            logits = logits_temp.clone()\n",
    "                            final_step = len(init_permutation_i) - r\n",
    "                        if logits_temp.argmax().item() == batch[\"label\"].item():\n",
    "                            correct_scores[batch_idx].append(scores_temp)\n",
    "                            correct_steps[batch_idx].append(len(init_permutation_i) - r)\n",
    "\n",
    "                \n",
    "                \n",
    "        final_scores.append(max_score)\n",
    "        final_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "        final_steps.append(final_step)\n",
    "        labels_test.append(batch[\"label\"].cpu())\n",
    "        logits_test.append(logits.detach().cpu())\n",
    "    labels_test = torch.cat(labels_test, dim=0)\n",
    "    logits_test = torch.stack(logits_test, dim=0)\n",
    "    preds_test = torch.argmax(logits_test, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "ts_f1_full = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=None)\n",
    "# full_f1_init\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "final_correctness = torch.tensor(final_correctness)\n",
    "init_correctness = torch.tensor(init_correctness)\n",
    "init_scores = torch.tensor(init_scores)\n",
    "final_scores = torch.tensor(final_scores)\n",
    "final_steps = torch.tensor(final_steps)\n",
    "total_steps = torch.tensor(total_steps)\n",
    "final_scores = F.sigmoid(torch.tensor(final_scores))\n",
    "init_scores = F.sigmoid(torch.tensor(init_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "for max_unlabeled in [16, 32, 64, 128]:\n",
    "    print(f\"============================max_unlabeled={max_unlabeled}===============================\")\n",
    "    test_dataset_iter_extra = GittablesTablewiseIterateDataset(cv=cv,\n",
    "                                split=\"test\", src=src,\n",
    "                                tokenizer=tokenizer,\n",
    "                                max_length=max_length,\n",
    "                                gt_only='all' not in task,\n",
    "                                device=device,\n",
    "                                base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                                small_tag=\"semi1\",\n",
    "                                max_unlabeled=max_unlabeled,\n",
    "                                adaptive_max_length=False,)\n",
    "    model.load_state_dict(best_state_dict, strict=False)\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    verifier.load_state_dict(veri_state_dict)\n",
    "    verifier.eval()\n",
    "    verifier = verifier.to(device)\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    init_scores = []\n",
    "    init_correctness = []\n",
    "    final_scores = []\n",
    "    final_correctness = []\n",
    "    num_cols = []\n",
    "    total_steps = []\n",
    "    final_steps = []\n",
    "    correct_scores = defaultdict(list)\n",
    "    correct_steps = defaultdict(list)\n",
    "    init_max_col_length = 8\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(test_dataset_iter_extra):\n",
    "            target_col_mask = batch[\"target_col_mask\"].T\n",
    "            embs = test_embs[batch_idx][0].reshape(1,-1).to(device)\n",
    "            logits = test_logits[batch_idx][0].reshape(-1).to(device)\n",
    "            scores_init = verifier(embs)\n",
    "            max_score = -float(\"inf\")\n",
    "\n",
    "            init_scores.append(scores_init.item())\n",
    "            init_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            init_permutation_i, init_permutation_i_extra = init_permutation_i[:init_max_col_length], init_permutation_i[init_max_col_length:]\n",
    "            \n",
    "            if 0 not in init_permutation_i:\n",
    "                col_to_exclude = init_permutation_i[-1]\n",
    "                init_permutation_i = init_permutation_i[:-1] + [0]\n",
    "                init_permutation_i_extra.remove(0)\n",
    "                init_permutation_i_extra = [col_to_exclude] + init_permutation_i_extra\n",
    "                assert 0 in init_permutation_i and 0 not in init_permutation_i_extra\n",
    "            \n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            early_stop = False\n",
    "            i = 0\n",
    "            final_step = 0\n",
    "            total_steps.append(len(init_permutation_i) - max(len(init_permutation_i)//2, len(init_permutation_i)-3) -1)\n",
    "            num_cols.append(len(init_permutation_i))\n",
    "            enough = False\n",
    "            for r in range(len(init_permutation_i),  max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "                for x in itertools.combinations(init_permutation_i, r):\n",
    "                    if 0 not in x:\n",
    "                        continue\n",
    "                    logits_temp = test_logits[batch_idx][i].reshape(-1).to(device)\n",
    "                    embs_temp = test_embs[batch_idx][i].reshape(1,-1).to(device)\n",
    "                    scores_temp = verifier(embs_temp).item()\n",
    "                    predict_temp = logits_temp.argmax().item()\n",
    "                    i += 1\n",
    "                    if scores_temp > max_score:\n",
    "                        max_score = scores_temp\n",
    "                        logits = logits_temp.clone()\n",
    "                        final_step = len(init_permutation_i) - r\n",
    "                    if logits_temp.argmax().item() == batch[\"label\"].item():\n",
    "                        correct_scores[batch_idx].append(scores_temp)\n",
    "                        correct_steps[batch_idx].append(len(init_permutation_i) - r)\n",
    "                    if F.sigmoid(torch.tensor(max_score)).item() > 0.999:\n",
    "                        enough = True\n",
    "                if enough:\n",
    "                    break  \n",
    "            if not enough and len(init_permutation_i_extra)>0:\n",
    "                for new_col_idx in init_permutation_i_extra:\n",
    "                    init_permutation_i_new = init_permutation_i + [new_col_idx]\n",
    "                    for r in range(len(init_permutation_i),  max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "                        for x in itertools.combinations(init_permutation_i_new, r):\n",
    "                            if 0 not in x or new_col_idx not in x:\n",
    "                                continue\n",
    "                            new_batch_data = []\n",
    "                            for col_i in x:\n",
    "                                if col_i == 0:\n",
    "                                    if len(new_batch_data) == 0:\n",
    "                                        cls_indexes_value = 0\n",
    "                                    else:\n",
    "                                        cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                                new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                            new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                            cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                            logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                            scores_temp = verifier(embs_temp.reshape(1,-1)).item()\n",
    "                            predict_temp = logits_temp.argmax().item()\n",
    "                            \n",
    "                            if scores_temp > max_score:\n",
    "                                max_score = scores_temp\n",
    "                                logits = logits_temp.clone()\n",
    "                                final_step = len(init_permutation_i) - r\n",
    "                            if logits_temp.argmax().item() == batch[\"label\"].item():\n",
    "                                correct_scores[batch_idx].append(scores_temp)\n",
    "                                correct_steps[batch_idx].append(len(init_permutation_i) - r)\n",
    "                            if F.sigmoid(torch.tensor(max_score)).item() > 0.999:\n",
    "                                enough = True\n",
    "                        if enough:\n",
    "                            break\n",
    "                    if enough:\n",
    "                        break\n",
    "                    \n",
    "                    \n",
    "            final_scores.append(max_score)\n",
    "            final_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "            final_steps.append(final_step)\n",
    "            labels_test.append(batch[\"label\"].cpu())\n",
    "            logits_test.append(logits.detach().cpu())\n",
    "        labels_test = torch.cat(labels_test, dim=0)\n",
    "        logits_test = torch.stack(logits_test, dim=0)\n",
    "        preds_test = torch.argmax(logits_test, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix, f1_score\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach().numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    ts_f1_full = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=None)\n",
    "    # full_f1_init\n",
    "    print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "    final_correctness = torch.tensor(final_correctness)\n",
    "    init_correctness = torch.tensor(init_correctness)\n",
    "    init_scores = torch.tensor(init_scores)\n",
    "    final_scores = torch.tensor(final_scores)\n",
    "    final_steps = torch.tensor(final_steps)\n",
    "    total_steps = torch.tensor(total_steps)\n",
    "    final_scores = F.sigmoid(torch.tensor(final_scores))\n",
    "    init_scores = F.sigmoid(torch.tensor(init_scores))\n",
    "    print((final_scores>0.999).sum(), len(final_scores), (final_scores>0.999).sum()/len(final_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_micro_f1=0.5567, ts_macro_f1=0.2983"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "for max_unlabeled in [32, 64, 128]:\n",
    "    print(f\"============================max_unlabeled={max_unlabeled}===============================\")\n",
    "    test_dataset_iter_extra = GittablesTablewiseIterateDataset(cv=cv,\n",
    "                                split=\"test\", src=src,\n",
    "                                tokenizer=tokenizer,\n",
    "                                max_length=max_length,\n",
    "                                gt_only='all' not in task,\n",
    "                                device=device,\n",
    "                                base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                                small_tag=\"semi1\",\n",
    "                                max_unlabeled=max_unlabeled,\n",
    "                                adaptive_max_length=False,)\n",
    "    model.load_state_dict(best_state_dict, strict=False)\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    verifier.load_state_dict(veri_state_dict)\n",
    "    verifier.eval()\n",
    "    verifier = verifier.to(device)\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    init_scores = []\n",
    "    init_correctness = []\n",
    "    final_scores = []\n",
    "    final_correctness = []\n",
    "    num_cols = []\n",
    "    total_steps = []\n",
    "    final_steps = []\n",
    "    correct_scores = defaultdict(list)\n",
    "    correct_steps = defaultdict(list)\n",
    "    init_max_col_length = 8\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(test_dataset_iter_extra):\n",
    "            target_col_mask = batch[\"target_col_mask\"].T\n",
    "            embs = test_embs[batch_idx][0].reshape(1,-1).to(device)\n",
    "            logits = test_logits[batch_idx][0].reshape(-1).to(device)\n",
    "            scores_init = verifier(embs)\n",
    "            max_score = -float(\"inf\")\n",
    "\n",
    "            init_scores.append(scores_init.item())\n",
    "            init_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            init_permutation_i, init_permutation_i_extra = init_permutation_i[:init_max_col_length], init_permutation_i[init_max_col_length:]\n",
    "            \n",
    "            if 0 not in init_permutation_i:\n",
    "                col_to_exclude = init_permutation_i[-1]\n",
    "                init_permutation_i = init_permutation_i[:-1] + [0]\n",
    "                init_permutation_i_extra.remove(0)\n",
    "                init_permutation_i_extra = [col_to_exclude] + init_permutation_i_extra\n",
    "                assert 0 in init_permutation_i and 0 not in init_permutation_i_extra\n",
    "            \n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            early_stop = False\n",
    "            i = 0\n",
    "            final_step = 0\n",
    "            total_steps.append(len(init_permutation_i) - max(len(init_permutation_i)//2, len(init_permutation_i)-3) -1)\n",
    "            num_cols.append(len(init_permutation_i))\n",
    "            enough = False\n",
    "            for r in range(len(init_permutation_i),  max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "                for x in itertools.combinations(init_permutation_i, r):\n",
    "                    if 0 not in x:\n",
    "                        continue\n",
    "                    logits_temp = test_logits[batch_idx][i].reshape(-1).to(device)\n",
    "                    embs_temp = test_embs[batch_idx][i].reshape(1,-1).to(device)\n",
    "                    scores_temp = verifier(embs_temp).item()\n",
    "                    predict_temp = logits_temp.argmax().item()\n",
    "                    i += 1\n",
    "                    if scores_temp > max_score:\n",
    "                        max_score = scores_temp\n",
    "                        logits = logits_temp.clone()\n",
    "                        final_step = len(init_permutation_i) - r\n",
    "                    if logits_temp.argmax().item() == batch[\"label\"].item():\n",
    "                        correct_scores[batch_idx].append(scores_temp)\n",
    "                        correct_steps[batch_idx].append(len(init_permutation_i) - r)\n",
    "                    if F.sigmoid(torch.tensor(max_score)).item() > 0.999:\n",
    "                        enough = True\n",
    "                if enough:\n",
    "                    break  \n",
    "            if not enough and len(init_permutation_i_extra)>0:\n",
    "                for new_col_idx in init_permutation_i_extra:\n",
    "                    init_permutation_i_new = init_permutation_i + [new_col_idx]\n",
    "                    for r in range(len(init_permutation_i),  max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "                        for x in itertools.combinations(init_permutation_i_new, r):\n",
    "                            if 0 not in x or new_col_idx not in x:\n",
    "                                continue\n",
    "                            new_batch_data = []\n",
    "                            for col_i in x:\n",
    "                                if col_i == 0:\n",
    "                                    if len(new_batch_data) == 0:\n",
    "                                        cls_indexes_value = 0\n",
    "                                    else:\n",
    "                                        cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                                new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                            new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                            cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                            logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                            scores_temp = verifier(embs_temp.reshape(1,-1)).item()\n",
    "                            predict_temp = logits_temp.argmax().item()\n",
    "                            \n",
    "                            if scores_temp > max_score:\n",
    "                                max_score = scores_temp\n",
    "                                logits = logits_temp.clone()\n",
    "                                final_step = len(init_permutation_i) - r\n",
    "                            if logits_temp.argmax().item() == batch[\"label\"].item():\n",
    "                                correct_scores[batch_idx].append(scores_temp)\n",
    "                                correct_steps[batch_idx].append(len(init_permutation_i) - r)\n",
    "                            if F.sigmoid(torch.tensor(max_score)).item() > 0.999:\n",
    "                                enough = True\n",
    "                        if enough:\n",
    "                            break\n",
    "                    if enough:\n",
    "                        break\n",
    "                    \n",
    "                    \n",
    "            final_scores.append(max_score)\n",
    "            final_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "            final_steps.append(final_step)\n",
    "            labels_test.append(batch[\"label\"].cpu())\n",
    "            logits_test.append(logits.detach().cpu())\n",
    "        labels_test = torch.cat(labels_test, dim=0)\n",
    "        logits_test = torch.stack(logits_test, dim=0)\n",
    "        preds_test = torch.argmax(logits_test, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix, f1_score\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach().numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    ts_f1_full = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=None)\n",
    "    # full_f1_init\n",
    "    print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "    final_correctness = torch.tensor(final_correctness)\n",
    "    init_correctness = torch.tensor(init_correctness)\n",
    "    init_scores = torch.tensor(init_scores)\n",
    "    final_scores = torch.tensor(final_scores)\n",
    "    final_steps = torch.tensor(final_steps)\n",
    "    total_steps = torch.tensor(total_steps)\n",
    "    final_scores = F.sigmoid(torch.tensor(final_scores))\n",
    "    init_scores = F.sigmoid(torch.tensor(init_scores))\n",
    "    print((final_scores>0.999).sum(), len(final_scores), (final_scores>0.999).sum()/len(final_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "for max_unlabeled in [16]:\n",
    "    print(f\"============================max_unlabeled={max_unlabeled}===============================\")\n",
    "    test_dataset_iter_extra = GittablesTablewiseIterateDataset(cv=cv,\n",
    "                                split=\"test\", src=src,\n",
    "                                tokenizer=tokenizer,\n",
    "                                max_length=max_length,\n",
    "                                gt_only='all' not in task,\n",
    "                                device=device,\n",
    "                                base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                                small_tag=\"semi1\",\n",
    "                                max_unlabeled=max_unlabeled,\n",
    "                                adaptive_max_length=False,)\n",
    "    model.load_state_dict(best_state_dict, strict=False)\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    verifier.load_state_dict(veri_state_dict)\n",
    "    verifier.eval()\n",
    "    verifier = verifier.to(device)\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    init_scores = []\n",
    "    init_correctness = []\n",
    "    final_scores = []\n",
    "    final_correctness = []\n",
    "    num_cols = []\n",
    "    total_steps = []\n",
    "    final_steps = []\n",
    "    correct_scores = defaultdict(list)\n",
    "    correct_steps = defaultdict(list)\n",
    "    init_max_col_length = 8\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(test_dataset_iter_extra):\n",
    "            target_col_mask = batch[\"target_col_mask\"].T\n",
    "            embs = test_embs[batch_idx][0].reshape(1,-1).to(device)\n",
    "            logits = test_logits[batch_idx][0].reshape(-1).to(device)\n",
    "            scores_init = verifier(embs)\n",
    "            max_score = -float(\"inf\")\n",
    "\n",
    "            init_scores.append(scores_init.item())\n",
    "            init_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            init_permutation_i, init_permutation_i_extra = init_permutation_i[:init_max_col_length], init_permutation_i[init_max_col_length:]\n",
    "            \n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            early_stop = False\n",
    "            i = 0\n",
    "            final_step = 0\n",
    "            total_steps.append(len(init_permutation_i) - max(len(init_permutation_i)//2, len(init_permutation_i)-3) -1)\n",
    "            num_cols.append(len(init_permutation_i))\n",
    "            enough = False\n",
    "            for r in range(len(init_permutation_i),  max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "                for x in itertools.combinations(init_permutation_i, r):\n",
    "                    if 0 not in x:\n",
    "                        continue\n",
    "                    logits_temp = test_logits[batch_idx][i].reshape(-1).to(device)\n",
    "                    embs_temp = test_embs[batch_idx][i].reshape(1,-1).to(device)\n",
    "                    scores_temp = verifier(embs_temp).item()\n",
    "                    predict_temp = logits_temp.argmax().item()\n",
    "                    i += 1\n",
    "                    if scores_temp > max_score:\n",
    "                        max_score = scores_temp\n",
    "                        logits = logits_temp.clone()\n",
    "                        final_step = len(init_permutation_i) - r\n",
    "                    if logits_temp.argmax().item() == batch[\"label\"].item():\n",
    "                        correct_scores[batch_idx].append(scores_temp)\n",
    "                        correct_steps[batch_idx].append(len(init_permutation_i) - r)\n",
    "                    if F.sigmoid(torch.tensor(max_score)).item() > 0.999:\n",
    "                        enough = True\n",
    "                if enough:\n",
    "                    break  \n",
    "                \n",
    "            if not enough and len(init_permutation_i_extra)>0:\n",
    "                for z in range(1, len(init_permutation_i_extra)+1):\n",
    "                    for new_col_idx in itertools.combinations(init_permutation_i_extra, z):\n",
    "                        init_permutation_i_new = init_permutation_i + list(new_col_idx)\n",
    "                        for r in range(len(init_permutation_i),  max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1):\n",
    "                            for x in itertools.combinations(init_permutation_i_new, r):\n",
    "                                if not set(list(new_col_idx)+[0]).issubset(set(x)):\n",
    "                                    continue\n",
    "                                new_batch_data = []\n",
    "                                for col_i in x:\n",
    "                                    if col_i == 0:\n",
    "                                        if len(new_batch_data) == 0:\n",
    "                                            cls_indexes_value = 0\n",
    "                                        else:\n",
    "                                            cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                                    new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                                new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                                cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                                logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                                scores_temp = verifier(embs_temp.reshape(1,-1)).item()\n",
    "                                predict_temp = logits_temp.argmax().item()\n",
    "                                \n",
    "                                if scores_temp > max_score:\n",
    "                                    max_score = scores_temp\n",
    "                                    logits = logits_temp.clone()\n",
    "                                    final_step = len(init_permutation_i) - r\n",
    "                                if logits_temp.argmax().item() == batch[\"label\"].item():\n",
    "                                    correct_scores[batch_idx].append(scores_temp)\n",
    "                                    correct_steps[batch_idx].append(len(init_permutation_i) - r)\n",
    "                                if F.sigmoid(torch.tensor(max_score)).item() > 0.999:\n",
    "                                    enough = True\n",
    "                            if enough:\n",
    "                                break\n",
    "                        if enough:\n",
    "                            break\n",
    "                        \n",
    "                    \n",
    "            final_scores.append(max_score)\n",
    "            final_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "            final_steps.append(final_step)\n",
    "            labels_test.append(batch[\"label\"].cpu())\n",
    "            logits_test.append(logits.detach().cpu())\n",
    "        labels_test = torch.cat(labels_test, dim=0)\n",
    "        logits_test = torch.stack(logits_test, dim=0)\n",
    "        preds_test = torch.argmax(logits_test, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix, f1_score\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach().numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    ts_f1_full = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=None)\n",
    "    # full_f1_init\n",
    "    print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "    final_correctness = torch.tensor(final_correctness)\n",
    "    init_correctness = torch.tensor(init_correctness)\n",
    "    init_scores = torch.tensor(init_scores)\n",
    "    final_scores = torch.tensor(final_scores)\n",
    "    final_steps = torch.tensor(final_steps)\n",
    "    total_steps = torch.tensor(total_steps)\n",
    "    final_scores = F.sigmoid(torch.tensor(final_scores))\n",
    "    init_scores = F.sigmoid(torch.tensor(init_scores))\n",
    "    print((final_scores>0.999).sum(), len(final_scores), (final_scores>0.999).sum()/len(final_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "        for batch_idx, batch in enumerate(test_dataset_iter_extra):\n",
    "            target_col_mask = batch[\"target_col_mask\"].T\n",
    "            embs = test_embs[batch_idx][0].reshape(1,-1).to(device)\n",
    "            logits = test_logits[batch_idx][0].reshape(-1).to(device)\n",
    "            scores_init = verifier(embs)\n",
    "            max_score = -float(\"inf\")\n",
    "\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            init_permutation_i, init_permutation_i_extra = init_permutation_i[:init_max_col_length], init_permutation_i[init_max_col_length:]\n",
    "            \n",
    "            if 0 not in init_permutation_i:\n",
    "                col_to_exclude = init_permutation_i[-1]\n",
    "                init_permutation_i = init_permutation_i[:-1] + [0]\n",
    "                init_permutation_i_extra.remove(0)\n",
    "                init_permutation_i_extra = [col_to_exclude] + init_permutation_i_extra\n",
    "                assert 0 in init_permutation_i and 0 not in init_permutation_i_extra\n",
    "            if len(init_permutation_i_extra) == 2:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_permutation_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_permutation_i_extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_permutation_i_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(new_col_idx)+[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for z in range(1, len(init_permutation_i_extra)+1):\n",
    "    for new_col_idx in itertools.combinations(init_permutation_i_extra, z):\n",
    "        init_permutation_i_new = init_permutation_i + list(new_col_idx)\n",
    "        for r in range(len(init_permutation_i),  max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1):\n",
    "            for x in itertools.combinations(init_permutation_i_new, r):\n",
    "                if not set(list(new_col_idx)+[0]).issubset(set(x)):\n",
    "                    continue\n",
    "                if 0 not in x:\n",
    "                    break\n",
    "                print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_permutation_i_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(list(new_col_idx)+[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_permutation_i_extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(test_dataset_iter_extra):\n",
    "        target_col_mask = batch[\"target_col_mask\"].T\n",
    "        init_permutation_i = get_permutation(target_col_mask)\n",
    "        num_cols.append(len(init_permutation_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# table search STARMIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list_1 = [\n",
    "    \"Name: Philip Duffy; Jeremy Oppenheim; Mark Sedwill;\",\n",
    "    \"Mode of Travel: Air; Taxi; Air;\",\n",
    "    \"Purpose: Regional Meeting; Exchange Visit; Evening Meal;\",\n",
    "    \"Destination: London; Ottawa; Bristol;\",\n",
    "    \"Day: 10; 30; 02;\",\n",
    "    \"Month: April; July; September;\",\n",
    "    \"Year: 2019; 2019; 2019;\",\n",
    "    \"Expense: 189.06; 8.08; 50.00;\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cur_maxlen = min(max_length, 512 // len(column_list_1) - 1)\n",
    "\n",
    "# print(tokenizer.cls_token)\n",
    "# print(group_df[\"data\"])\n",
    "token_ids_list = [tokenizer.encode(\n",
    "                tokenizer.cls_token + \" \" + str(x), add_special_tokens=False, max_length=cur_maxlen, truncation=True) for x in column_list_1]\n",
    "token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                    token_ids_list)).to(device)\n",
    "cls_index_list = [0] + np.cumsum(\n",
    "    np.array([len(x) for x in token_ids_list])).tolist()[:-1]\n",
    "cls_indexes = torch.LongTensor(cls_index_list).to(device).reshape(-1, 1)\n",
    "cls_indexes = torch.hstack([torch.zeros_like(cls_indexes), cls_indexes])\n",
    "logits, embs_1 = model(token_ids.reshape(1, -1), cls_indexes=cls_indexes, get_enc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "cur_maxlen = min(max_length, 512 // len(column_list_1) - 1)\n",
    "\n",
    "# print(tokenizer.cls_token)\n",
    "# print(group_df[\"data\"])\n",
    "token_ids_list = [tokenizer.encode(\n",
    "                tokenizer.cls_token + \" \" + str(x), add_special_tokens=False, max_length=cur_maxlen, truncation=True) for x in column_list_1]\n",
    "token_ids = nn.utils.rnn.pad_sequence(\n",
    "      [torch.tensor(x) for x in token_ids_list], padding_value=tokenizer.pad_token_id).to(device)\n",
    "cls_indexes = torch.nonzero(\n",
    "                token_ids == tokenizer.cls_token_id)\n",
    "logits, embs_1_seperate = model(token_ids, cls_indexes=cls_indexes, get_enc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list_2 = [\n",
    "    \"Name: Clark; Gyimah; Harrington;\",\n",
    "    \"Date: 23/07; 03/09; 05/08;\",\n",
    "    \"Destination: France; Belgium; China;\",\n",
    "    \"Purpose: Discuss EU; Build Relations; Discuss Productivity;\",\n",
    "]\n",
    "cur_maxlen = min(max_length, 512 // len(column_list_2) - 1)\n",
    "\n",
    "# print(tokenizer.cls_token)\n",
    "# print(group_df[\"data\"])\n",
    "token_ids_list = [tokenizer.encode(\n",
    "                tokenizer.cls_token + \" \" + str(x), add_special_tokens=False, max_length=cur_maxlen, truncation=True) \n",
    "                  for x in column_list_2]\n",
    "token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                    token_ids_list)).to(device)\n",
    "cls_index_list = [0] + np.cumsum(\n",
    "    np.array([len(x) for x in token_ids_list])).tolist()[:-1]\n",
    "cls_indexes = torch.LongTensor(cls_index_list).to(device).reshape(-1, 1)\n",
    "cls_indexes = torch.hstack([torch.zeros_like(cls_indexes), cls_indexes])\n",
    "logits, embs_2 = model(token_ids.reshape(1, -1), cls_indexes=cls_indexes, get_enc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids = token_ids.reshape(1, -1)\n",
    "attention_mask = token_ids != 0\n",
    "res = model.bert(token_ids, attention_mask=attention_mask, return_dict=True, output_attentions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(res['attentions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res['attentions'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res['attentions'][0].squeeze().mean(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res['attentions'][0].squeeze().mean(0)[cls_mask][:, cls_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_mask = (token_ids==tokenizer.cls_token_id).reshape(-1)\n",
    "acc_attention = []\n",
    "for i in range(len(res['attentions'])):\n",
    "    attn_i = res['attentions'][i].squeeze().mean(0)[cls_mask][:, cls_mask].mean(0)\n",
    "    acc_attention.append(attn_i)\n",
    "    print(attn_i)\n",
    "acc_attention = torch.stack(acc_attention, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_mask = (token_ids==tokenizer.cls_token_id).reshape(-1)\n",
    "acc_attention = torch.ones_like(res['attentions'][0].squeeze().mean(0)[cls_mask][:, cls_mask].mean(0))\n",
    "for i in range(len(res['attentions'])-1, -1, -1):\n",
    "    attn_i = res['attentions'][i].squeeze().mean(0)[cls_mask][:, cls_mask].mean(0)\n",
    "    acc_attention = acc_attention * attn_i\n",
    "    print(acc_attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res['attentions'][0].squeeze().mean(0)[cls_mask][:, cls_mask].fill_diagonal_(0).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "cur_maxlen = min(max_length, 512 // len(column_list_2) - 1)\n",
    "\n",
    "# print(tokenizer.cls_token)\n",
    "# print(group_df[\"data\"])\n",
    "token_ids_list = [tokenizer.encode(\n",
    "                tokenizer.cls_token + \" \" + str(x), add_special_tokens=False, max_length=cur_maxlen, truncation=True) \n",
    "                  for x in column_list_2]\n",
    "token_ids = nn.utils.rnn.pad_sequence(\n",
    "      [torch.tensor(x) for x in token_ids_list], padding_value=tokenizer.pad_token_id).to(device)\n",
    "cls_indexes = torch.nonzero(\n",
    "                token_ids == tokenizer.cls_token_id)\n",
    "logits, embs_2_seperate = model(token_ids, cls_indexes=cls_indexes, get_enc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list_3 = [\n",
    "    'Bird Name: Pine Siskin; American Robin; Northern Flicker;',\n",
    "    'Scientific Name: Carduelis Pinus; Turdus migratorius; Colaptes auratus;',\n",
    "    'Date: 2019; 2019; 2019;',\n",
    "    'Location: Ottawa; Ottawa; London;'\n",
    "]\n",
    "\n",
    "cur_maxlen = min(max_length, 512 // len(column_list_3) - 1)\n",
    "\n",
    "# print(tokenizer.cls_token)\n",
    "# print(group_df[\"data\"])\n",
    "token_ids_list = [tokenizer.encode(\n",
    "                tokenizer.cls_token + \" \" + str(x), add_special_tokens=False, max_length=cur_maxlen, truncation=True) \n",
    "                  for x in column_list_3]\n",
    "token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                    token_ids_list)).to(device)\n",
    "cls_index_list = [0] + np.cumsum(\n",
    "    np.array([len(x) for x in token_ids_list])).tolist()[:-1]\n",
    "cls_indexes = torch.LongTensor(cls_index_list).to(device).reshape(-1, 1)\n",
    "cls_indexes = torch.hstack([torch.zeros_like(cls_indexes), cls_indexes])\n",
    "logits, embs_3 = model(token_ids.reshape(1, -1), cls_indexes=cls_indexes, get_enc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "cur_maxlen = min(max_length, 512 // len(column_list_3) - 1)\n",
    "\n",
    "# print(tokenizer.cls_token)\n",
    "# print(group_df[\"data\"])\n",
    "token_ids_list = [tokenizer.encode(\n",
    "                tokenizer.cls_token + \" \" + str(x), add_special_tokens=False, max_length=cur_maxlen, truncation=True) \n",
    "                  for x in column_list_3]\n",
    "token_ids = nn.utils.rnn.pad_sequence(\n",
    "      [torch.tensor(x) for x in token_ids_list], padding_value=tokenizer.pad_token_id).to(device)\n",
    "cls_indexes = torch.nonzero(\n",
    "                token_ids == tokenizer.cls_token_id)\n",
    "logits, embs_3_seperate = model(token_ids, cls_indexes=cls_indexes, get_enc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_similarity(embs_1.detach().cpu().numpy(), embs_2.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cosine_similarity(embs_1.detach().cpu().numpy(), embs_2.detach().cpu().numpy()).max(0))\n",
    "cosine_similarity(embs_1.detach().cpu().numpy(), embs_2.detach().cpu().numpy()).max(0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cosine_similarity(embs_1_seperate.detach().cpu().numpy(), embs_2_seperate.detach().cpu().numpy()).max(0))\n",
    "cosine_similarity(embs_1_seperate.detach().cpu().numpy(), embs_2_seperate.detach().cpu().numpy()).max(0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((final_scores>0.999).sum(), len(final_scores), (final_scores>0.999).sum()/len(final_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "    if len(group_df) > 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_embs = sb_model.encode(group_df[\"data\"].to_list())\n",
    "# use cosine similarity to find the closest column\n",
    "closest_col = []\n",
    "for i in range(8):\n",
    "    sim = F.cosine_similarity(col_embs, centers[i].reshape(1, -1))\n",
    "    closest_col.append(sim.argmax().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kmeans cluster the columns and find the column closest to the center\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=8, random_state=0).fit(col_embs)\n",
    "centers = torch.tensor(kmeans.cluster_centers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the closest column to the center\n",
    "closest_col = []\n",
    "col_embs = torch.tensor(col_embs)\n",
    "for i in range(8):\n",
    "    dist = torch.norm(col_embs - centers[i], dim=1)\n",
    "    closest_col.append(dist.argmin().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in closest_col:\n",
    "    print(group_df.iloc[i][\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embs_pos = []\n",
    "test_embs_neg = []\n",
    "for batch_idx in range(len(test_embs)):\n",
    "    for i in range(len(test_embs[batch_idx])):\n",
    "        if test_label[batch_idx][i].item() == 1:\n",
    "            test_embs_pos.append(test_embs[batch_idx][i])\n",
    "        else:\n",
    "            test_embs_neg.append(test_embs[batch_idx][i])\n",
    "test_embs_pos = torch.stack(test_embs_pos, dim=0)\n",
    "test_embs_neg = torch.stack(test_embs_neg, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Pairwise cosine similarity\n",
    "test_similarity_matrix = cosine_similarity(test_embs_pos.numpy(), test_embs_neg.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95077914"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_similarity_matrix.max(1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14223903"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_similarity_matrix.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
