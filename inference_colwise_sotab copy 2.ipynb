{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/zhihao/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/zhihao/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "from time import time\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from collections import defaultdict\n",
    "\n",
    "# import pytrec_eval\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss, BCEWithLogitsLoss\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, BertConfig, AutoTokenizer\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from accelerate import Accelerator\n",
    "from copy import deepcopy\n",
    "\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "from watchog.dataset import (\n",
    "    # collate_fn,\n",
    "    TURLColTypeTablewiseDataset,\n",
    "    TURLRelExtTablewiseDataset,\n",
    "    SatoCVTablewiseDataset,\n",
    "    ColPoplTablewiseDataset,\n",
    "    SotabCVTablewiseDataset\n",
    ")\n",
    "\n",
    "from watchog.dataset import TableDataset, SupCLTableDataset, SemtableCVTablewiseDataset, GittablesColwiseDataset, GittablesTablewiseDataset\n",
    "from watchog.model import BertMultiPairPooler, BertForMultiOutputClassification, BertForMultiOutputClassificationColPopl\n",
    "from watchog.model import SupCLforTable, UnsupCLforTable, lm_mp\n",
    "from watchog.utils import load_checkpoint, f1_score_multilabel, collate_fn, get_col_pred, ColPoplEvaluator\n",
    "from watchog.utils import task_num_class_dict\n",
    "from accelerate import DistributedDataParallelKwargs\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args={\"wandb\": false, \"model\": \"Watchog\", \"unlabeled_train_only\": false, \"context_encoding_type\": \"v0\", \"pool_version\": \"v0.2\", \"random_sample\": false, \"comment\": \"debug\", \"shortcut_name\": \"bert-base-uncased\", \"max_length\": 64, \"adaptive_max_length\": false, \"max_num_col\": 8, \"batch_size\": 16, \"epoch\": 1, \"random_seed\": 4649, \"train_n_seed_cols\": -1, \"num_classes\": 91, \"multi_gpu\": false, \"fp16\": false, \"warmup\": 0.0, \"lr\": 5e-05, \"task\": \"SOTAB\", \"colpair\": false, \"metadata\": false, \"from_scratch\": false, \"cl_tag\": \"wikitables/simclr/bert_100000_10_32_256_5e-05_sample_row4,sample_row4_tfidf_entity_column_0.05_0_last.pt\", \"dropout_prob\": 0.5, \"eval_test\": true, \"small_tag\": \"semi1\", \"data_path\": \"/data/yongkang/TU/\", \"pretrained_ckpt_path\": \"/data/zhihao/TU/Watchog/model/\"}\n",
      "SOTAB/wikitables-simclr-bert_100000_10_32_256_5e-05_sample_row4,sample_row4_tfidf_entity_column_0.05_0_last.pt_bert-base-uncased-semi1-bs16-ml64-ne1-do0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1394094/3060214680.py:213: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(ckpt_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(augment_op='sample_row4,sample_row4', batch_size=32, data_path='/data/zhihao/TU/TURL/', fp16=True, gpus='0', lm='bert', logdir='/data/zhihao/TU/Watchog/model/', lr=5e-05, max_len=256, mode='simclr', model='Watchog', n_epochs=10, pretrain_data='wikitables', pretrained_model_path='', projector=768, run_id=0, sample_meth='tfidf_entity', save_model=10, single_column=False, size=100000, table_order='column', temperature=0.05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "    device = torch.device(2)\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--wandb\", type=bool, default=False)\n",
    "    parser.add_argument(\"--model\", type=str, default=\"Watchog\")\n",
    "    parser.add_argument(\"--unlabeled_train_only\", type=bool, default=False)\n",
    "    parser.add_argument(\"--context_encoding_type\", type=str, default=\"v0\")\n",
    "    parser.add_argument(\"--pool_version\", type=str, default=\"v0.2\")\n",
    "    parser.add_argument(\"--random_sample\", type=bool, default=False)\n",
    "    parser.add_argument(\"--comment\", type=str, default=\"debug\", help=\"to distinguish the runs\")\n",
    "    parser.add_argument(\n",
    "        \"--shortcut_name\",\n",
    "        default=\"bert-base-uncased\",\n",
    "        type=str,\n",
    "        help=\"Huggingface model shortcut name \",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--max_length\",\n",
    "        default=64,\n",
    "        type=int,\n",
    "        help=\n",
    "        \"The maximum total input sequence length after tokenization. Sequences longer \"\n",
    "        \"than this will be truncated, sequences shorter will be padded.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--adaptive_max_length\",\n",
    "        default=False,\n",
    "        type=bool,\n",
    "    )    \n",
    "    parser.add_argument(\n",
    "        \"--max_num_col\",\n",
    "        default=8,\n",
    "        type=int,\n",
    "    )   \n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--batch_size\",\n",
    "        default=16,\n",
    "        type=int,\n",
    "        help=\"Batch size\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--epoch\",\n",
    "        default=1,\n",
    "        type=int,\n",
    "        help=\"Number of epochs for training\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--random_seed\",\n",
    "        default=4649,\n",
    "        type=int,\n",
    "        help=\"Random seed\",\n",
    "    )\n",
    "    \n",
    "    parser.add_argument(\n",
    "        \"--train_n_seed_cols\",\n",
    "        default=-1,\n",
    "        type=int,\n",
    "        help=\"number of seeding columns in training\",\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--num_classes\",\n",
    "        default=78,\n",
    "        type=int,\n",
    "        help=\"Number of classes\",\n",
    "    )\n",
    "    parser.add_argument(\"--multi_gpu\",\n",
    "                        action=\"store_true\",\n",
    "                        default=False,\n",
    "                        help=\"Use multiple GPU\")\n",
    "    parser.add_argument(\"--fp16\",\n",
    "                        action=\"store_true\",\n",
    "                        default=False,\n",
    "                        help=\"Use FP16\")\n",
    "    parser.add_argument(\"--warmup\",\n",
    "                        type=float,\n",
    "                        default=0.,\n",
    "                        help=\"Warmup ratio\")\n",
    "    parser.add_argument(\"--lr\", type=float, default=5e-5, help=\"Learning rate\")\n",
    "    parser.add_argument(\"--task\",\n",
    "                        type=str,\n",
    "                        default='SOTAB',\n",
    "                        choices=[\n",
    "                            \"sato0\", \"sato1\", \"sato2\", \"sato3\", \"sato4\",\n",
    "                            \"msato0\", \"msato1\", \"msato2\", \"msato3\", \"msato4\",\n",
    "                            \"gt-dbpedia0\", \"gt-dbpedia1\", \"gt-dbpedia2\", \"gt-dbpedia3\", \"gt-dbpedia4\",\n",
    "                            \"gt-dbpedia-all0\", \"gt-dbpedia-all1\", \"gt-dbpedia-all2\", \"gt-dbpedia-all3\", \"gt-dbpedia-all4\",\n",
    "                            \"gt-schema-all0\", \"gt-schema-all1\", \"gt-schema-all2\", \"gt-schema-all3\", \"gt-schema-all4\",\n",
    "                            \"gt-semtab22-dbpedia\", \"gt-semtab22-dbpedia0\", \"gt-semtab22-dbpedia1\", \"gt-semtab22-dbpedia2\", \"gt-semtab22-dbpedia3\", \"gt-semtab22-dbpedia4\",\n",
    "                            \"gt-semtab22-dbpedia-all\", \"gt-semtab22-dbpedia-all0\", \"gt-semtab22-dbpedia-all1\", \"gt-semtab22-dbpedia-all2\", \"gt-semtab22-dbpedia-all3\", \"gt-semtab22-dbpedia-all4\",\n",
    "                            \"gt-semtab22-schema-class-all\", \"gt-semtab22-schema-property-all\",\n",
    "                            \"turl\", \"turl-re\", \"col-popl-1\", \"col-popl-2\", \"col-popl-3\", \"row-popl\",\n",
    "                            \"col-popl-turl-0\", \"col-popl-turl-1\", \"col-popl-turl-2\",\n",
    "                            \"col-popl-turl-mdonly-0\", \"col-popl-turl-mdonly-1\", \"col-popl-turl-mdonly-2\"\n",
    "                        ],\n",
    "                        help=\"Task names}\")\n",
    "    parser.add_argument(\"--colpair\",\n",
    "                        action=\"store_true\",\n",
    "                        help=\"Use column pair embedding\")\n",
    "    parser.add_argument(\"--metadata\",\n",
    "                        action=\"store_true\",\n",
    "                        help=\"Use column header metadata\")\n",
    "    parser.add_argument(\"--from_scratch\",\n",
    "                        action=\"store_true\",\n",
    "                        help=\"Training from scratch\")\n",
    "    parser.add_argument(\"--cl_tag\",\n",
    "                        type=str,\n",
    "                        default=\"wikitables/simclr/bert_100000_10_32_256_5e-05_sample_row4,sample_row4_tfidf_entity_column_0.05_0_last.pt\",\n",
    "                        help=\"path to the pre-trained file\")\n",
    "    parser.add_argument(\"--dropout_prob\",\n",
    "                        type=float,\n",
    "                        default=0.5)\n",
    "    parser.add_argument(\"--eval_test\",\n",
    "                        action=\"store_true\",\n",
    "                        help=\"evaluate on testset and do not save the model file\")\n",
    "    parser.add_argument(\"--small_tag\",\n",
    "                        type=str,\n",
    "                        default=\"semi1\",\n",
    "                        help=\"e.g., by_table_t5_v1\")\n",
    "    parser.add_argument(\"--data_path\",\n",
    "                        type=str,\n",
    "                        default=\"/data/yongkang/TU/\")\n",
    "    parser.add_argument(\"--pretrained_ckpt_path\",\n",
    "                        type=str,\n",
    "                        default=\"/data/zhihao/TU/Watchog/model/\")    \n",
    "\n",
    "    args = parser.parse_args([])\n",
    "    task = args.task\n",
    "    if args.small_tag != \"\":\n",
    "        args.eval_test = True\n",
    "    \n",
    "    args.num_classes = task_num_class_dict[task]\n",
    "    if args.colpair:\n",
    "        assert \"turl-re\" == task, \"colpair can be only used for Relation Extraction\"\n",
    "    if args.metadata:\n",
    "        assert \"turl-re\" == task or \"turl\" == task, \"metadata can be only used for TURL datasets\"\n",
    "    if \"col-popl\":\n",
    "        # metrics = {\n",
    "        #     \"accuracy\": CategoricalAccuracy(tie_break=True),\n",
    "        # }\n",
    "        if args.train_n_seed_cols != -1:\n",
    "            if \"col-popl\" in task:\n",
    "                assert args.train_n_seed_cols == int(task[-1]),  \"# of seed columns must match\"\n",
    "\n",
    "    print(\"args={}\".format(json.dumps(vars(args))))\n",
    "\n",
    "    max_length = args.max_length\n",
    "    batch_size = args.batch_size\n",
    "    num_train_epochs = args.epoch\n",
    "\n",
    "    shortcut_name = args.shortcut_name\n",
    "\n",
    "    if args.colpair and args.metadata:\n",
    "        taskname = \"{}-colpair-metadata\".format(task)\n",
    "    elif args.colpair:\n",
    "        taskname = \"{}-colpair\".format(task)\n",
    "    elif args.metadata:\n",
    "        taskname = \"{}-metadata\".format(task)\n",
    "    elif args.train_n_seed_cols == -1 and 'popl' in task:\n",
    "        taskname = \"{}-mix\".format(task)\n",
    "    else:\n",
    "        taskname = \"\".join(task)\n",
    "\n",
    "    if args.from_scratch:\n",
    "        if \"gt\" in task:\n",
    "            tag_name = \"{}/{}-{}-{}-pool{}-max_cols{}-rand{}-bs{}-ml{}-ne{}-do{}{}\".format(\n",
    "                taskname,  \"{}-fromscratch\".format(shortcut_name), args.small_tag, args.comment, args.pool_version, args.max_num_col, args.random_sample,\n",
    "                batch_size, max_length, num_train_epochs, args.dropout_prob, \n",
    "                '-rs{}'.format(args.random_seed) if args.random_seed != 4649 else '')\n",
    "        else:\n",
    "            tag_name = \"{}/{}-{}-{}-bs{}-ml{}-ne{}-do{}{}\".format(\n",
    "                taskname,  \"{}-fromscratch\".format(shortcut_name), args.small_tag, args.comment, \n",
    "                batch_size, max_length, num_train_epochs, args.dropout_prob, \n",
    "                '-rs{}'.format(args.random_seed) if args.random_seed != 4649 else '')\n",
    "        \n",
    "    else:\n",
    "        if \"gt\" in task:\n",
    "            tag_name = \"{}/{}_{}-pool{}-max_cols{}-rand{}-bs{}-ml{}-ne{}-do{}{}\".format(\n",
    "                taskname, args.cl_tag.replace('/', '-'),  shortcut_name, args.small_tag, args.pool_version, args.max_num_col, args.random_sample,\n",
    "                batch_size, max_length, num_train_epochs, args.dropout_prob,\n",
    "                '-rs{}'.format(args.random_seed) if args.random_seed != 4649 else '')\n",
    "        else:\n",
    "            tag_name = \"{}/{}_{}-{}-bs{}-ml{}-ne{}-do{}{}\".format(\n",
    "                taskname, args.cl_tag.replace('/', '-'),  shortcut_name, args.small_tag,\n",
    "                batch_size, max_length, num_train_epochs, args.dropout_prob,\n",
    "                '-rs{}'.format(args.random_seed) if args.random_seed != 4649 else '')\n",
    "\n",
    "    # if args.eval_test:\n",
    "    #     if args.small_tag != '':\n",
    "    #         tag_name = tag_name.replace('outputs', 'small_outputs')\n",
    "    #         tag_name += '-' + args.small_tag\n",
    "    print(tag_name)\n",
    "    file_path = os.path.join(args.data_path, \"Watchog\", \"outputs\", tag_name)\n",
    "\n",
    "    dirpath = os.path.dirname(file_path)\n",
    "    if not os.path.exists(dirpath):\n",
    "        print(\"{} not exists. Created\".format(dirpath))\n",
    "        os.makedirs(dirpath)\n",
    "    \n",
    "    if args.fp16:\n",
    "        torch.backends.cuda.matmul.allow_fp16_reduced_precision_reduction = True\n",
    "        \n",
    "      \n",
    "        \n",
    "    # accelerator = Accelerator(mixed_precision=\"no\" if not args.fp16 else \"fp16\")   \n",
    "    ddp_kwargs = DistributedDataParallelKwargs(find_unused_parameters=True)\n",
    "    accelerator = Accelerator(mixed_precision=\"no\" if not args.fp16 else \"fp16\", kwargs_handlers=[ddp_kwargs])\n",
    "\n",
    "    device = torch.device(2)\n",
    "    ckpt_path = os.path.join(args.pretrained_ckpt_path, args.cl_tag)\n",
    "    # ckpt_path = '/efs/checkpoints/{}.pt'.format(args.cl_tag)\n",
    "    ckpt = torch.load(ckpt_path, map_location=device)\n",
    "    ckpt_hp = ckpt['hp']\n",
    "    print(ckpt_hp)\n",
    " \n",
    "    setattr(ckpt_hp, 'batch_size', args.batch_size)\n",
    "    setattr(ckpt_hp, 'hidden_dropout_prob', args.dropout_prob)\n",
    "    setattr(ckpt_hp, 'shortcut_name', args.shortcut_name)\n",
    "    setattr(ckpt_hp, 'num_labels', args.num_classes)\n",
    "    \n",
    "    \n",
    "    \n",
    "    tokenizer = BertTokenizer.from_pretrained(shortcut_name)\n",
    "    padder = collate_fn(tokenizer.pad_token_id)\n",
    "    if task == \"turl-re\" and args.colpair:\n",
    "        model = BertForMultiOutputClassification(ckpt_hp, device=device, lm=ckpt['hp'].lm, col_pair='Pair')\n",
    "    elif \"col-popl\" in task:\n",
    "        model = BertForMultiOutputClassificationColPopl(ckpt_hp, device=device, lm=ckpt['hp'].lm, n_seed_cols=int(task[i][-1]), cls_for_md=\"md\" in task)\n",
    "    else:\n",
    "        model = BertForMultiOutputClassification(ckpt_hp, device=device, lm=ckpt['hp'].lm, version=\"v0\", use_attention_mask=True)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/data/yongkang/TU/SOTAB/comma_train_filter_sotab.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group = df.groupby('table_id')\n",
    "num_cols = []\n",
    "num_cols_gt = []\n",
    "for table_id, group in df_group:\n",
    "    num_cols.append(len(group))\n",
    "    num_cols_gt.append(len(group[group['label']>-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 30 7.929148215681167 7.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "print(min(num_cols), max(num_cols), np.mean(num_cols), np.median(num_cols))\n",
    "sns.histplot(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 29 2.8656768255622125 2.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "print(min(num_cols_gt), max(num_cols_gt), np.mean(num_cols_gt), np.median(num_cols_gt))\n",
    "sns.histplot(num_cols_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bert', 'is', 'a', 'powerful', 'language', 'model', '.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"BERT is a powerful language model.\"\n",
    "tokenizer.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "标签映射关系从 /data/yongkang/TU/SOTAB/label_mapping.txt 读取成功\n",
      "数据已从 /data/yongkang/TU/SOTAB/comma_test_fully_deduplicated_sotab.csv 加载\n",
      "start encoder\n",
      "Processed 1000 entries. Recent dataframe sample:\n",
      "Processed 2000 entries. Recent dataframe sample:\n",
      "Processed 3000 entries. Recent dataframe sample:\n",
      "Processed 4000 entries. Recent dataframe sample:\n",
      "Processed 5000 entries. Recent dataframe sample:\n",
      "Processed 6000 entries. Recent dataframe sample:\n",
      "Processed 7000 entries. Recent dataframe sample:\n",
      "test 7026\n"
     ]
    }
   ],
   "source": [
    "dataset_cls = SotabCVTablewiseDataset\n",
    "cv = 0\n",
    "src = None\n",
    "# train_dataset = dataset_cls(cv=cv,\n",
    "#                             split=\"train\",\n",
    "#                             src=src,\n",
    "#                             tokenizer=tokenizer,\n",
    "#                             max_length=max_length,\n",
    "#                             gt_only='all' not in task,\n",
    "#                             device=device,\n",
    "#                             base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "#                             small_tag=\"semi1\")\n",
    "# valid_dataset = dataset_cls(cv=cv,\n",
    "#                             split=\"valid\", src=src,\n",
    "#                             tokenizer=tokenizer,\n",
    "#                             max_length=max_length,\n",
    "#                             gt_only='all' not in task,\n",
    "#                             device=device,\n",
    "#                             base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "#                             small_tag=\"semi1\")\n",
    "test_dataset = dataset_cls(# cv=cv,\n",
    "                            split=\"test\",\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            # multicol_only=multicol_only,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"SOTAB\")\n",
    "                            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7026"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataloader = DataLoader(train_dataset,\n",
    "#                                 batch_size=batch_size,\n",
    "#                             #   collate_fn=collate_fn)\n",
    "#                             collate_fn=padder)\n",
    "# valid_dataloader = DataLoader(valid_dataset,\n",
    "#                                 batch_size=batch_size,\n",
    "#                             #   collate_fn=collate_fn)\n",
    "#                             collate_fn=padder)\n",
    "test_dataloader = DataLoader(test_dataset,\n",
    "                                batch_size=64,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "标签映射关系从 /data/yongkang/TU/SOTAB/label_mapping.txt 读取成功\n",
      "数据已从 /data/yongkang/TU/SOTAB/comma_train_fully_deduplicated_sotab.csv 加载\n",
      "start encoder\n",
      "Processed 1000 entries. Recent dataframe sample:\n",
      "Processed 2000 entries. Recent dataframe sample:\n",
      "Processed 3000 entries. Recent dataframe sample:\n",
      "Processed 4000 entries. Recent dataframe sample:\n",
      "Processed 5000 entries. Recent dataframe sample:\n",
      "Processed 6000 entries. Recent dataframe sample:\n",
      "Processed 7000 entries. Recent dataframe sample:\n",
      "Processed 8000 entries. Recent dataframe sample:\n",
      "Processed 9000 entries. Recent dataframe sample:\n",
      "Processed 10000 entries. Recent dataframe sample:\n",
      "Processed 11000 entries. Recent dataframe sample:\n",
      "train 11517\n"
     ]
    }
   ],
   "source": [
    "dataset_cls = SotabCVTablewiseDataset\n",
    "cv = 0\n",
    "src = None\n",
    "train_dataset = dataset_cls(# cv=cv,\n",
    "                            split=\"train\",\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            # multicol_only=multicol_only,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"SOTAB\")\n",
    "                            )\n",
    "train_dataloader = DataLoader(train_dataset,\n",
    "                                batch_size=20,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_freq = torch.zeros(args.num_classes)\n",
    "for batch in train_dataloader:\n",
    "    for i in batch[\"label\"][batch[\"label\"]>-1].cpu().tolist():\n",
    "        class_freq[i] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_freq = torch.zeros(args.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cls_tokens(hidden_states, cls_indexes, head=False):\n",
    "    cls_embeddings = []\n",
    "    for i, j in cls_indexes:\n",
    "        sub_sentence_cls_embeddings = hidden_states[i, 0, :] if head else hidden_states[i, j, :]\n",
    "        cls_embeddings.append(sub_sentence_cls_embeddings)\n",
    "    cls_embeddings = torch.stack(cls_embeddings)\n",
    "    return cls_embeddings\n",
    "#pooled_outputs = extract_cls_tokens(hidden_states, cls_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"label\"].cpu().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 768])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs.detach().cpu().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [274]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m plm_embs_train \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m labels_train \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mtrain_dataloader\u001b[49m):\n\u001b[1;32m      6\u001b[0m     cls_indexes \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnonzero(\n\u001b[1;32m      7\u001b[0m                     batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m==\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mcls_token_id)\n\u001b[1;32m      8\u001b[0m     embs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mbert(batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mT)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model = model.to(device)\n",
    "plm_embs_train = []\n",
    "labels_train = []\n",
    "for batch_idx, batch in enumerate(train_dataloader):\n",
    "    cls_indexes = torch.nonzero(\n",
    "                    batch[\"data\"].T == tokenizer.cls_token_id)\n",
    "    embs = model.bert(batch[\"data\"].T)\n",
    "    embs = extract_cls_tokens(embs[0], cls_indexes)\n",
    "    label = batch[\"label\"].cpu()\n",
    "    plm_embs_train.append(embs.detach().cpu()[label>-1])\n",
    "    labels_train.append(label[label>-1])\n",
    "plm_embs_train = torch.cat(plm_embs_train, dim=0)\n",
    "labels_train = torch.cat(labels_train, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3463, 768])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plm_embs_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_samples\n",
    "from sklearn.metrics import silhouette_score\n",
    "def silhouette_score_per_cluster(embeddings, labels, metric=\"cosine\"):\n",
    "    sample_silhouette_values = silhouette_samples(embeddings, labels, metric=metric)\n",
    "    unique_labels = np.unique(labels)\n",
    "    silhouette_per_cluster = []\n",
    "    for label in unique_labels:\n",
    "        cluster_silhouettes = sample_silhouette_values[labels == label]\n",
    "        silhouette_per_cluster.append(np.mean(cluster_silhouettes))\n",
    "    return np.array(silhouette_per_cluster).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "plm_embs_train_silhouette_values = silhouette_samples(plm_embs_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.21431549"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(plm_embs_train_silhouette_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming plm_embs_train_silhouette_values is your data\n",
    "sns.histplot(plm_embs_train_silhouette_values)\n",
    "\n",
    "# Add a red vertical line at x = 0\n",
    "plt.axvline(x=0, color='red', linestyle='--', linewidth=2)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "semi1_cv_{}.csv 1 64 None v0 False\n",
      "train 3463\n"
     ]
    }
   ],
   "source": [
    "dataset_col = GittablesColwiseDataset\n",
    "train_dataset_col = dataset_col(cv=cv,\n",
    "                            split=\"train\",\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            train_ratio=1.0,\n",
    "                            device=device,\n",
    "                            small_tag=\"semi1\",\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            max_num_col=1,\n",
    "                            sampling_method=None,\n",
    "                            random_seed=0,\n",
    "                            context_encoding_type=args.context_encoding_type,\n",
    "                            adaptive_max_length=False                                       \n",
    "                            )\n",
    "# dataset_cls(cv=cv,\n",
    "#                                             split=\"train\",\n",
    "#                                             tokenizer=tokenizer,\n",
    "#                                             max_length=max_length,\n",
    "#                                             gt_only='all' not in task,\n",
    "#                                             device=device,\n",
    "#                                             base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "#                                             small_tag=args.small_tag,\n",
    "#                                             max_num_col=args.max_num_col,\n",
    "#                                             sampling_method=args.sampling_method,\n",
    "#                                             random_seed=args.random_seed,\n",
    "#                                             context_encoding_type=args.context_encoding_type,\n",
    "#                                             adaptive_max_length=args.adaptive_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader_col = DataLoader(train_dataset_col,\n",
    "                                batch_size=batch_size,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model = model.to(device)\n",
    "plm_embs_train_col = []\n",
    "labels_train_col = []\n",
    "for batch_idx, batch in enumerate(train_dataloader_col):\n",
    "    cls_indexes = torch.nonzero(\n",
    "                    batch[\"data\"].T == tokenizer.cls_token_id)\n",
    "    embs = model.bert(batch[\"data\"].T)\n",
    "    embs = extract_cls_tokens(embs[0], cls_indexes)\n",
    "    plm_embs_train_col.append(embs.detach().cpu())\n",
    "    labels_train_col.append(batch[\"label\"].cpu())\n",
    "plm_embs_train_col = torch.cat(plm_embs_train_col, dim=0)\n",
    "labels_train_col = torch.cat(labels_train_col, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3463, 768])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plm_embs_train_col.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3463, 768])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plm_embs_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "plm_embs_train_silhouette_values_col = silhouette_samples(plm_embs_train_col, labels_train_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.22704358"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(plm_embs_train_silhouette_values_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "st_model = SentenceTransformer(\"all-mpnet-base-v2\", cache_folder=\"/data/zhihao/TU/Watchog/sentence_transformers_cache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_dirpath = \"/data/zhihao/TU/GitTables/semtab_gittables/2022/\"\n",
    "seperator = \"semi1\"\n",
    "basename = seperator+\"_cv_{}.csv\"\n",
    "df_list = []\n",
    "filepath = os.path.join(base_dirpath, basename.format(cv))\n",
    "df_test = pd.read_csv(filepath)\n",
    "\n",
    "df_group_test = df_test.groupby(\"table_id\")\n",
    "\n",
    "\n",
    "\n",
    "df_list = []\n",
    "for i in range(5):\n",
    "    if i == cv:\n",
    "        continue\n",
    "    filepath = os.path.join(base_dirpath, basename.format(i))\n",
    "    df_list.append(pd.read_csv(filepath))\n",
    "df_train = pd.concat(df_list, axis=0)\n",
    "df_group_train = df_train.groupby(\"table_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_cluster = []\n",
    "embeddings_cluster = []\n",
    "embeddings_cluster_context = []\n",
    "for i, (index, group_df) in enumerate(df_group_train):\n",
    "    labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "    labels_cluster += labeled_columns[\"class_id\"].values.tolist()\n",
    "    # if len(labeled_columns) > 1:\n",
    "    #     embeddings_cluster.append(ft_model.get_sentence_vector(\" \".join(labeled_columns[\"data\"].values)))\n",
    "    #     embeddings_cluster_context.append(ft_model.get_sentence_vector(\" \".join(group_df[\"data\"].values)))\n",
    "    #     break\n",
    "    for text in labeled_columns[\"data\"].values:\n",
    "        embeddings_cluster.append(st_model.encode(text))\n",
    "        embeddings_cluster_context.append(st_model.encode(st_model.tokenizer.sep_token.join(group_df[\"data\"].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_cluster = np.stack(embeddings_cluster, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_cluster_context = np.stack(embeddings_cluster_context, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_cluster = np.array(labels_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_cluster_silhouette_values = silhouette_samples(embeddings_cluster, labels_cluster)\n",
    "embeddings_cluster_context_silhouette_values = silhouette_samples(embeddings_cluster_context, labels_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.08592572"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(embeddings_cluster_silhouette_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.15294842"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(embeddings_cluster_context_silhouette_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example data: Two sets of values\n",
    "values_set_1 = embeddings_cluster_silhouette_values  # Replace with your actual data\n",
    "values_set_2 = embeddings_cluster_context_silhouette_values  # Replace with your second set of values\n",
    "\n",
    "mean_set_1 = np.mean(values_set_1)\n",
    "mean_set_2 = np.mean(values_set_2)\n",
    "# Set the style of the visualization\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Create the figure and axis\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot the first set of values\n",
    "sns.histplot(values_set_1, color='skyblue', kde=True, label='w.o. context', bins=30, alpha=0.7)\n",
    "\n",
    "# Plot the second set of values\n",
    "sns.histplot(values_set_2, color='salmon', kde=True, label='with context', bins=30, alpha=0.7)\n",
    "\n",
    "# Add a vertical line at x=0 for reference\n",
    "plt.axvline(x=0, color='black', linestyle='--', linewidth=2)\n",
    "\n",
    "plt.axvline(x=mean_set_1, color='blue', linestyle='-', linewidth=2, label=f'Mean  ({mean_set_1:.2f})')\n",
    "plt.axvline(x=mean_set_2, color='red', linestyle='-', linewidth=2, label=f'Set 2 Mean ({mean_set_2:.2f})')\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Comparison of Silhouette Score between column embeddings with and w.o. context', fontsize=16)\n",
    "plt.xlabel('Silhouette Score', fontsize=14)\n",
    "plt.ylabel('Frequency', fontsize=14)\n",
    "plt.legend()\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "# Remove the top and right spines for a cleaner look\n",
    "sns.despine()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"/data/zhihao/TU/Watchog/outputs/gt-semtab22-dbpedia-all0/bert-base-uncased-fromscratch-semi1-poolv0-unlabeled8-randTrue-bs16-ml64-ne50-do0.1_eval.json\", 'r') as f:\n",
    "    results = json.load(f)\n",
    "# bert-base-uncased-fromscratch-semi1-poolv0-unlabeled8-randTrue-bs16-ml64-ne50-do0.1_best_f1_micro.pt\n",
    "# labels_train = np.array(results['train']['tr_true_list'])\n",
    "# preds_train = np.array(results['train']['tr_pred_list'])\n",
    "# class_f1_train = np.array(results['train']['tr_class_f1'])\n",
    "\n",
    "labels = np.array(results['f1_macro']['true_list'])\n",
    "preds = np.array(results['f1_macro']['pred_list'])\n",
    "class_f1 = np.array(results['f1_macro']['ts_class_f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1394094/1786997412.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_state_dict = torch.load(\"/data/yongkang/TU/Watchog/outputs/SOTAB/bert-base-uncased-fromscratch-comma-bs16-ml128-ne50-do0.5_fully_deduplicated_best_f1_micro.pt\", map_location=device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_state_dict = torch.load(\"/data/yongkang/TU/Watchog/outputs/SOTAB/bert-base-uncased-fromscratch-comma-bs16-ml128-ne50-do0.5_fully_deduplicated_best_f1_micro.pt\", map_location=device)\n",
    "model.load_state_dict(best_state_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_train = []\n",
    "labels_train = []\n",
    "for batch_idx, batch in enumerate(train_dataloader):\n",
    "    cls_indexes = torch.nonzero(\n",
    "                    batch[\"data\"].T == tokenizer.cls_token_id)\n",
    "    embs = model.bert(batch[\"data\"].T)\n",
    "    embs = extract_cls_tokens(embs[0], cls_indexes)\n",
    "    ft_embs_train.append(embs.detach().cpu())\n",
    "    labels_train.append(batch[\"label\"].cpu())\n",
    "ft_embs_train = torch.cat(ft_embs_train, dim=0)\n",
    "labels_train = torch.cat(labels_train, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_dataset,\n",
    "                                batch_size=64,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)\n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test_origin = []\n",
    "logits_test_origin_1 = []\n",
    "cls_indexes_all_1 = []\n",
    "for batch_idx, batch in enumerate(test_dataloader):\n",
    "    cls_indexes = torch.nonzero(\n",
    "                    batch[\"data\"].T == tokenizer.cls_token_id)\n",
    "    \n",
    "    # embs = model.bert(batch[\"data\"].T)\n",
    "    logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,).detach().cpu()\n",
    "    # embs = extract_cls_tokens(embs[0], cls_indexes)\n",
    "    # ft_embs_test.append(embs.detach().cpu())\n",
    "    labels_test_origin.append(batch[\"label\"].cpu())\n",
    "    if logits.dim() == 1:\n",
    "        logits = logits.unsqueeze(0)\n",
    "    logits_test_origin_1.append(logits)\n",
    "    cls_indexes_all_1.append(cls_indexes.detach().cpu())\n",
    "# ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "\n",
    "labels_test_origin = torch.cat(labels_test_origin, dim=0)\n",
    "logits_test_origin_1 = torch.cat(logits_test_origin_1, dim=0)\n",
    "preds_test_origin_1 = torch.argmax(logits_test_origin_1, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_equal = []\n",
    "for i in range(len(logits_test_origin_16)):\n",
    "    is_equal.append(torch.equal(logits_test_origin_16[i], logits_test_origin_1[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "True in is_equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1085, 101])"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_test_origin_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_micro_f1=0.7269, ts_macro_f1=0.6960\n"
     ]
    }
   ],
   "source": [
    "ts_pred_list_origin = logits_test_origin_1.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "ts_micro_f1 = f1_score(labels_test_origin.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list_origin,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test_origin.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list_origin,\n",
    "                    average=\"macro\")\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_945138/1939110723.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ood_labels = torch.tensor(preds_test_origin_1 == labels_test_origin).float()\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "ood_score = F.softmax(logits_test_origin_1, dim=1).max(1).values\n",
    "ood_labels = torch.tensor(preds_test_origin_1 == labels_test_origin).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81275285856383"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(ood_labels, ood_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_entropy(probs):\n",
    "    # Adding a small value (1e-9) to avoid log(0)\n",
    "    if probs.dim() == 1:\n",
    "        return -torch.sum(probs * torch.log(probs))\n",
    "    else:\n",
    "        return -torch.sum(probs * torch.log(probs), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4054970/4129975340.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ood_labels = torch.tensor(preds_test_origin_1 != labels_test_origin).float()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7723833738213859"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "ood_score = compute_entropy(F.softmax(logits_test_origin_1, dim=1))\n",
    "ood_labels = torch.tensor(preds_test_origin_1 != labels_test_origin).float()\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(ood_labels, ood_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(ood_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(ood_score[ood_labels==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(ood_score[ood_labels==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7680)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 0.25\n",
    "(ood_score[ood_labels==1] > threshold).sum()/sum(ood_score> threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7262)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 0.1\n",
    "(ood_score[ood_labels==1] > threshold).sum()/sum(ood_score> threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8188)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ood_score[ood_labels==0] < 0.99).sum()/len(ood_score[ood_labels==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3378)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ood_score[ood_labels==1] < 0.99).sum()/len(ood_score[ood_labels==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3378)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ood_score[ood_labels==1] < 0.99).sum()/len(ood_score[ood_labels==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import re\n",
    "import transformers\n",
    "from torch.utils import data\n",
    "from torch.nn.utils import rnn\n",
    "from transformers import AutoTokenizer\n",
    "from typing import List\n",
    "from functools import reduce\n",
    "import operator\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "class SOTABTablewiseIterateDataset(data.Dataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            # cv: int,\n",
    "            split: str,  # train or test\n",
    "            tokenizer: AutoTokenizer,\n",
    "            max_length: int = 256,\n",
    "            # multicol_only: bool = False,\n",
    "            train_ratio: float = 1.0,\n",
    "            device: torch.device = None,\n",
    "            base_dirpath: str = \"/data/yongkang/TU/SOTAB\",\n",
    "            small_tag: str = \"\",\n",
    "            label_encoder: LabelEncoder = None,\n",
    "            max_unlabeled=8,\n",
    "            random_sample=False, # TODO\n",
    "            gt_only=True,\n",
    "            ):\n",
    "        # ?\n",
    "        if device is None:\n",
    "            device = torch.device('cpu')\n",
    "\n",
    "        assert split in [\"train\", \"valid\", \"test\"]\n",
    "        if split == \"train\":\n",
    "            gt_df = pd.read_csv(os.path.join(base_dirpath, \"CTA_training_small_gt.csv\"))\n",
    "            data_folder = \"Train\"\n",
    "        elif split == \"valid\":\n",
    "            gt_df = pd.read_csv(os.path.join(base_dirpath, \"CTA_validation_gt.csv\"))\n",
    "            data_folder = \"Validation\"\n",
    "        else:  # test\n",
    "            gt_df = pd.read_csv(os.path.join(base_dirpath, \"CTA_test_gt.csv\"))\n",
    "            data_folder = \"Test\"\n",
    "\n",
    "        # 初始化或加载 LabelEncoder\n",
    "        if label_encoder is None:\n",
    "            label_encoder = LabelEncoder()\n",
    "            label_encoder.fit(gt_df['label'])\n",
    "        self.label_encoder = label_encoder\n",
    "\n",
    "        # gt_set = set(zip(gt_df[\"table_name\"], gt_df[\"column_index\"]))\n",
    "\n",
    "        table_files = [f for f in os.listdir(os.path.join(base_dirpath, data_folder)) if f in gt_df['table_name'].values]\n",
    "\n",
    "        mapping_file_path = os.path.join(base_dirpath, \"label_mapping.txt\")\n",
    "        df_csv_path = os.path.join(base_dirpath, f\"comma_{split}_fully_deduplicated_sotab.csv\")\n",
    "\n",
    "        # 检查是否存在之前保存的标签映射关系\n",
    "        if os.path.exists(mapping_file_path):\n",
    "            # 如果存在，直接从文件中读取映射\n",
    "            with open(mapping_file_path, 'r') as f:\n",
    "                label_mapping = json.load(f)\n",
    "            next_label_id = max(label_mapping.values()) + 1\n",
    "            print(f\"标签映射关系从 {mapping_file_path} 读取成功\")\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"{mapping_file_path} 文件不存在，请确认文件路径\")\n",
    "\n",
    "        # 检查 CSV 文件是否存在\n",
    "        if os.path.exists(df_csv_path):\n",
    "            # 直接从 CSV 文件中读取数据\n",
    "            df = pd.read_csv(df_csv_path)\n",
    "            print(f\"数据已从 {df_csv_path} 加载\")\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"{df_csv_path} 文件不存在，请确认文件路径\")\n",
    "        \n",
    "        if gt_only:\n",
    "            df = df[df[\"label\"] > -1]\n",
    "\n",
    "        data_list = []\n",
    "\n",
    "        df['label'] = df['label'].astype(int)\n",
    "        df.drop(df[(df['data'].isna()) & (df['label'] == -1)].index, inplace=True)\n",
    "        df['column_index'] = df['column_index'].astype(int)\n",
    "        df['data'] = df['data'].astype(str)\n",
    "\n",
    "        print(\"start encoder\")\n",
    "        for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "            # if split == \"train\" and ((i >= num_train) or (i >= valid_index)):\n",
    "            #     break\n",
    "            # if split == \"valid\" and i < valid_index:\n",
    "            #     continue\n",
    "\n",
    "            labeled_columns = group_df[group_df['label'] > -1]\n",
    "            unlabeled_columns = group_df[group_df['label'] == -1]\n",
    "            num_unlabeled = min(max(max_unlabeled-len(labeled_columns), 0), len(unlabeled_columns))\n",
    "            unlabeled_columns = unlabeled_columns.sample(num_unlabeled) if random_sample else unlabeled_columns[0:num_unlabeled]\n",
    "            group_df = pd.concat([group_df[group_df['label'] > -1], unlabeled_columns]) # TODO\n",
    "            group_df.sort_values(by=['column_index'], inplace=True)\n",
    "\n",
    "            num_labels = len(list(group_df[\"label\"].values))\n",
    "            if max_length <= 128:\n",
    "                cur_maxlen = min(max_length, 512 // num_labels - 1)\n",
    "            else:\n",
    "                cur_maxlen = max(1, max_length // num_labels - 1)\n",
    "\n",
    "            token_ids_list = group_df[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=cur_maxlen, truncation=True)).tolist(\n",
    "                )\n",
    "            token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                                token_ids_list)).to(device)\n",
    "            for col_i in range(len(token_ids_list)):\n",
    "                if group_df[\"label\"].values[col_i] == -1:\n",
    "                    continue\n",
    "                target_col_mask = []\n",
    "                cls_index_value = 0\n",
    "                context_id = 1\n",
    "                new_token_ids_list = []\n",
    "                for col_j in range(len(token_ids_list)):\n",
    "                    if len(set(target_col_mask)) == max_unlabeled-1 and 0 not in target_col_mask and col_j != col_i:\n",
    "                        # skip the rest of the columns until the target one\n",
    "                        continue\n",
    "                    \n",
    "                    if col_j == col_i:\n",
    "                        target_col_mask += [0] * len(token_ids_list[col_j])\n",
    "                    else:\n",
    "                        target_col_mask += [context_id] * len(token_ids_list[col_j])\n",
    "                        context_id += 1\n",
    "                    if col_j < col_i:\n",
    "                        cls_index_value += len(token_ids_list[col_j])\n",
    "                    new_token_ids_list.append(token_ids_list[col_j])\n",
    "                    if len(set(target_col_mask)) == max_unlabeled and 0 in target_col_mask:\n",
    "                        break\n",
    "                new_token_ids_list = torch.LongTensor(reduce(operator.add,\n",
    "                                                new_token_ids_list)).to(device)\n",
    "                cls_index_list = [cls_index_value] \n",
    "                for cls_index in cls_index_list:\n",
    "                    assert token_ids[\n",
    "                        cls_index] == tokenizer.cls_token_id, \"cls_indexes validation\"\n",
    "                cls_indexes = torch.LongTensor(cls_index_list).to(device)\n",
    "                class_ids = torch.LongTensor(\n",
    "                    [group_df[\"label\"].values[col_i]]).to(device)\n",
    "                target_col_mask = torch.LongTensor(target_col_mask).to(device)\n",
    "                data_list.append(\n",
    "                    [index,\n",
    "                    len(group_df), new_token_ids_list, class_ids, cls_indexes, target_col_mask])                \n",
    "        print(split, len(data_list))\n",
    "        self.table_df = pd.DataFrame(data_list,\n",
    "                                     columns=[\n",
    "                                         \"table_id\", \"num_col\", \"data_tensor\",\n",
    "                                         \"label_tensor\", \"cls_indexes\", \"target_col_mask\"\n",
    "                                     ])\n",
    "        \"\"\"\n",
    "        # NOTE: msato contains a small portion of single-col tables. keep it to be consistent.  \n",
    "        if multicol_only:\n",
    "            # Check\n",
    "            num_all_tables = len(self.table_df)\n",
    "            self.table_df = self.table_df[self.table_df[\"num_col\"] > 1]\n",
    "            assert len(self.table_df) == num_all_tables\n",
    "        \"\"\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.table_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"data\": self.table_df.iloc[idx][\"data_tensor\"],\n",
    "            \"label\": self.table_df.iloc[idx][\"label_tensor\"],\n",
    "            \"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"],\n",
    "            \"target_col_mask\": self.table_df.iloc[idx][\"target_col_mask\"],\n",
    "        }\n",
    "        #\"idx\": torch.LongTensor([idx])}\n",
    "        #\"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(pad_token_id, data_only=True):\n",
    "    '''padder for input batch'''\n",
    "\n",
    "    def padder(samples):    \n",
    "        data = torch.nn.utils.rnn.pad_sequence(\n",
    "            [sample[\"data\"] for sample in samples], padding_value=pad_token_id)\n",
    "        if not data_only:\n",
    "            label = torch.nn.utils.rnn.pad_sequence(\n",
    "                [sample[\"label\"] for sample in samples], padding_value=-1)\n",
    "        else:\n",
    "            label = torch.cat([sample[\"label\"] for sample in samples])\n",
    "        batch = {\"data\": data, \"label\": label}\n",
    "        if \"idx\" in samples[0]:\n",
    "            batch[\"idx\"] = [sample[\"idx\"] for sample in samples]\n",
    "        if \"cls_indexes\" in samples[0]:\n",
    "            cls_indexes = torch.nn.utils.rnn.pad_sequence(\n",
    "                [sample[\"cls_indexes\"] for sample in samples], padding_value=0)\n",
    "            batch[\"cls_indexes\"] = cls_indexes\n",
    "        if \"target_col_mask\" in samples[0]:\n",
    "            target_col_mask = torch.nn.utils.rnn.pad_sequence(\n",
    "                [sample[\"target_col_mask\"] for sample in samples], padding_value=-1)\n",
    "            batch[\"target_col_mask\"] = target_col_mask\n",
    "        if \"table_embedding\" in samples[0]:\n",
    "            table_embeddings = [sample[\"table_embedding\"] for sample in samples]\n",
    "            batch[\"table_embedding\"] = torch.stack(table_embeddings, dim=0)\n",
    "        return batch\n",
    "        \n",
    "    return padder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "标签映射关系从 /data/yongkang/TU/SOTAB/label_mapping.txt 读取成功\n",
      "数据已从 /data/yongkang/TU/SOTAB/comma_test_fully_deduplicated_sotab.csv 加载\n",
      "start encoder\n",
      "test 15040\n"
     ]
    }
   ],
   "source": [
    "src = None\n",
    "test_dataset_iter = SOTABTablewiseIterateDataset(# cv=cv,\n",
    "                                        split=\"test\",\n",
    "                                        tokenizer=tokenizer,\n",
    "                                        max_length=max_length,\n",
    "                                        # multicol_only=multicol_only,\n",
    "                                        device=device,\n",
    "                                        gt_only=False,\n",
    "                                        base_dirpath=os.path.join(args.data_path, \"SOTAB\")\n",
    "                                        )\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "test_dataloader_iter = DataLoader(test_dataset_iter,\n",
    "                                batch_size=1,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "标签映射关系从 /data/yongkang/TU/SOTAB/label_mapping.txt 读取成功\n",
      "数据已从 /data/yongkang/TU/SOTAB/comma_valid_fully_deduplicated_sotab.csv 加载\n",
      "start encoder\n",
      "valid 16840\n"
     ]
    }
   ],
   "source": [
    "src = None\n",
    "valid_dataset_iter = SOTABTablewiseIterateDataset(# cv=cv,\n",
    "                                        split=\"valid\",\n",
    "                                        tokenizer=tokenizer,\n",
    "                                        max_length=max_length,\n",
    "                                        # multicol_only=multicol_only,\n",
    "                                        device=device,\n",
    "                                        gt_only=False,\n",
    "                                        base_dirpath=os.path.join(args.data_path, \"SOTAB\")\n",
    "                                        )\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "valid_dataloader_iter = DataLoader(valid_dataset_iter,\n",
    "                                batch_size=1,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "标签映射关系从 /data/yongkang/TU/SOTAB/label_mapping.txt 读取成功\n",
      "数据已从 /data/yongkang/TU/SOTAB/comma_train_fully_deduplicated_sotab.csv 加载\n",
      "start encoder\n",
      "train 33004\n"
     ]
    }
   ],
   "source": [
    "max_num_cols = 8\n",
    "train_dataset_iter = SOTABTablewiseIterateDataset(\n",
    "                            split=\"train\", \n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only=False,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"SOTAB\"),\n",
    "                            max_unlabeled=max_num_cols)\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "train_dataloader_iter = DataLoader(train_dataset_iter,\n",
    "                                batch_size=1,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     init_permutation_i \u001b[38;5;241m=\u001b[39m get_permutation(target_col_mask)\n\u001b[1;32m      6\u001b[0m     num_cols_train\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mlen\u001b[39m(init_permutation_i))\n\u001b[0;32m----> 7\u001b[0m \u001b[43msns\u001b[49m\u001b[38;5;241m.\u001b[39mhistplot(num_cols_train)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sns' is not defined"
     ]
    }
   ],
   "source": [
    "num_cols_train = []\n",
    "for batch_idx, batch in enumerate(train_dataloader_iter):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    init_permutation_i = get_permutation(target_col_mask)\n",
    "    num_cols_train.append(len(init_permutation_i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(num_cols_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_micro_f1=0.8781, ts_macro_f1=0.8657\n",
      "ts_micro_f1=0.8781, ts_macro_f1=0.8657\n",
      "ts_micro_f1=0.0000, ts_macro_f1=nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhihao/jupyterprojects/jupyter/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "/home/zhihao/jupyterprojects/jupyter/lib/python3.8/site-packages/numpy/lib/function_base.py:495: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/home/zhihao/jupyterprojects/jupyter/lib/python3.8/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "    labels_test.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "    num_cols.append(batch[\"target_col_mask\"].max().item())\n",
    "labels_test = torch.cat(labels_test, dim=0)\n",
    "logits_test = torch.stack(logits_test, dim=0)\n",
    "preds_test = torch.argmax(logits_test, dim=1)\n",
    "num_cols = torch.tensor(num_cols)\n",
    " \n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "mask = num_cols > 0\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach()[mask].numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach()[~mask].numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_idx = []\n",
    "for batch_idx, batch in enumerate(train_dataloader_iter):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    if not batch[\"data\"].T.shape == target_col_mask.shape:\n",
    "        wrong_idx.append(batch_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4921"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wrong_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 420])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Threshold: 1.5****************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1394094/2362306214.py:54: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
      "/tmp/ipykernel_1394094/2362306214.py:109: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n"
     ]
    }
   ],
   "source": [
    "# brute force perumate in validation TODO: restrict mamimus length of permutation\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "import torch.nn.functional as F\n",
    "train_data = defaultdict(list)\n",
    "train_logits = defaultdict(list)\n",
    "train_cls_indexes = defaultdict(list)\n",
    "train_target_col_mask = defaultdict(list)\n",
    "train_embs = defaultdict(list)\n",
    "train_col_num = defaultdict(list)\n",
    "train_label = defaultdict(list)\n",
    "train_class = defaultdict(list)\n",
    "train_target_embs = defaultdict(list)\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "for threshold in [1.5]:\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    log = defaultdict(list)\n",
    "    num_cols = []\n",
    "    corrected = 0\n",
    "    total_mistakes = 0\n",
    "    num_permutations = {}\n",
    "    init_permutation = {}\n",
    "    init_correctness = {}\n",
    "    score_init = {}\n",
    "    score_permutation = defaultdict(list)\n",
    "    permutation_correctness = defaultdict(list)\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(train_dataloader_iter):\n",
    "            cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "            target_col_mask = batch[\"target_col_mask\"].T\n",
    "            logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "            score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
    "            label_i = batch[\"label\"].item()\n",
    "            predict_init = logits.argmax().item()\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            init_permutation[batch_idx] = init_permutation_i\n",
    "            if predict_init == label_i:\n",
    "                init_correctness[batch_idx] = True\n",
    "            else:\n",
    "                init_correctness[batch_idx] = False\n",
    "            num_permutations[batch_idx] = 0\n",
    "\n",
    "            train_data[batch_idx].append(batch[\"data\"].T.cpu())\n",
    "            train_logits[batch_idx].append(logits.detach().cpu())\n",
    "            train_cls_indexes[batch_idx].append(batch[\"cls_indexes\"].cpu().item())\n",
    "            train_embs[batch_idx].append(embs.cpu())\n",
    "            train_col_num[batch_idx].append(len(init_permutation_i))\n",
    "            train_label[batch_idx].append(torch.tensor(predict_init == label_i).long()) # indicate whether the permutation is correct or not\n",
    "            train_class[batch_idx].append(label_i)\n",
    "\n",
    "\n",
    "            x = [0]\n",
    "            new_batch_data = []\n",
    "            for col_i in x:\n",
    "                if col_i == 0:\n",
    "                    if len(new_batch_data) == 0:\n",
    "                        cls_indexes_value = 0\n",
    "                    else:\n",
    "                        cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "            new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "            cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "            logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "            train_target_embs[batch_idx].append(embs_temp.cpu())\n",
    "\n",
    "            num_cols.append(len(init_permutation_i))\n",
    "            labels_test.append(batch[\"label\"].cpu().item())\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            assert -1 not in col_idx_set\n",
    "            for r in range(len(init_permutation_i)-1, 0, -1): # not \n",
    "                for x in itertools.combinations(init_permutation_i, r):\n",
    "                    if 0 not in x:\n",
    "                        continue\n",
    "\n",
    "                    num_permutations[batch_idx] += 1\n",
    "                    new_batch_data = []\n",
    "                    for col_i in x:\n",
    "                        if col_i == 0:\n",
    "                            if len(new_batch_data) == 0:\n",
    "                                cls_indexes_value = 0\n",
    "                            else:\n",
    "                                cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                        new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                    new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                    cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                    logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                    ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n",
    "                    score_permutation[batch_idx].append(ood_score_temp)\n",
    "                    predict_temp = logits_temp.argmax().item()\n",
    "                    permutation_correctness[batch_idx].append(predict_temp == label_i)\n",
    "                    if predict_temp == label_i and r < max(len(init_permutation_i)-2, len(init_permutation_i)//2):\n",
    "                        continue\n",
    "                    \n",
    "                    \n",
    "                    train_data[batch_idx].append(new_batch_data.cpu())\n",
    "                    train_logits[batch_idx].append(logits_temp.detach().cpu())\n",
    "                    train_cls_indexes[batch_idx].append(cls_indexes_value)\n",
    "                    train_embs[batch_idx].append(embs_temp.cpu())\n",
    "                    train_col_num[batch_idx].append(len(x))\n",
    "                    train_label[batch_idx].append(torch.tensor(predict_temp == label_i).long()) # indicate whether the permutation is correct or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_samples = 0\n",
    "for batch_idx, batch in enumerate(train_dataloader_iter):\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    init_permutation_i = get_permutation(target_col_mask)\n",
    "\n",
    "    assert -1 not in col_idx_set\n",
    "    for r in range(len(init_permutation_i), 0, -1): # not \n",
    "        for x in itertools.combinations(init_permutation_i, r):\n",
    "            if 0 not in x:\n",
    "                continue\n",
    "            total_samples += 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2821583"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33004"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16840"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_dataloader_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11517"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# SOTAB, col num from 8 to 1, all negs, half pos\n",
    "os.makedirs(\"/data/zhihao/TU/Watchog/trainfication\", exist_ok=True)\n",
    "torch.save({\"data\": train_data, \"label\": train_label, \"logits\": train_logits, \"cls_indexes\": train_cls_indexes, \"embs\": train_embs, \"target_embs\":train_target_embs , \"col_num\": train_col_num}, f\"/data/zhihao/TU/Watchog/trainfication/{args.task}_train_data.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "955609\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.7282)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_all = torch.cat([torch.tensor(train_label[i]) for i in train_label], dim=0)\n",
    "print(len(train_labels_all))\n",
    "train_labels_all.sum()/len(train_labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SOTAB'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1394094/1574061451.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  veri_results = torch.load( f\"/data/zhihao/TU/Watchog/verification/{args.task}_veri_data.pth\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.makedirs(\"/data/zhihao/TU/Watchog/verification\", exist_ok=True)\n",
    "# {args.task}_veri_data: min length: max(len(init_permutation_i)//2, len(init_permutation_i)-3)\n",
    "# {args.task}_veri_data_1: min length: for those without correct permutation, \n",
    "veri_results = torch.load( f\"/data/zhihao/TU/Watchog/verification/{args.task}_veri_data.pth\")\n",
    "veri_data = veri_results[\"data\"]\n",
    "veri_label = veri_results[\"label\"]\n",
    "veri_logits = veri_results[\"logits\"]\n",
    "veri_cls_indexes = veri_results[\"cls_indexes\"]\n",
    "veri_embs = veri_results[\"embs\"]\n",
    "veri_target_embs = veri_results[\"target_embs\"]\n",
    "veri_col_num = veri_results[\"col_num\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = len(train_data)\n",
    "for i in veri_data:\n",
    "    train_data[num_train+i] = veri_data[i]\n",
    "    train_label[num_train+i] = veri_label[i]\n",
    "    train_logits[num_train+i] = veri_logits[i]\n",
    "    train_cls_indexes[num_train+i] = veri_cls_indexes[i]\n",
    "    train_embs[num_train+i] = veri_embs[i]\n",
    "    train_target_embs[num_train+i] = veri_target_embs[i]\n",
    "    train_col_num[num_train+i] = veri_col_num[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2385537\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.7962)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_all = torch.cat([torch.tensor(train_label[i]) for i in train_label], dim=0)\n",
    "print(len(train_labels_all))\n",
    "train_labels_all.sum()/len(train_labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Threshold: 1.5****************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1385896/3553952053.py:55: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
      "/tmp/ipykernel_1385896/3553952053.py:107: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n"
     ]
    }
   ],
   "source": [
    "# brute force perumate in validation TODO: restrict mamimus length of permutation\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "import torch.nn.functional as F\n",
    "test_data = defaultdict(list)\n",
    "test_logits = defaultdict(list)\n",
    "test_cls_indexes = defaultdict(list)\n",
    "test_target_col_mask = defaultdict(list)\n",
    "test_embs = defaultdict(list)\n",
    "test_col_num = defaultdict(list)\n",
    "test_label = defaultdict(list)\n",
    "test_class = defaultdict(list)\n",
    "test_target_embs = defaultdict(list)\n",
    "test_drop_idx = defaultdict(list)\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "for threshold in [1.5]:\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    log = defaultdict(list)\n",
    "    num_cols = []\n",
    "    corrected = 0\n",
    "    total_mistakes = 0\n",
    "    num_permutations = {}\n",
    "    init_permutation = {}\n",
    "    init_correctness = {}\n",
    "    score_init = {}\n",
    "    score_permutation = defaultdict(list)\n",
    "    permutation_correctness = defaultdict(list)\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "            cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "            target_col_mask = batch[\"target_col_mask\"].T\n",
    "            logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "            score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
    "            label_i = batch[\"label\"].item()\n",
    "            predict_init = logits.argmax().item()\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            init_permutation[batch_idx] = init_permutation_i\n",
    "            if predict_init == label_i:\n",
    "                init_correctness[batch_idx] = True\n",
    "            else:\n",
    "                init_correctness[batch_idx] = False\n",
    "            num_permutations[batch_idx] = 0\n",
    "\n",
    "\n",
    "            x = [0]\n",
    "            new_batch_data = []\n",
    "            for col_i in x:\n",
    "                if col_i == 0:\n",
    "                    if len(new_batch_data) == 0:\n",
    "                        cls_indexes_value = 0\n",
    "                    else:\n",
    "                        cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "            new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "            cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "            logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "            test_target_embs[batch_idx].append(embs_temp.cpu())\n",
    "\n",
    "\n",
    "            num_cols.append(len(init_permutation_i))\n",
    "            labels_test.append(batch[\"label\"].cpu())\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            assert -1 not in col_idx_set\n",
    "            for r in range(len(init_permutation_i), 1, -1): # not \n",
    "                for x in itertools.combinations(init_permutation_i, r):\n",
    "                    if 0 not in x:\n",
    "                        continue\n",
    "\n",
    "                    num_permutations[batch_idx] += 1\n",
    "                    new_batch_data = []\n",
    "                    if len(x) != len(init_permutation_i):\n",
    "                        drop_idx = (set(init_permutation_i)-set(x)).pop()\n",
    "                    else:\n",
    "                        drop_idx = -1\n",
    "                    for col_i in x:\n",
    "                        if col_i == 0:\n",
    "                            if len(new_batch_data) == 0:\n",
    "                                cls_indexes_value = 0\n",
    "                            else:\n",
    "                                cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                        new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                    new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                    cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                    logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                    ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n",
    "                    score_permutation[batch_idx].append(ood_score_temp)\n",
    "                    predict_temp = logits_temp.argmax().item()\n",
    "                    permutation_correctness[batch_idx].append(predict_temp == label_i)\n",
    "                    \n",
    "                    test_data[batch_idx].append(new_batch_data.cpu())\n",
    "                    test_logits[batch_idx].append(logits_temp.detach().cpu())\n",
    "                    test_cls_indexes[batch_idx].append(cls_indexes_value)\n",
    "                    test_embs[batch_idx].append(embs_temp.cpu())\n",
    "                    test_col_num[batch_idx].append(len(x))\n",
    "                    test_label[batch_idx].append(torch.tensor(predict_temp == label_i).long()) # indicate whether the permutation is correct or not\n",
    "                    test_class[batch_idx].append(label_i)\n",
    "                    test_drop_idx[batch_idx].append(drop_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"/data/zhihao/TU/Watchog/verification\", exist_ok=True)\n",
    "torch.save({\"data\": test_data, \"logits\": test_logits, \"cls_indexes\": test_cls_indexes, \n",
    "            \"embs\": test_embs, \"col_num\": test_col_num, \"label\": test_label, \"class\": test_class}, f\"/data/zhihao/TU/Watchog/verification/{args.task}_test_data.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "ood_score = F.softmax(logits_test, dim=1).max(1).values\n",
    "ood_labels = torch.tensor(preds == labels).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8592)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ood_score[ood_labels==0] < 0.99).sum()/sum(ood_labels==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7678)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "(ood_score[ood_labels==0] < threshold).sum()/sum(ood_score<threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_micro_f1=0.5284, ts_macro_f1=0.4741\n",
      "ts_micro_f1=0.5284, ts_macro_f1=0.4741\n",
      "ts_micro_f1=0.0000, ts_macro_f1=nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhihao/jupyterprojects/jupyter/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "/home/zhihao/jupyterprojects/jupyter/lib/python3.8/site-packages/numpy/lib/function_base.py:495: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/home/zhihao/jupyterprojects/jupyter/lib/python3.8/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "# Single column results\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "    cls_indexes = torch.LongTensor([[0, 0]]).to(device)\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits = model(batch[\"data\"].T[:, target_col_mask[0]==0], cls_indexes=cls_indexes,)\n",
    "    labels_test.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "    num_cols.append(batch[\"target_col_mask\"].max().item())\n",
    "labels_test = torch.cat(labels_test, dim=0)\n",
    "logits_test = torch.stack(logits_test, dim=0)\n",
    "preds_test = torch.argmax(logits_test, dim=1)\n",
    "num_cols = torch.tensor(num_cols)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "mask = num_cols > 0\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach()[mask].numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach()[~mask].numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cheat drop one-column\n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "log = defaultdict(list)\n",
    "num_cols = []\n",
    "corrected = 0\n",
    "total_mistakes = 0\n",
    "logits_init = []\n",
    "logits_correct = []\n",
    "for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "    num_cols.append(batch[\"target_col_mask\"].max().item())\n",
    "    if 1 in target_col_mask and logits.argmax().item() != batch[\"label\"].item():\n",
    "        total_mistakes += 1\n",
    "        for col_i in target_col_mask.unique():\n",
    "            if col_i == 0 or col_i == -1:\n",
    "                continue\n",
    "            new_batch_data = batch[\"data\"].T[target_col_mask!=col_i].reshape(1, -1)\n",
    "            target_col_mask_temp = target_col_mask[target_col_mask!=col_i].reshape(1, -1)\n",
    "            cls_indexes = (target_col_mask_temp == 0).nonzero()[0].reshape(1, -1)\n",
    "            logits_temp = model(new_batch_data, cls_indexes=cls_indexes,)\n",
    "            if logits_temp.argmax().item() == batch[\"label\"].item():\n",
    "                logits_init.append(logits.detach().cpu())\n",
    "                logits_correct.append(logits_temp.detach().cpu())\n",
    "                corrected += 1\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cheat brute force permutation\n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "log = defaultdict(list)\n",
    "num_cols = []\n",
    "corrected = 0\n",
    "total_mistakes = 0\n",
    "logits_init = []\n",
    "logits_correct = []\n",
    "for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "    num_cols.append(batch[\"target_col_mask\"].max().item())\n",
    "    if 1 in target_col_mask and logits.argmax().item() != batch[\"label\"].item():\n",
    "        total_mistakes += 1\n",
    "        for col_i in target_col_mask.unique():\n",
    "            if col_i == 0 or col_i == -1:\n",
    "                continue\n",
    "            new_batch_data = batch[\"data\"].T[target_col_mask!=col_i].reshape(1, -1)\n",
    "            target_col_mask_temp = target_col_mask[target_col_mask!=col_i].reshape(1, -1)\n",
    "            cls_indexes = (target_col_mask_temp == 0).nonzero()[0].reshape(1, -1)\n",
    "            logits_temp = model(new_batch_data, cls_indexes=cls_indexes,)\n",
    "            if logits_temp.argmax().item() == batch[\"label\"].item():\n",
    "                logits_init.append(logits.detach().cpu())\n",
    "                logits_correct.append(logits_temp.detach().cpu())\n",
    "                corrected += 1\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(logits_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "314"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_init = torch.stack(logits_init, dim=0)\n",
    "logits_correct = torch.stack(logits_correct, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ood_score_init = F.softmax(logits_init, dim=1).max(1).values\n",
    "ood_score_correct = F.softmax(logits_correct, dim=1).max(1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(23)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((ood_score_correct - ood_score_init)>0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 314 0.10828025477707007\n"
     ]
    }
   ],
   "source": [
    "print(corrected, total_mistakes, corrected/total_mistakes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_permutation(x):\n",
    "    new = []\n",
    "    for k in x.tolist()[0]:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Context length: 3****************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_945138/4260784345.py:42: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  max_msp = F.softmax(logits_init).detach().cpu().max().item()\n",
      "/tmp/ipykernel_945138/4260784345.py:45: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  min_entropy = compute_entropy(F.softmax(logits_init)).item()\n",
      "/tmp/ipykernel_945138/4260784345.py:73: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  temp_msp = F.softmax(logits_temp).max().item()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_micro_f1=0.9592, ts_macro_f1=0.9528\n",
      "ts_micro_f1=0.9592, ts_macro_f1=0.9528\n",
      "ts_micro_f1=0.0000, ts_macro_f1=nan\n",
      "*********************Context length: 4****************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhihao/jupyterprojects/jupyter/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "/home/zhihao/jupyterprojects/jupyter/lib/python3.8/site-packages/numpy/lib/function_base.py:495: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/home/zhihao/jupyterprojects/jupyter/lib/python3.8/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/tmp/ipykernel_945138/4260784345.py:42: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  max_msp = F.softmax(logits_init).detach().cpu().max().item()\n",
      "/tmp/ipykernel_945138/4260784345.py:45: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  min_entropy = compute_entropy(F.softmax(logits_init)).item()\n",
      "/tmp/ipykernel_945138/4260784345.py:73: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  temp_msp = F.softmax(logits_temp).max().item()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_micro_f1=0.9726, ts_macro_f1=0.9668\n",
      "ts_micro_f1=0.9726, ts_macro_f1=0.9668\n",
      "ts_micro_f1=0.0000, ts_macro_f1=nan\n",
      "*********************Context length: 6****************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhihao/jupyterprojects/jupyter/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "/home/zhihao/jupyterprojects/jupyter/lib/python3.8/site-packages/numpy/lib/function_base.py:495: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/home/zhihao/jupyterprojects/jupyter/lib/python3.8/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/tmp/ipykernel_945138/4260784345.py:42: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  max_msp = F.softmax(logits_init).detach().cpu().max().item()\n",
      "/tmp/ipykernel_945138/4260784345.py:45: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  min_entropy = compute_entropy(F.softmax(logits_init)).item()\n",
      "/tmp/ipykernel_945138/4260784345.py:73: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  temp_msp = F.softmax(logits_temp).max().item()\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [48]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m new_batch_data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(new_batch_data, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     65\u001b[0m cls_indexes \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m0\u001b[39m, cls_indexes_value])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 66\u001b[0m logits_temp \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_batch_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcls_indexes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcls_indexes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logits_temp\u001b[38;5;241m.\u001b[39margmax()\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m==\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mitem():\n\u001b[1;32m     68\u001b[0m     logits \u001b[38;5;241m=\u001b[39m logits_temp\u001b[38;5;241m.\u001b[39mclone()\n",
      "File \u001b[0;32m~/jupyterprojects/jupyter/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/jupyterprojects/jupyter/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/jupyterprojects/TU/watchog/watchog/model.py:571\u001b[0m, in \u001b[0;36mBertForMultiOutputClassification.forward\u001b[0;34m(self, input_ids, get_enc, cls_indexes, token_type_ids)\u001b[0m\n\u001b[1;32m    569\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    570\u001b[0m \u001b[38;5;66;03m# BertModelMultiOutput\u001b[39;00m\n\u001b[0;32m--> 571\u001b[0m bert_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    572\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    573\u001b[0m table_length \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mlen\u001b[39m(input_ids[i]\u001b[38;5;241m.\u001b[39mnonzero()) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(input_ids))]\n\u001b[1;32m    574\u001b[0m \u001b[38;5;66;03m# Note: returned tensor contains pooled_output of all tokens (to make the tensor size consistent)\u001b[39;00m\n",
      "File \u001b[0;32m~/jupyterprojects/jupyter/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/jupyterprojects/jupyter/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/jupyterprojects/jupyter/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:1141\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1134\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m-> 1141\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1142\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1153\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1154\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/jupyterprojects/jupyter/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/jupyterprojects/jupyter/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/jupyterprojects/jupyter/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:694\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    683\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    684\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    685\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    691\u001b[0m         output_attentions,\n\u001b[1;32m    692\u001b[0m     )\n\u001b[1;32m    693\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 694\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    704\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/jupyterprojects/jupyter/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/jupyterprojects/jupyter/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/jupyterprojects/jupyter/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:584\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    573\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    574\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    581\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    582\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    583\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 584\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    593\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m~/jupyterprojects/jupyter/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/jupyterprojects/jupyter/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/jupyterprojects/jupyter/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:514\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    505\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    506\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    512\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    513\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m--> 514\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    523\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[1;32m    524\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/jupyterprojects/jupyter/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/jupyterprojects/jupyter/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/jupyterprojects/jupyter/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:407\u001b[0m, in \u001b[0;36mBertSdpaSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    405\u001b[0m     key_layer, value_layer \u001b[38;5;241m=\u001b[39m past_key_value\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 407\u001b[0m     key_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose_for_scores(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_states\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    408\u001b[0m     value_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose_for_scores(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue(current_states))\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cross_attention:\n",
      "File \u001b[0;32m~/jupyterprojects/jupyter/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/jupyterprojects/jupyter/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/jupyterprojects/jupyter/lib/python3.8/site-packages/torch/nn/modules/linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Cheat brute force perumate\n",
    "\n",
    "import itertools\n",
    "import torch.nn.functional as F\n",
    "\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "for context_length in [3, 4, 6, 8, 12, 16]:\n",
    "    print(f\"*********************Context length: {context_length}****************************\")\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    log = defaultdict(list)\n",
    "    num_cols = []\n",
    "    threshold = 0.8\n",
    "    corrected = 0\n",
    "    total_mistakes = 0\n",
    "    init_permutation = defaultdict(list)\n",
    "    corrected_permutation = defaultdict(list)\n",
    "    init_logits = defaultdict(list)\n",
    "    corrected_logits = defaultdict(list)\n",
    "    MSP_permutation = defaultdict(list)\n",
    "    MSP_logits = defaultdict(list)\n",
    "    MSP_corrected = 0\n",
    "    Entropy_permutation = defaultdict(list)\n",
    "    Entropy_logits = defaultdict(list)\n",
    "    Entropy_corrected = 0\n",
    "    for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "        cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "        target_col_mask = batch[\"target_col_mask\"].T\n",
    "        logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "        logits_init = logits.clone()\n",
    "        num_cols.append(batch[\"target_col_mask\"].max().item())\n",
    "        if 1 in target_col_mask and logits.argmax().item() != batch[\"label\"].item():\n",
    "            total_mistakes += 1\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            successs = False\n",
    "            init_permutation[batch_idx].append(get_permutation(target_col_mask))\n",
    "            init_logits[batch_idx].append(logits_init.detach().cpu())        \n",
    "            max_msp = F.softmax(logits_init).detach().cpu().max().item()\n",
    "            msp_logits = logits_init.clone().detach().cpu()\n",
    "            msp_perm = get_permutation(target_col_mask)[0]\n",
    "            min_entropy = compute_entropy(F.softmax(logits_init)).item()\n",
    "            entropy_logits = logits_init.clone().detach().cpu()\n",
    "            entropy_perm = get_permutation(target_col_mask)[0]\n",
    "            assert -1 not in col_idx_set\n",
    "            for r in range(1, min(len(col_idx_set) + 1, context_length+1)):\n",
    "                for subset in itertools.combinations(col_idx_set, r):\n",
    "                    if 0 not in subset:\n",
    "                        continue\n",
    "                    for x in itertools.permutations(subset):\n",
    "                        if x[0] != 0:\n",
    "                            continue\n",
    "                        new_batch_data = []\n",
    "                        for col_i in x:\n",
    "                            if col_i == 0:\n",
    "                                if len(new_batch_data) == 0:\n",
    "                                    cls_indexes_value = 0\n",
    "                                else:\n",
    "                                    cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                            new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "\n",
    "                        new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                        cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                        logits_temp = model(new_batch_data, cls_indexes=cls_indexes,)\n",
    "                        if logits_temp.argmax().item() == batch[\"label\"].item():\n",
    "                            logits = logits_temp.clone()\n",
    "                            successs = True\n",
    "                            corrected_permutation[batch_idx].append(x)\n",
    "                            corrected_logits[batch_idx].append(logits_temp.clone().detach().cpu())\n",
    "                        \n",
    "                        temp_msp = F.softmax(logits_temp).max().item()\n",
    "                        if max_msp < temp_msp:\n",
    "                            max_msp = temp_msp\n",
    "                            msp_logits = logits_temp.clone().detach().cpu()\n",
    "                            msp_perm = x\n",
    "                        # temp_entropy = compute_entropy(F.softmax(logits_temp)).item()\n",
    "                        # if min_entropy > temp_entropy:\n",
    "                        #     min_entropy = temp_entropy\n",
    "                        #     entropy_logits = logits_temp.clone().detach().cpu()\n",
    "                        #     entropy_perm = x\n",
    "            MSP_logits[batch_idx].append(msp_logits)\n",
    "            MSP_permutation[batch_idx].append(msp_perm)\n",
    "            if msp_logits.argmax().item() == batch[\"label\"].item():\n",
    "                MSP_corrected += 1\n",
    "                # print(f\"MSP correct {batch_idx}\")\n",
    "            # Entropy_logits[batch_idx].append(entropy_logits)\n",
    "            # Entropy_permutation[batch_idx].append(entropy_perm)\n",
    "            # if entropy_logits.argmax().item() == batch[\"label\"].item():\n",
    "            #     Entropy_corrected += 1\n",
    "            #     # print(f\"Entropy correct {batch_idx}\")\n",
    "            if successs:\n",
    "                corrected += 1\n",
    "        labels_test.append(batch[\"label\"].cpu())\n",
    "        logits_test.append(logits.detach().cpu())\n",
    "    labels_test = torch.cat(labels_test, dim=0)\n",
    "    logits_test = torch.stack(logits_test, dim=0)\n",
    "    preds_test = torch.argmax(logits_test, dim=1)\n",
    "    num_cols = torch.tensor(num_cols)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix, f1_score\n",
    "    mask = num_cols > 0\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach().numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach()[mask].numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach()[~mask].numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# brute force perumate, find uncertain init prediction, weighted msp\n",
    "import itertools\n",
    "\n",
    "\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "idx_list = []\n",
    "uncertain_init_mask = []\n",
    "uncertain_target_mask = []\n",
    "correct_init_mask = []\n",
    "correct_target_mask = []\n",
    "correct_permutation_mask = []\n",
    "correct_msp_mask = []\n",
    "init_target_mask = []\n",
    "ood_score_init_list = []\n",
    "ood_score_target_list = []\n",
    "ood_score_final_list = []\n",
    "\n",
    "alpha = 1.0\n",
    "class_weights = (1.0 / class_freq) ** alpha\n",
    "debias_threshold = 0.9\n",
    "# Normalize the weights\n",
    "class_weights /= class_weights.sum()\n",
    "context_length = 2\n",
    "for threshold in [0.5]:\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    log = defaultdict(list)\n",
    "    num_cols = []\n",
    "    corrected = 0\n",
    "    total_mistakes = 0\n",
    "\n",
    "    for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "        target_col_mask = batch[\"target_col_mask\"].T\n",
    "        if 1 in target_col_mask:\n",
    "            idx_list.append(batch_idx)\n",
    "\n",
    "            cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "            logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "            logits = reweight_logits(logits.detach().cpu(), class_weights)\n",
    "            num_cols.append(batch[\"target_col_mask\"].max().item())         \n",
    "            ood_score_init = logits.max().item()\n",
    "            ood_score_init_list.append(ood_score_init)\n",
    "            uncertain_init_mask.append(ood_score_init < threshold)\n",
    "            predict_init = logits.argmax().item()\n",
    "            correct_init_mask.append(predict_init == batch[\"label\"].item())\n",
    "            \n",
    "            cls_indexes = torch.tensor([0, 0]).reshape(1, -1).to(device)\n",
    "            logits_temp = model(batch[\"data\"].T[target_col_mask==0].reshape(1, -1), cls_indexes=cls_indexes,)  \n",
    "            logits_temp = reweight_logits(logits_temp.detach().cpu(), class_weights)\n",
    "            ood_score_target = logits_temp.max().item()\n",
    "            ood_score_target_list.append(ood_score_target)\n",
    "            uncertain_target_mask.append(ood_score_target < threshold)\n",
    "            predict_target = logits_temp.argmax().item()\n",
    "            correct_target_mask.append(predict_target == batch[\"label\"].item())\n",
    "            \n",
    "\n",
    "            init_target_mask.append(predict_target == predict_init)\n",
    "            \n",
    "            correct_permutation = False\n",
    "            ood_score_max = max_msp = 0\n",
    "            max_msp_debiased = 0\n",
    "            debias_class = []\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            assert -1 not in col_idx_set\n",
    "            for r in range(1, len(col_idx_set) + 1):\n",
    "                for subset in itertools.combinations(col_idx_set, context_length+1):\n",
    "                    # if 0 not in subset:\n",
    "                    #     continue\n",
    "                    for x in itertools.permutations(subset):\n",
    "                        new_batch_data = []\n",
    "                        for col_i in x:\n",
    "                            if col_i == 0:\n",
    "                                if len(new_batch_data) == 0:\n",
    "                                    cls_indexes_value = 0\n",
    "                                else:\n",
    "                                    cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                            new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                        new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                        cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                        logits_temp = model(new_batch_data, cls_indexes=cls_indexes,)\n",
    "                        logits_temp = reweight_logits(logits_temp.detach().cpu(), class_weights)\n",
    "                        msp_temp = logits_temp.max().item()\n",
    "                        predict_temp = logits_temp.argmax().item()\n",
    "                        if 0 not in x and msp_temp > debias_threshold and (predict_temp!=predict_target or predict_temp!=predict_init):\n",
    "                            debias_class.append(predict_temp)\n",
    "                            continue\n",
    "                        # print(x, msp_temp, predict_temp)\n",
    "                        if msp_temp > max_msp and 0 in x and predict_temp not in debias_class:\n",
    "                            max_msp = msp_temp\n",
    "                            msp_predict = predict_temp\n",
    "                        if predict_temp == batch[\"label\"].item():\n",
    "                            correct_permutation = True\n",
    "            ood_score_final_list.append(max_msp)\n",
    "            correct_permutation_mask.append(correct_permutation)\n",
    "            correct_msp_mask.append(msp_predict == batch[\"label\"].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# brute force perumate, find uncertain init prediction\n",
    "import itertools\n",
    "\n",
    "\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "idx_list = []\n",
    "uncertain_init_mask = []\n",
    "uncertain_target_mask = []\n",
    "correct_init_mask = []\n",
    "correct_target_mask = []\n",
    "correct_permutation_mask = []\n",
    "correct_msp_mask = []\n",
    "init_target_mask = []\n",
    "ood_score_init_list = []\n",
    "ood_score_target_list = []\n",
    "\n",
    "\n",
    "alpha = 1.0\n",
    "class_weights = (1.0 / class_freq) ** alpha\n",
    "\n",
    "# Normalize the weights\n",
    "class_weights /= class_weights.sum()\n",
    "for threshold in [0.5]:\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    log = defaultdict(list)\n",
    "    num_cols = []\n",
    "    corrected = 0\n",
    "    total_mistakes = 0\n",
    "\n",
    "    for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "        target_col_mask = batch[\"target_col_mask\"].T\n",
    "        if 1 in target_col_mask:\n",
    "            idx_list.append(batch_idx)\n",
    "\n",
    "            cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "            logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "            num_cols.append(batch[\"target_col_mask\"].max().item())\n",
    "            ood_score_init = F.softmax(logits.detach()).max().item()\n",
    "            ood_score_init_list.append(ood_score_init)\n",
    "            uncertain_init_mask.append(ood_score_init < threshold)\n",
    "            predict_init = logits.argmax().item()\n",
    "            correct_init_mask.append(predict_init == batch[\"label\"].item())\n",
    "            \n",
    "            cls_indexes = torch.tensor([0, 0]).reshape(1, -1).to(device)\n",
    "            logits_temp = model(batch[\"data\"].T[target_col_mask==0].reshape(1, -1), cls_indexes=cls_indexes,)    \n",
    "            ood_score_target = F.softmax(logits_temp.detach()).max().item()\n",
    "            ood_score_target_list.append(ood_score_target)\n",
    "            uncertain_target_mask.append(ood_score_target < threshold)\n",
    "            predict_target = logits_temp.argmax().item()\n",
    "            correct_target_mask.append(predict_target == batch[\"label\"].item())\n",
    "            \n",
    "            init_target_mask.append(predict_target == predict_init)\n",
    "            \n",
    "            correct_permutation = False\n",
    "            ood_score_max = 0\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            assert -1 not in col_idx_set\n",
    "            for r in range(1, len(col_idx_set) + 1):\n",
    "                for subset in itertools.combinations(col_idx_set, r):\n",
    "                    for x in itertools.permutations(subset):\n",
    "                        if 0 not in x:\n",
    "                            continue\n",
    "                        new_batch_data = []\n",
    "                        for col_i in x:\n",
    "                            if col_i == 0:\n",
    "                                if len(new_batch_data) == 0:\n",
    "                                    cls_indexes_value = 0\n",
    "                                else:\n",
    "                                    cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                            new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                        new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                        cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                        logits_temp = model(new_batch_data, cls_indexes=cls_indexes,)\n",
    "                        ood_score_temp =F.softmax(logits_temp.detach()).max().item()\n",
    "                        predict_temp = logits_temp.argmax().item()\n",
    "                        if ood_score_temp > ood_score_max:\n",
    "                            ood_score_max = ood_score_temp \n",
    "                            predict_ood = logits_temp.argmax().item()\n",
    "                        if predict_temp == batch[\"label\"].item():\n",
    "                            correct_permutation = True\n",
    "            correct_permutation_mask.append(correct_permutation)\n",
    "            correct_msp_mask.append(predict_ood == batch[\"label\"].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reweight_logits(logits, class_weights):\n",
    "    # Step 1: Apply exp(logits)\n",
    "    exp_logits = torch.exp(logits)\n",
    "    \n",
    "    # Step 2: Multiply by class weights\n",
    "    # reweighted_exp = exp_logits * torch.sqrt(class_weights)\n",
    "    reweighted_exp = exp_logits * class_weights\n",
    "    # Step 3: Normalize to get valid probabilities (like softmax)\n",
    "    reweighted_probs = reweighted_exp / reweighted_exp.sum(dim=-1, keepdim=True)\n",
    "    \n",
    "    return reweighted_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2586507/3498784723.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  class_freq = torch.load(\"/data/yongkang/TU/SOTAB/class_freq.pt\")\n"
     ]
    }
   ],
   "source": [
    "class_freq = torch.load(\"/data/yongkang/TU/SOTAB/class_freq.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Threshold: 0.5****************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2586507/1723896548.py:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  logits = F.softmax(logits.detach().cpu())\n",
      "/tmp/ipykernel_2586507/1723896548.py:59: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  logits_temp = F.softmax(logits_temp.detach().cpu())\n",
      "/tmp/ipykernel_2586507/1723896548.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  logits_temp = F.softmax(logits_temp.detach().cpu())\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# brute force perumate, find uncertain init prediction, weighted msp\n",
    "import itertools\n",
    "\n",
    "\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "idx_list = []\n",
    "uncertain_init_mask = []\n",
    "uncertain_target_mask = []\n",
    "correct_init_mask = []\n",
    "correct_target_mask = []\n",
    "correct_permutation_mask = []\n",
    "correct_msp_mask = []\n",
    "init_target_mask = []\n",
    "ood_score_init_list = []\n",
    "ood_score_target_list = []\n",
    "ood_score_final_list = []\n",
    "\n",
    "alpha = 1.0\n",
    "class_weights = (1.0 / class_freq) ** alpha\n",
    "debias_threshold = 0.9\n",
    "# Normalize the weights\n",
    "class_weights /= class_weights.sum()\n",
    "context_length = 2\n",
    "for threshold in [0.5]:\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    log = defaultdict(list)\n",
    "    num_cols = []\n",
    "    corrected = 0\n",
    "    total_mistakes = 0\n",
    "\n",
    "    for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "        target_col_mask = batch[\"target_col_mask\"].T\n",
    "        if 1 in target_col_mask:\n",
    "            idx_list.append(batch_idx)\n",
    "\n",
    "            cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "            logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "            # logits = reweight_logits(logits.detach().cpu(), class_weights)\n",
    "            logits = F.softmax(logits.detach().cpu())\n",
    "            num_cols.append(batch[\"target_col_mask\"].max().item())         \n",
    "            ood_score_init = logits.max().item()\n",
    "            ood_score_init_list.append(ood_score_init)\n",
    "            uncertain_init_mask.append(ood_score_init < threshold)\n",
    "            predict_init = logits.argmax().item()\n",
    "            correct_init_mask.append(predict_init == batch[\"label\"].item())\n",
    "            \n",
    "            cls_indexes = torch.tensor([0, 0]).reshape(1, -1).to(device)\n",
    "            logits_temp = model(batch[\"data\"].T[target_col_mask==0].reshape(1, -1), cls_indexes=cls_indexes,)  \n",
    "            # logits_temp = reweight_logits(logits_temp.detach().cpu(), class_weights)\n",
    "            logits_temp = F.softmax(logits_temp.detach().cpu())\n",
    "            ood_score_target = logits_temp.max().item()\n",
    "            ood_score_target_list.append(ood_score_target)\n",
    "            uncertain_target_mask.append(ood_score_target < threshold)\n",
    "            predict_target = logits_temp.argmax().item()\n",
    "            correct_target_mask.append(predict_target == batch[\"label\"].item())\n",
    "            \n",
    "\n",
    "            init_target_mask.append(predict_target == predict_init)\n",
    "            \n",
    "            correct_permutation = False\n",
    "            ood_score_max = max_msp = 0\n",
    "            max_msp_debiased = 0\n",
    "            debias_class = []\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            assert -1 not in col_idx_set\n",
    "            for r in range(1, min(len(col_idx_set) + 1, context_length+1)):\n",
    "                for subset in itertools.combinations(col_idx_set, r):\n",
    "                    if 0 not in subset:\n",
    "                        continue\n",
    "                    for x in itertools.permutations(subset):\n",
    "                        new_batch_data = []\n",
    "                        for col_i in x:\n",
    "                            if col_i == 0:\n",
    "                                if len(new_batch_data) == 0:\n",
    "                                    cls_indexes_value = 0\n",
    "                                else:\n",
    "                                    cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                            new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                        new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                        cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                        logits_temp = model(new_batch_data, cls_indexes=cls_indexes,)\n",
    "                        # logits_temp = reweight_logits(logits_temp.detach().cpu(), class_weights)\n",
    "                        logits_temp = F.softmax(logits_temp.detach().cpu())\n",
    "                        msp_temp = logits_temp.max().item()\n",
    "                        predict_temp = logits_temp.argmax().item()\n",
    "                        if 0 not in x and msp_temp > debias_threshold and (predict_temp!=predict_target or predict_temp!=predict_init):\n",
    "                            debias_class.append(predict_temp)\n",
    "                            continue\n",
    "                        # print(x, msp_temp, predict_temp)\n",
    "                        if msp_temp > max_msp and 0 in x and predict_temp not in debias_class:\n",
    "                            max_msp = msp_temp\n",
    "                            msp_predict = predict_temp\n",
    "                        if predict_temp == batch[\"label\"].item():\n",
    "                            correct_permutation = True\n",
    "            ood_score_final_list.append(max_msp)\n",
    "            correct_permutation_mask.append(correct_permutation)\n",
    "            correct_msp_mask.append(msp_predict == batch[\"label\"].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15040 15040 15040 15040 15040 15040 15040 15040\n"
     ]
    }
   ],
   "source": [
    "\n",
    "idx_list = torch.tensor(idx_list)\n",
    "uncertain_init_mask = torch.tensor(uncertain_init_mask)\n",
    "uncertain_target_mask = torch.tensor(uncertain_target_mask)\n",
    "correct_init_mask = torch.tensor(correct_init_mask)\n",
    "correct_target_mask = torch.tensor(correct_target_mask)\n",
    "correct_permutation_mask = torch.tensor(correct_permutation_mask)\n",
    "correct_msp_mask = torch.tensor(correct_msp_mask)\n",
    "init_target_mask = torch.tensor(init_target_mask)\n",
    "ood_score_init_list = torch.tensor(ood_score_init_list)\n",
    "ood_score_target_list = torch.tensor(ood_score_target_list)\n",
    "ood_score_final_list = torch.tensor(ood_score_final_list)\n",
    "print(len(idx_list), len(uncertain_init_mask), len(uncertain_target_mask), len(init_target_mask), len(correct_init_mask), len(correct_target_mask), len(correct_permutation_mask), len(correct_msp_mask))\n",
    "\n",
    "# torch.save({\"idx_list\": idx_list, \"uncertain_init_mask\": uncertain_init_mask, \"uncertain_target_mask\": uncertain_target_mask, \"init_target_mask\": init_target_mask, \"correct_init_mask\": correct_init_mask, \"correct_target_mask\": correct_target_mask, \"correct_permutation_mask\": correct_permutation_mask, \"correct_msp_mask\": correct_msp_mask, \"ood_score_init_list\": ood_score_init_list, \"ood_score_target_list\": ood_score_target_list, \"ood_score_final_list\": ood_score_final_list}, f\"./results/SOTAB_brute_force_permutation_context@{context_length}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Threshold: 0.5****************************\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# brute force perumate, find uncertain init prediction, weighted msp\n",
    "import itertools\n",
    "\n",
    "\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "idx_list = []\n",
    "uncertain_init_mask = []\n",
    "uncertain_target_mask = []\n",
    "correct_init_mask = []\n",
    "correct_target_mask = []\n",
    "correct_permutation_mask = []\n",
    "correct_msp_mask = []\n",
    "init_target_mask = []\n",
    "ood_score_init_list = []\n",
    "ood_score_target_list = []\n",
    "ood_score_final_list = []\n",
    "\n",
    "alpha = 1.0\n",
    "class_weights = (1.0 / class_freq) ** alpha\n",
    "debias_threshold = 0.9\n",
    "# Normalize the weights\n",
    "class_weights /= class_weights.sum()\n",
    "context_length = 3\n",
    "for threshold in [0.5]:\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    log = defaultdict(list)\n",
    "    num_cols = []\n",
    "    corrected = 0\n",
    "    total_mistakes = 0\n",
    "\n",
    "    for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "        target_col_mask = batch[\"target_col_mask\"].T\n",
    "        if 1 in target_col_mask:\n",
    "            idx_list.append(batch_idx)\n",
    "\n",
    "            cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "            logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "            logits = reweight_logits(logits.detach().cpu(), class_weights)\n",
    "            num_cols.append(batch[\"target_col_mask\"].max().item())         \n",
    "            ood_score_init = logits.max().item()\n",
    "            ood_score_init_list.append(ood_score_init)\n",
    "            uncertain_init_mask.append(ood_score_init < threshold)\n",
    "            predict_init = logits.argmax().item()\n",
    "            correct_init_mask.append(predict_init == batch[\"label\"].item())\n",
    "            \n",
    "            cls_indexes = torch.tensor([0, 0]).reshape(1, -1).to(device)\n",
    "            logits_temp = model(batch[\"data\"].T[target_col_mask==0].reshape(1, -1), cls_indexes=cls_indexes,)  \n",
    "            logits_temp = reweight_logits(logits_temp.detach().cpu(), class_weights)\n",
    "            ood_score_target = logits_temp.max().item()\n",
    "            ood_score_target_list.append(ood_score_target)\n",
    "            uncertain_target_mask.append(ood_score_target < threshold)\n",
    "            predict_target = logits_temp.argmax().item()\n",
    "            correct_target_mask.append(predict_target == batch[\"label\"].item())\n",
    "            \n",
    "\n",
    "            init_target_mask.append(predict_target == predict_init)\n",
    "            \n",
    "            correct_permutation = False\n",
    "            ood_score_max = max_msp = 0\n",
    "            max_msp_debiased = 0\n",
    "            debias_class = []\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            assert -1 not in col_idx_set\n",
    "            for r in range(1, min(len(col_idx_set) + 1, context_length+1)):\n",
    "                for subset in itertools.combinations(col_idx_set, r):\n",
    "                    if 0 not in subset:\n",
    "                        continue\n",
    "                    for x in itertools.permutations(subset):\n",
    "                        new_batch_data = []\n",
    "                        for col_i in x:\n",
    "                            if col_i == 0:\n",
    "                                if len(new_batch_data) == 0:\n",
    "                                    cls_indexes_value = 0\n",
    "                                else:\n",
    "                                    cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                            new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                        new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                        cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                        logits_temp = model(new_batch_data, cls_indexes=cls_indexes,)\n",
    "                        logits_temp = reweight_logits(logits_temp.detach().cpu(), class_weights)\n",
    "                        msp_temp = logits_temp.max().item()\n",
    "                        predict_temp = logits_temp.argmax().item()\n",
    "                        if 0 not in x and msp_temp > debias_threshold and (predict_temp!=predict_target or predict_temp!=predict_init):\n",
    "                            debias_class.append(predict_temp)\n",
    "                            continue\n",
    "                        # print(x, msp_temp, predict_temp)\n",
    "                        if msp_temp > max_msp and 0 in x and predict_temp not in debias_class:\n",
    "                            max_msp = msp_temp\n",
    "                            msp_predict = predict_temp\n",
    "                        if predict_temp == batch[\"label\"].item():\n",
    "                            correct_permutation = True\n",
    "            ood_score_final_list.append(max_msp)\n",
    "            correct_permutation_mask.append(correct_permutation)\n",
    "            correct_msp_mask.append(msp_predict == batch[\"label\"].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(87.5263)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_freq.max()/class_freq.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15040 15040 15040 15040 15040 15040 15040 15040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1991562/1785266914.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  idx_list = torch.tensor(idx_list)\n",
      "/tmp/ipykernel_1991562/1785266914.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  uncertain_init_mask = torch.tensor(uncertain_init_mask)\n",
      "/tmp/ipykernel_1991562/1785266914.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  uncertain_target_mask = torch.tensor(uncertain_target_mask)\n",
      "/tmp/ipykernel_1991562/1785266914.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  correct_init_mask = torch.tensor(correct_init_mask)\n",
      "/tmp/ipykernel_1991562/1785266914.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  correct_target_mask = torch.tensor(correct_target_mask)\n",
      "/tmp/ipykernel_1991562/1785266914.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  correct_permutation_mask = torch.tensor(correct_permutation_mask)\n",
      "/tmp/ipykernel_1991562/1785266914.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  correct_msp_mask = torch.tensor(correct_msp_mask)\n",
      "/tmp/ipykernel_1991562/1785266914.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  init_target_mask = torch.tensor(init_target_mask)\n",
      "/tmp/ipykernel_1991562/1785266914.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ood_score_init_list = torch.tensor(ood_score_init_list)\n",
      "/tmp/ipykernel_1991562/1785266914.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ood_score_target_list = torch.tensor(ood_score_target_list)\n",
      "/tmp/ipykernel_1991562/1785266914.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ood_score_final_list = torch.tensor(ood_score_final_list)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "idx_list = torch.tensor(idx_list)\n",
    "uncertain_init_mask = torch.tensor(uncertain_init_mask)\n",
    "uncertain_target_mask = torch.tensor(uncertain_target_mask)\n",
    "correct_init_mask = torch.tensor(correct_init_mask)\n",
    "correct_target_mask = torch.tensor(correct_target_mask)\n",
    "correct_permutation_mask = torch.tensor(correct_permutation_mask)\n",
    "correct_msp_mask = torch.tensor(correct_msp_mask)\n",
    "init_target_mask = torch.tensor(init_target_mask)\n",
    "ood_score_init_list = torch.tensor(ood_score_init_list)\n",
    "ood_score_target_list = torch.tensor(ood_score_target_list)\n",
    "ood_score_final_list = torch.tensor(ood_score_final_list)\n",
    "print(len(idx_list), len(uncertain_init_mask), len(uncertain_target_mask), len(init_target_mask), len(correct_init_mask), len(correct_target_mask), len(correct_permutation_mask), len(correct_msp_mask))\n",
    "\n",
    "# torch.save({\"idx_list\": idx_list, \"uncertain_init_mask\": uncertain_init_mask, \"uncertain_target_mask\": uncertain_target_mask, \"init_target_mask\": init_target_mask, \"correct_init_mask\": correct_init_mask, \"correct_target_mask\": correct_target_mask, \"correct_permutation_mask\": correct_permutation_mask, \"correct_msp_mask\": correct_msp_mask, \"ood_score_init_list\": ood_score_init_list, \"ood_score_target_list\": ood_score_target_list, \"ood_score_final_list\": ood_score_final_list}, f\"./results/SOTAB_brute_force_permutation_weighted_context@{context_length}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Threshold: 0.5****************************\n",
      "Init\n",
      "13175 14821 0.8889413669792862\n",
      "62 219 0.2831050228310502\n",
      "MSP\n",
      "11161 14821 0.753053100330612\n",
      "45 219 0.2054794520547945\n",
      "MSP & Init\n",
      "10941\n",
      "13395 14821 0.9037851696916538\n",
      "82 219 0.3744292237442922\n",
      "Permutation\n",
      "14253 14821 0.9616760002698873\n",
      "171 219 0.7808219178082192\n",
      "*********************Threshold: 0.8****************************\n",
      "Init\n",
      "12908 14189 0.9097187962506167\n",
      "329 851 0.38660399529964745\n",
      "MSP\n",
      "10975 14189 0.7734865036295722\n",
      "231 851 0.27144535840188017\n",
      "MSP & Init\n",
      "10833\n",
      "13050 14189 0.9197265487349355\n",
      "427 851 0.5017626321974148\n",
      "Permutation\n",
      "13716 14189 0.9666643174289943\n",
      "708 851 0.8319623971797885\n",
      "*********************Threshold: 0.9****************************\n",
      "Init\n",
      "12734 13845 0.9197544239797761\n",
      "503 1195 0.42092050209205023\n",
      "MSP\n",
      "10871 13845 0.7851932105453232\n",
      "335 1195 0.2803347280334728\n",
      "MSP & Init\n",
      "10757\n",
      "12848 13845 0.9279884434814012\n",
      "629 1195 0.5263598326359833\n",
      "Permutation\n",
      "13432 13845 0.9701697363669195\n",
      "992 1195 0.8301255230125523\n"
     ]
    }
   ],
   "source": [
    "# weighted, only uncertain init\n",
    "for threshold in [0.5, 0.8, 0.9]:\n",
    "    uncertain_init_mask = ood_score_init_list < threshold\n",
    "    uncertain_target_mask = ood_score_target_list < threshold\n",
    "    condition_mask = ~uncertain_init_mask\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    print(\"Init\")\n",
    "    # init prediction\n",
    "    print((condition_mask&correct_init_mask).sum().item(), \n",
    "        (condition_mask).sum().item(), \n",
    "        (condition_mask&correct_init_mask).sum().item()/(condition_mask).sum().item())\n",
    "    # init prediction\n",
    "    print((~condition_mask&correct_init_mask).sum().item(), \n",
    "        (~condition_mask).sum().item(), \n",
    "       (~condition_mask&correct_init_mask).sum().item()/(~condition_mask).sum().item())\n",
    "    print(\"MSP\")\n",
    "    # msp prediction\n",
    "    print((condition_mask&correct_msp_mask).sum().item(), \n",
    "        (condition_mask).sum().item(), \n",
    "        (condition_mask&correct_msp_mask).sum().item()/(condition_mask).sum().item())\n",
    "    # msp prediction\n",
    "    print((~condition_mask&correct_msp_mask).sum().item(), \n",
    "        (~condition_mask).sum().item(), \n",
    "        (~condition_mask&correct_msp_mask).sum().item()/(~condition_mask).sum().item())\n",
    "    print(\"MSP & Init\")\n",
    "    print(((condition_mask&correct_init_mask)&(condition_mask&correct_msp_mask)).sum().item())\n",
    "    # print(((~(init_target_mask&(~uncertain_init_mask & ~uncertain_target_mask))& correct_msp_mask)&(~(init_target_mask&(~uncertain_init_mask & ~uncertain_target_mask))& correct_init_mask)).sum().item())\n",
    "    print(((condition_mask&correct_init_mask)|(condition_mask&correct_msp_mask)).sum().item(),\n",
    "          (condition_mask).sum().item(), \n",
    "          ((condition_mask&correct_init_mask)|(condition_mask&correct_msp_mask)).sum().item()/(condition_mask).sum().item())\n",
    "    print(((~condition_mask&correct_init_mask)|(~condition_mask&correct_msp_mask)).sum().item(),\n",
    "          (~condition_mask).sum().item(), \n",
    "          ((~condition_mask&correct_init_mask)|(~condition_mask&correct_msp_mask)).sum().item()/(~condition_mask).sum().item())\n",
    "    print(\"Permutation\")\n",
    "    print((condition_mask&correct_permutation_mask).sum().item(), \n",
    "        (condition_mask).sum().item(), \n",
    "        (condition_mask&correct_permutation_mask).sum().item()/(condition_mask).sum().item())\n",
    "    # msp prediction\n",
    "    print((~condition_mask&correct_permutation_mask).sum().item(), \n",
    "         (~condition_mask).sum().item(), \n",
    "        (~condition_mask&correct_permutation_mask).sum().item()/(~condition_mask).sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Threshold: 0.5****************************\n",
      "Init\n",
      "13164 14871 0.885212830340932\n",
      "42 169 0.2485207100591716\n",
      "MSP\n",
      "10647 14871 0.7159572321968933\n",
      "27 169 0.15976331360946747\n",
      "MSP & Init\n",
      "10443\n",
      "13368 14871 0.898930804922332\n",
      "58 169 0.3431952662721893\n",
      "Permutation\n",
      "13296 14871 0.8940891668347791\n",
      "84 169 0.4970414201183432\n",
      "*********************Threshold: 0.8****************************\n",
      "Init\n",
      "12923 14278 0.9050987533267965\n",
      "283 762 0.37139107611548555\n",
      "MSP\n",
      "10496 14278 0.7351169631601064\n",
      "178 762 0.2335958005249344\n",
      "MSP & Init\n",
      "10361\n",
      "13058 14278 0.9145538590839053\n",
      "368 762 0.48293963254593175\n",
      "Permutation\n",
      "12928 14278 0.9054489424289116\n",
      "452 762 0.5931758530183727\n",
      "*********************Threshold: 0.9****************************\n",
      "Init\n",
      "12731 13900 0.9158992805755396\n",
      "475 1140 0.4166666666666667\n",
      "MSP\n",
      "10408 13900 0.7487769784172662\n",
      "266 1140 0.23333333333333334\n",
      "MSP & Init\n",
      "10304\n",
      "12835 13900 0.9233812949640288\n",
      "591 1140 0.5184210526315789\n",
      "Permutation\n",
      "12681 13900 0.9123021582733813\n",
      "699 1140 0.6131578947368421\n"
     ]
    }
   ],
   "source": [
    "# weighted, only uncertain init\n",
    "for threshold in [0.5, 0.8, 0.9]:\n",
    "    uncertain_init_mask = ood_score_init_list < threshold\n",
    "    uncertain_target_mask = ood_score_target_list < threshold\n",
    "    condition_mask = ~uncertain_init_mask\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    print(\"Init\")\n",
    "    # init prediction\n",
    "    print((condition_mask&correct_init_mask).sum().item(), \n",
    "        (condition_mask).sum().item(), \n",
    "        (condition_mask&correct_init_mask).sum().item()/(condition_mask).sum().item())\n",
    "    # init prediction\n",
    "    print((~condition_mask&correct_init_mask).sum().item(), \n",
    "        (~condition_mask).sum().item(), \n",
    "       (~condition_mask&correct_init_mask).sum().item()/(~condition_mask).sum().item())\n",
    "    print(\"MSP\")\n",
    "    # msp prediction\n",
    "    print((condition_mask&correct_msp_mask).sum().item(), \n",
    "        (condition_mask).sum().item(), \n",
    "        (condition_mask&correct_msp_mask).sum().item()/(condition_mask).sum().item())\n",
    "    # msp prediction\n",
    "    print((~condition_mask&correct_msp_mask).sum().item(), \n",
    "        (~condition_mask).sum().item(), \n",
    "        (~condition_mask&correct_msp_mask).sum().item()/(~condition_mask).sum().item())\n",
    "    print(\"MSP & Init\")\n",
    "    print(((condition_mask&correct_init_mask)&(condition_mask&correct_msp_mask)).sum().item())\n",
    "    # print(((~(init_target_mask&(~uncertain_init_mask & ~uncertain_target_mask))& correct_msp_mask)&(~(init_target_mask&(~uncertain_init_mask & ~uncertain_target_mask))& correct_init_mask)).sum().item())\n",
    "    print(((condition_mask&correct_init_mask)|(condition_mask&correct_msp_mask)).sum().item(),\n",
    "          (condition_mask).sum().item(), \n",
    "          ((condition_mask&correct_init_mask)|(condition_mask&correct_msp_mask)).sum().item()/(condition_mask).sum().item())\n",
    "    print(((~condition_mask&correct_init_mask)|(~condition_mask&correct_msp_mask)).sum().item(),\n",
    "          (~condition_mask).sum().item(), \n",
    "          ((~condition_mask&correct_init_mask)|(~condition_mask&correct_msp_mask)).sum().item()/(~condition_mask).sum().item())\n",
    "    print(\"Permutation\")\n",
    "    print((condition_mask&correct_permutation_mask).sum().item(), \n",
    "        (condition_mask).sum().item(), \n",
    "        (condition_mask&correct_permutation_mask).sum().item()/(condition_mask).sum().item())\n",
    "    # msp prediction\n",
    "    print((~condition_mask&correct_permutation_mask).sum().item(), \n",
    "         (~condition_mask).sum().item(), \n",
    "        (~condition_mask&correct_permutation_mask).sum().item()/(~condition_mask).sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126\n"
     ]
    }
   ],
   "source": [
    "target_id_list_msp = idx_list[~condition_mask&correct_msp_mask&~correct_init_mask]\n",
    "print(len(target_id_list_msp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294\n"
     ]
    }
   ],
   "source": [
    "target_id_list_init = idx_list[~condition_mask&correct_init_mask&~correct_msp_mask]\n",
    "print(len(target_id_list_init))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Threshold: 0.5****************************\n",
      "Init\n",
      "7457 7941 0.9390504974184611\n",
      "5780 7099 0.8141991829835188\n",
      "MSP\n",
      "7386 7941 0.9301095579901776\n",
      "3820 7099 0.5381039583039865\n",
      "MSP & Init\n",
      "7368\n",
      "7475 7941 0.9413172144566175\n",
      "6002 7099 0.8454711931257923\n",
      "Permutation\n",
      "7740 7941 0.9746883264072534\n",
      "6684 7099 0.9415410621214255\n",
      "*********************Threshold: 0.8****************************\n",
      "Init\n",
      "6701 7091 0.9450007051191651\n",
      "6536 7949 0.8222417914203044\n",
      "MSP\n",
      "6654 7091 0.9383725849668594\n",
      "4552 7949 0.5726506478802366\n",
      "MSP & Init\n",
      "6648\n",
      "6707 7091 0.9458468481173319\n",
      "6770 7949 0.8516794565354132\n",
      "Permutation\n",
      "6922 7091 0.9761669722183048\n",
      "7502 7949 0.9437665115108819\n",
      "*********************Threshold: 0.9****************************\n",
      "Init\n",
      "6209 6547 0.9483733007484344\n",
      "7028 8493 0.8275050041210409\n",
      "MSP\n",
      "6170 6547 0.9424163739117153\n",
      "5036 8493 0.5929589073354528\n",
      "MSP & Init\n",
      "6167\n",
      "6212 6547 0.9488315258897205\n",
      "7265 8493 0.8554103379253503\n",
      "Permutation\n",
      "6392 6547 0.9763250343668856\n",
      "8032 8493 0.945720004709761\n",
      "*********************Threshold: 0.99****************************\n",
      "Init\n",
      "4732 4941 0.9577008702691763\n",
      "8505 10099 0.8421625903554807\n",
      "MSP\n",
      "4721 4941 0.9554746002833434\n",
      "6485 10099 0.6421427864144965\n",
      "MSP & Init\n",
      "4721\n",
      "4732 4941 0.9577008702691763\n",
      "8745 10099 0.8659273195365877\n",
      "Permutation\n",
      "4832 4941 0.977939688322202\n",
      "9592 10099 0.9497970096049114\n"
     ]
    }
   ],
   "source": [
    "# weighted, only uncertain init\n",
    "\n",
    "for threshold in [0.5, 0.8, 0.9, 0.99]:\n",
    "    uncertain_init_mask = ood_score_init_list < threshold\n",
    "    uncertain_target_mask = ood_score_target_list < threshold\n",
    "    condition_mask = (init_target_mask&(~uncertain_init_mask & ~uncertain_target_mask))\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    print(\"Init\")\n",
    "    # init prediction\n",
    "    print((condition_mask&correct_init_mask).sum().item(), \n",
    "        (condition_mask).sum().item(), \n",
    "        (condition_mask&correct_init_mask).sum().item()/(condition_mask).sum().item())\n",
    "    # init prediction\n",
    "    print((~condition_mask&correct_init_mask).sum().item(), \n",
    "        (~condition_mask).sum().item(), \n",
    "       (~condition_mask&correct_init_mask).sum().item()/(~condition_mask).sum().item())\n",
    "    print(\"MSP\")\n",
    "    # msp prediction\n",
    "    print((condition_mask&correct_msp_mask).sum().item(), \n",
    "        (condition_mask).sum().item(), \n",
    "        (condition_mask&correct_msp_mask).sum().item()/(condition_mask).sum().item())\n",
    "    # msp prediction\n",
    "    print((~condition_mask&correct_msp_mask).sum().item(), \n",
    "        (~condition_mask).sum().item(), \n",
    "        (~condition_mask&correct_msp_mask).sum().item()/(~condition_mask).sum().item())\n",
    "    print(\"MSP & Init\")\n",
    "    print(((condition_mask&correct_init_mask)&(condition_mask&correct_msp_mask)).sum().item())\n",
    "    # print(((~(init_target_mask&(~uncertain_init_mask & ~uncertain_target_mask))& correct_msp_mask)&(~(init_target_mask&(~uncertain_init_mask & ~uncertain_target_mask))& correct_init_mask)).sum().item())\n",
    "    print(((condition_mask&correct_init_mask)|(condition_mask&correct_msp_mask)).sum().item(),\n",
    "          (condition_mask).sum().item(), \n",
    "          ((condition_mask&correct_init_mask)|(condition_mask&correct_msp_mask)).sum().item()/(condition_mask).sum().item())\n",
    "    print(((~condition_mask&correct_init_mask)|(~condition_mask&correct_msp_mask)).sum().item(),\n",
    "          (~condition_mask).sum().item(), \n",
    "          ((~condition_mask&correct_init_mask)|(~condition_mask&correct_msp_mask)).sum().item()/(~condition_mask).sum().item())\n",
    "    print(\"Permutation\")\n",
    "    print((condition_mask&correct_permutation_mask).sum().item(), \n",
    "        (condition_mask).sum().item(), \n",
    "        (condition_mask&correct_permutation_mask).sum().item()/(condition_mask).sum().item())\n",
    "    # msp prediction\n",
    "    print((~condition_mask&correct_permutation_mask).sum().item(), \n",
    "         (~condition_mask).sum().item(), \n",
    "        (~condition_mask&correct_permutation_mask).sum().item()/(~condition_mask).sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Threshold: 0.99****************************\n",
      "Init\n",
      "11984 12610 0.9503568596352101\n",
      "1253 2430 0.5156378600823045\n",
      "MSP\n",
      "10066 12610 0.7982553528945282\n",
      "709 2430 0.2917695473251029\n",
      "MSP & Init\n",
      "10019\n",
      "12031 12610 0.9540840602696273\n",
      "Permutation\n",
      "11864 12610 0.9408406026962728\n",
      "1569 2430 0.645679012345679\n",
      "*********************Threshold: 0.999****************************\n",
      "Init\n",
      "8374 8533 0.9813664596273292\n",
      "4863 6507 0.7473490087597972\n",
      "MSP\n",
      "7629 8533 0.8940583616547522\n",
      "3146 6507 0.483479329952359\n",
      "MSP & Init\n",
      "7625\n",
      "8378 8533 0.9818352279385913\n",
      "Permutation\n",
      "8317 8533 0.9746865111918435\n",
      "5116 6507 0.7862302136161057\n"
     ]
    }
   ],
   "source": [
    "# weighted, only uncertain init\n",
    "\n",
    "for threshold in [0.99, 0.999]:\n",
    "    uncertain_init_mask = ood_score_init_list < threshold\n",
    "    uncertain_target_mask = ood_score_target_list < threshold\n",
    "    condition_mask = ~uncertain_init_mask\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    print(\"Init\")\n",
    "    # init prediction\n",
    "    print((condition_mask&correct_init_mask).sum().item(), \n",
    "        (condition_mask).sum().item(), \n",
    "        (condition_mask&correct_init_mask).sum().item()/(condition_mask).sum().item())\n",
    "    # init prediction\n",
    "    print((~condition_mask&correct_init_mask).sum().item(), \n",
    "        (~condition_mask).sum().item(), \n",
    "       (~condition_mask&correct_init_mask).sum().item()/(~condition_mask).sum().item())\n",
    "    print(\"MSP\")\n",
    "    # msp prediction\n",
    "    print((condition_mask&correct_msp_mask).sum().item(), \n",
    "        (condition_mask).sum().item(), \n",
    "        (condition_mask&correct_msp_mask).sum().item()/(condition_mask).sum().item())\n",
    "    # msp prediction\n",
    "    print((~condition_mask&correct_msp_mask).sum().item(), \n",
    "        (~condition_mask).sum().item(), \n",
    "        (~condition_mask&correct_msp_mask).sum().item()/(~condition_mask).sum().item())\n",
    "    print(\"MSP & Init\")\n",
    "    print(((condition_mask&correct_init_mask)&(condition_mask&correct_msp_mask)).sum().item())\n",
    "    # print(((~(init_target_mask&(~uncertain_init_mask & ~uncertain_target_mask))& correct_msp_mask)&(~(init_target_mask&(~uncertain_init_mask & ~uncertain_target_mask))& correct_init_mask)).sum().item())\n",
    "    print(((condition_mask&correct_init_mask)|(condition_mask&correct_msp_mask)).sum().item(),\n",
    "          (condition_mask).sum().item(), \n",
    "          ((condition_mask&correct_init_mask)|(condition_mask&correct_msp_mask)).sum().item()/(condition_mask).sum().item())\n",
    "    print(\"Permutation\")\n",
    "    print((condition_mask&correct_permutation_mask).sum().item(), \n",
    "        (condition_mask).sum().item(), \n",
    "        (condition_mask&correct_permutation_mask).sum().item()/(condition_mask).sum().item())\n",
    "    # msp prediction\n",
    "    print((~condition_mask&correct_permutation_mask).sum().item(), \n",
    "         (~condition_mask).sum().item(), \n",
    "        (~condition_mask&correct_permutation_mask).sum().item()/(~condition_mask).sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   62,   111,   157,   178,   520,   544,   676,   681,   740,   776,\n",
       "          790,   874,   945,  1099,  1154,  1185,  1237,  1281,  1309,  1360,\n",
       "         1378,  2244,  2270,  2395,  2416,  2577,  2781,  2906,  2916,  3282,\n",
       "         3631,  3655,  3674,  3706,  3783,  3817,  4070,  4161,  4269,  4361,\n",
       "         4424,  4555,  4608,  4698,  4739,  4900,  4974,  4998,  5584,  5617,\n",
       "         5795,  5937,  6017,  6184,  6222,  6493,  6885,  7166,  7243,  7313,\n",
       "         7353,  7451,  8032,  8220,  8280,  8542,  8598,  8698,  8832,  8972,\n",
       "         9087,  9286,  9692,  9743,  9772, 10176, 10196, 10327, 10335, 10541,\n",
       "        10669, 10688, 10697, 10698, 10703, 10727, 10772, 10829, 10892, 10997,\n",
       "        11336, 11374, 11418, 11431, 11575, 11618, 11690, 11759, 11815, 11866,\n",
       "        11965, 11970, 12038, 12039, 12246, 12267, 12446, 12458, 12500, 12666,\n",
       "        12770, 12847, 13372, 13436, 13491, 13534, 13623, 13982, 14235, 14249,\n",
       "        14322, 14406, 14732, 14764, 14901, 14917])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_id_list_msp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   36,   103,   154,   198,   250,   291,   306,   318,   339,   372,\n",
       "          411,   416,   521,   539,   558,   616,   628,   650,   659,   703,\n",
       "          812,   824,   947,  1113,  1126,  1297,  1322,  1358,  1439,  1479,\n",
       "         1736,  1908,  2010,  2040,  2147,  2176,  2215,  2276,  2291,  2327,\n",
       "         2332,  2477,  2507,  2509,  2620,  2831,  2936,  3092,  3098,  3119,\n",
       "         3155,  3191,  3203,  3283,  3357,  3391,  3499,  3549,  3563,  3581,\n",
       "         3614,  3645,  3656,  3703,  3716,  3760,  3803,  3900,  3906,  3913,\n",
       "         3918,  3977,  3981,  3994,  4045,  4054,  4078,  4121,  4173,  4188,\n",
       "         4202,  4206,  4216,  4252,  4260,  4319,  4358,  4379,  4380,  4425,\n",
       "         4458,  4463,  4470,  4474,  4520,  4523,  4528,  4539,  4597,  4622,\n",
       "         4641,  4647,  4680,  4685,  4720,  4733,  4768,  4771,  4859,  4874,\n",
       "         5007,  5034,  5075,  5097,  5116,  5268,  5477,  5496,  5507,  5657,\n",
       "         5680,  5941,  5946,  5950,  5958,  6228,  6408,  6484,  6643,  6857,\n",
       "         6921,  6947,  6962,  6986,  6997,  7004,  7024,  7095,  7147,  7196,\n",
       "         7206,  7223,  7237,  7248,  7258,  7293,  7332,  7336,  7373,  7407,\n",
       "         7444,  7449,  7456,  7462,  7463,  7489,  7519,  7580,  7582,  7691,\n",
       "         7707,  7748,  7768,  7850,  7859,  7897,  7905,  8071,  8088,  8098,\n",
       "         8184,  8296,  8424,  8797,  8806,  9068,  9114,  9167,  9176,  9224,\n",
       "         9320,  9393,  9404,  9454,  9517,  9546,  9567,  9610,  9673,  9696,\n",
       "         9706,  9767,  9790,  9858,  9932, 10026, 10125, 10179, 10200, 10205,\n",
       "        10219, 10257, 10282, 10292, 10391, 10494, 10518, 10520, 10528, 10531,\n",
       "        10544, 10564, 10584, 10664, 10705, 10717, 10819, 10893, 10910, 11065,\n",
       "        11105, 11270, 11360, 11380, 11385, 11390, 11391, 11401, 11424, 11447,\n",
       "        11453, 11455, 11459, 11463, 11464, 11497, 11650, 11651, 11686, 11716,\n",
       "        11742, 11776, 11794, 11937, 11987, 12023, 12034, 12036, 12055, 12128,\n",
       "        12137, 12162, 12196, 12252, 12256, 12258, 12259, 12262, 12276, 12386,\n",
       "        12421, 12432, 12460, 12470, 12581, 12660, 12711, 12785, 12800, 12810,\n",
       "        13299, 13430, 13692, 13743, 13801, 13961, 14201, 14267, 14395, 14440,\n",
       "        14506, 14575, 14589, 14613, 14711, 14843, 14856, 14864, 14870, 14910,\n",
       "        14957, 14973, 15003, 15032])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_id_list_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_permutation(x):\n",
    "    new = []\n",
    "    for k in x.tolist()[0]:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "[1, 2, 3, 0, 4, 5] 0.8812775015830994 22\n",
      "********************************************************\n",
      "(0,) 0.6231377720832825 22\n",
      "(1,) 0.9957733154296875 70\n",
      "(2,) 0.5916683077812195 15\n",
      "(3,) 0.9956215620040894 36\n",
      "(4,) 0.24058352410793304 52\n",
      "(5,) 0.8036993145942688 21\n",
      "(0, 1) 0.623483419418335 21\n",
      "(1, 0) 0.7788912653923035 21\n",
      "(0, 2) 0.8990749716758728 21\n",
      "(2, 0) 0.8319035172462463 21\n",
      "(0, 3) 0.7897941470146179 22\n",
      "(3, 0) 0.5998058319091797 22\n",
      "(0, 4) 0.5257799029350281 21\n",
      "(4, 0) 0.4978789985179901 22\n",
      "(0, 5) 0.8483963012695312 22\n",
      "(5, 0) 0.8151366710662842 21\n",
      "(1, 2) 0.9215726256370544 70\n",
      "(2, 1) 0.7245780825614929 15\n",
      "(1, 3) 0.9854430556297302 10\n",
      "(3, 1) 0.9996833801269531 36\n",
      "(1, 4) 0.9965258836746216 70\n",
      "(4, 1) 0.7776814103126526 23\n",
      "(1, 5) 0.9462572336196899 25\n",
      "(5, 1) 0.9986319541931152 21\n",
      "(2, 3) 0.525371789932251 11\n",
      "(3, 2) 0.9990768432617188 36\n",
      "(2, 4) 0.9957641959190369 15\n",
      "(4, 2) 0.3540210723876953 90\n",
      "(2, 5) 0.9965428709983826 15\n",
      "(5, 2) 0.9775940179824829 21\n",
      "(3, 4) 0.9981549978256226 36\n",
      "(4, 3) 0.9545211791992188 23\n",
      "(3, 5) 0.9995652437210083 36\n",
      "(5, 3) 0.8654304146766663 21\n",
      "(4, 5) 0.7254802584648132 22\n",
      "(5, 4) 0.9651039242744446 21\n",
      "(0, 1, 2) 0.8521706461906433 21\n",
      "(0, 2, 1) 0.31712806224823 21\n",
      "(1, 0, 2) 0.5163378715515137 21\n",
      "(1, 2, 0) 0.8167496919631958 21\n",
      "(2, 0, 1) 0.5898533463478088 85\n",
      "(2, 1, 0) 0.6469727158546448 21\n",
      "(0, 1, 3) 0.47779932618141174 22\n",
      "(0, 3, 1) 0.6742392778396606 22\n",
      "(1, 0, 3) 0.5640438795089722 22\n",
      "(1, 3, 0) 0.680184006690979 22\n",
      "(3, 0, 1) 0.6555355787277222 21\n",
      "(3, 1, 0) 0.5330227613449097 22\n",
      "(0, 1, 4) 0.7077590823173523 21\n",
      "(0, 4, 1) 0.7931420207023621 21\n",
      "(1, 0, 4) 0.6062927842140198 21\n",
      "(1, 4, 0) 0.6641509532928467 22\n",
      "(4, 0, 1) 0.9502133727073669 21\n",
      "(4, 1, 0) 0.794995903968811 21\n",
      "(0, 1, 5) 0.8073763251304626 21\n",
      "(0, 5, 1) 0.8252884745597839 22\n",
      "(1, 0, 5) 0.4985255300998688 21\n",
      "(1, 5, 0) 0.7539069056510925 22\n",
      "(5, 0, 1) 0.8739128112792969 21\n",
      "(5, 1, 0) 0.705287516117096 21\n",
      "(0, 2, 3) 0.7289807200431824 21\n",
      "(0, 3, 2) 0.6143319606781006 21\n",
      "(2, 0, 3) 0.6341006755828857 22\n",
      "(2, 3, 0) 0.7437969446182251 22\n",
      "(3, 0, 2) 0.49086058139801025 22\n",
      "(3, 2, 0) 0.5430687069892883 21\n",
      "(0, 2, 4) 0.8500897288322449 21\n",
      "(0, 4, 2) 0.926241934299469 21\n",
      "(2, 0, 4) 0.8912362456321716 21\n",
      "(2, 4, 0) 0.47849464416503906 21\n",
      "(4, 0, 2) 0.566292405128479 21\n",
      "(4, 2, 0) 0.9102399349212646 21\n",
      "(0, 2, 5) 0.7732349038124084 21\n",
      "(0, 5, 2) 0.5370839238166809 21\n",
      "(2, 0, 5) 0.690322995185852 21\n",
      "(2, 5, 0) 0.8000416159629822 22\n",
      "(5, 0, 2) 0.9818845391273499 21\n",
      "(5, 2, 0) 0.7732245922088623 21\n",
      "(0, 3, 4) 0.6719536185264587 22\n",
      "(0, 4, 3) 0.6373788118362427 22\n",
      "(3, 0, 4) 0.5808832049369812 22\n",
      "(3, 4, 0) 0.8275600671768188 22\n",
      "(4, 0, 3) 0.9675399661064148 22\n",
      "(4, 3, 0) 0.8880635499954224 22\n",
      "(0, 3, 5) 0.936516284942627 22\n",
      "(0, 5, 3) 0.9617098569869995 22\n",
      "(3, 0, 5) 0.9056289196014404 22\n",
      "(3, 5, 0) 0.8873873949050903 22\n",
      "(5, 0, 3) 0.9184826612472534 22\n",
      "(5, 3, 0) 0.8660963177680969 22\n",
      "(0, 4, 5) 0.8750492930412292 22\n",
      "(0, 5, 4) 0.9121107459068298 22\n",
      "(4, 0, 5) 0.5429823994636536 22\n",
      "(4, 5, 0) 0.9434357285499573 21\n",
      "(5, 0, 4) 0.9059708118438721 21\n",
      "(5, 4, 0) 0.9006255865097046 22\n",
      "(1, 2, 3) 0.997596800327301 10\n",
      "(1, 3, 2) 0.9990562200546265 10\n",
      "(2, 1, 3) 0.9936754107475281 15\n",
      "(2, 3, 1) 0.8890881538391113 15\n",
      "(3, 1, 2) 0.9996163845062256 36\n",
      "(3, 2, 1) 0.9995563626289368 36\n",
      "(1, 2, 4) 0.7700409293174744 70\n",
      "(1, 4, 2) 0.4663763642311096 70\n",
      "(2, 1, 4) 0.9553652405738831 15\n",
      "(2, 4, 1) 0.8995310068130493 15\n",
      "(4, 1, 2) 0.4296773672103882 70\n",
      "(4, 2, 1) 0.7216250896453857 60\n",
      "(1, 2, 5) 0.8523590564727783 25\n",
      "(1, 5, 2) 0.766772449016571 25\n",
      "(2, 1, 5) 0.991267740726471 15\n",
      "(2, 5, 1) 0.9957684278488159 15\n",
      "(5, 1, 2) 0.99821537733078 21\n",
      "(5, 2, 1) 0.9969750046730042 21\n",
      "(1, 3, 4) 0.9958842396736145 10\n",
      "(1, 4, 3) 0.9929420351982117 10\n",
      "(3, 1, 4) 0.9996914267539978 36\n",
      "(3, 4, 1) 0.9996904730796814 36\n",
      "(4, 1, 3) 0.9794312119483948 23\n",
      "(4, 3, 1) 0.9663736820220947 36\n",
      "(1, 3, 5) 0.9985412955284119 10\n",
      "(1, 5, 3) 0.9963921308517456 10\n",
      "(3, 1, 5) 0.999679684638977 36\n",
      "(3, 5, 1) 0.9996742606163025 36\n",
      "(5, 1, 3) 0.9984769225120544 21\n",
      "(5, 3, 1) 0.997428834438324 21\n",
      "(1, 4, 5) 0.6356540322303772 24\n",
      "(1, 5, 4) 0.6900884509086609 25\n",
      "(4, 1, 5) 0.7327120900154114 22\n",
      "(4, 5, 1) 0.875889241695404 21\n",
      "(5, 1, 4) 0.9985678195953369 21\n",
      "(5, 4, 1) 0.998716413974762 21\n",
      "(2, 3, 4) 0.8242821097373962 15\n",
      "(2, 4, 3) 0.9663170576095581 15\n",
      "(3, 2, 4) 0.9991130828857422 36\n",
      "(3, 4, 2) 0.9993121027946472 36\n",
      "(4, 2, 3) 0.5026529431343079 10\n",
      "(4, 3, 2) 0.6877405047416687 10\n",
      "(2, 3, 5) 0.9694510102272034 15\n",
      "(2, 5, 3) 0.9971737265586853 15\n",
      "(3, 2, 5) 0.9995561838150024 36\n",
      "(3, 5, 2) 0.9995781183242798 36\n",
      "(5, 2, 3) 0.9521227478981018 21\n",
      "(5, 3, 2) 0.9536160826683044 21\n",
      "(2, 4, 5) 0.9977224469184875 15\n",
      "(2, 5, 4) 0.9982863068580627 15\n",
      "(4, 2, 5) 0.3070194125175476 30\n",
      "(4, 5, 2) 0.4443338215351105 22\n",
      "(5, 2, 4) 0.9857251644134521 21\n",
      "(5, 4, 2) 0.9915456771850586 21\n",
      "(3, 4, 5) 0.9995956420898438 36\n",
      "(3, 5, 4) 0.9994972944259644 36\n",
      "(4, 3, 5) 0.9967085719108582 36\n",
      "(4, 5, 3) 0.4260094165802002 22\n",
      "(5, 3, 4) 0.9406554698944092 21\n",
      "(5, 4, 3) 0.9363822937011719 21\n",
      "********************************************************\n",
      "(5, 0, 2) 0.9818845391273499 21\n"
     ]
    }
   ],
   "source": [
    "# use target as head, the MSP context\n",
    "import itertools\n",
    "  \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "log = defaultdict(list)\n",
    "num_cols = []\n",
    "threshold = 0.8\n",
    "corrected = 0\n",
    "total_mistakes = 0\n",
    "init_permutation = defaultdict(list)\n",
    "corrected_permutation = defaultdict(list)\n",
    "init_logits = defaultdict(list)\n",
    "corrected_logits = defaultdict(list)\n",
    "\n",
    "alpha = 1.0\n",
    "class_weights = (1.0 / class_freq) ** alpha\n",
    "\n",
    "# Normalize the weights\n",
    "class_weights /= class_weights.sum()\n",
    "\n",
    "for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "    if batch_idx == 103:\n",
    "        break\n",
    "cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "target_col_mask = batch[\"target_col_mask\"].T\n",
    "logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,).detach().cpu()\n",
    "logits = reweight_logits(logits, class_weights)\n",
    "logits_init = logits.clone()\n",
    "num_cols.append(batch[\"target_col_mask\"].max().item())\n",
    "# if batch_idx == 355:\n",
    "\n",
    "\n",
    "# print(\"****weighted****************\")\n",
    "col_idx_set = target_col_mask.unique().tolist()\n",
    "successs = False\n",
    "init_permutation[batch_idx].append(get_permutation(target_col_mask))\n",
    "init_logits[batch_idx].append(logits_init.detach().cpu())     \n",
    "init_msp = logits_init.max().item()\n",
    "print(batch[\"label\"].item())\n",
    "print(get_permutation(target_col_mask), init_msp, init_logits[batch_idx][0].argmax().item())   \n",
    "print(\"********************************************************\")\n",
    "assert -1 not in col_idx_set\n",
    "max_msp = 0 \n",
    "for r in range(1, min(len(col_idx_set) + 1, context_length+1)):\n",
    "    for subset in itertools.combinations(col_idx_set, r):\n",
    "        # if 0 not in subset:\n",
    "        #     continue\n",
    "        for x in itertools.permutations(subset):\n",
    "            new_batch_data = []\n",
    "            for col_i in x:\n",
    "                if col_i == 0:\n",
    "                    if len(new_batch_data) == 0:\n",
    "                        cls_indexes_value = 0\n",
    "                    else:\n",
    "                        cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "            if 0 not in x:\n",
    "                cls_indexes_value = 0\n",
    "            new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "            cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "            logits_temp = model(new_batch_data, cls_indexes=cls_indexes,).detach().cpu()\n",
    "            # print(\"****origin****************\")\n",
    "            # msp_temp = F.softmax(logits_temp).max().item()\n",
    "            # predict_temp = F.softmax(logits_temp).argmax().item()\n",
    "            # print(x, F.softmax(logits_temp).max(), F.softmax(logits_temp).argmax())\n",
    "            # print(\"****weighted****************\")\n",
    "            logits_temp = reweight_logits(logits_temp, class_weights)\n",
    "            msp_temp = logits_temp.max().item()\n",
    "            predict_temp = logits_temp.argmax().item()\n",
    "            print(x, msp_temp, predict_temp)\n",
    "            if msp_temp > max_msp and 0 in x:\n",
    "                max_msp = msp_temp\n",
    "                best_msp_perm = x\n",
    "                msp_predict = predict_temp\n",
    "print(\"********************************************************\")\n",
    "print(best_msp_perm, max_msp, msp_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Threshold: 0.9****************************\n",
      "MSP\n",
      "10871 13845 0.7851932105453232\n",
      "335 1195 0.2803347280334728\n",
      "*********************MSP Threshold: 0.8****************************\n",
      "0 335 0.0\n",
      "335 335 1.0\n",
      "335 1193 0.2808046940486169\n",
      "0 2 0.0\n",
      "*********************MSP Threshold: 0.9****************************\n",
      "4 335 0.011940298507462687\n",
      "331 335 0.9880597014925373\n",
      "331 1145 0.28908296943231443\n",
      "4 50 0.08\n",
      "*********************MSP Threshold: 0.99****************************\n",
      "33 335 0.09850746268656717\n",
      "302 335 0.9014925373134328\n",
      "302 1029 0.293488824101069\n",
      "33 166 0.19879518072289157\n",
      "*********************MSP Threshold: 0.999****************************\n",
      "158 335 0.4716417910447761\n",
      "177 335 0.5283582089552239\n",
      "177 595 0.29747899159663865\n",
      "158 600 0.2633333333333333\n"
     ]
    }
   ],
   "source": [
    "for threshold in [0.9]:\n",
    "    # uncertain_init_mask = ood_score_init_list < threshold\n",
    "    # uncertain_target_mask = ood_score_target_list < threshold\n",
    "    # condition_mask = (init_target_mask&(~uncertain_init_mask & ~uncertain_target_mask))\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    print(\"MSP\")\n",
    "    # msp prediction\n",
    "    print((condition_mask&correct_msp_mask).sum().item(), \n",
    "        (condition_mask).sum().item(), \n",
    "        (condition_mask&correct_msp_mask).sum().item()/(condition_mask).sum().item())\n",
    "    # msp prediction\n",
    "    print((~condition_mask&correct_msp_mask).sum().item(), \n",
    "        (~condition_mask).sum().item(), \n",
    "        (~condition_mask&correct_msp_mask).sum().item()/(~condition_mask).sum().item())\n",
    "    for msp_threshold in [0.8, 0.9, 0.99, 0.999]:\n",
    "        print(f\"*********************MSP Threshold: {msp_threshold}****************************\")\n",
    "        msp_uncertain_mask = ood_score_final_list < msp_threshold\n",
    "        sub_condition = ~condition_mask&correct_msp_mask\n",
    "        # msp prediction\n",
    "        print((sub_condition&msp_uncertain_mask).sum().item(), \n",
    "            (sub_condition).sum().item(), \n",
    "            (sub_condition&msp_uncertain_mask).sum().item()/(sub_condition).sum().item())\n",
    "        print((sub_condition&~msp_uncertain_mask).sum().item(), \n",
    "            (sub_condition).sum().item(), \n",
    "            (sub_condition&~msp_uncertain_mask).sum().item()/(sub_condition).sum().item())\n",
    "        \n",
    "        print((~condition_mask&~msp_uncertain_mask&correct_msp_mask).sum().item(), \n",
    "            (~condition_mask&~msp_uncertain_mask).sum().item(), \n",
    "            (~condition_mask&~msp_uncertain_mask&correct_msp_mask).sum().item()/(~condition_mask&~msp_uncertain_mask).sum().item())\n",
    "        \n",
    "        print((~condition_mask&msp_uncertain_mask&correct_msp_mask).sum().item(), \n",
    "            (~condition_mask&msp_uncertain_mask).sum().item(), \n",
    "            (~condition_mask&msp_uncertain_mask&correct_msp_mask).sum().item()/(~condition_mask&msp_uncertain_mask).sum().item())\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
