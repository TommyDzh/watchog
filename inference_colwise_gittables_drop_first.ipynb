{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "from time import time\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from collections import defaultdict\n",
    "\n",
    "# import pytrec_eval\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss, BCEWithLogitsLoss\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, BertConfig, AutoTokenizer\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from accelerate import Accelerator\n",
    "from copy import deepcopy\n",
    "\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "from watchog.dataset import (\n",
    "    # collate_fn,\n",
    "    TURLColTypeTablewiseDataset,\n",
    "    TURLRelExtTablewiseDataset,\n",
    "    SatoCVTablewiseDataset,\n",
    "    ColPoplTablewiseDataset\n",
    ")\n",
    "\n",
    "from watchog.dataset import TableDataset, SupCLTableDataset, SemtableCVTablewiseDataset, GittablesColwiseDataset, GittablesTablewiseDataset\n",
    "from watchog.model import BertMultiPairPooler, BertForMultiOutputClassification, BertForMultiOutputClassificationColPopl, Verifier\n",
    "from watchog.model import SupCLforTable, UnsupCLforTable, lm_mp\n",
    "from watchog.utils import load_checkpoint, f1_score_multilabel, collate_fn, get_col_pred, ColPoplEvaluator\n",
    "from watchog.utils import task_num_class_dict\n",
    "from accelerate import DistributedDataParallelKwargs\n",
    "import wandb\n",
    "\n",
    "from argparse import Namespace\n",
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import re\n",
    "import transformers\n",
    "from torch.utils import data\n",
    "from torch.nn.utils import rnn\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from typing import List\n",
    "from functools import reduce\n",
    "import operator\n",
    "\n",
    "from itertools import chain\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args={\"wandb\": false, \"model\": \"Watchog\", \"unlabeled_train_only\": false, \"context_encoding_type\": \"v0\", \"pool_version\": \"v0.2\", \"random_sample\": false, \"comment\": \"debug\", \"shortcut_name\": \"bert-base-uncased\", \"max_length\": 64, \"adaptive_max_length\": false, \"max_num_col\": 8, \"batch_size\": 3, \"epoch\": 1, \"random_seed\": 4649, \"train_n_seed_cols\": -1, \"num_classes\": 101, \"multi_gpu\": false, \"fp16\": false, \"warmup\": 0.0, \"lr\": 5e-05, \"task\": \"gt-semtab22-dbpedia-all0\", \"colpair\": false, \"metadata\": false, \"from_scratch\": false, \"cl_tag\": \"wikitables/simclr/bert_100000_10_32_256_5e-05_sample_row4,sample_row4_tfidf_entity_column_0.05_0_last.pt\", \"dropout_prob\": 0.5, \"eval_test\": true, \"small_tag\": \"semi1\", \"data_path\": \"/data/zhihao/TU/\", \"pretrained_ckpt_path\": \"/data/zhihao/TU/Watchog/model/\"}\n",
      "gt-semtab22-dbpedia-all0/wikitables-simclr-bert_100000_10_32_256_5e-05_sample_row4,sample_row4_tfidf_entity_column_0.05_0_last.pt_bert-base-uncased-poolsemi1-max_colsv0.2-rand8-bsFalse-ml3-ne64-do10.5\n",
      "Namespace(augment_op='sample_row4,sample_row4', batch_size=32, data_path='/data/zhihao/TU/TURL/', fp16=True, gpus='0', lm='bert', logdir='/data/zhihao/TU/Watchog/model/', lr=5e-05, max_len=256, mode='simclr', model='Watchog', n_epochs=10, pretrain_data='wikitables', pretrained_model_path='', projector=768, run_id=0, sample_meth='tfidf_entity', save_model=10, single_column=False, size=100000, table_order='column', temperature=0.05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "    device = torch.device(2)\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--wandb\", type=bool, default=False)\n",
    "    parser.add_argument(\"--model\", type=str, default=\"Watchog\")\n",
    "    parser.add_argument(\"--unlabeled_train_only\", type=bool, default=False)\n",
    "    parser.add_argument(\"--context_encoding_type\", type=str, default=\"v0\")\n",
    "    parser.add_argument(\"--pool_version\", type=str, default=\"v0.2\")\n",
    "    parser.add_argument(\"--random_sample\", type=bool, default=False)\n",
    "    parser.add_argument(\"--comment\", type=str, default=\"debug\", help=\"to distinguish the runs\")\n",
    "    parser.add_argument(\n",
    "        \"--shortcut_name\",\n",
    "        default=\"bert-base-uncased\",\n",
    "        type=str,\n",
    "        help=\"Huggingface model shortcut name \",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--max_length\",\n",
    "        default=64,\n",
    "        type=int,\n",
    "        help=\n",
    "        \"The maximum total input sequence length after tokenization. Sequences longer \"\n",
    "        \"than this will be truncated, sequences shorter will be padded.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--adaptive_max_length\",\n",
    "        default=False,\n",
    "        type=bool,\n",
    "    )    \n",
    "    parser.add_argument(\n",
    "        \"--max_num_col\",\n",
    "        default=8,\n",
    "        type=int,\n",
    "    )   \n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--batch_size\",\n",
    "        default=3,\n",
    "        type=int,\n",
    "        help=\"Batch size\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--epoch\",\n",
    "        default=1,\n",
    "        type=int,\n",
    "        help=\"Number of epochs for training\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--random_seed\",\n",
    "        default=4649,\n",
    "        type=int,\n",
    "        help=\"Random seed\",\n",
    "    )\n",
    "    \n",
    "    parser.add_argument(\n",
    "        \"--train_n_seed_cols\",\n",
    "        default=-1,\n",
    "        type=int,\n",
    "        help=\"number of seeding columns in training\",\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--num_classes\",\n",
    "        default=78,\n",
    "        type=int,\n",
    "        help=\"Number of classes\",\n",
    "    )\n",
    "    parser.add_argument(\"--multi_gpu\",\n",
    "                        action=\"store_true\",\n",
    "                        default=False,\n",
    "                        help=\"Use multiple GPU\")\n",
    "    parser.add_argument(\"--fp16\",\n",
    "                        action=\"store_true\",\n",
    "                        default=False,\n",
    "                        help=\"Use FP16\")\n",
    "    parser.add_argument(\"--warmup\",\n",
    "                        type=float,\n",
    "                        default=0.,\n",
    "                        help=\"Warmup ratio\")\n",
    "    parser.add_argument(\"--lr\", type=float, default=5e-5, help=\"Learning rate\")\n",
    "    parser.add_argument(\"--task\",\n",
    "                        type=str,\n",
    "                        default='gt-semtab22-dbpedia-all0',\n",
    "                        choices=[\n",
    "                            \"sato0\", \"sato1\", \"sato2\", \"sato3\", \"sato4\",\n",
    "                            \"msato0\", \"msato1\", \"msato2\", \"msato3\", \"msato4\",\n",
    "                            \"gt-dbpedia0\", \"gt-dbpedia1\", \"gt-dbpedia2\", \"gt-dbpedia3\", \"gt-dbpedia4\",\n",
    "                            \"gt-dbpedia-all0\", \"gt-dbpedia-all1\", \"gt-dbpedia-all2\", \"gt-dbpedia-all3\", \"gt-dbpedia-all4\",\n",
    "                            \"gt-schema-all0\", \"gt-schema-all1\", \"gt-schema-all2\", \"gt-schema-all3\", \"gt-schema-all4\",\n",
    "                            \"gt-semtab22-dbpedia\", \"gt-semtab22-dbpedia0\", \"gt-semtab22-dbpedia1\", \"gt-semtab22-dbpedia2\", \"gt-semtab22-dbpedia3\", \"gt-semtab22-dbpedia4\",\n",
    "                            \"gt-semtab22-dbpedia-all\", \"gt-semtab22-dbpedia-all0\", \"gt-semtab22-dbpedia-all1\", \"gt-semtab22-dbpedia-all2\", \"gt-semtab22-dbpedia-all3\", \"gt-semtab22-dbpedia-all4\",\n",
    "                            \"gt-semtab22-schema-class-all\", \"gt-semtab22-schema-property-all\",\n",
    "                            \"turl\", \"turl-re\", \"col-popl-1\", \"col-popl-2\", \"col-popl-3\", \"row-popl\",\n",
    "                            \"col-popl-turl-0\", \"col-popl-turl-1\", \"col-popl-turl-2\",\n",
    "                            \"col-popl-turl-mdonly-0\", \"col-popl-turl-mdonly-1\", \"col-popl-turl-mdonly-2\"\n",
    "                        ],\n",
    "                        help=\"Task names}\")\n",
    "    parser.add_argument(\"--colpair\",\n",
    "                        action=\"store_true\",\n",
    "                        help=\"Use column pair embedding\")\n",
    "    parser.add_argument(\"--metadata\",\n",
    "                        action=\"store_true\",\n",
    "                        help=\"Use column header metadata\")\n",
    "    parser.add_argument(\"--from_scratch\",\n",
    "                        action=\"store_true\",\n",
    "                        help=\"Training from scratch\")\n",
    "    parser.add_argument(\"--cl_tag\",\n",
    "                        type=str,\n",
    "                        default=\"wikitables/simclr/bert_100000_10_32_256_5e-05_sample_row4,sample_row4_tfidf_entity_column_0.05_0_last.pt\",\n",
    "                        help=\"path to the pre-trained file\")\n",
    "    parser.add_argument(\"--dropout_prob\",\n",
    "                        type=float,\n",
    "                        default=0.5)\n",
    "    parser.add_argument(\"--eval_test\",\n",
    "                        action=\"store_true\",\n",
    "                        help=\"evaluate on testset and do not save the model file\")\n",
    "    parser.add_argument(\"--small_tag\",\n",
    "                        type=str,\n",
    "                        default=\"semi1\",\n",
    "                        help=\"e.g., by_table_t5_v1\")\n",
    "    parser.add_argument(\"--data_path\",\n",
    "                        type=str,\n",
    "                        default=\"/data/zhihao/TU/\")\n",
    "    parser.add_argument(\"--pretrained_ckpt_path\",\n",
    "                        type=str,\n",
    "                        default=\"/data/zhihao/TU/Watchog/model/\")    \n",
    "\n",
    "    args = parser.parse_args([])\n",
    "    task = args.task\n",
    "    if args.small_tag != \"\":\n",
    "        args.eval_test = True\n",
    "    \n",
    "    args.num_classes = task_num_class_dict[task]\n",
    "    if args.colpair:\n",
    "        assert \"turl-re\" == task, \"colpair can be only used for Relation Extraction\"\n",
    "    if args.metadata:\n",
    "        assert \"turl-re\" == task or \"turl\" == task, \"metadata can be only used for TURL datasets\"\n",
    "    if \"col-popl\":\n",
    "        # metrics = {\n",
    "        #     \"accuracy\": CategoricalAccuracy(tie_break=True),\n",
    "        # }\n",
    "        if args.train_n_seed_cols != -1:\n",
    "            if \"col-popl\" in task:\n",
    "                assert args.train_n_seed_cols == int(task[-1]),  \"# of seed columns must match\"\n",
    "\n",
    "    print(\"args={}\".format(json.dumps(vars(args))))\n",
    "\n",
    "    max_length = args.max_length\n",
    "    batch_size = args.batch_size\n",
    "    num_train_epochs = args.epoch\n",
    "\n",
    "    shortcut_name = args.shortcut_name\n",
    "\n",
    "    if args.colpair and args.metadata:\n",
    "        taskname = \"{}-colpair-metadata\".format(task)\n",
    "    elif args.colpair:\n",
    "        taskname = \"{}-colpair\".format(task)\n",
    "    elif args.metadata:\n",
    "        taskname = \"{}-metadata\".format(task)\n",
    "    elif args.train_n_seed_cols == -1 and 'popl' in task:\n",
    "        taskname = \"{}-mix\".format(task)\n",
    "    else:\n",
    "        taskname = \"\".join(task)\n",
    "    cv = int(task[-1])\n",
    "\n",
    "    if args.from_scratch:\n",
    "        if \"gt\" in task:\n",
    "            tag_name = \"{}/{}-{}-{}-pool{}-max_cols{}-rand{}-bs{}-ml{}-ne{}-do{}{}\".format(\n",
    "                taskname,  \"{}-fromscratch\".format(shortcut_name), args.small_tag, args.comment, args.pool_version, args.max_num_col, args.random_sample,\n",
    "                batch_size, max_length, num_train_epochs, args.dropout_prob, \n",
    "                '-rs{}'.format(args.random_seed) if args.random_seed != 4649 else '')\n",
    "        else:\n",
    "            tag_name = \"{}/{}-{}-{}-bs{}-ml{}-ne{}-do{}{}\".format(\n",
    "                taskname,  \"{}-fromscratch\".format(shortcut_name), args.small_tag, args.comment, \n",
    "                batch_size, max_length, num_train_epochs, args.dropout_prob, \n",
    "                '-rs{}'.format(args.random_seed) if args.random_seed != 4649 else '')\n",
    "        \n",
    "    else:\n",
    "        if \"gt\" in task:\n",
    "            tag_name = \"{}/{}_{}-pool{}-max_cols{}-rand{}-bs{}-ml{}-ne{}-do{}{}\".format(\n",
    "                taskname, args.cl_tag.replace('/', '-'),  shortcut_name, args.small_tag, args.pool_version, args.max_num_col, args.random_sample,\n",
    "                batch_size, max_length, num_train_epochs, args.dropout_prob,\n",
    "                '-rs{}'.format(args.random_seed) if args.random_seed != 4649 else '')\n",
    "        else:\n",
    "            tag_name = \"{}/{}_{}-{}-bs{}-ml{}-ne{}-do{}{}\".format(\n",
    "                taskname, args.cl_tag.replace('/', '-'),  shortcut_name, args.small_tag,\n",
    "                batch_size, max_length, num_train_epochs, args.dropout_prob,\n",
    "                '-rs{}'.format(args.random_seed) if args.random_seed != 4649 else '')\n",
    "\n",
    "    # if args.eval_test:\n",
    "    #     if args.small_tag != '':\n",
    "    #         tag_name = tag_name.replace('outputs', 'small_outputs')\n",
    "    #         tag_name += '-' + args.small_tag\n",
    "    print(tag_name)\n",
    "    file_path = os.path.join(args.data_path, \"Watchog\", \"outputs\", tag_name)\n",
    "\n",
    "    dirpath = os.path.dirname(file_path)\n",
    "    if not os.path.exists(dirpath):\n",
    "        print(\"{} not exists. Created\".format(dirpath))\n",
    "        os.makedirs(dirpath)\n",
    "    \n",
    "    if args.fp16:\n",
    "        torch.backends.cuda.matmul.allow_fp16_reduced_precision_reduction = True\n",
    "        \n",
    "      \n",
    "        \n",
    "    # accelerator = Accelerator(mixed_precision=\"no\" if not args.fp16 else \"fp16\")   \n",
    "    ddp_kwargs = DistributedDataParallelKwargs(find_unused_parameters=True)\n",
    "    accelerator = Accelerator(mixed_precision=\"no\" if not args.fp16 else \"fp16\", kwargs_handlers=[ddp_kwargs])\n",
    "\n",
    "    device = torch.device(0)\n",
    "    ckpt_path = os.path.join(args.pretrained_ckpt_path, args.cl_tag)\n",
    "    # ckpt_path = '/efs/checkpoints/{}.pt'.format(args.cl_tag)\n",
    "    ckpt = torch.load(ckpt_path, map_location=device)\n",
    "    ckpt_hp = ckpt['hp']\n",
    "    print(ckpt_hp)\n",
    " \n",
    "    setattr(ckpt_hp, 'batch_size', args.batch_size)\n",
    "    setattr(ckpt_hp, 'hidden_dropout_prob', args.dropout_prob)\n",
    "    setattr(ckpt_hp, 'shortcut_name', args.shortcut_name)\n",
    "    setattr(ckpt_hp, 'num_labels', args.num_classes)\n",
    "    \n",
    "    \n",
    "    \n",
    "    tokenizer = BertTokenizer.from_pretrained(shortcut_name)\n",
    "    padder = collate_fn(tokenizer.pad_token_id)\n",
    "    if task == \"turl-re\" and args.colpair:\n",
    "        model = BertForMultiOutputClassification(ckpt_hp, device=device, lm=ckpt['hp'].lm, col_pair='Pair')\n",
    "    elif \"col-popl\" in task:\n",
    "        model = BertForMultiOutputClassificationColPopl(ckpt_hp, device=device, lm=ckpt['hp'].lm, n_seed_cols=int(task[i][-1]), cls_for_md=\"md\" in task)\n",
    "    else:\n",
    "        model = BertForMultiOutputClassification(ckpt_hp, device=device, lm=ckpt['hp'].lm, version=\"v0\", use_attention_mask=True)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best_state_dict = torch.load(\"/data/zhihao/TU/Watchog/outputs/gt-semtab22-dbpedia-all0/bert-base-uncased-fromscratch-semi1-AttnMask-max-unlabeled@8-poolv0-unlabeled8-randFalse-bs16-ml128-ne50-do0.1_best_f1_micro.pt\", map_location=device)\n",
    "best_state_dict = torch.load(\"/data/zhihao/TU/Watchog/outputs/gt-semtab22-dbpedia-all0/bert-base-uncased-fromscratch-semi1-Repeat@5-AttnMask-UnlabelValid-max-unlabeled@8-poolv0-unlabeled8-randFalse-bs16-ml128-ne50-do0.1_best_f1_macro.pt\", map_location=device)\n",
    "model.load_state_dict(best_state_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join(\"/data/zhihao/TU/GitTables/semtab_gittables/2022\",\"semi_cv_{}.csv\".format(0))\n",
    "df = pd.read_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = []\n",
    "for i in range(5):\n",
    "    if i == cv:\n",
    "        continue\n",
    "    filepath = os.path.join(\"/data/zhihao/TU/GitTables/semtab_gittables/2022\",\"semi_cv_{}.csv\".format(i))\n",
    "    df_train.append(pd.read_csv(filepath))\n",
    "df_train = pd.concat(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "    if len(group_df) >= 8 and len(group_df[group_df['class_id'] > -1]) >=4:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_column(values):\n",
    "    \"\"\"\n",
    "    Classify column values into one of three types:\n",
    "    1. All Characters: All values are alphabetic.\n",
    "    2. Both Characters and Numerics: At least one value contains both letters and numbers.\n",
    "    3. All Numerics: All values are numeric (integers or floats).\n",
    "\n",
    "    Args:\n",
    "        values (list): List of column values (as strings).\n",
    "    \n",
    "    Returns:\n",
    "        str: Classification of the column ('All Characters', 'Both Characters and Numerics', 'All Numerics').\n",
    "    \"\"\"\n",
    "    if type(values) != list:\n",
    "        raise ValueError(\"Invalid input type\")\n",
    "    importance = 0\n",
    "    all_characters = True\n",
    "    all_numerics = True\n",
    "    mixed = False\n",
    "    for value in values:\n",
    "        # Strip any whitespace around the value\n",
    "        value = value.replace(' ', '')\n",
    "        if value.replace('-', '', 1).replace('.', '', 1).isdigit():\n",
    "            all_characters = False\n",
    "        if value.isalpha():\n",
    "            all_numerics = False\n",
    "    if all_characters and all_numerics:\n",
    "        all_characters = False\n",
    "        all_numerics = False\n",
    "    if not all_characters and not all_numerics:\n",
    "        mixed = True\n",
    "    if all_characters:\n",
    "        importance += 200\n",
    "    elif mixed:\n",
    "        importance += 100\n",
    "    elif all_numerics:\n",
    "        importance += 0\n",
    "    else:\n",
    "        raise ValueError(\"Invalid column values\")\n",
    "    unique_values = set(values) \n",
    "    importance += min(99, len(unique_values))\n",
    "    \n",
    "\n",
    "    return importance\n",
    "\n",
    "# Example usage:\n",
    "values1 = [\"state id\"]\n",
    "values2 = [\"0.0\", \"0.0\", \"0.0\", \"-10.0\"]\n",
    "values3 = [\"1997-1-1\"]\n",
    "values4 = [\"2020\", \"123\", \"abc\"]\n",
    "\n",
    "print(classify_column(values1))  # Output: Both Characters and Numerics\n",
    "print(classify_column(values2))  # Output: All Numerics\n",
    "print(classify_column(values3))  # Output: Both Characters and Numerics\n",
    "print(classify_column(values4))  # Output: Both Characters and Numerics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_scores = group_df[\"data\"].apply(lambda x: classify_column(x.split(';'))).tolist(\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df[\"class_id\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels_raw = []\n",
    "for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "    group_df.sort_values(by=['col_idx'], inplace=True)\n",
    "    all_labels_raw.append(torch.tensor(group_df[\"class_id\"].values))\n",
    "all_labels_raw = torch.cat(all_labels_raw)\n",
    "all_labels_raw = all_labels_raw[all_labels_raw > -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_labels_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.equal(all_labels_raw, labels_test_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GittablesTablewiseLabelLastDataset(data.Dataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            cv: int,\n",
    "            split: str,\n",
    "            src: str,  # train or test\n",
    "            tokenizer: AutoTokenizer,\n",
    "            max_length: int = 256,\n",
    "            gt_only: bool = False,\n",
    "            device: torch.device = None,\n",
    "            base_dirpath: str = \"/data/zhihao/TU/GitTables/semtab_gittables/2022\",\n",
    "            base_tag: str = '', # blank, comma\n",
    "            small_tag: str = \"\",\n",
    "            train_ratio: float = 1.0,\n",
    "            max_unlabeled=8,\n",
    "            adaptive_max_length=True,\n",
    "            random_sample=False, # TODO\n",
    "            train_only=False,\n",
    "            seed=0): # TODO\n",
    "        if device is None:\n",
    "            device = torch.device('cpu')\n",
    "        basename = small_tag+ \"_cv_{}.csv\"\n",
    "    \n",
    "        if split in [\"train\", \"valid\"]:\n",
    "            df_list = []\n",
    "            for i in range(5):\n",
    "                if i == cv:\n",
    "                    continue\n",
    "                filepath = os.path.join(base_dirpath, basename.format(i))\n",
    "                df_list.append(pd.read_csv(filepath))\n",
    "                print(split, i)\n",
    "            df = pd.concat(df_list, axis=0)\n",
    "        else:\n",
    "            # test\n",
    "            filepath = os.path.join(base_dirpath, basename.format(cv))\n",
    "            df = pd.read_csv(filepath)\n",
    "            print(split)\n",
    "\n",
    "\n",
    "        if gt_only:\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "        if train_only and split != \"train\":\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "\n",
    "        \n",
    "        data_list = []\n",
    "        \n",
    "        df['class_id'] = df['class_id'].astype(int)\n",
    "        df.drop(df[(df['data'].isna()) & (df['class_id'] == -1)].index, inplace=True)\n",
    "        df['col_idx'] = df['col_idx'].astype(int)\n",
    "        df['data'] = df['data'].astype(str)\n",
    "        \n",
    "        num_tables = len(df.groupby(\"table_id\"))\n",
    "        valid_index = int(num_tables * 0.8)\n",
    "        num_train = int(train_ratio * num_tables * 0.8)        \n",
    "        \n",
    "        # df.drop(df[(df['data'] == '') & (df['class_id'] == -1)].index, inplace=True)\n",
    "        total_num_cols = 0\n",
    "        for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "            if (split == \"train\") and ((i >= num_train) or (i >= valid_index)):\n",
    "                break\n",
    "            if split == \"valid\" and i < valid_index:\n",
    "                continue\n",
    "            #     break\n",
    "            num_cols = len(group_df)\n",
    "            group_df.sort_values(by=['col_idx'], inplace=True)\n",
    "            labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "            unlabeled_columns = group_df[group_df['class_id'] == -1]\n",
    "            num_unlabeled = min(max(max_unlabeled-len(labeled_columns), 0), len(unlabeled_columns)) if max_unlabeled > 0 else len(unlabeled_columns)\n",
    "            unlabeled_columns = unlabeled_columns.tail(num_unlabeled)\n",
    "            # group_df = pd.concat([group_df[group_df['class_id'] > -1], unlabeled_columns.sample(min(10-len(labeled_columns), len(unlabeled_columns)))])\n",
    "            # group_df = pd.concat([group_df[group_df['class_id'] > -1], unlabeled_columns[0:min(max(10-len(labeled_columns), 0), len(unlabeled_columns))]])\n",
    "            group_df = pd.concat([group_df[group_df['class_id'] > -1], unlabeled_columns]) \n",
    "            group_df.sort_values(by=['col_idx'], inplace=True) # TODO \n",
    "            col_idx_list = group_df[\"col_idx\"].values\n",
    "            \n",
    "            if max_length <= 128 and adaptive_max_length:\n",
    "                cur_maxlen = min(max_length, 512 // len(target_table) - 1)\n",
    "            else:\n",
    "                cur_maxlen = max_length\n",
    "                \n",
    "            token_ids_list = group_df[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=cur_maxlen, truncation=True)).tolist(\n",
    "                )\n",
    "            token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                                token_ids_list)).to(device)\n",
    "            for col_i in range(len(token_ids_list)):\n",
    "                if group_df[\"class_id\"].values[col_i] == -1:\n",
    "                    continue\n",
    "                target_col_mask = []\n",
    "                cls_index_value = 0\n",
    "                context_id = 1\n",
    "                for col_j in range(len(token_ids_list)):\n",
    "                    if col_j == col_i:\n",
    "                        target_col_mask += [0] * len(token_ids_list[col_j])\n",
    "                    else:\n",
    "                        target_col_mask += [context_id] * len(token_ids_list[col_j])\n",
    "                        context_id += 1\n",
    "                    if col_j < col_i:\n",
    "                        cls_index_value += len(token_ids_list[col_j])\n",
    "                cls_index_list = [cls_index_value] \n",
    "                for cls_index in cls_index_list:\n",
    "                    assert token_ids[\n",
    "                        cls_index] == tokenizer.cls_token_id, \"cls_indexes validation\"\n",
    "                cls_indexes = torch.LongTensor(cls_index_list).to(device)\n",
    "                class_ids = torch.LongTensor(\n",
    "                    [group_df[\"class_id\"].values[col_i]]).to(device)\n",
    "                target_col_mask = torch.LongTensor(target_col_mask).to(device)\n",
    "                data_list.append(\n",
    "                    [index,\n",
    "                    len(group_df), token_ids, class_ids, cls_indexes, target_col_mask, num_cols, col_idx_list])                \n",
    "        print(split, len(data_list))\n",
    "        self.table_df = pd.DataFrame(data_list,\n",
    "                                     columns=[\n",
    "                                         \"table_id\", \"num_col\", \"data_tensor\",\n",
    "                                         \"label_tensor\", \"cls_indexes\", \"target_col_mask\", \"initial_num_col\", \"col_idx_list\"\n",
    "                                     ])\n",
    "        \"\"\"\n",
    "        # NOTE: msato contains a small portion of single-col tables. keep it to be consistent.  \n",
    "        if multicol_only:\n",
    "            # Check\n",
    "            num_all_tables = len(self.table_df)\n",
    "            self.table_df = self.table_df[self.table_df[\"num_col\"] > 1]\n",
    "            assert len(self.table_df) == num_all_tables\n",
    "        \"\"\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.table_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"data\": self.table_df.iloc[idx][\"data_tensor\"],\n",
    "            \"label\": self.table_df.iloc[idx][\"label_tensor\"],\n",
    "            \"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"],\n",
    "            \"target_col_mask\": self.table_df.iloc[idx][\"target_col_mask\"],\n",
    "            \"initial_num_col\": self.table_df.iloc[idx][\"initial_num_col\"],\n",
    "            \"col_idx_list\": self.table_df.iloc[idx][\"col_idx_list\"],\n",
    "        }\n",
    "        #\"idx\": torch.LongTensor([idx])}\n",
    "        #\"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GittablesTablewiseLabelFirstDataset(data.Dataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            cv: int,\n",
    "            split: str,\n",
    "            src: str,  # train or test\n",
    "            tokenizer: AutoTokenizer,\n",
    "            max_length: int = 256,\n",
    "            gt_only: bool = False,\n",
    "            device: torch.device = None,\n",
    "            base_dirpath: str = \"/data/zhihao/TU/GitTables/semtab_gittables/2022\",\n",
    "            base_tag: str = '', # blank, comma\n",
    "            small_tag: str = \"\",\n",
    "            train_ratio: float = 1.0,\n",
    "            max_unlabeled=8,\n",
    "            adaptive_max_length=True,\n",
    "            random_sample=False, # TODO\n",
    "            train_only=False,\n",
    "            seed=0): # TODO\n",
    "        if device is None:\n",
    "            device = torch.device('cpu')\n",
    "        basename = small_tag+ \"_cv_{}.csv\"\n",
    "    \n",
    "        if split in [\"train\", \"valid\"]:\n",
    "            df_list = []\n",
    "            for i in range(5):\n",
    "                if i == cv:\n",
    "                    continue\n",
    "                filepath = os.path.join(base_dirpath, basename.format(i))\n",
    "                df_list.append(pd.read_csv(filepath))\n",
    "                print(split, i)\n",
    "            df = pd.concat(df_list, axis=0)\n",
    "        else:\n",
    "            # test\n",
    "            filepath = os.path.join(base_dirpath, basename.format(cv))\n",
    "            df = pd.read_csv(filepath)\n",
    "            print(split)\n",
    "\n",
    "\n",
    "        if gt_only:\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "        if train_only and split != \"train\":\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "\n",
    "        \n",
    "        data_list = []\n",
    "        \n",
    "        df['class_id'] = df['class_id'].astype(int)\n",
    "        df.drop(df[(df['data'].isna()) & (df['class_id'] == -1)].index, inplace=True)\n",
    "        df['col_idx'] = df['col_idx'].astype(int)\n",
    "        df['data'] = df['data'].astype(str)\n",
    "        \n",
    "        num_tables = len(df.groupby(\"table_id\"))\n",
    "        valid_index = int(num_tables * 0.8)\n",
    "        num_train = int(train_ratio * num_tables * 0.8)        \n",
    "        \n",
    "        # df.drop(df[(df['data'] == '') & (df['class_id'] == -1)].index, inplace=True)\n",
    "        total_num_cols = 0\n",
    "        for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "            if (split == \"train\") and ((i >= num_train) or (i >= valid_index)):\n",
    "                break\n",
    "            if split == \"valid\" and i < valid_index:\n",
    "                continue\n",
    "            #     break\n",
    "            num_cols = len(group_df)\n",
    "            group_df.sort_values(by=['col_idx'], inplace=True)\n",
    "            labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "            unlabeled_columns = group_df[group_df['class_id'] == -1]\n",
    "            num_unlabeled = min(max(max_unlabeled-len(labeled_columns), 0), len(unlabeled_columns)) if max_unlabeled > 0 else len(unlabeled_columns)\n",
    "            unlabeled_columns = unlabeled_columns.head(num_unlabeled)\n",
    "            # group_df = pd.concat([group_df[group_df['class_id'] > -1], unlabeled_columns.sample(min(10-len(labeled_columns), len(unlabeled_columns)))])\n",
    "            # group_df = pd.concat([group_df[group_df['class_id'] > -1], unlabeled_columns[0:min(max(10-len(labeled_columns), 0), len(unlabeled_columns))]])\n",
    "            group_df = pd.concat([group_df[group_df['class_id'] > -1], unlabeled_columns]) \n",
    "            group_df.sort_values(by=['col_idx'], inplace=True) # TODO \n",
    "\n",
    "            if max_length <= 128 and adaptive_max_length:\n",
    "                cur_maxlen = min(max_length, 512 // len(target_table) - 1)\n",
    "            else:\n",
    "                cur_maxlen = max_length\n",
    "                \n",
    "            token_ids_list = group_df[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=cur_maxlen, truncation=True)).tolist(\n",
    "                )\n",
    "            token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                                token_ids_list)).to(device)\n",
    "            for col_i in range(len(token_ids_list)):\n",
    "                if group_df[\"class_id\"].values[col_i] == -1:\n",
    "                    continue\n",
    "                target_col_mask = []\n",
    "                cls_index_value = 0\n",
    "                context_id = 1\n",
    "                for col_j in range(len(token_ids_list)):\n",
    "                    if col_j == col_i:\n",
    "                        target_col_mask += [0] * len(token_ids_list[col_j])\n",
    "                    else:\n",
    "                        target_col_mask += [context_id] * len(token_ids_list[col_j])\n",
    "                        context_id += 1\n",
    "                    if col_j < col_i:\n",
    "                        cls_index_value += len(token_ids_list[col_j])\n",
    "                cls_index_list = [cls_index_value] \n",
    "                for cls_index in cls_index_list:\n",
    "                    assert token_ids[\n",
    "                        cls_index] == tokenizer.cls_token_id, \"cls_indexes validation\"\n",
    "                cls_indexes = torch.LongTensor(cls_index_list).to(device)\n",
    "                class_ids = torch.LongTensor(\n",
    "                    [group_df[\"class_id\"].values[col_i]]).to(device)\n",
    "                target_col_mask = torch.LongTensor(target_col_mask).to(device)\n",
    "                data_list.append(\n",
    "                    [index,\n",
    "                    len(group_df), token_ids, class_ids, cls_indexes, target_col_mask, num_cols])                \n",
    "        print(split, len(data_list))\n",
    "        self.table_df = pd.DataFrame(data_list,\n",
    "                                     columns=[\n",
    "                                         \"table_id\", \"num_col\", \"data_tensor\",\n",
    "                                         \"label_tensor\", \"cls_indexes\", \"target_col_mask\", \"initial_num_col\"\n",
    "                                     ])\n",
    "        \"\"\"\n",
    "        # NOTE: msato contains a small portion of single-col tables. keep it to be consistent.  \n",
    "        if multicol_only:\n",
    "            # Check\n",
    "            num_all_tables = len(self.table_df)\n",
    "            self.table_df = self.table_df[self.table_df[\"num_col\"] > 1]\n",
    "            assert len(self.table_df) == num_all_tables\n",
    "        \"\"\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.table_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"data\": self.table_df.iloc[idx][\"data_tensor\"],\n",
    "            \"label\": self.table_df.iloc[idx][\"label_tensor\"],\n",
    "            \"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"],\n",
    "            \"target_col_mask\": self.table_df.iloc[idx][\"target_col_mask\"],\n",
    "            \"initial_num_col\": self.table_df.iloc[idx][\"initial_num_col\"],\n",
    "        }\n",
    "        #\"idx\": torch.LongTensor([idx])}\n",
    "        #\"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GittablesTablewiseRandomDataset(data.Dataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            cv: int,\n",
    "            split: str,\n",
    "            src: str,  # train or test\n",
    "            tokenizer: AutoTokenizer,\n",
    "            max_length: int = 256,\n",
    "            gt_only: bool = False,\n",
    "            device: torch.device = None,\n",
    "            base_dirpath: str = \"/data/zhihao/TU/GitTables/semtab_gittables/2022\",\n",
    "            base_tag: str = '', # blank, comma\n",
    "            small_tag: str = \"\",\n",
    "            train_ratio: float = 1.0,\n",
    "            max_unlabeled=8,\n",
    "            adaptive_max_length=True,\n",
    "            random_sample=False, # TODO\n",
    "            train_only=False,\n",
    "            seed=0): # TODO\n",
    "        if device is None:\n",
    "            device = torch.device('cpu')\n",
    "        basename = small_tag+ \"_cv_{}.csv\"\n",
    "    \n",
    "        if split in [\"train\", \"valid\"]:\n",
    "            df_list = []\n",
    "            for i in range(5):\n",
    "                if i == cv:\n",
    "                    continue\n",
    "                filepath = os.path.join(base_dirpath, basename.format(i))\n",
    "                df_list.append(pd.read_csv(filepath))\n",
    "                print(split, i)\n",
    "            df = pd.concat(df_list, axis=0)\n",
    "        else:\n",
    "            # test\n",
    "            filepath = os.path.join(base_dirpath, basename.format(cv))\n",
    "            df = pd.read_csv(filepath)\n",
    "            print(split)\n",
    "\n",
    "\n",
    "        if gt_only:\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "        if train_only and split != \"train\":\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "\n",
    "        \n",
    "        data_list = []\n",
    "        \n",
    "        df['class_id'] = df['class_id'].astype(int)\n",
    "        df.drop(df[(df['data'].isna()) & (df['class_id'] == -1)].index, inplace=True)\n",
    "        df['col_idx'] = df['col_idx'].astype(int)\n",
    "        df['data'] = df['data'].astype(str)\n",
    "        \n",
    "        num_tables = len(df.groupby(\"table_id\"))\n",
    "        valid_index = int(num_tables * 0.8)\n",
    "        num_train = int(train_ratio * num_tables * 0.8)        \n",
    "        \n",
    "        # df.drop(df[(df['data'] == '') & (df['class_id'] == -1)].index, inplace=True)\n",
    "        total_num_cols = 0\n",
    "        for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "            if (split == \"train\") and ((i >= num_train) or (i >= valid_index)):\n",
    "                break\n",
    "            if split == \"valid\" and i < valid_index:\n",
    "                continue\n",
    "            #     break\n",
    "            labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "            for index, target_column in labeled_columns.iterrows():\n",
    "                target_col_idx = target_column[\"col_idx\"]\n",
    "                \n",
    "                other_columns = group_df.drop(index).sample(min(max_unlabeled, len(group_df))-1, random_state=seed)\n",
    "                \n",
    "\n",
    "                target_table = pd.concat([target_column.to_frame().T, other_columns], ignore_index=True)\n",
    "\n",
    "                # other_columns['distance'] = abs(other_columns['col_idx'] - target_col_idx)\n",
    "                # other_columns.sort_values(by='distance', inplace=True)\n",
    "                # nearby_columns = other_columns.head(max_unlabeled-1)\n",
    "                # target_table = pd.concat([target_column.to_frame().T, nearby_columns], ignore_index=True)\n",
    "                \n",
    "                \n",
    "                target_cls = target_column[\"class_id\"]\n",
    "                target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "                col_idx_list = target_table[\"col_idx\"].tolist()\n",
    "\n",
    "                if max_length <= 128 and adaptive_max_length:\n",
    "                    cur_maxlen = min(max_length, 512 // len(target_table) - 1)\n",
    "                else:\n",
    "                    cur_maxlen = max_length\n",
    "                    \n",
    "                token_ids_list = target_table[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                    tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=cur_maxlen, truncation=True)).tolist(\n",
    "                    )\n",
    "                token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                                    token_ids_list)).to(device)\n",
    "\n",
    "                target_col_mask = []\n",
    "                cls_index_value = 0\n",
    "                context_id = 1\n",
    "                meet_target = False\n",
    "                for idx, col_i in enumerate(col_idx_list):\n",
    "                    if col_i == target_col_idx:\n",
    "                        target_col_mask += [0] * len(token_ids_list[idx])\n",
    "                        meet_target = True\n",
    "                    else:\n",
    "                        target_col_mask += [context_id] * len(token_ids_list[idx])\n",
    "                        context_id += 1\n",
    "                    if not meet_target:\n",
    "                        cls_index_value += len(token_ids_list[idx])\n",
    "                cls_index_list = [cls_index_value] \n",
    "                for cls_index in cls_index_list:\n",
    "                    assert token_ids[\n",
    "                        cls_index] == tokenizer.cls_token_id, \"cls_indexes validation\"\n",
    "                cls_indexes = torch.LongTensor(cls_index_list).to(device)\n",
    "                class_ids = torch.LongTensor(\n",
    "                    [target_cls]).to(device)\n",
    "                target_col_mask = torch.LongTensor(target_col_mask).to(device)\n",
    "                data_list.append(\n",
    "                    [index,\n",
    "                    len(target_table), token_ids, class_ids, cls_indexes, target_col_mask, len(group_df)])         \n",
    "        print(split, len(data_list))\n",
    "        self.table_df = pd.DataFrame(data_list,\n",
    "                                     columns=[\n",
    "                                         \"table_id\", \"num_col\", \"data_tensor\",\n",
    "                                         \"label_tensor\", \"cls_indexes\", \"target_col_mask\", \"initial_num_col\"\n",
    "                                     ])\n",
    "        \"\"\"\n",
    "        # NOTE: msato contains a small portion of single-col tables. keep it to be consistent.  \n",
    "        if multicol_only:\n",
    "            # Check\n",
    "            num_all_tables = len(self.table_df)\n",
    "            self.table_df = self.table_df[self.table_df[\"num_col\"] > 1]\n",
    "            assert len(self.table_df) == num_all_tables\n",
    "        \"\"\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.table_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"data\": self.table_df.iloc[idx][\"data_tensor\"],\n",
    "            \"label\": self.table_df.iloc[idx][\"label_tensor\"],\n",
    "            \"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"],\n",
    "            \"target_col_mask\": self.table_df.iloc[idx][\"target_col_mask\"],\n",
    "            \"initial_num_col\": self.table_df.iloc[idx][\"initial_num_col\"],\n",
    "        }\n",
    "        #\"idx\": torch.LongTensor([idx])}\n",
    "        #\"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GittablesTablewiseLabelRandomDataset(data.Dataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            cv: int,\n",
    "            split: str,\n",
    "            src: str,  # train or test\n",
    "            tokenizer: AutoTokenizer,\n",
    "            max_length: int = 256,\n",
    "            gt_only: bool = False,\n",
    "            device: torch.device = None,\n",
    "            base_dirpath: str = \"/data/zhihao/TU/GitTables/semtab_gittables/2022\",\n",
    "            base_tag: str = '', # blank, comma\n",
    "            small_tag: str = \"\",\n",
    "            train_ratio: float = 1.0,\n",
    "            max_unlabeled=8,\n",
    "            adaptive_max_length=True,\n",
    "            random_sample=False, # TODO\n",
    "            train_only=False,\n",
    "            seed=0): # TODO\n",
    "        if device is None:\n",
    "            device = torch.device('cpu')\n",
    "        basename = small_tag+ \"_cv_{}.csv\"\n",
    "    \n",
    "        if split in [\"train\", \"valid\"]:\n",
    "            df_list = []\n",
    "            for i in range(5):\n",
    "                if i == cv:\n",
    "                    continue\n",
    "                filepath = os.path.join(base_dirpath, basename.format(i))\n",
    "                df_list.append(pd.read_csv(filepath))\n",
    "                print(split, i)\n",
    "            df = pd.concat(df_list, axis=0)\n",
    "        else:\n",
    "            # test\n",
    "            filepath = os.path.join(base_dirpath, basename.format(cv))\n",
    "            df = pd.read_csv(filepath)\n",
    "            print(split)\n",
    "\n",
    "\n",
    "        if gt_only:\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "        if train_only and split != \"train\":\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "\n",
    "        \n",
    "        data_list = []\n",
    "        \n",
    "        df['class_id'] = df['class_id'].astype(int)\n",
    "        df.drop(df[(df['data'].isna()) & (df['class_id'] == -1)].index, inplace=True)\n",
    "        df['col_idx'] = df['col_idx'].astype(int)\n",
    "        df['data'] = df['data'].astype(str)\n",
    "        \n",
    "        num_tables = len(df.groupby(\"table_id\"))\n",
    "        valid_index = int(num_tables * 0.8)\n",
    "        num_train = int(train_ratio * num_tables * 0.8)        \n",
    "        \n",
    "        # df.drop(df[(df['data'] == '') & (df['class_id'] == -1)].index, inplace=True)\n",
    "        total_num_cols = 0\n",
    "        for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "            if (split == \"train\") and ((i >= num_train) or (i >= valid_index)):\n",
    "                break\n",
    "            if split == \"valid\" and i < valid_index:\n",
    "                continue\n",
    "            #     break\n",
    "            num_cols = len(group_df)\n",
    "            group_df.sort_values(by=['col_idx'], inplace=True)\n",
    "            labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "            unlabeled_columns = group_df[group_df['class_id'] == -1]\n",
    "            num_unlabeled = min(max(max_unlabeled-len(labeled_columns), 0), len(unlabeled_columns)) if max_unlabeled > 0 else len(unlabeled_columns)\n",
    "            unlabeled_columns = unlabeled_columns.sample(num_unlabeled, random_state=seed) \n",
    "            # group_df = pd.concat([group_df[group_df['class_id'] > -1], unlabeled_columns.sample(min(10-len(labeled_columns), len(unlabeled_columns)))])\n",
    "            # group_df = pd.concat([group_df[group_df['class_id'] > -1], unlabeled_columns[0:min(max(10-len(labeled_columns), 0), len(unlabeled_columns))]])\n",
    "            group_df = pd.concat([group_df[group_df['class_id'] > -1], unlabeled_columns]) \n",
    "            group_df.sort_values(by=['col_idx'], inplace=True) # TODO \n",
    "\n",
    "            if max_length <= 128 and adaptive_max_length:\n",
    "                cur_maxlen = min(max_length, 512 // len(target_table) - 1)\n",
    "            else:\n",
    "                cur_maxlen = max_length\n",
    "                \n",
    "            token_ids_list = group_df[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=cur_maxlen, truncation=True)).tolist(\n",
    "                )\n",
    "            token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                                token_ids_list)).to(device)\n",
    "            for col_i in range(len(token_ids_list)):\n",
    "                if group_df[\"class_id\"].values[col_i] == -1:\n",
    "                    continue\n",
    "                target_col_mask = []\n",
    "                cls_index_value = 0\n",
    "                context_id = 1\n",
    "                for col_j in range(len(token_ids_list)):\n",
    "                    if col_j == col_i:\n",
    "                        target_col_mask += [0] * len(token_ids_list[col_j])\n",
    "                    else:\n",
    "                        target_col_mask += [context_id] * len(token_ids_list[col_j])\n",
    "                        context_id += 1\n",
    "                    if col_j < col_i:\n",
    "                        cls_index_value += len(token_ids_list[col_j])\n",
    "                cls_index_list = [cls_index_value] \n",
    "                for cls_index in cls_index_list:\n",
    "                    assert token_ids[\n",
    "                        cls_index] == tokenizer.cls_token_id, \"cls_indexes validation\"\n",
    "                cls_indexes = torch.LongTensor(cls_index_list).to(device)\n",
    "                class_ids = torch.LongTensor(\n",
    "                    [group_df[\"class_id\"].values[col_i]]).to(device)\n",
    "                target_col_mask = torch.LongTensor(target_col_mask).to(device)\n",
    "                data_list.append(\n",
    "                    [index,\n",
    "                    len(group_df), token_ids, class_ids, cls_indexes, target_col_mask, num_cols])                \n",
    "        print(split, len(data_list))\n",
    "        self.table_df = pd.DataFrame(data_list,\n",
    "                                     columns=[\n",
    "                                         \"table_id\", \"num_col\", \"data_tensor\",\n",
    "                                         \"label_tensor\", \"cls_indexes\", \"target_col_mask\", \"initial_num_col\"\n",
    "                                     ])\n",
    "        \"\"\"\n",
    "        # NOTE: msato contains a small portion of single-col tables. keep it to be consistent.  \n",
    "        if multicol_only:\n",
    "            # Check\n",
    "            num_all_tables = len(self.table_df)\n",
    "            self.table_df = self.table_df[self.table_df[\"num_col\"] > 1]\n",
    "            assert len(self.table_df) == num_all_tables\n",
    "        \"\"\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.table_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"data\": self.table_df.iloc[idx][\"data_tensor\"],\n",
    "            \"label\": self.table_df.iloc[idx][\"label_tensor\"],\n",
    "            \"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"],\n",
    "            \"target_col_mask\": self.table_df.iloc[idx][\"target_col_mask\"],\n",
    "            \"initial_num_col\": self.table_df.iloc[idx][\"initial_num_col\"],\n",
    "        }\n",
    "        #\"idx\": torch.LongTensor([idx])}\n",
    "        #\"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GittablesTablewiseIterateRandomDataset(data.Dataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            cv: int,\n",
    "            split: str,\n",
    "            src: str,  # train or test\n",
    "            tokenizer: AutoTokenizer,\n",
    "            max_length: int = 256,\n",
    "            gt_only: bool = False,\n",
    "            device: torch.device = None,\n",
    "            base_dirpath: str = \"/data/zhihao/TU/GitTables/semtab_gittables/2022\",\n",
    "            base_tag: str = '', # blank, comma\n",
    "            small_tag: str = \"\",\n",
    "            train_ratio: float = 1.0,\n",
    "            max_unlabeled=8,\n",
    "            adaptive_max_length=True,\n",
    "            random_sample=False, # TODO\n",
    "            train_only=False): # TODO\n",
    "        if device is None:\n",
    "            device = torch.device('cpu')\n",
    "        basename = small_tag+ \"_cv_{}.csv\"\n",
    "    \n",
    "        if split in [\"train\", \"valid\"]:\n",
    "            df_list = []\n",
    "            for i in range(5):\n",
    "                if i == cv:\n",
    "                    continue\n",
    "                filepath = os.path.join(base_dirpath, basename.format(i))\n",
    "                df_list.append(pd.read_csv(filepath))\n",
    "                print(split, i)\n",
    "            df = pd.concat(df_list, axis=0)\n",
    "        else:\n",
    "            # test\n",
    "            filepath = os.path.join(base_dirpath, basename.format(cv))\n",
    "            df = pd.read_csv(filepath)\n",
    "            print(split)\n",
    "\n",
    "\n",
    "        if gt_only:\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "        if train_only and split != \"train\":\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "\n",
    "        \n",
    "        data_list = []\n",
    "        \n",
    "        df['class_id'] = df['class_id'].astype(int)\n",
    "        df.drop(df[(df['data'].isna()) & (df['class_id'] == -1)].index, inplace=True)\n",
    "        df['col_idx'] = df['col_idx'].astype(int)\n",
    "        df['data'] = df['data'].astype(str)\n",
    "        \n",
    "        num_tables = len(df.groupby(\"table_id\"))\n",
    "        valid_index = int(num_tables * 0.8)\n",
    "        num_train = int(train_ratio * num_tables * 0.8)        \n",
    "        \n",
    "        # df.drop(df[(df['data'] == '') & (df['class_id'] == -1)].index, inplace=True)\n",
    "        total_num_cols = 0\n",
    "        for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "            if (split == \"train\") and ((i >= num_train) or (i >= valid_index)):\n",
    "                break\n",
    "            if split == \"valid\" and i < valid_index:\n",
    "                continue\n",
    "            #     break\n",
    "            num_cols = len(group_df)\n",
    "            group_df.sort_values(by=['col_idx'], inplace=True)\n",
    "            labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "            unlabeled_columns = group_df[group_df['class_id'] == -1]\n",
    "            if len(group_df) <= max_unlabeled:\n",
    "                num_unlabeled = min(max(max_unlabeled-len(labeled_columns), 0), len(unlabeled_columns)) if max_unlabeled > 0 else len(unlabeled_columns)\n",
    "                unlabeled_columns = unlabeled_columns.sample(num_unlabeled) if random_sample else unlabeled_columns[0:num_unlabeled]\n",
    "                # group_df = pd.concat([group_df[group_df['class_id'] > -1], unlabeled_columns.sample(min(10-len(labeled_columns), len(unlabeled_columns)))])\n",
    "                # group_df = pd.concat([group_df[group_df['class_id'] > -1], unlabeled_columns[0:min(max(10-len(labeled_columns), 0), len(unlabeled_columns))]])\n",
    "                current_df = pd.concat([labeled_columns, unlabeled_columns]) \n",
    "                current_df.sort_values(by=['col_idx'], inplace=True) # TODO \n",
    "                if max_length <= 128 and adaptive_max_length:\n",
    "                    cur_maxlen = min(max_length, 512 // len(current_df) - 1)\n",
    "                else:\n",
    "                    cur_maxlen = max_length\n",
    "                    \n",
    "                token_ids_list = current_df[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                    tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=cur_maxlen, truncation=True)).tolist(\n",
    "                    )\n",
    "                token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                                    token_ids_list)).to(device)\n",
    "                for col_i in range(len(token_ids_list)):\n",
    "                    if group_df[\"class_id\"].values[col_i] == -1:\n",
    "                        continue\n",
    "                    target_col_mask = []\n",
    "                    cls_index_value = 0\n",
    "                    context_id = 1\n",
    "                    for col_j in range(len(token_ids_list)):\n",
    "                        if col_j == col_i:\n",
    "                            target_col_mask += [0] * len(token_ids_list[col_j])\n",
    "                        else:\n",
    "                            target_col_mask += [context_id] * len(token_ids_list[col_j])\n",
    "                            context_id += 1\n",
    "                        if col_j < col_i:\n",
    "                            cls_index_value += len(token_ids_list[col_j])\n",
    "                    cls_index_list = [cls_index_value] \n",
    "                    for cls_index in cls_index_list:\n",
    "                        assert token_ids[\n",
    "                            cls_index] == tokenizer.cls_token_id, \"cls_indexes validation\"\n",
    "                    cls_indexes = torch.LongTensor(cls_index_list).to(device)\n",
    "                    class_ids = torch.LongTensor(\n",
    "                        [group_df[\"class_id\"].values[col_i]]).to(device)\n",
    "                    target_col_mask = torch.LongTensor(target_col_mask).to(device)\n",
    "                    col_idx = group_df[\"col_idx\"].values\n",
    "                    data_list.append(\n",
    "                        [index,\n",
    "                        len(group_df), token_ids, class_ids, cls_indexes, target_col_mask, num_cols, col_idx])  \n",
    "            else:\n",
    "                num_cols_to_append = max_unlabeled-len(labeled_columns)\n",
    "                num_repeat = min(len(unlabeled_columns)//num_cols_to_append, 100) \n",
    "                rest_unlabeled_columns = unlabeled_columns\n",
    "                for repeat_i in range(num_repeat):\n",
    "                    columns_to_append = rest_unlabeled_columns.sample(num_cols_to_append)\n",
    "                    rest_unlabeled_columns = rest_unlabeled_columns.drop(columns_to_append.index)\n",
    "                    current_df = pd.concat([labeled_columns, columns_to_append]) \n",
    "                    current_df.sort_values(by=['col_idx'], inplace=True) # TODO \n",
    "                    if max_length <= 128 and adaptive_max_length:\n",
    "                        cur_maxlen = min(max_length, 512 // len(current_df) - 1)\n",
    "                    else:\n",
    "                        cur_maxlen = max_length\n",
    "                        \n",
    "                    token_ids_list = current_df[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                        tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=cur_maxlen, truncation=True)).tolist(\n",
    "                        )\n",
    "                    token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                                        token_ids_list)).to(device)\n",
    "                    for col_i in range(len(token_ids_list)):\n",
    "                        if group_df[\"class_id\"].values[col_i] == -1:\n",
    "                            continue\n",
    "                        target_col_mask = []\n",
    "                        cls_index_value = 0\n",
    "                        context_id = 1\n",
    "                        for col_j in range(len(token_ids_list)):\n",
    "                            if col_j == col_i:\n",
    "                                target_col_mask += [0] * len(token_ids_list[col_j])\n",
    "                            else:\n",
    "                                target_col_mask += [context_id] * len(token_ids_list[col_j])\n",
    "                                context_id += 1\n",
    "                            if col_j < col_i:\n",
    "                                cls_index_value += len(token_ids_list[col_j])\n",
    "                        cls_index_list = [cls_index_value] \n",
    "                        for cls_index in cls_index_list:\n",
    "                            assert token_ids[\n",
    "                                cls_index] == tokenizer.cls_token_id, \"cls_indexes validation\"\n",
    "                        cls_indexes = torch.LongTensor(cls_index_list).to(device)\n",
    "                        class_ids = torch.LongTensor(\n",
    "                            [group_df[\"class_id\"].values[col_i]]).to(device)\n",
    "                        target_col_mask = torch.LongTensor(target_col_mask).to(device)\n",
    "                        col_idx = group_df[\"col_idx\"].values\n",
    "                        data_list.append(\n",
    "                            [index,\n",
    "                            len(group_df), token_ids, class_ids, cls_indexes, target_col_mask, num_cols, col_idx])  \n",
    "                \n",
    "        print(split, len(data_list))\n",
    "        self.table_df = pd.DataFrame(data_list,\n",
    "                                     columns=[\n",
    "                                         \"table_id\", \"num_col\", \"data_tensor\",\n",
    "                                         \"label_tensor\", \"cls_indexes\", \"target_col_mask\", \"initial_num_col\", \"col_idx\"\n",
    "                                     ])\n",
    "        \"\"\"\n",
    "        # NOTE: msato contains a small portion of single-col tables. keep it to be consistent.  \n",
    "        if multicol_only:\n",
    "            # Check\n",
    "            num_all_tables = len(self.table_df)\n",
    "            self.table_df = self.table_df[self.table_df[\"num_col\"] > 1]\n",
    "            assert len(self.table_df) == num_all_tables\n",
    "        \"\"\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.table_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"data\": self.table_df.iloc[idx][\"data_tensor\"],\n",
    "            \"label\": self.table_df.iloc[idx][\"label_tensor\"],\n",
    "            \"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"],\n",
    "            \"target_col_mask\": self.table_df.iloc[idx][\"target_col_mask\"],\n",
    "            \"initial_num_col\": self.table_df.iloc[idx][\"initial_num_col\"],\n",
    "            \"col_idx\": self.table_df.iloc[idx][\"col_idx\"]\n",
    "        }\n",
    "        #\"idx\": torch.LongTensor([idx])}\n",
    "        #\"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GittablesTablewiseIterateDataset(data.Dataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            cv: int,\n",
    "            split: str,\n",
    "            src: str,  # train or test\n",
    "            tokenizer: AutoTokenizer,\n",
    "            max_length: int = 256,\n",
    "            gt_only: bool = False,\n",
    "            device: torch.device = None,\n",
    "            base_dirpath: str = \"/data/zhihao/TU/GitTables/semtab_gittables/2022\",\n",
    "            base_tag: str = '', # blank, comma\n",
    "            small_tag: str = \"\",\n",
    "            train_ratio: float = 1.0,\n",
    "            max_unlabeled=8,\n",
    "            adaptive_max_length=True,\n",
    "            random_sample=False, # TODO\n",
    "            train_only=False): # TODO\n",
    "        if device is None:\n",
    "            device = torch.device('cpu')\n",
    "        basename = small_tag+ \"_cv_{}.csv\"\n",
    "    \n",
    "        if split in [\"train\", \"valid\"]:\n",
    "            df_list = []\n",
    "            for i in range(5):\n",
    "                if i == cv:\n",
    "                    continue\n",
    "                filepath = os.path.join(base_dirpath, basename.format(i))\n",
    "                df_list.append(pd.read_csv(filepath))\n",
    "                print(split, i)\n",
    "            df = pd.concat(df_list, axis=0)\n",
    "        else:\n",
    "            # test\n",
    "            filepath = os.path.join(base_dirpath, basename.format(cv))\n",
    "            df = pd.read_csv(filepath)\n",
    "            print(split)\n",
    "\n",
    "\n",
    "        if gt_only:\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "        if train_only and split != \"train\":\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "\n",
    "        \n",
    "        data_list = []\n",
    "        \n",
    "        df['class_id'] = df['class_id'].astype(int)\n",
    "        df.drop(df[(df['data'].isna()) & (df['class_id'] == -1)].index, inplace=True)\n",
    "        df['col_idx'] = df['col_idx'].astype(int)\n",
    "        df['data'] = df['data'].astype(str)\n",
    "        \n",
    "        num_tables = len(df.groupby(\"table_id\"))\n",
    "        valid_index = int(num_tables * 0.8)\n",
    "        num_train = int(train_ratio * num_tables * 0.8)        \n",
    "        \n",
    "        # df.drop(df[(df['data'] == '') & (df['class_id'] == -1)].index, inplace=True)\n",
    "        total_num_cols = 0\n",
    "        for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "            if (split == \"train\") and ((i >= num_train) or (i >= valid_index)):\n",
    "                break\n",
    "            if split == \"valid\" and i < valid_index:\n",
    "                continue\n",
    "            #     break\n",
    "            num_cols = len(group_df)\n",
    "            group_df.sort_values(by=['col_idx'], inplace=True)\n",
    "            labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "            unlabeled_columns = group_df[group_df['class_id'] == -1]\n",
    "            num_unlabeled = min(max(max_unlabeled-len(labeled_columns), 0), len(unlabeled_columns)) if max_unlabeled > 0 else len(unlabeled_columns)\n",
    "            unlabeled_columns = unlabeled_columns.sample(num_unlabeled) if random_sample else unlabeled_columns[0:num_unlabeled]\n",
    "            # group_df = pd.concat([group_df[group_df['class_id'] > -1], unlabeled_columns.sample(min(10-len(labeled_columns), len(unlabeled_columns)))])\n",
    "            # group_df = pd.concat([group_df[group_df['class_id'] > -1], unlabeled_columns[0:min(max(10-len(labeled_columns), 0), len(unlabeled_columns))]])\n",
    "            group_df = pd.concat([group_df[group_df['class_id'] > -1], unlabeled_columns]) \n",
    "            group_df.sort_values(by=['col_idx'], inplace=True) # TODO \n",
    "\n",
    "            if max_length <= 128 and adaptive_max_length:\n",
    "                cur_maxlen = min(max_length, 512 // len(group_df) - 1)\n",
    "            else:\n",
    "                cur_maxlen = max_length\n",
    "                \n",
    "            token_ids_list = group_df[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=cur_maxlen, truncation=True)).tolist(\n",
    "                )\n",
    "            token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                                token_ids_list)).to(device)\n",
    "            for col_i in range(len(token_ids_list)):\n",
    "                if group_df[\"class_id\"].values[col_i] == -1:\n",
    "                    continue\n",
    "                target_col_mask = []\n",
    "                cls_index_value = 0\n",
    "                context_id = 1\n",
    "                for col_j in range(len(token_ids_list)):\n",
    "                    if col_j == col_i:\n",
    "                        target_col_mask += [0] * len(token_ids_list[col_j])\n",
    "                    else:\n",
    "                        target_col_mask += [context_id] * len(token_ids_list[col_j])\n",
    "                        context_id += 1\n",
    "                    if col_j < col_i:\n",
    "                        cls_index_value += len(token_ids_list[col_j])\n",
    "                cls_index_list = [cls_index_value] \n",
    "                for cls_index in cls_index_list:\n",
    "                    assert token_ids[\n",
    "                        cls_index] == tokenizer.cls_token_id, \"cls_indexes validation\"\n",
    "                cls_indexes = torch.LongTensor(cls_index_list).to(device)\n",
    "                class_ids = torch.LongTensor(\n",
    "                    [group_df[\"class_id\"].values[col_i]]).to(device)\n",
    "                target_col_mask = torch.LongTensor(target_col_mask).to(device)\n",
    "                col_idx = group_df[\"col_idx\"].values\n",
    "                data_list.append(\n",
    "                    [index,\n",
    "                    len(group_df), token_ids, class_ids, cls_indexes, target_col_mask, num_cols, col_idx])                \n",
    "        print(split, len(data_list))\n",
    "        self.table_df = pd.DataFrame(data_list,\n",
    "                                     columns=[\n",
    "                                         \"table_id\", \"num_col\", \"data_tensor\",\n",
    "                                         \"label_tensor\", \"cls_indexes\", \"target_col_mask\", \"initial_num_col\", \"col_idx\"\n",
    "                                     ])\n",
    "        \"\"\"\n",
    "        # NOTE: msato contains a small portion of single-col tables. keep it to be consistent.  \n",
    "        if multicol_only:\n",
    "            # Check\n",
    "            num_all_tables = len(self.table_df)\n",
    "            self.table_df = self.table_df[self.table_df[\"num_col\"] > 1]\n",
    "            assert len(self.table_df) == num_all_tables\n",
    "        \"\"\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.table_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"data\": self.table_df.iloc[idx][\"data_tensor\"],\n",
    "            \"label\": self.table_df.iloc[idx][\"label_tensor\"],\n",
    "            \"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"],\n",
    "            \"target_col_mask\": self.table_df.iloc[idx][\"target_col_mask\"],\n",
    "            \"initial_num_col\": self.table_df.iloc[idx][\"initial_num_col\"],\n",
    "            \"col_idx\": self.table_df.iloc[idx][\"col_idx\"]\n",
    "        }\n",
    "        #\"idx\": torch.LongTensor([idx])}\n",
    "        #\"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df[\"col_idx\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_columns.iloc[:len(other_columns)//2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GittablesTablewiseFirstDataset(data.Dataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            cv: int,\n",
    "            split: str,\n",
    "            src: str,  # train or test\n",
    "            tokenizer: AutoTokenizer,\n",
    "            max_length: int = 256,\n",
    "            gt_only: bool = False,\n",
    "            device: torch.device = None,\n",
    "            base_dirpath: str = \"/data/zhihao/TU/GitTables/semtab_gittables/2022\",\n",
    "            base_tag: str = '', # blank, comma\n",
    "            small_tag: str = \"\",\n",
    "            train_ratio: float = 1.0,\n",
    "            max_unlabeled=8,\n",
    "            adaptive_max_length=True,\n",
    "            random_sample=False, # TODO\n",
    "            train_only=False): # TODO\n",
    "        if device is None:\n",
    "            device = torch.device('cpu')\n",
    "        basename = small_tag+ \"_cv_{}.csv\"\n",
    "    \n",
    "        if split in [\"train\", \"valid\"]:\n",
    "            df_list = []\n",
    "            for i in range(5):\n",
    "                if i == cv:\n",
    "                    continue\n",
    "                filepath = os.path.join(base_dirpath, basename.format(i))\n",
    "                df_list.append(pd.read_csv(filepath))\n",
    "                print(split, i)\n",
    "            df = pd.concat(df_list, axis=0)\n",
    "        else:\n",
    "            # test\n",
    "            filepath = os.path.join(base_dirpath, basename.format(cv))\n",
    "            df = pd.read_csv(filepath)\n",
    "            print(split)\n",
    "\n",
    "\n",
    "        if gt_only:\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "        if train_only and split != \"train\":\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "\n",
    "        \n",
    "        data_list = []\n",
    "        \n",
    "        df['class_id'] = df['class_id'].astype(int)\n",
    "        df.drop(df[(df['data'].isna()) & (df['class_id'] == -1)].index, inplace=True)\n",
    "        df['col_idx'] = df['col_idx'].astype(int)\n",
    "        df['data'] = df['data'].astype(str)\n",
    "        \n",
    "        num_tables = len(df.groupby(\"table_id\"))\n",
    "        valid_index = int(num_tables * 0.8)\n",
    "        num_train = int(train_ratio * num_tables * 0.8)        \n",
    "        \n",
    "        # df.drop(df[(df['data'] == '') & (df['class_id'] == -1)].index, inplace=True)\n",
    "        total_num_cols = 0\n",
    "        for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "            if (split == \"train\") and ((i >= num_train) or (i >= valid_index)):\n",
    "                break\n",
    "            if split == \"valid\" and i < valid_index:\n",
    "                continue\n",
    "            #     break\n",
    "            group_df.sort_values(by=['col_idx'], inplace=True)\n",
    "            group_df = group_df.reset_index(drop=True)\n",
    "            labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "            labeled_columns.sort_values(by=['col_idx'], inplace=True)\n",
    "            for index, target_column in labeled_columns.iterrows():\n",
    "                other_columns = group_df.drop(index).head(max_unlabeled-1)\n",
    "                # if len(group_df)-len(target_column)+1 >= max_unlabeled: # TODO\n",
    "                #     other_columns = group_df.drop(labeled_columns.index).head(max_unlabeled-1)\n",
    "                # else:\n",
    "                #     other_columns = group_df.drop(index).head(max_unlabeled-1)\n",
    "\n",
    "                target_table = pd.concat([target_column.to_frame().T, other_columns], ignore_index=True)\n",
    "                # target_table = pd.concat([other_columns.iloc[:len(other_columns)//2], target_column.to_frame().T, other_columns.iloc[len(other_columns)//2:]], ignore_index=True)\n",
    "\n",
    "                target_col_idx = target_column[\"col_idx\"]\n",
    "                target_cls = target_column[\"class_id\"]\n",
    "                target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "                col_idx_list = target_table[\"col_idx\"].tolist()\n",
    "\n",
    "\n",
    "                if max_length <= 128 and adaptive_max_length:\n",
    "                    cur_maxlen = min(max_length, 512 // len(target_table) - 1)\n",
    "                else:\n",
    "                    cur_maxlen = max_length\n",
    "                    \n",
    "                token_ids_list = target_table[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                    tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=cur_maxlen, truncation=True)).tolist(\n",
    "                    )\n",
    "                token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                                    token_ids_list)).to(device)\n",
    "\n",
    "                target_col_mask = []\n",
    "                cls_index_value = 0\n",
    "                context_id = 1\n",
    "                meet_target = False\n",
    "                for idx, col_i in enumerate(col_idx_list):\n",
    "                    if col_i == target_col_idx:\n",
    "                        target_col_mask += [0] * len(token_ids_list[idx])\n",
    "                        meet_target = True\n",
    "                    else:\n",
    "                        target_col_mask += [context_id] * len(token_ids_list[idx])\n",
    "                        context_id += 1\n",
    "                    if not meet_target:\n",
    "                        cls_index_value += len(token_ids_list[idx])\n",
    "                cls_index_list = [cls_index_value] \n",
    "                for cls_index in cls_index_list:\n",
    "                    assert token_ids[\n",
    "                        cls_index] == tokenizer.cls_token_id, \"cls_indexes validation\"\n",
    "                cls_indexes = torch.LongTensor(cls_index_list).to(device)\n",
    "                class_ids = torch.LongTensor(\n",
    "                    [target_cls]).to(device)\n",
    "                target_col_mask = torch.LongTensor(target_col_mask).to(device)\n",
    "                data_list.append(\n",
    "                    [index,\n",
    "                    len(target_table), token_ids, class_ids, cls_indexes, target_col_mask])                        \n",
    "        print(split, len(data_list))\n",
    "        self.table_df = pd.DataFrame(data_list,\n",
    "                                     columns=[\n",
    "                                         \"table_id\", \"num_col\", \"data_tensor\",\n",
    "                                         \"label_tensor\", \"cls_indexes\", \"target_col_mask\",\n",
    "                                     ])\n",
    "        \"\"\"\n",
    "        # NOTE: msato contains a small portion of single-col tables. keep it to be consistent.  \n",
    "        if multicol_only:\n",
    "            # Check\n",
    "            num_all_tables = len(self.table_df)\n",
    "            self.table_df = self.table_df[self.table_df[\"num_col\"] > 1]\n",
    "            assert len(self.table_df) == num_all_tables\n",
    "        \"\"\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.table_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"data\": self.table_df.iloc[idx][\"data_tensor\"],\n",
    "            \"label\": self.table_df.iloc[idx][\"label_tensor\"],\n",
    "            \"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"],\n",
    "            \"target_col_mask\": self.table_df.iloc[idx][\"target_col_mask\"],\n",
    "            # \"initial_num_col\": self.table_df.iloc[idx][\"initial_num_col\"],\n",
    "        }\n",
    "        #\"idx\": torch.LongTensor([idx])}\n",
    "        #\"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GittablesTablewiseLastDataset(data.Dataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            cv: int,\n",
    "            split: str,\n",
    "            src: str,  # train or test\n",
    "            tokenizer: AutoTokenizer,\n",
    "            max_length: int = 256,\n",
    "            gt_only: bool = False,\n",
    "            device: torch.device = None,\n",
    "            base_dirpath: str = \"/data/zhihao/TU/GitTables/semtab_gittables/2022\",\n",
    "            base_tag: str = '', # blank, comma\n",
    "            small_tag: str = \"\",\n",
    "            train_ratio: float = 1.0,\n",
    "            max_unlabeled=8,\n",
    "            adaptive_max_length=True,\n",
    "            random_sample=False, # TODO\n",
    "            train_only=False): # TODO\n",
    "        if device is None:\n",
    "            device = torch.device('cpu')\n",
    "        basename = small_tag+ \"_cv_{}.csv\"\n",
    "    \n",
    "        if split in [\"train\", \"valid\"]:\n",
    "            df_list = []\n",
    "            for i in range(5):\n",
    "                if i == cv:\n",
    "                    continue\n",
    "                filepath = os.path.join(base_dirpath, basename.format(i))\n",
    "                df_list.append(pd.read_csv(filepath))\n",
    "                print(split, i)\n",
    "            df = pd.concat(df_list, axis=0)\n",
    "        else:\n",
    "            # test\n",
    "            filepath = os.path.join(base_dirpath, basename.format(cv))\n",
    "            df = pd.read_csv(filepath)\n",
    "            print(split)\n",
    "\n",
    "\n",
    "        if gt_only:\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "        if train_only and split != \"train\":\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "\n",
    "        \n",
    "        data_list = []\n",
    "        \n",
    "        df['class_id'] = df['class_id'].astype(int)\n",
    "        df.drop(df[(df['data'].isna()) & (df['class_id'] == -1)].index, inplace=True)\n",
    "        df['col_idx'] = df['col_idx'].astype(int)\n",
    "        df['data'] = df['data'].astype(str)\n",
    "        \n",
    "        num_tables = len(df.groupby(\"table_id\"))\n",
    "        valid_index = int(num_tables * 0.8)\n",
    "        num_train = int(train_ratio * num_tables * 0.8)        \n",
    "        \n",
    "        # df.drop(df[(df['data'] == '') & (df['class_id'] == -1)].index, inplace=True)\n",
    "        total_num_cols = 0\n",
    "        self.col_idx_list = []\n",
    "        for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "            if (split == \"train\") and ((i >= num_train) or (i >= valid_index)):\n",
    "                break\n",
    "            if split == \"valid\" and i < valid_index:\n",
    "                continue\n",
    "            #     break\n",
    "            group_df.sort_values(by=['col_idx'], inplace=True)\n",
    "            group_df = group_df.reset_index(drop=True)\n",
    "            labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "            labeled_columns.sort_values(by=['col_idx'], inplace=True)\n",
    "            unlabeled_columns = group_df[group_df['class_id'] == -1]\n",
    "            for index, target_column in labeled_columns.iterrows():\n",
    "                other_columns = group_df.drop(index).tail(max_unlabeled-1)\n",
    "                target_table = pd.concat([target_column.to_frame().T, other_columns], ignore_index=True)\n",
    "                \n",
    "                # num_unlabeled = min(max(max_unlabeled-len(labeled_columns), 0), len(unlabeled_columns)) if max_unlabeled > 0 else len(unlabeled_columns)\n",
    "                # target_table = pd.concat([labeled_columns, unlabeled_columns.tail(num_unlabeled)], ignore_index=True)\n",
    "                # if len(group_df) >= 8:\n",
    "                #     assert len(target_table) == max_unlabeled\n",
    "                # else:\n",
    "                #     assert len(target_table) == len(group_df)\n",
    "    \n",
    "                target_col_idx =target_column[\"col_idx\"]\n",
    "                target_cls = target_column[\"class_id\"]\n",
    "                target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "                col_idx_list = target_table[\"col_idx\"].tolist()\n",
    "\n",
    "\n",
    "                if max_length <= 128 and adaptive_max_length:\n",
    "                    cur_maxlen = min(max_length, 512 // len(target_table) - 1)\n",
    "                else:\n",
    "                    cur_maxlen = max_length\n",
    "                    \n",
    "                token_ids_list = target_table[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                    tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=cur_maxlen, truncation=True)).tolist(\n",
    "                    )\n",
    "                token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                                    token_ids_list)).to(device)\n",
    "\n",
    "                target_col_mask = []\n",
    "                cls_index_value = 0\n",
    "                context_id = 1\n",
    "                meet_target = False\n",
    "                for idx, col_i in enumerate(col_idx_list):\n",
    "                    if col_i == target_col_idx:\n",
    "                        target_col_mask += [0] * len(token_ids_list[idx])\n",
    "                        meet_target = True\n",
    "                    else:\n",
    "                        target_col_mask += [context_id] * len(token_ids_list[idx])\n",
    "                        context_id += 1\n",
    "                    if not meet_target:\n",
    "                        cls_index_value += len(token_ids_list[idx])\n",
    "                cls_index_list = [cls_index_value] \n",
    "                for cls_index in cls_index_list:\n",
    "                    assert token_ids[\n",
    "                        cls_index] == tokenizer.cls_token_id, \"cls_indexes validation\"\n",
    "                cls_indexes = torch.LongTensor(cls_index_list).to(device)\n",
    "                class_ids = torch.LongTensor(\n",
    "                    [target_cls]).to(device)\n",
    "                target_col_mask = torch.LongTensor(target_col_mask).to(device)\n",
    "                data_list.append(\n",
    "                    [index,\n",
    "                    len(target_table), token_ids, class_ids, cls_indexes, target_col_mask, col_idx_list])                        \n",
    "        print(split, len(data_list))\n",
    "        self.table_df = pd.DataFrame(data_list,\n",
    "                                     columns=[\n",
    "                                         \"table_id\", \"num_col\", \"data_tensor\",\n",
    "                                         \"label_tensor\", \"cls_indexes\", \"target_col_mask\", \"col_idx_list\"\n",
    "                                     ])\n",
    "        \"\"\"\n",
    "        # NOTE: msato contains a small portion of single-col tables. keep it to be consistent.  \n",
    "        if multicol_only:\n",
    "            # Check\n",
    "            num_all_tables = len(self.table_df)\n",
    "            self.table_df = self.table_df[self.table_df[\"num_col\"] > 1]\n",
    "            assert len(self.table_df) == num_all_tables\n",
    "        \"\"\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.table_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"data\": self.table_df.iloc[idx][\"data_tensor\"],\n",
    "            \"label\": self.table_df.iloc[idx][\"label_tensor\"],\n",
    "            \"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"],\n",
    "            \"target_col_mask\": self.table_df.iloc[idx][\"target_col_mask\"],\n",
    "            \"col_idx_list\": self.table_df.iloc[idx][\"col_idx_list\"],\n",
    "            # \"initial_num_col\": self.table_df.iloc[idx][\"initial_num_col\"],\n",
    "        }\n",
    "        #\"idx\": torch.LongTensor([idx])}\n",
    "        #\"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labeled = df[df[\"class_id\"] > -1]\n",
    "test_labels = df_labeled[\"class_id\"].values\n",
    "similar_label = []\n",
    "for label, x in zip(df_labeled[\"class_id\"], df_labeled[\"data\"]):\n",
    "    scores = bm25.get_scores(tokenizer.encode(\n",
    "                    tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=max_length, truncation=True))\n",
    "    top_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:1]\n",
    "    similar_label.append(training_labeled_class[top_indices[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "    token_list = group_df[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "            tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=max_length, truncation=True)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm_group_scores = defaultdict(list)\n",
    "i = 0\n",
    "bm_group_scores[i] =[bm25.get_scores(x) for x in token_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(bm_group_scores[i][0]).topk(1).values.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_classify_acc = 0\n",
    "bm_group_scores = defaultdict(list)\n",
    "K = 1\n",
    "for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "    group_df = group_df.reset_index(drop=True)\n",
    "    # scores = bm25.get_scores(test_dataset_gt[idx][\"data\"].cpu().tolist())\n",
    "    token_list = group_df[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "            tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=max_length, truncation=True)).tolist()\n",
    "    \n",
    "    bm_group_scores[i] =[bm25.get_scores(x) for x in token_list]\n",
    "    semantic_scores = torch.tensor([torch.tensor(score).topk(K).values.mean().item() for score in bm_group_scores[i]])\n",
    "    labeled_columns_index = group_df[group_df['class_id'] > -1].index.to_list()\n",
    "    assert len(labeled_columns_index) < 8\n",
    "    if set(labeled_columns_index).issubset(set(semantic_scores.topk(min(len(group_df), 8)).indices.tolist())):\n",
    "        label_classify_acc += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for K in [1,3,5]:\n",
    "    label_classify_acc = 0\n",
    "    for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "        group_df = group_df.reset_index(drop=True)\n",
    "        # scores = bm25.get_scores(test_dataset_gt[idx][\"data\"].cpu().tolist())\n",
    "        semantic_scores = torch.tensor([torch.tensor(score).topk(K).values.mean().item() for score in bm_group_scores[i]])\n",
    "        labeled_columns_index = group_df[group_df['class_id'] > -1].index.to_list()\n",
    "        assert len(labeled_columns_index) < 8\n",
    "        if set(labeled_columns_index).issubset(set(semantic_scores.topk(min(len(group_df), 8)).indices.tolist())):\n",
    "            label_classify_acc += 1\n",
    "    print(f\"************************** K={K} **************************\")\n",
    "    print(label_classify_acc/len(df.groupby(\"table_id\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_classify_acc = 0\n",
    "bm_group_scores_ind = defaultdict(list)\n",
    "K = 1\n",
    "for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "    group_df = group_df.reset_index(drop=True)\n",
    "    # scores = bm25.get_scores(test_dataset_gt[idx][\"data\"].cpu().tolist())\n",
    "    token_list = group_df[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "            tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=max_length, truncation=True)).tolist()\n",
    "    \n",
    "    bm_group_scores_ind[i] =[bm25_ind.get_scores(x) for x in token_list]\n",
    "    semantic_scores = torch.tensor([torch.tensor(score).topk(K).values.mean().item() for score in bm_group_scores_ind[i]])\n",
    "    labeled_columns_index = group_df[group_df['class_id'] > -1].index.to_list()\n",
    "    assert len(labeled_columns_index) < 8\n",
    "    if set(labeled_columns_index).issubset(set(semantic_scores.topk(min(len(group_df), 8)).indices.tolist())):\n",
    "        label_classify_acc += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for K in [1,3,5]:\n",
    "    label_classify_acc = 0\n",
    "    for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "        group_df = group_df.reset_index(drop=True)\n",
    "        # scores = bm25.get_scores(test_dataset_gt[idx][\"data\"].cpu().tolist())\n",
    "        semantic_scores = torch.tensor([torch.tensor(score).topk(K).values.mean().item() for score in bm_group_scores_ind[i]])\n",
    "        labeled_columns_index = group_df[group_df['class_id'] > -1].index.to_list()\n",
    "        assert len(labeled_columns_index) < 8\n",
    "        if set(labeled_columns_index).issubset(set(semantic_scores.topk(min(len(group_df), 8)).indices.tolist())):\n",
    "            label_classify_acc += 1\n",
    "    print(f\"************************** K={K} **************************\")\n",
    "    print(label_classify_acc/len(df.groupby(\"table_id\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for K in [1]:\n",
    "    label_classify_acc = []\n",
    "    for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "        group_df = group_df.reset_index(drop=True)\n",
    "        # scores = bm25.get_scores(test_dataset_gt[idx][\"data\"].cpu().tolist())\n",
    "        semantic_scores = torch.tensor([torch.tensor(score).topk(K).values.mean().item() for score in bm_group_scores_ind[i]])\n",
    "        labeled_columns_index = group_df[group_df['class_id'] > -1].index.to_list()\n",
    "        assert len(labeled_columns_index) < 8\n",
    "        if set(labeled_columns_index).issubset(set(semantic_scores.topk(min(len(group_df), 8)).indices.tolist())):\n",
    "            label_classify_acc.append(1)\n",
    "        else:\n",
    "            label_classify_acc.append(0)\n",
    "    print(f\"************************** K={K} **************************\")\n",
    "    label_classify_acc = torch.tensor(label_classify_acc)\n",
    "    print(label_classify_acc[num_cols>8].sum()/(num_cols>8).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_classify_acc/len(df.groupby(\"table_id\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_scores.topk(min(len(group_df), 8)).indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_label = torch.tensor(similar_label)\n",
    "test_labels = torch.tensor(test_labels)\n",
    "(similar_label==test_labels).sum().item()/len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labeled = df[df[\"class_id\"] > -1]\n",
    "test_labels = df_labeled[\"class_id\"].values\n",
    "similar_label = []\n",
    "for label, x in zip(df_labeled[\"class_id\"], df_labeled[\"data\"]):\n",
    "    scores = F.cosine_similarity(training_corpus_embs, torch.tensor(sb_model.encode([x])).cpu().reshape(1,-1))\n",
    "    top_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:1]\n",
    "    similar_label.append(training_labeled_class[top_indices[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_label = torch.tensor(similar_label)\n",
    "test_labels = torch.tensor(test_labels)\n",
    "(similar_label==test_labels).sum().item()/len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_classify_acc = 0\n",
    "for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "    group_df = group_df.reset_index(drop=True)\n",
    "    # scores = bm25.get_scores(test_dataset_gt[idx][\"data\"].cpu().tolist())\n",
    "    semantic_scores = torch.tensor(group_df[\"data\"].apply(lambda x: max(F.cosine_similarity(training_corpus_embs, torch.tensor(sb_model.encode([x])).cpu().reshape(1,-1)))))\n",
    "    labeled_columns_index = group_df[group_df['class_id'] > -1].index.to_list()\n",
    "    assert len(labeled_columns_index) < 8\n",
    "    if set(labeled_columns_index).issubset(set(semantic_scores.topk(min(len(group_df), 8)).indices.tolist())):\n",
    "        label_classify_acc += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_classify_acc/len(df.groupby(\"table_id\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_list = sb_model.encode(group_df[\"data\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = []\n",
    "for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "    num_cols.append(len(group_df))\n",
    "num_cols = torch.tensor(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_classify_acc = []\n",
    "for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "    group_df = group_df.reset_index(drop=True)\n",
    "    # scores = bm25.get_scores(test_dataset_gt[idx][\"data\"].cpu().tolist())\n",
    "    semantic_scores = torch.tensor(group_df[\"data\"].apply(lambda x: max(F.cosine_similarity(training_corpus_embs_ind, torch.tensor(sb_model.encode([x])).cpu().reshape(1,-1)))))\n",
    "    labeled_columns_index = group_df[group_df['class_id'] > -1].index.to_list()\n",
    "    assert len(labeled_columns_index) < 8\n",
    "    if set(labeled_columns_index).issubset(set(semantic_scores.topk(min(len(group_df), 8)).indices.tolist())):\n",
    "        label_classify_acc.append(1)\n",
    "    else:\n",
    "        label_classify_acc.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_classify_acc = torch.tensor(label_classify_acc)\n",
    "print(label_classify_acc.sum().item()/len(df.groupby(\"table_id\")))\n",
    "print(label_classify_acc[num_cols>8].sum()/(num_cols>8).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_classify_acc = []\n",
    "for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "    group_df = group_df.reset_index(drop=True)\n",
    "    # scores = bm25.get_scores(test_dataset_gt[idx][\"data\"].cpu().tolist())\n",
    "    semantic_scores = torch.tensor(group_df[\"data\"].apply(lambda x: max(F.cosine_similarity(training_corpus_embs_ind, torch.tensor(sb_model.encode([x])).cpu().reshape(1,-1)))))\n",
    "    labeled_columns_index = group_df[group_df['class_id'] > -1].index.to_list()\n",
    "    assert len(labeled_columns_index) < 8\n",
    "    if set(labeled_columns_index).issubset(set(semantic_scores.topk(min(len(group_df), 8)).indices.tolist())):\n",
    "        label_classify_acc.append(1)\n",
    "    else:\n",
    "        label_classify_acc.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = group_df[\"data\"].to_list()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EU distance\n",
    "label_classify_acc = []\n",
    "for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "    group_df = group_df.reset_index(drop=True)\n",
    "    # scores = bm25.get_scores(test_dataset_gt[idx][\"data\"].cpu().tolist())\n",
    "    semantic_scores = torch.tensor(group_df[\"data\"].apply(lambda x: (1/(torch.cdist(training_corpus_embs_ind, torch.tensor(sb_model.encode([x])).cpu().reshape(1,-1)+1e-5))).max().item()).tolist())\n",
    "    labeled_columns_index = group_df[group_df['class_id'] > -1].index.to_list()\n",
    "    assert len(labeled_columns_index) < 8\n",
    "    if set(labeled_columns_index).issubset(set(semantic_scores.topk(min(len(group_df), 8)).indices.tolist())):\n",
    "        label_classify_acc.append(1)\n",
    "    else:\n",
    "        label_classify_acc.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_classify_acc = torch.tensor(label_classify_acc)\n",
    "print(label_classify_acc.sum().item()/len(df.groupby(\"table_id\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MahalanobisDistance(object):\n",
    "    def __init__(self, ftrain, labels_train):\n",
    "        self.xc = [ftrain[labels_train == i] for i in np.unique(labels_train)]\n",
    "        self.cov_inv = torch.linalg.pinv(torch.Tensor(np.cov(ftrain.T, bias=True))).numpy()\n",
    "    def __call__(self, ftest):\n",
    "        dtest = [\n",
    "            np.sum(\n",
    "                (ftest - np.mean(x, axis=0, keepdims=True))\n",
    "                * (\n",
    "                    self.cov_inv.dot(\n",
    "                        (ftest - np.mean(x, axis=0, keepdims=True)).T\n",
    "                    )\n",
    "                ).T,\n",
    "                axis=-1,\n",
    "            )\n",
    "            for x in self.xc\n",
    "        ]\n",
    "\n",
    "        dtest = np.min(dtest, axis=0)\n",
    "\n",
    "        return dtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_distance = MahalanobisDistance(training_corpus_embs_doduo.numpy(), training_corpus_labels.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mahalanobis distance\n",
    "for K in [1]:\n",
    "    print(f\"************************** K={K} **************************\")\n",
    "    label_classify_acc = []\n",
    "    for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "        group_df = group_df.reset_index(drop=True)\n",
    "        token_list = group_df[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=max_length, truncation=True)).tolist()\n",
    "        token_list = torch.nn.utils.rnn.pad_sequence(\n",
    "        [torch.LongTensor(tokens) for tokens in token_list], padding_value=0).T.to(device)\n",
    "        cls_indexes = torch.nonzero(\n",
    "                    token_list == tokenizer.cls_token_id)\n",
    "        logits, embs = model(token_list, cls_indexes=cls_indexes, get_enc=True)\n",
    "        embs = embs.cpu()\n",
    "        if len(embs.size()) == 1:\n",
    "            embs = embs.unsqueeze(0)\n",
    "        semantic_scores = 1 / torch.tensor(md_distance(embs.detach().cpu().numpy()))\n",
    "        labeled_columns_index = group_df[group_df['class_id'] > -1].index.to_list()\n",
    "        assert len(labeled_columns_index) < 8\n",
    "        if set(labeled_columns_index).issubset(set(semantic_scores.topk(min(len(group_df), 8)).indices.tolist())):\n",
    "            label_classify_acc.append(1)\n",
    "        else:\n",
    "            label_classify_acc.append(0)\n",
    "    label_classify_acc = torch.tensor(label_classify_acc)\n",
    "    print(label_classify_acc.sum().item()/len(df.groupby(\"table_id\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_corpus_embs_doduo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.norm(training_corpus_embs_doduo, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_distance_cos = MahalanobisDistance(F.normalize(training_corpus_embs_doduo).numpy(), training_corpus_labels.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = F.normalize(training_corpus_embs_doduo).mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = F.normalize(training_corpus_embs_doduo.mean(1, keepdim=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mahalanobis distance COS\n",
    "for K in [1]:\n",
    "    print(f\"************************** K={K} **************************\")\n",
    "    label_classify_acc = []\n",
    "    for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "        group_df = group_df.reset_index(drop=True)\n",
    "        token_list = group_df[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=max_length, truncation=True)).tolist()\n",
    "        token_list = torch.nn.utils.rnn.pad_sequence(\n",
    "        [torch.LongTensor(tokens) for tokens in token_list], padding_value=0).T.to(device)\n",
    "        cls_indexes = torch.nonzero(\n",
    "                    token_list == tokenizer.cls_token_id)\n",
    "        logits, embs = model(token_list, cls_indexes=cls_indexes, get_enc=True)\n",
    "        embs = embs.cpu()\n",
    "        if len(embs.size()) == 1:\n",
    "            embs = embs.unsqueeze(0)\n",
    "        semantic_scores = 1 / torch.tensor(md_distance_cos(F.normalize(embs.detach().cpu()).numpy()))\n",
    "        labeled_columns_index = group_df[group_df['class_id'] > -1].index.to_list()\n",
    "        assert len(labeled_columns_index) < 8\n",
    "        if set(labeled_columns_index).issubset(set(semantic_scores.topk(min(len(group_df), 8)).indices.tolist())):\n",
    "            label_classify_acc.append(1)\n",
    "        else:\n",
    "            label_classify_acc.append(0)\n",
    "    label_classify_acc = torch.tensor(label_classify_acc)\n",
    "    print(label_classify_acc.sum().item()/len(df.groupby(\"table_id\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for K in [1,3,5]:\n",
    "    print(f\"************************** K={K} **************************\")\n",
    "    label_classify_acc = []\n",
    "    for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "        group_df = group_df.reset_index(drop=True)\n",
    "        token_list = group_df[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=max_length, truncation=True)).tolist()\n",
    "        token_list = torch.nn.utils.rnn.pad_sequence(\n",
    "        [torch.LongTensor(tokens) for tokens in token_list], padding_value=0).T.to(device)\n",
    "        cls_indexes = torch.nonzero(\n",
    "                    token_list == tokenizer.cls_token_id)\n",
    "        logits, embs = model(token_list, cls_indexes=cls_indexes, get_enc=True)\n",
    "        embs = embs.cpu()\n",
    "        if len(embs.size()) == 1:\n",
    "            embs = embs.unsqueeze(0)\n",
    "        semantic_scores = torch.mm(training_corpus_embs_doduo/ training_corpus_embs_doduo.norm(dim=1, keepdim=True), (embs/ embs.norm(dim=1, keepdim=True)).T).T.topk(K).values.mean(1)\n",
    "        labeled_columns_index = group_df[group_df['class_id'] > -1].index.to_list()\n",
    "        assert len(labeled_columns_index) < 8\n",
    "        if set(labeled_columns_index).issubset(set(semantic_scores.topk(min(len(group_df), 8)).indices.tolist())):\n",
    "            label_classify_acc.append(1)\n",
    "        else:\n",
    "            label_classify_acc.append(0)\n",
    "    label_classify_acc = torch.tensor(label_classify_acc)\n",
    "    print(label_classify_acc.sum().item()/len(df.groupby(\"table_id\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EU\n",
    "for K in [1]:\n",
    "    print(f\"************************** K={K} **************************\")\n",
    "    label_classify_acc = []\n",
    "    for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "        group_df = group_df.reset_index(drop=True)\n",
    "        token_list = group_df[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=max_length, truncation=True)).tolist()\n",
    "        token_list = torch.nn.utils.rnn.pad_sequence(\n",
    "        [torch.LongTensor(tokens) for tokens in token_list], padding_value=0).T.to(device)\n",
    "        cls_indexes = torch.nonzero(\n",
    "                    token_list == tokenizer.cls_token_id)\n",
    "        logits, embs = model(token_list, cls_indexes=cls_indexes, get_enc=True)\n",
    "        embs = embs.cpu()\n",
    "        if len(embs.size()) == 1:\n",
    "            embs = embs.unsqueeze(0)\n",
    "        semantic_scores = (1/ (torch.cdist(embs, training_corpus_embs_doduo)+1e-5)).topk(K).values.mean(1)\n",
    "        labeled_columns_index = group_df[group_df['class_id'] > -1].index.to_list()\n",
    "        assert len(labeled_columns_index) < 8\n",
    "        if set(labeled_columns_index).issubset(set(semantic_scores.topk(min(len(group_df), 8)).indices.tolist())):\n",
    "            label_classify_acc.append(1)\n",
    "        else:\n",
    "            label_classify_acc.append(0)\n",
    "    label_classify_acc = torch.tensor(label_classify_acc)\n",
    "    print(label_classify_acc.sum().item()/len(df.groupby(\"table_id\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_corpus_embs_doduo_center.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class center\n",
    "for K in [1,3,5]:\n",
    "    print(f\"************************** K={K} **************************\")\n",
    "    label_classify_acc = []\n",
    "    for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "        group_df = group_df.reset_index(drop=True)\n",
    "        token_list = group_df[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=max_length, truncation=True)).tolist()\n",
    "        token_list = torch.nn.utils.rnn.pad_sequence(\n",
    "        [torch.LongTensor(tokens) for tokens in token_list], padding_value=0).T.to(device)\n",
    "        cls_indexes = torch.nonzero(\n",
    "                    token_list == tokenizer.cls_token_id)\n",
    "        logits, embs = model(token_list, cls_indexes=cls_indexes, get_enc=True)\n",
    "        embs = embs.cpu()\n",
    "        if len(embs.size()) == 1:\n",
    "            embs = embs.unsqueeze(0)\n",
    "        semantic_scores = torch.mm(training_corpus_embs_doduo_center/ training_corpus_embs_doduo_center.norm(dim=1, keepdim=True), (embs/ embs.norm(dim=1, keepdim=True)).T).T.topk(K).values.mean(1)\n",
    "        labeled_columns_index = group_df[group_df['class_id'] > -1].index.to_list()\n",
    "        assert len(labeled_columns_index) < 8\n",
    "        if set(labeled_columns_index).issubset(set(semantic_scores.topk(min(len(group_df), 8)).indices.tolist())):\n",
    "            label_classify_acc.append(1)\n",
    "        else:\n",
    "            label_classify_acc.append(0)\n",
    "    label_classify_acc = torch.tensor(label_classify_acc)\n",
    "    print(label_classify_acc.sum().item()/len(df.groupby(\"table_id\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class center EU\n",
    "for K in [1,3,5]:\n",
    "    print(f\"************************** K={K} **************************\")\n",
    "    label_classify_acc = []\n",
    "    for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "        group_df = group_df.reset_index(drop=True)\n",
    "        token_list = group_df[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=max_length, truncation=True)).tolist()\n",
    "        token_list = torch.nn.utils.rnn.pad_sequence(\n",
    "        [torch.LongTensor(tokens) for tokens in token_list], padding_value=0).T.to(device)\n",
    "        cls_indexes = torch.nonzero(\n",
    "                    token_list == tokenizer.cls_token_id)\n",
    "        logits, embs = model(token_list, cls_indexes=cls_indexes, get_enc=True)\n",
    "        embs = embs.cpu()\n",
    "        if len(embs.size()) == 1:\n",
    "            embs = embs.unsqueeze(0)\n",
    "        semantic_scores = (1/ (torch.cdist(embs, training_corpus_embs_doduo_center)+1e-5)).topk(K).values.mean(1)\n",
    "        labeled_columns_index = group_df[group_df['class_id'] > -1].index.to_list()\n",
    "        assert len(labeled_columns_index) < 8\n",
    "        if set(labeled_columns_index).issubset(set(semantic_scores.topk(min(len(group_df), 8)).indices.tolist())):\n",
    "            label_classify_acc.append(1)\n",
    "        else:\n",
    "            label_classify_acc.append(0)\n",
    "    label_classify_acc = torch.tensor(label_classify_acc)\n",
    "    print(label_classify_acc.sum().item()/len(df.groupby(\"table_id\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all training embs\n",
    "for K in [1,3,5]:\n",
    "    print(f\"************************** K={K} **************************\")\n",
    "    label_classify_acc = []\n",
    "    for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "        group_df = group_df.reset_index(drop=True)\n",
    "        token_list = group_df[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=max_length, truncation=True)).tolist()\n",
    "        token_list = torch.nn.utils.rnn.pad_sequence(\n",
    "        [torch.LongTensor(tokens) for tokens in token_list], padding_value=0).T.to(device)\n",
    "        cls_indexes = torch.nonzero(\n",
    "                    token_list == tokenizer.cls_token_id)\n",
    "        logits, embs = model(token_list, cls_indexes=cls_indexes, get_enc=True)\n",
    "        embs = embs.cpu()\n",
    "        if len(embs.size()) == 1:\n",
    "            embs = embs.unsqueeze(0)\n",
    "        semantic_scores = torch.mm(training_corpus_embs_doduo_all/ training_corpus_embs_doduo_all.norm(dim=1, keepdim=True), (embs/ embs.norm(dim=1, keepdim=True)).T).T.topk(K).values.mean(1)\n",
    "        labeled_columns_index = group_df[group_df['class_id'] > -1].index.to_list()\n",
    "        assert len(labeled_columns_index) < 8\n",
    "        if set(labeled_columns_index).issubset(set(semantic_scores.topk(min(len(group_df), 8)).indices.tolist())):\n",
    "            label_classify_acc.append(1)\n",
    "        else:\n",
    "            label_classify_acc.append(0)\n",
    "    label_classify_acc = torch.tensor(label_classify_acc)\n",
    "    print(label_classify_acc.sum().item()/len(df.groupby(\"table_id\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mm(training_corpus_embs_doduo/ training_corpus_embs_doduo.norm(dim=1, keepdim=True), (embs/ embs.norm(dim=1, keepdim=True)).T).T.topk(5).values.mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(num_cols>8).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_classify_acc/len(df.groupby(\"table_id\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = F.cosine_similarity(training_corpus_embs_ind, torch.tensor(sb_model.encode([df_labeled_corpus[idx]])).cpu().reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in group_df[\"data\"]:\n",
    "#     print(x)\n",
    "#     scores = bm25.get_scores(tokenizer.encode(\n",
    "#                     tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=max_length, truncation=True))\n",
    "#     top_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:5]\n",
    "\n",
    "#     # Fetch the top 5 documents\n",
    "#     top_documents = [training_labeled_corpus[i] for i in top_indices]\n",
    "#     for i, doc in enumerate(top_documents):\n",
    "#         print(f\"Rank {i+1}: Document: {tokenizer.decode(doc)} => BM25 Score: {scores[top_indices[i]]}\")\n",
    "#     print(\"*******************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "class GittablesTablewiseIterateClusterExtraDataset(data.Dataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            cv: int,\n",
    "            split: str,\n",
    "            src: str,  # train or test\n",
    "            tokenizer: AutoTokenizer,\n",
    "            max_length: int = 256,\n",
    "            gt_only: bool = False,\n",
    "            device: torch.device = None,\n",
    "            base_dirpath: str = \"/data/zhihao/TU/GitTables/semtab_gittables/2022\",\n",
    "            base_tag: str = '', # blank, comma\n",
    "            small_tag: str = \"\",\n",
    "            train_ratio: float = 1.0,\n",
    "            max_unlabeled=8,\n",
    "            adaptive_max_length=True,\n",
    "            random_sample=False, # TODO\n",
    "            train_only=False,\n",
    "            training_corpus_embs_doduo=None,\n",
    "            df_train_labeled=None, \n",
    "            kmeans=None): # TODO\n",
    "        if device is None:\n",
    "            device = torch.device('cpu')\n",
    "        basename = small_tag+ \"_cv_{}.csv\"\n",
    "    \n",
    "        if split in [\"train\", \"valid\"]:\n",
    "            df_list = []\n",
    "            for i in range(5):\n",
    "                if i == cv:\n",
    "                    continue\n",
    "                filepath = os.path.join(base_dirpath, basename.format(i))\n",
    "                df_list.append(pd.read_csv(filepath))\n",
    "                print(split, i)\n",
    "            df = pd.concat(df_list, axis=0)\n",
    "        else:\n",
    "            # test\n",
    "            filepath = os.path.join(base_dirpath, basename.format(cv))\n",
    "            df = pd.read_csv(filepath)\n",
    "            print(split)\n",
    "\n",
    "\n",
    "        if gt_only:\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "        if train_only and split != \"train\":\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "\n",
    "        \n",
    "        data_list = []\n",
    "        \n",
    "        df['class_id'] = df['class_id'].astype(int)\n",
    "        df.drop(df[(df['data'].isna()) & (df['class_id'] == -1)].index, inplace=True)\n",
    "        df['col_idx'] = df['col_idx'].astype(int)\n",
    "        df['data'] = df['data'].astype(str)\n",
    "        \n",
    "        num_tables = len(df.groupby(\"table_id\"))\n",
    "        valid_index = int(num_tables * 0.8)\n",
    "        num_train = int(train_ratio * num_tables * 0.8)        \n",
    "        \n",
    "        \n",
    "\n",
    "        # kmeans = KMeans(n_clusters=max_unlabeled-1, random_state=0).fit(training_corpus_embs_doduo)\n",
    "        centers = torch.tensor(kmeans.cluster_centers_)\n",
    "        cluster_labels = torch.tensor(kmeans.labels_)\n",
    "        training_embs_cluster = []\n",
    "        training_embs_cluster_index = []\n",
    "        for cluster_i in np.unique(kmeans.labels_):\n",
    "            training_embs_cluster.append(training_corpus_embs_doduo[cluster_labels == cluster_i])\n",
    "            training_embs_cluster_index.append((cluster_labels == cluster_i).nonzero().reshape(-1))\n",
    "        num_clusters = len(training_embs_cluster)\n",
    "                \n",
    "                \n",
    "        total_num_cols = 0\n",
    "        self.correctness_checklist = []\n",
    "        for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "            if (split == \"train\") and ((i >= num_train) or (i >= valid_index)):\n",
    "                break\n",
    "            if split == \"valid\" and i < valid_index:\n",
    "                continue\n",
    "            #     break\n",
    "            \n",
    "            group_df = group_df.reset_index(drop=True)\n",
    "\n",
    "                \n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                token_list = group_df[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                        tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=max_length, truncation=True)).tolist()\n",
    "                token_list = torch.nn.utils.rnn.pad_sequence(\n",
    "                [torch.LongTensor(tokens) for tokens in token_list], padding_value=0).T.to(device)\n",
    "                cls_indexes = torch.nonzero(\n",
    "                            token_list == tokenizer.cls_token_id)\n",
    "                logits, embs = model(token_list, cls_indexes=cls_indexes, get_enc=True)\n",
    "                col_embs = embs.cpu()\n",
    "                if len(embs.size()) == 1:\n",
    "                    col_embs = col_embs.unsqueeze(0)\n",
    "                        \n",
    "            labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "            labeled_columns.sort_values(by=['col_idx'], inplace=True)\n",
    "            for index, target_column in labeled_columns.iterrows():\n",
    "                target_col_idx = target_column[\"col_idx\"]\n",
    "                if len(group_df) < max_unlabeled:\n",
    "                    closest_cols = []\n",
    "                    cloeses_scores = []\n",
    "                    for i in range(num_clusters):\n",
    "                        sim = F.cosine_similarity(training_embs_cluster[i], col_embs[index].reshape(1, -1))\n",
    "                        sim_score_i = sim.max().item()\n",
    "                        closest_index = training_embs_cluster_index[i][sim.argmax().item()].item()\n",
    "                        closest_cols.append(closest_index)\n",
    "                        cloeses_scores.append(sim_score_i)\n",
    "                    cloeses_scores_topk = torch.Tensor(cloeses_scores).argsort(descending=True)[:max_unlabeled-len(group_df)]\n",
    "                    closest_cols = torch.tensor(closest_cols)[cloeses_scores_topk].tolist()\n",
    "                    target_table = pd.concat([group_df, df_train_labeled.iloc[closest_cols]], ignore_index=True)\n",
    "                    assert len(target_table) == max_unlabeled\n",
    "                    # if len(target_table) < max_unlabeled:\n",
    "                    #     print(len(target_table), max_unlabeled)\n",
    "                else:\n",
    "                    target_table = group_df\n",
    "\n",
    "    \n",
    "                \n",
    "                target_cls = target_column[\"class_id\"]\n",
    "                target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "                col_idx_list = target_table[\"col_idx\"].tolist()\n",
    "                # target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "\n",
    "                if max_length <= 128 and adaptive_max_length:\n",
    "                    cur_maxlen = min(max_length, 512 // len(target_table) - 1)\n",
    "                else:\n",
    "                    cur_maxlen = max_length\n",
    "                    \n",
    "                token_ids_list = target_table[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                    tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=cur_maxlen, truncation=True)).tolist(\n",
    "                    )\n",
    "                token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                                    token_ids_list)).to(device)\n",
    "\n",
    "                target_col_mask = []\n",
    "                cls_index_value = 0\n",
    "                context_id = 1\n",
    "                meet_target = False\n",
    "                for idx, col_i in enumerate(col_idx_list):\n",
    "                    if col_i == target_col_idx:\n",
    "                        target_col_mask += [0] * len(token_ids_list[idx])\n",
    "                        meet_target = True\n",
    "                    else:\n",
    "                        target_col_mask += [context_id] * len(token_ids_list[idx])\n",
    "                        context_id += 1\n",
    "                    if not meet_target:\n",
    "                        cls_index_value += len(token_ids_list[idx])\n",
    "                cls_index_list = [cls_index_value] \n",
    "                for cls_index in cls_index_list:\n",
    "                    assert token_ids[\n",
    "                        cls_index] == tokenizer.cls_token_id, \"cls_indexes validation\"\n",
    "                cls_indexes = torch.LongTensor(cls_index_list).to(device)\n",
    "                class_ids = torch.LongTensor(\n",
    "                    [target_cls]).to(device)\n",
    "                target_col_mask = torch.LongTensor(target_col_mask).to(device)\n",
    "                data_list.append(\n",
    "                    [index,\n",
    "                    len(target_table), token_ids, class_ids, cls_indexes, target_col_mask])                \n",
    "        print(split, len(data_list))\n",
    "        self.table_df = pd.DataFrame(data_list,\n",
    "                                     columns=[\n",
    "                                         \"table_id\", \"num_col\", \"data_tensor\",\n",
    "                                         \"label_tensor\", \"cls_indexes\", \"target_col_mask\"\n",
    "                                     ])\n",
    "        \"\"\"\n",
    "        # NOTE: msato contains a small portion of single-col tables. keep it to be consistent.  \n",
    "        if multicol_only:\n",
    "            # Check\n",
    "            num_all_tables = len(self.table_df)\n",
    "            self.table_df = self.table_df[self.table_df[\"num_col\"] > 1]\n",
    "            assert len(self.table_df) == num_all_tables\n",
    "        \"\"\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.table_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"data\": self.table_df.iloc[idx][\"data_tensor\"],\n",
    "            \"label\": self.table_df.iloc[idx][\"label_tensor\"],\n",
    "            \"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"],\n",
    "            \"target_col_mask\": self.table_df.iloc[idx][\"target_col_mask\"],\n",
    "        }\n",
    "        #\"idx\": torch.LongTensor([idx])}\n",
    "        #\"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "class GittablesTablewiseIterateClusterDataset(data.Dataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            cv: int,\n",
    "            split: str,\n",
    "            src: str,  # train or test\n",
    "            tokenizer: AutoTokenizer,\n",
    "            max_length: int = 256,\n",
    "            gt_only: bool = False,\n",
    "            device: torch.device = None,\n",
    "            base_dirpath: str = \"/data/zhihao/TU/GitTables/semtab_gittables/2022\",\n",
    "            base_tag: str = '', # blank, comma\n",
    "            small_tag: str = \"\",\n",
    "            train_ratio: float = 1.0,\n",
    "            max_unlabeled=8,\n",
    "            adaptive_max_length=True,\n",
    "            random_sample=False, # TODO\n",
    "            train_only=False): # TODO\n",
    "        if device is None:\n",
    "            device = torch.device('cpu')\n",
    "        basename = small_tag+ \"_cv_{}.csv\"\n",
    "    \n",
    "        if split in [\"train\", \"valid\"]:\n",
    "            df_list = []\n",
    "            for i in range(5):\n",
    "                if i == cv:\n",
    "                    continue\n",
    "                filepath = os.path.join(base_dirpath, basename.format(i))\n",
    "                df_list.append(pd.read_csv(filepath))\n",
    "                print(split, i)\n",
    "            df = pd.concat(df_list, axis=0)\n",
    "        else:\n",
    "            # test\n",
    "            filepath = os.path.join(base_dirpath, basename.format(cv))\n",
    "            df = pd.read_csv(filepath)\n",
    "            print(split)\n",
    "\n",
    "\n",
    "        if gt_only:\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "        if train_only and split != \"train\":\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "\n",
    "        \n",
    "        data_list = []\n",
    "        \n",
    "        df['class_id'] = df['class_id'].astype(int)\n",
    "        df.drop(df[(df['data'].isna()) & (df['class_id'] == -1)].index, inplace=True)\n",
    "        df['col_idx'] = df['col_idx'].astype(int)\n",
    "        df['data'] = df['data'].astype(str)\n",
    "        \n",
    "        num_tables = len(df.groupby(\"table_id\"))\n",
    "        valid_index = int(num_tables * 0.8)\n",
    "        num_train = int(train_ratio * num_tables * 0.8)        \n",
    "        \n",
    "        # df.drop(df[(df['data'] == '') & (df['class_id'] == -1)].index, inplace=True)\n",
    "        total_num_cols = 0\n",
    "        self.correctness_checklist = []\n",
    "        for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "            if (split == \"train\") and ((i >= num_train) or (i >= valid_index)):\n",
    "                break\n",
    "            if split == \"valid\" and i < valid_index:\n",
    "                continue\n",
    "            #     break\n",
    "            \n",
    "            group_df = group_df.reset_index(drop=True)\n",
    "            # scores = bm25.get_scores(test_dataset_gt[idx][\"data\"].cpu().tolist())\n",
    "            # semantic_scores = torch.tensor(group_df[\"data\"].apply(lambda x: max(bm25.get_scores(tokenizer.encode(\n",
    "            #         tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=max_length, truncation=True)))))\n",
    "            \n",
    "            # labeled_columns_index = group_df[group_df['class_id'] > -1].index.to_list()\n",
    "            # assert len(labeled_columns_index) < 8\n",
    "            # if set(labeled_columns_index).issubset(set(semantic_scores.topk(min(len(group_df), max_unlabeled)).indices.tolist())):\n",
    "            #     self.correctness_checklist.append(1)\n",
    "            # else:\n",
    "            #     self.correctness_checklist.append(0)\n",
    "            if len(group_df) > max_unlabeled:\n",
    "                # col_embs = sb_model.encode(group_df[\"data\"].to_list())\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    model.eval()\n",
    "                    token_list = group_df[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                            tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=max_length, truncation=True)).tolist()\n",
    "                    token_list = torch.nn.utils.rnn.pad_sequence(\n",
    "                    [torch.LongTensor(tokens) for tokens in token_list], padding_value=0).T.to(device)\n",
    "                    cls_indexes = torch.nonzero(\n",
    "                                token_list == tokenizer.cls_token_id)\n",
    "                    logits, embs = model(token_list, cls_indexes=cls_indexes, get_enc=True)\n",
    "                    col_embs = embs.cpu()\n",
    "                    if len(embs.size()) == 1:\n",
    "                        col_embs = col_embs.unsqueeze(0)\n",
    "                        \n",
    "                kmeans = KMeans(n_clusters=max_unlabeled-1, random_state=0).fit(col_embs)\n",
    "                centers = torch.tensor(kmeans.cluster_centers_)\n",
    "                col_embs = torch.tensor(col_embs)\n",
    "                cluster_labels = torch.tensor(kmeans.labels_)\n",
    "                col_embs_cluster = []\n",
    "                col_embs_cluster_index = []\n",
    "                for cluster_i in np.unique(kmeans.labels_):\n",
    "                    col_embs_cluster.append(col_embs[cluster_labels == cluster_i])\n",
    "                    col_embs_cluster_index.append((cluster_labels == cluster_i).nonzero().reshape(-1))\n",
    "                num_clusters = len(col_embs_cluster)\n",
    "            labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "            labeled_columns.sort_values(by=['col_idx'], inplace=True)\n",
    "            for index, target_column in labeled_columns.iterrows():\n",
    "                target_col_idx = target_column[\"col_idx\"]\n",
    "                if len(group_df) > max_unlabeled:\n",
    "                    closest_cols = []\n",
    "                    for i in range(num_clusters):\n",
    "                        # try:\n",
    "                        sim = F.cosine_similarity(col_embs_cluster[i], col_embs[index].reshape(1, -1))\n",
    "                        # except:\n",
    "                        #     raise ValueError(\"here\")\n",
    "                        # try:\n",
    "                        closest_index = col_embs_cluster_index[i][sim.argmax().item()].item()\n",
    "                        # except:\n",
    "                        #     print(\"here\")\n",
    "                        if closest_index == index and len(col_embs_cluster[i]) > 1:\n",
    "                            closest_index = col_embs_cluster_index[i][sim.argsort(descending=True)[1].item()].item()\n",
    "                        closest_cols.append(closest_index)\n",
    "                    other_columns = group_df.iloc[closest_cols]\n",
    "                else:\n",
    "                    other_columns = group_df.drop(index)\n",
    "                target_table = pd.concat([target_column.to_frame().T, other_columns], ignore_index=True)\n",
    "                \n",
    "                # if len(group_df) >= 8:\n",
    "                #     assert len(target_table) == max_unlabeled\n",
    "                # else:\n",
    "                #     assert len(target_table) == len(group_df)\n",
    "    \n",
    "                \n",
    "                target_cls = target_column[\"class_id\"]\n",
    "                target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "                col_idx_list = target_table[\"col_idx\"].tolist()\n",
    "                # target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "\n",
    "                if max_length <= 128 and adaptive_max_length:\n",
    "                    cur_maxlen = min(max_length, 512 // len(target_table) - 1)\n",
    "                else:\n",
    "                    cur_maxlen = max_length\n",
    "                    \n",
    "                token_ids_list = target_table[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                    tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=cur_maxlen, truncation=True)).tolist(\n",
    "                    )\n",
    "                token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                                    token_ids_list)).to(device)\n",
    "\n",
    "                target_col_mask = []\n",
    "                cls_index_value = 0\n",
    "                context_id = 1\n",
    "                meet_target = False\n",
    "                for idx, col_i in enumerate(col_idx_list):\n",
    "                    if col_i == target_col_idx:\n",
    "                        target_col_mask += [0] * len(token_ids_list[idx])\n",
    "                        meet_target = True\n",
    "                    else:\n",
    "                        target_col_mask += [context_id] * len(token_ids_list[idx])\n",
    "                        context_id += 1\n",
    "                    if not meet_target:\n",
    "                        cls_index_value += len(token_ids_list[idx])\n",
    "                cls_index_list = [cls_index_value] \n",
    "                for cls_index in cls_index_list:\n",
    "                    assert token_ids[\n",
    "                        cls_index] == tokenizer.cls_token_id, \"cls_indexes validation\"\n",
    "                cls_indexes = torch.LongTensor(cls_index_list).to(device)\n",
    "                class_ids = torch.LongTensor(\n",
    "                    [target_cls]).to(device)\n",
    "                target_col_mask = torch.LongTensor(target_col_mask).to(device)\n",
    "                data_list.append(\n",
    "                    [index,\n",
    "                    len(target_table), token_ids, class_ids, cls_indexes, target_col_mask])                \n",
    "        print(split, len(data_list))\n",
    "        self.table_df = pd.DataFrame(data_list,\n",
    "                                     columns=[\n",
    "                                         \"table_id\", \"num_col\", \"data_tensor\",\n",
    "                                         \"label_tensor\", \"cls_indexes\", \"target_col_mask\"\n",
    "                                     ])\n",
    "        \"\"\"\n",
    "        # NOTE: msato contains a small portion of single-col tables. keep it to be consistent.  \n",
    "        if multicol_only:\n",
    "            # Check\n",
    "            num_all_tables = len(self.table_df)\n",
    "            self.table_df = self.table_df[self.table_df[\"num_col\"] > 1]\n",
    "            assert len(self.table_df) == num_all_tables\n",
    "        \"\"\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.table_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"data\": self.table_df.iloc[idx][\"data_tensor\"],\n",
    "            \"label\": self.table_df.iloc[idx][\"label_tensor\"],\n",
    "            \"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"],\n",
    "            \"target_col_mask\": self.table_df.iloc[idx][\"target_col_mask\"],\n",
    "        }\n",
    "        #\"idx\": torch.LongTensor([idx])}\n",
    "        #\"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class GittablesTablewiseIterateClusterDataset(data.Dataset):\n",
    "\n",
    "#     def __init__(\n",
    "#             self,\n",
    "#             cv: int,\n",
    "#             split: str,\n",
    "#             src: str,  # train or test\n",
    "#             tokenizer: AutoTokenizer,\n",
    "#             max_length: int = 256,\n",
    "#             gt_only: bool = False,\n",
    "#             device: torch.device = None,\n",
    "#             base_dirpath: str = \"/data/zhihao/TU/GitTables/semtab_gittables/2022\",\n",
    "#             base_tag: str = '', # blank, comma\n",
    "#             small_tag: str = \"\",\n",
    "#             train_ratio: float = 1.0,\n",
    "#             max_unlabeled=8,\n",
    "#             adaptive_max_length=True,\n",
    "#             random_sample=False, # TODO\n",
    "#             train_only=False): # TODO\n",
    "#         if device is None:\n",
    "#             device = torch.device('cpu')\n",
    "#         basename = small_tag+ \"_cv_{}.csv\"\n",
    "    \n",
    "#         if split in [\"train\", \"valid\"]:\n",
    "#             df_list = []\n",
    "#             for i in range(5):\n",
    "#                 if i == cv:\n",
    "#                     continue\n",
    "#                 filepath = os.path.join(base_dirpath, basename.format(i))\n",
    "#                 df_list.append(pd.read_csv(filepath))\n",
    "#                 print(split, i)\n",
    "#             df = pd.concat(df_list, axis=0)\n",
    "#         else:\n",
    "#             # test\n",
    "#             filepath = os.path.join(base_dirpath, basename.format(cv))\n",
    "#             df = pd.read_csv(filepath)\n",
    "#             print(split)\n",
    "\n",
    "\n",
    "#         if gt_only:\n",
    "#             df = df[df[\"class_id\"] > -1]\n",
    "#         if train_only and split != \"train\":\n",
    "#             df = df[df[\"class_id\"] > -1]\n",
    "\n",
    "        \n",
    "#         data_list = []\n",
    "        \n",
    "#         df['class_id'] = df['class_id'].astype(int)\n",
    "#         df.drop(df[(df['data'].isna()) & (df['class_id'] == -1)].index, inplace=True)\n",
    "#         df['col_idx'] = df['col_idx'].astype(int)\n",
    "#         df['data'] = df['data'].astype(str)\n",
    "        \n",
    "#         num_tables = len(df.groupby(\"table_id\"))\n",
    "#         valid_index = int(num_tables * 0.8)\n",
    "#         num_train = int(train_ratio * num_tables * 0.8)        \n",
    "        \n",
    "#         # df.drop(df[(df['data'] == '') & (df['class_id'] == -1)].index, inplace=True)\n",
    "#         total_num_cols = 0\n",
    "#         self.correctness_checklist = []\n",
    "#         for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "#             if (split == \"train\") and ((i >= num_train) or (i >= valid_index)):\n",
    "#                 break\n",
    "#             if split == \"valid\" and i < valid_index:\n",
    "#                 continue\n",
    "#             #     break\n",
    "            \n",
    "#             group_df = group_df.reset_index(drop=True)\n",
    "#             # scores = bm25.get_scores(test_dataset_gt[idx][\"data\"].cpu().tolist())\n",
    "#             # semantic_scores = torch.tensor(group_df[\"data\"].apply(lambda x: max(bm25.get_scores(tokenizer.encode(\n",
    "#             #         tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=max_length, truncation=True)))))\n",
    "            \n",
    "#             # labeled_columns_index = group_df[group_df['class_id'] > -1].index.to_list()\n",
    "#             # assert len(labeled_columns_index) < 8\n",
    "#             # if set(labeled_columns_index).issubset(set(semantic_scores.topk(min(len(group_df), max_unlabeled)).indices.tolist())):\n",
    "#             #     self.correctness_checklist.append(1)\n",
    "#             # else:\n",
    "#             #     self.correctness_checklist.append(0)\n",
    "#             if len(group_df) > max_unlabeled:\n",
    "#                 # col_embs = sb_model.encode(group_df[\"data\"].to_list())\n",
    "                \n",
    "#                 with torch.no_grad():\n",
    "#                     model.eval()\n",
    "#                     token_list = group_df[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "#                             tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=max_length, truncation=True)).tolist()\n",
    "#                     token_list = torch.nn.utils.rnn.pad_sequence(\n",
    "#                     [torch.LongTensor(tokens) for tokens in token_list], padding_value=0).T.to(device)\n",
    "#                     cls_indexes = torch.nonzero(\n",
    "#                                 token_list == tokenizer.cls_token_id)\n",
    "#                     logits, embs = model(token_list, cls_indexes=cls_indexes, get_enc=True)\n",
    "#                     col_embs = embs.cpu()\n",
    "#                     if len(embs.size()) == 1:\n",
    "#                         col_embs = col_embs.unsqueeze(0)\n",
    "                        \n",
    "#                 kmeans = KMeans(n_clusters=max_unlabeled-1, random_state=0).fit(col_embs)\n",
    "#                 centers = torch.tensor(kmeans.cluster_centers_)\n",
    "#                 col_embs = torch.tensor(col_embs)\n",
    "#                 cluster_labels = torch.tensor(kmeans.labels_)\n",
    "#                 col_embs_cluster = []\n",
    "#                 col_embs_cluster_index = []\n",
    "#                 for cluster_i in np.unique(kmeans.labels_):\n",
    "#                     col_embs_cluster.append(col_embs[cluster_labels == cluster_i])\n",
    "#                     col_embs_cluster_index.append((cluster_labels == cluster_i).nonzero().reshape(-1))\n",
    "#                 num_clusters = len(col_embs_cluster)\n",
    "#             labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "#             labeled_columns.sort_values(by=['col_idx'], inplace=True)\n",
    "#             for index, target_column in labeled_columns.iterrows():\n",
    "#                 target_col_idx = target_column[\"col_idx\"]\n",
    "#                 if len(group_df) > max_unlabeled:\n",
    "#                     closest_cols = []\n",
    "#                     for i in range(num_clusters):\n",
    "#                         # try:\n",
    "#                         sim = F.cosine_similarity(col_embs_cluster[i], col_embs[index].reshape(1, -1))\n",
    "#                         # except:\n",
    "#                         #     raise ValueError(\"here\")\n",
    "#                         # try:\n",
    "#                         closest_index = col_embs_cluster_index[i][sim.argmax().item()].item()\n",
    "#                         # except:\n",
    "#                         #     print(\"here\")\n",
    "#                         if closest_index == index and len(col_embs_cluster[i]) > 1:\n",
    "#                             closest_index = col_embs_cluster_index[i][sim.argsort(descending=True)[1].item()].item()\n",
    "#                         closest_cols.append(closest_index)\n",
    "#                     other_columns = group_df.iloc[closest_cols]\n",
    "#                 else:\n",
    "#                     other_columns = group_df.drop(index)\n",
    "#                 target_table = pd.concat([target_column.to_frame().T, other_columns], ignore_index=True)\n",
    "                \n",
    "#                 # if len(group_df) >= 8:\n",
    "#                 #     assert len(target_table) == max_unlabeled\n",
    "#                 # else:\n",
    "#                 #     assert len(target_table) == len(group_df)\n",
    "    \n",
    "                \n",
    "#                 target_cls = target_column[\"class_id\"]\n",
    "#                 target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "#                 col_idx_list = target_table[\"col_idx\"].tolist()\n",
    "#                 # target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "\n",
    "#                 if max_length <= 128 and adaptive_max_length:\n",
    "#                     cur_maxlen = min(max_length, 512 // len(target_table) - 1)\n",
    "#                 else:\n",
    "#                     cur_maxlen = max_length\n",
    "                    \n",
    "#                 token_ids_list = target_table[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "#                     tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=cur_maxlen, truncation=True)).tolist(\n",
    "#                     )\n",
    "#                 token_ids = torch.LongTensor(reduce(operator.add,\n",
    "#                                                     token_ids_list)).to(device)\n",
    "\n",
    "#                 target_col_mask = []\n",
    "#                 cls_index_value = 0\n",
    "#                 context_id = 1\n",
    "#                 meet_target = False\n",
    "#                 for idx, col_i in enumerate(col_idx_list):\n",
    "#                     if col_i == target_col_idx:\n",
    "#                         target_col_mask += [0] * len(token_ids_list[idx])\n",
    "#                         meet_target = True\n",
    "#                     else:\n",
    "#                         target_col_mask += [context_id] * len(token_ids_list[idx])\n",
    "#                         context_id += 1\n",
    "#                     if not meet_target:\n",
    "#                         cls_index_value += len(token_ids_list[idx])\n",
    "#                 cls_index_list = [cls_index_value] \n",
    "#                 for cls_index in cls_index_list:\n",
    "#                     assert token_ids[\n",
    "#                         cls_index] == tokenizer.cls_token_id, \"cls_indexes validation\"\n",
    "#                 cls_indexes = torch.LongTensor(cls_index_list).to(device)\n",
    "#                 class_ids = torch.LongTensor(\n",
    "#                     [target_cls]).to(device)\n",
    "#                 target_col_mask = torch.LongTensor(target_col_mask).to(device)\n",
    "#                 data_list.append(\n",
    "#                     [index,\n",
    "#                     len(target_table), token_ids, class_ids, cls_indexes, target_col_mask])                \n",
    "#         print(split, len(data_list))\n",
    "#         self.table_df = pd.DataFrame(data_list,\n",
    "#                                      columns=[\n",
    "#                                          \"table_id\", \"num_col\", \"data_tensor\",\n",
    "#                                          \"label_tensor\", \"cls_indexes\", \"target_col_mask\"\n",
    "#                                      ])\n",
    "#         \"\"\"\n",
    "#         # NOTE: msato contains a small portion of single-col tables. keep it to be consistent.  \n",
    "#         if multicol_only:\n",
    "#             # Check\n",
    "#             num_all_tables = len(self.table_df)\n",
    "#             self.table_df = self.table_df[self.table_df[\"num_col\"] > 1]\n",
    "#             assert len(self.table_df) == num_all_tables\n",
    "#         \"\"\"\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.table_df)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         return {\n",
    "#             \"data\": self.table_df.iloc[idx][\"data_tensor\"],\n",
    "#             \"label\": self.table_df.iloc[idx][\"label_tensor\"],\n",
    "#             \"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"],\n",
    "#             \"target_col_mask\": self.table_df.iloc[idx][\"target_col_mask\"],\n",
    "#         }\n",
    "#         #\"idx\": torch.LongTensor([idx])}\n",
    "#         #\"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class GittablesTablewiseIterateClusterDataset(data.Dataset):\n",
    "\n",
    "#     def __init__(\n",
    "#             self,\n",
    "#             cv: int,\n",
    "#             split: str,\n",
    "#             src: str,  # train or test\n",
    "#             tokenizer: AutoTokenizer,\n",
    "#             max_length: int = 256,\n",
    "#             gt_only: bool = False,\n",
    "#             device: torch.device = None,\n",
    "#             base_dirpath: str = \"/data/zhihao/TU/GitTables/semtab_gittables/2022\",\n",
    "#             base_tag: str = '', # blank, comma\n",
    "#             small_tag: str = \"\",\n",
    "#             train_ratio: float = 1.0,\n",
    "#             max_unlabeled=8,\n",
    "#             adaptive_max_length=True,\n",
    "#             random_sample=False, # TODO\n",
    "#             train_only=False): # TODO\n",
    "#         if device is None:\n",
    "#             device = torch.device('cpu')\n",
    "#         basename = small_tag+ \"_cv_{}.csv\"\n",
    "    \n",
    "#         if split in [\"train\", \"valid\"]:\n",
    "#             df_list = []\n",
    "#             for i in range(5):\n",
    "#                 if i == cv:\n",
    "#                     continue\n",
    "#                 filepath = os.path.join(base_dirpath, basename.format(i))\n",
    "#                 df_list.append(pd.read_csv(filepath))\n",
    "#                 print(split, i)\n",
    "#             df = pd.concat(df_list, axis=0)\n",
    "#         else:\n",
    "#             # test\n",
    "#             filepath = os.path.join(base_dirpath, basename.format(cv))\n",
    "#             df = pd.read_csv(filepath)\n",
    "#             print(split)\n",
    "\n",
    "\n",
    "#         if gt_only:\n",
    "#             df = df[df[\"class_id\"] > -1]\n",
    "#         if train_only and split != \"train\":\n",
    "#             df = df[df[\"class_id\"] > -1]\n",
    "\n",
    "        \n",
    "#         data_list = []\n",
    "        \n",
    "#         df['class_id'] = df['class_id'].astype(int)\n",
    "#         df.drop(df[(df['data'].isna()) & (df['class_id'] == -1)].index, inplace=True)\n",
    "#         df['col_idx'] = df['col_idx'].astype(int)\n",
    "#         df['data'] = df['data'].astype(str)\n",
    "        \n",
    "#         num_tables = len(df.groupby(\"table_id\"))\n",
    "#         valid_index = int(num_tables * 0.8)\n",
    "#         num_train = int(train_ratio * num_tables * 0.8)        \n",
    "        \n",
    "#         # df.drop(df[(df['data'] == '') & (df['class_id'] == -1)].index, inplace=True)\n",
    "#         total_num_cols = 0\n",
    "#         self.correctness_checklist = []\n",
    "#         for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "#             if (split == \"train\") and ((i >= num_train) or (i >= valid_index)):\n",
    "#                 break\n",
    "#             if split == \"valid\" and i < valid_index:\n",
    "#                 continue\n",
    "#             #     break\n",
    "            \n",
    "#             group_df = group_df.reset_index(drop=True)\n",
    "#             # scores = bm25.get_scores(test_dataset_gt[idx][\"data\"].cpu().tolist())\n",
    "#             # semantic_scores = torch.tensor(group_df[\"data\"].apply(lambda x: max(bm25.get_scores(tokenizer.encode(\n",
    "#             #         tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=max_length, truncation=True)))))\n",
    "            \n",
    "#             # labeled_columns_index = group_df[group_df['class_id'] > -1].index.to_list()\n",
    "#             # assert len(labeled_columns_index) < 8\n",
    "#             # if set(labeled_columns_index).issubset(set(semantic_scores.topk(min(len(group_df), max_unlabeled)).indices.tolist())):\n",
    "#             #     self.correctness_checklist.append(1)\n",
    "#             # else:\n",
    "#             #     self.correctness_checklist.append(0)\n",
    "#             if len(group_df) > max_unlabeled:\n",
    "#                 # col_embs = sb_model.encode(group_df[\"data\"].to_list())\n",
    "                \n",
    "#                 with torch.no_grad():\n",
    "#                     model.eval()\n",
    "#                     token_list = group_df[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "#                             tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=max_length, truncation=True)).tolist()\n",
    "#                     token_list = torch.nn.utils.rnn.pad_sequence(\n",
    "#                     [torch.LongTensor(tokens) for tokens in token_list], padding_value=0).T.to(device)\n",
    "#                     cls_indexes = torch.nonzero(\n",
    "#                                 token_list == tokenizer.cls_token_id)\n",
    "#                     logits, embs = model(token_list, cls_indexes=cls_indexes, get_enc=True)\n",
    "#                     col_embs = embs.cpu()\n",
    "#                     if len(embs.size()) == 1:\n",
    "#                         col_embs = col_embs.unsqueeze(0)\n",
    "                        \n",
    "#                 kmeans = KMeans(n_clusters=max_unlabeled-1, random_state=0).fit(col_embs)\n",
    "#                 centers = torch.tensor(kmeans.cluster_centers_)\n",
    "#                 col_embs = torch.tensor(col_embs)\n",
    "                \n",
    "#             labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "#             labeled_columns.sort_values(by=['col_idx'], inplace=True)\n",
    "#             for index, target_column in labeled_columns.iterrows():\n",
    "#                 target_col_idx = target_column[\"col_idx\"]\n",
    "#                 if len(group_df) > max_unlabeled:\n",
    "#                     closest_cols = []\n",
    "#                     for i in range(max_unlabeled-1):\n",
    "#                         sim = F.cosine_similarity(col_embs, centers[i].reshape(1, -1))\n",
    "#                         closest_index = sim.argmax().item()\n",
    "#                         if closest_index == target_col_idx:\n",
    "#                             closest_index = sim.argsort(descending=True)[1].item()\n",
    "#                         closest_cols.append(closest_index)\n",
    "#                     other_columns = group_df.iloc[closest_cols]\n",
    "#                 else:\n",
    "#                     other_columns = group_df.drop(index)\n",
    "#                 target_table = pd.concat([target_column.to_frame().T, other_columns], ignore_index=True)\n",
    "                \n",
    "#                 # if len(group_df) >= 8:\n",
    "#                 #     assert len(target_table) == max_unlabeled\n",
    "#                 # else:\n",
    "#                 #     assert len(target_table) == len(group_df)\n",
    "    \n",
    "                \n",
    "#                 target_cls = target_column[\"class_id\"]\n",
    "#                 target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "#                 col_idx_list = target_table[\"col_idx\"].tolist()\n",
    "#                 # target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "\n",
    "#                 if max_length <= 128 and adaptive_max_length:\n",
    "#                     cur_maxlen = min(max_length, 512 // len(target_table) - 1)\n",
    "#                 else:\n",
    "#                     cur_maxlen = max_length\n",
    "                    \n",
    "#                 token_ids_list = target_table[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "#                     tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=cur_maxlen, truncation=True)).tolist(\n",
    "#                     )\n",
    "#                 token_ids = torch.LongTensor(reduce(operator.add,\n",
    "#                                                     token_ids_list)).to(device)\n",
    "\n",
    "#                 target_col_mask = []\n",
    "#                 cls_index_value = 0\n",
    "#                 context_id = 1\n",
    "#                 meet_target = False\n",
    "#                 for idx, col_i in enumerate(col_idx_list):\n",
    "#                     if col_i == target_col_idx:\n",
    "#                         target_col_mask += [0] * len(token_ids_list[idx])\n",
    "#                         meet_target = True\n",
    "#                     else:\n",
    "#                         target_col_mask += [context_id] * len(token_ids_list[idx])\n",
    "#                         context_id += 1\n",
    "#                     if not meet_target:\n",
    "#                         cls_index_value += len(token_ids_list[idx])\n",
    "#                 cls_index_list = [cls_index_value] \n",
    "#                 for cls_index in cls_index_list:\n",
    "#                     assert token_ids[\n",
    "#                         cls_index] == tokenizer.cls_token_id, \"cls_indexes validation\"\n",
    "#                 cls_indexes = torch.LongTensor(cls_index_list).to(device)\n",
    "#                 class_ids = torch.LongTensor(\n",
    "#                     [target_cls]).to(device)\n",
    "#                 target_col_mask = torch.LongTensor(target_col_mask).to(device)\n",
    "#                 data_list.append(\n",
    "#                     [index,\n",
    "#                     len(target_table), token_ids, class_ids, cls_indexes, target_col_mask])                \n",
    "#         print(split, len(data_list))\n",
    "#         self.table_df = pd.DataFrame(data_list,\n",
    "#                                      columns=[\n",
    "#                                          \"table_id\", \"num_col\", \"data_tensor\",\n",
    "#                                          \"label_tensor\", \"cls_indexes\", \"target_col_mask\"\n",
    "#                                      ])\n",
    "#         \"\"\"\n",
    "#         # NOTE: msato contains a small portion of single-col tables. keep it to be consistent.  \n",
    "#         if multicol_only:\n",
    "#             # Check\n",
    "#             num_all_tables = len(self.table_df)\n",
    "#             self.table_df = self.table_df[self.table_df[\"num_col\"] > 1]\n",
    "#             assert len(self.table_df) == num_all_tables\n",
    "#         \"\"\"\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.table_df)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         return {\n",
    "#             \"data\": self.table_df.iloc[idx][\"data_tensor\"],\n",
    "#             \"label\": self.table_df.iloc[idx][\"label_tensor\"],\n",
    "#             \"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"],\n",
    "#             \"target_col_mask\": self.table_df.iloc[idx][\"target_col_mask\"],\n",
    "#         }\n",
    "#         #\"idx\": torch.LongTensor([idx])}\n",
    "#         #\"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GittablesTablewiseIterateLabelDataset(data.Dataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            cv: int,\n",
    "            split: str,\n",
    "            src: str,  # train or test\n",
    "            tokenizer: AutoTokenizer,\n",
    "            max_length: int = 256,\n",
    "            gt_only: bool = False,\n",
    "            device: torch.device = None,\n",
    "            base_dirpath: str = \"/data/zhihao/TU/GitTables/semtab_gittables/2022\",\n",
    "            base_tag: str = '', # blank, comma\n",
    "            small_tag: str = \"\",\n",
    "            train_ratio: float = 1.0,\n",
    "            max_unlabeled=8,\n",
    "            adaptive_max_length=True,\n",
    "            random_sample=False, # TODO\n",
    "            train_only=False): # TODO\n",
    "        if device is None:\n",
    "            device = torch.device('cpu')\n",
    "        basename = small_tag+ \"_cv_{}.csv\"\n",
    "    \n",
    "        if split in [\"train\", \"valid\"]:\n",
    "            df_list = []\n",
    "            for i in range(5):\n",
    "                if i == cv:\n",
    "                    continue\n",
    "                filepath = os.path.join(base_dirpath, basename.format(i))\n",
    "                df_list.append(pd.read_csv(filepath))\n",
    "                print(split, i)\n",
    "            df = pd.concat(df_list, axis=0)\n",
    "        else:\n",
    "            # test\n",
    "            filepath = os.path.join(base_dirpath, basename.format(cv))\n",
    "            df = pd.read_csv(filepath)\n",
    "            print(split)\n",
    "\n",
    "\n",
    "        if gt_only:\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "        if train_only and split != \"train\":\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "\n",
    "        \n",
    "        data_list = []\n",
    "        \n",
    "        df['class_id'] = df['class_id'].astype(int)\n",
    "        df.drop(df[(df['data'].isna()) & (df['class_id'] == -1)].index, inplace=True)\n",
    "        df['col_idx'] = df['col_idx'].astype(int)\n",
    "        df['data'] = df['data'].astype(str)\n",
    "        \n",
    "        num_tables = len(df.groupby(\"table_id\"))\n",
    "        valid_index = int(num_tables * 0.8)\n",
    "        num_train = int(train_ratio * num_tables * 0.8)        \n",
    "        \n",
    "        # df.drop(df[(df['data'] == '') & (df['class_id'] == -1)].index, inplace=True)\n",
    "        total_num_cols = 0\n",
    "        self.correctness_checklist = []\n",
    "        for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "            if (split == \"train\") and ((i >= num_train) or (i >= valid_index)):\n",
    "                break\n",
    "            if split == \"valid\" and i < valid_index:\n",
    "                continue\n",
    "            #     break\n",
    "            \n",
    "            group_df = group_df.reset_index(drop=True)\n",
    "            # scores = bm25.get_scores(test_dataset_gt[idx][\"data\"].cpu().tolist())\n",
    "            # semantic_scores = torch.tensor(group_df[\"data\"].apply(lambda x: max(bm25.get_scores(tokenizer.encode(\n",
    "            #         tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=max_length, truncation=True)))))\n",
    "            \n",
    "            # labeled_columns_index = group_df[group_df['class_id'] > -1].index.to_list()\n",
    "            # assert len(labeled_columns_index) < 8\n",
    "            # if set(labeled_columns_index).issubset(set(semantic_scores.topk(min(len(group_df), max_unlabeled)).indices.tolist())):\n",
    "            #     self.correctness_checklist.append(1)\n",
    "            # else:\n",
    "            #     self.correctness_checklist.append(0)\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                token_list = group_df[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                        tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=max_length, truncation=True)).tolist()\n",
    "                token_list = torch.nn.utils.rnn.pad_sequence(\n",
    "                [torch.LongTensor(tokens) for tokens in token_list], padding_value=0).T.to(device)\n",
    "                cls_indexes = torch.nonzero(\n",
    "                            token_list == tokenizer.cls_token_id)\n",
    "                logits, embs = model(token_list, cls_indexes=cls_indexes, get_enc=True)\n",
    "                embs = embs.cpu()\n",
    "                if len(embs.size()) == 1:\n",
    "                    embs = embs.unsqueeze(0)\n",
    "                # semantic_scores = torch.mm(training_corpus_embs_doduo_center/ training_corpus_embs_doduo_center.norm(dim=1, keepdim=True), (embs/ embs.norm(dim=1, keepdim=True)).T).T.topk(1).values.mean(1)\n",
    "                semantic_scores = (1/ (torch.cdist(embs, training_corpus_embs_doduo)+1e-5)).topk(1).values.mean(1)\n",
    "            \n",
    "                \n",
    "            group_df[\"semantic_scores\"] = semantic_scores\n",
    "            group_df.sort_values(by=['semantic_scores'], ascending=False, inplace=True) \n",
    "            labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "            labeled_columns.sort_values(by=['col_idx'], inplace=True)\n",
    "            for index, target_column in labeled_columns.iterrows():\n",
    "                other_columns = group_df.drop(index)\n",
    "                # other_labeled = other_columns[other_columns['class_id'] > -1].head(max_unlabeled-1)\n",
    "                # other_unlabeled = other_columns[other_columns['class_id'] == -1].drop_duplicates(subset=['data'], keep='first').head(max_unlabeled-len(other_labeled)-1)\n",
    "                # target_table = pd.concat([target_column.to_frame().T, other_labeled, other_unlabeled], ignore_index=True)\n",
    "                \n",
    "                other_columns = other_columns.head(max_unlabeled-1)\n",
    "                target_table = pd.concat([target_column.to_frame().T, other_columns], ignore_index=True)\n",
    "                \n",
    "                # if len(group_df) >= 8:\n",
    "                #     assert len(target_table) == max_unlabeled\n",
    "                # else:\n",
    "                #     assert len(target_table) == len(group_df)\n",
    "    \n",
    "                target_col_idx = target_column[\"col_idx\"]\n",
    "                target_cls = target_column[\"class_id\"]\n",
    "                target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "                col_idx_list = target_table[\"col_idx\"].tolist()\n",
    "                # target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "\n",
    "                if max_length <= 128 and adaptive_max_length:\n",
    "                    cur_maxlen = min(max_length, 512 // len(target_table) - 1)\n",
    "                else:\n",
    "                    cur_maxlen = max_length\n",
    "                    \n",
    "                token_ids_list = target_table[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                    tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=cur_maxlen, truncation=True)).tolist(\n",
    "                    )\n",
    "                token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                                    token_ids_list)).to(device)\n",
    "\n",
    "                target_col_mask = []\n",
    "                cls_index_value = 0\n",
    "                context_id = 1\n",
    "                meet_target = False\n",
    "                for idx, col_i in enumerate(col_idx_list):\n",
    "                    if col_i == target_col_idx:\n",
    "                        target_col_mask += [0] * len(token_ids_list[idx])\n",
    "                        meet_target = True\n",
    "                    else:\n",
    "                        target_col_mask += [context_id] * len(token_ids_list[idx])\n",
    "                        context_id += 1\n",
    "                    if not meet_target:\n",
    "                        cls_index_value += len(token_ids_list[idx])\n",
    "                cls_index_list = [cls_index_value] \n",
    "                for cls_index in cls_index_list:\n",
    "                    assert token_ids[\n",
    "                        cls_index] == tokenizer.cls_token_id, \"cls_indexes validation\"\n",
    "                cls_indexes = torch.LongTensor(cls_index_list).to(device)\n",
    "                class_ids = torch.LongTensor(\n",
    "                    [target_cls]).to(device)\n",
    "                target_col_mask = torch.LongTensor(target_col_mask).to(device)\n",
    "                data_list.append(\n",
    "                    [index,\n",
    "                    len(target_table), token_ids, class_ids, cls_indexes, target_col_mask])                \n",
    "        print(split, len(data_list))\n",
    "        self.table_df = pd.DataFrame(data_list,\n",
    "                                     columns=[\n",
    "                                         \"table_id\", \"num_col\", \"data_tensor\",\n",
    "                                         \"label_tensor\", \"cls_indexes\", \"target_col_mask\"\n",
    "                                     ])\n",
    "        \"\"\"\n",
    "        # NOTE: msato contains a small portion of single-col tables. keep it to be consistent.  \n",
    "        if multicol_only:\n",
    "            # Check\n",
    "            num_all_tables = len(self.table_df)\n",
    "            self.table_df = self.table_df[self.table_df[\"num_col\"] > 1]\n",
    "            assert len(self.table_df) == num_all_tables\n",
    "        \"\"\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.table_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"data\": self.table_df.iloc[idx][\"data_tensor\"],\n",
    "            \"label\": self.table_df.iloc[idx][\"label_tensor\"],\n",
    "            \"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"],\n",
    "            \"target_col_mask\": self.table_df.iloc[idx][\"target_col_mask\"],\n",
    "        }\n",
    "        #\"idx\": torch.LongTensor([idx])}\n",
    "        #\"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GittablesTablewiseIterateSemanticDataset(data.Dataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            cv: int,\n",
    "            split: str,\n",
    "            src: str,  # train or test\n",
    "            tokenizer: AutoTokenizer,\n",
    "            max_length: int = 256,\n",
    "            gt_only: bool = False,\n",
    "            device: torch.device = None,\n",
    "            base_dirpath: str = \"/data/zhihao/TU/GitTables/semtab_gittables/2022\",\n",
    "            base_tag: str = '', # blank, comma\n",
    "            small_tag: str = \"\",\n",
    "            train_ratio: float = 1.0,\n",
    "            max_unlabeled=8,\n",
    "            adaptive_max_length=True,\n",
    "            random_sample=False, # TODO\n",
    "            train_only=False): # TODO\n",
    "        if device is None:\n",
    "            device = torch.device('cpu')\n",
    "        basename = small_tag+ \"_cv_{}.csv\"\n",
    "    \n",
    "        if split in [\"train\", \"valid\"]:\n",
    "            df_list = []\n",
    "            for i in range(5):\n",
    "                if i == cv:\n",
    "                    continue\n",
    "                filepath = os.path.join(base_dirpath, basename.format(i))\n",
    "                df_list.append(pd.read_csv(filepath))\n",
    "                print(split, i)\n",
    "            df = pd.concat(df_list, axis=0)\n",
    "        else:\n",
    "            # test\n",
    "            filepath = os.path.join(base_dirpath, basename.format(cv))\n",
    "            df = pd.read_csv(filepath)\n",
    "            print(split)\n",
    "\n",
    "\n",
    "        if gt_only:\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "        if train_only and split != \"train\":\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "\n",
    "        \n",
    "        data_list = []\n",
    "        \n",
    "        df['class_id'] = df['class_id'].astype(int)\n",
    "        df.drop(df[(df['data'].isna()) & (df['class_id'] == -1)].index, inplace=True)\n",
    "        df['col_idx'] = df['col_idx'].astype(int)\n",
    "        df['data'] = df['data'].astype(str)\n",
    "        \n",
    "        num_tables = len(df.groupby(\"table_id\"))\n",
    "        valid_index = int(num_tables * 0.8)\n",
    "        num_train = int(train_ratio * num_tables * 0.8)        \n",
    "        \n",
    "        # df.drop(df[(df['data'] == '') & (df['class_id'] == -1)].index, inplace=True)\n",
    "        total_num_cols = 0\n",
    "        for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "            if (split == \"train\") and ((i >= num_train) or (i >= valid_index)):\n",
    "                break\n",
    "            if split == \"valid\" and i < valid_index:\n",
    "                continue\n",
    "            #     break\n",
    "            \n",
    "            group_df = group_df.reset_index(drop=True)\n",
    "            semantic_scores = torch.tensor(group_df[\"data\"].apply(lambda x: classify_column(x.split(';'))).tolist())\n",
    "            group_df[\"semantic_scores\"] = semantic_scores\n",
    "            group_df.sort_values(by=['semantic_scores'], ascending=False, inplace=True) \n",
    "            labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "            labeled_columns.sort_values(by=['col_idx'], inplace=True)\n",
    "            for index, target_column in labeled_columns.iterrows():\n",
    "                other_columns = group_df.drop(index).drop_duplicates(subset=['data'], keep='first')\n",
    "                # other_labeled = other_columns[other_columns['class_id'] > -1].head(max_unlabeled-1)\n",
    "                # other_unlabeled = other_columns[other_columns['class_id'] == -1].drop_duplicates(subset=['data'], keep='first').head(max_unlabeled-len(other_labeled)-1)\n",
    "                # target_table = pd.concat([target_column.to_frame().T, other_labeled, other_unlabeled], ignore_index=True)\n",
    "                \n",
    "                other_columns = other_columns.head(max_unlabeled-1)\n",
    "                target_table = pd.concat([target_column.to_frame().T, other_columns], ignore_index=True)\n",
    "                \n",
    "                # if len(group_df) >= 8:\n",
    "                #     assert len(target_table) == max_unlabeled\n",
    "                # else:\n",
    "                #     assert len(target_table) == len(group_df)\n",
    "    \n",
    "                target_col_idx = target_table[\"col_idx\"].values[0]\n",
    "                target_cls = target_table[\"class_id\"].values[0]\n",
    "                target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "                col_idx_list = target_table[\"col_idx\"].tolist()\n",
    "                # target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "\n",
    "                if max_length <= 128 and adaptive_max_length:\n",
    "                    cur_maxlen = min(max_length, 512 // len(target_table) - 1)\n",
    "                else:\n",
    "                    cur_maxlen = max_length\n",
    "                    \n",
    "                token_ids_list = target_table[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                    tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=cur_maxlen, truncation=True)).tolist(\n",
    "                    )\n",
    "                token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                                    token_ids_list)).to(device)\n",
    "\n",
    "                target_col_mask = []\n",
    "                cls_index_value = 0\n",
    "                context_id = 1\n",
    "                meet_target = False\n",
    "                for idx, col_i in enumerate(col_idx_list):\n",
    "                    if col_i == target_col_idx:\n",
    "                        target_col_mask += [0] * len(token_ids_list[idx])\n",
    "                        meet_target = True\n",
    "                    else:\n",
    "                        target_col_mask += [context_id] * len(token_ids_list[idx])\n",
    "                        context_id += 1\n",
    "                    if not meet_target:\n",
    "                        cls_index_value += len(token_ids_list[idx])\n",
    "                cls_index_list = [cls_index_value] \n",
    "                for cls_index in cls_index_list:\n",
    "                    assert token_ids[\n",
    "                        cls_index] == tokenizer.cls_token_id, \"cls_indexes validation\"\n",
    "                cls_indexes = torch.LongTensor(cls_index_list).to(device)\n",
    "                class_ids = torch.LongTensor(\n",
    "                    [target_cls]).to(device)\n",
    "                target_col_mask = torch.LongTensor(target_col_mask).to(device)\n",
    "                data_list.append(\n",
    "                    [index,\n",
    "                    len(target_table), token_ids, class_ids, cls_indexes, target_col_mask])                \n",
    "        print(split, len(data_list))\n",
    "        self.table_df = pd.DataFrame(data_list,\n",
    "                                     columns=[\n",
    "                                         \"table_id\", \"num_col\", \"data_tensor\",\n",
    "                                         \"label_tensor\", \"cls_indexes\", \"target_col_mask\"\n",
    "                                     ])\n",
    "        \"\"\"\n",
    "        # NOTE: msato contains a small portion of single-col tables. keep it to be consistent.  \n",
    "        if multicol_only:\n",
    "            # Check\n",
    "            num_all_tables = len(self.table_df)\n",
    "            self.table_df = self.table_df[self.table_df[\"num_col\"] > 1]\n",
    "            assert len(self.table_df) == num_all_tables\n",
    "        \"\"\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.table_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"data\": self.table_df.iloc[idx][\"data_tensor\"],\n",
    "            \"label\": self.table_df.iloc[idx][\"label_tensor\"],\n",
    "            \"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"],\n",
    "            \"target_col_mask\": self.table_df.iloc[idx][\"target_col_mask\"],\n",
    "        }\n",
    "        #\"idx\": torch.LongTensor([idx])}\n",
    "        #\"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptive_max_length=True\n",
    "global_i = 0 \n",
    "for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "    #     break\n",
    "    group_df = group_df.reset_index(drop=True)\n",
    "    semantic_scores = torch.tensor(group_df[\"data\"].apply(lambda x: classify_column(x.split(';'))).tolist())\n",
    "    group_df[\"semantic_scores\"] = semantic_scores\n",
    "    group_df.sort_values(by=['semantic_scores'], ascending=False, inplace=True) \n",
    "    labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "    labeled_columns.sort_values(by=['col_idx'], inplace=True)\n",
    "    for index_i, target_column in labeled_columns.iterrows():\n",
    "        other_columns = group_df.drop(index_i).drop_duplicates(subset=['data'], keep='first')\n",
    "        other_labeled = other_columns[other_columns['class_id'] > -1].head(max_unlabeled-1)\n",
    "        other_unlabeled = other_columns[other_columns['class_id'] == -1].head(max_unlabeled-len(other_labeled)-1)\n",
    "\n",
    "    \n",
    "        target_table = pd.concat([target_column.to_frame().T, other_labeled, other_unlabeled], ignore_index=True)\n",
    "    \n",
    "        target_col_idx = target_table[\"col_idx\"].values[0]\n",
    "        target_cls = target_table[\"class_id\"].values[0]\n",
    "        target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "        col_idx_list = target_table[\"col_idx\"].tolist()\n",
    "        # target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "        if target_cls != labels_test_original[global_i]:\n",
    "            print(i, target_cls, labels_test_original[global_i].item())\n",
    "            raise ValueError(\"target_cls != labels_test_original[global_i]\")\n",
    "        global_i += 1\n",
    "        if max_length <= 128 and adaptive_max_length:\n",
    "            cur_maxlen = min(max_length, 512 // len(target_table) - 1)\n",
    "        else:\n",
    "            cur_maxlen = max_length\n",
    "            \n",
    "        token_ids_list = target_table[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "            tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=cur_maxlen, truncation=True)).tolist(\n",
    "            )\n",
    "        token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                            token_ids_list)).to(device)\n",
    "\n",
    "        target_col_mask = []\n",
    "        cls_index_value = 0\n",
    "        context_id = 1\n",
    "        meet_target = False\n",
    "        for idx, col_i in enumerate(col_idx_list):\n",
    "            if col_i == target_col_idx:\n",
    "                target_col_mask += [0] * len(token_ids_list[idx])\n",
    "                meet_target = True\n",
    "            else:\n",
    "                target_col_mask += [context_id] * len(token_ids_list[idx])\n",
    "                context_id += 1\n",
    "            if not meet_target:\n",
    "                cls_index_value += len(token_ids_list[idx])\n",
    "        cls_index_list = [cls_index_value] \n",
    "        for cls_index in cls_index_list:\n",
    "            assert token_ids[\n",
    "                cls_index] == tokenizer.cls_token_id, \"cls_indexes validation\"\n",
    "        cls_indexes = torch.LongTensor(cls_index_list).to(device)\n",
    "        class_ids = torch.LongTensor(\n",
    "            [target_cls]).to(device)\n",
    "        target_col_mask = torch.LongTensor(target_col_mask).to(device)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "    if i == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GittablesTablewiseIterateDistantDataset(data.Dataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            cv: int,\n",
    "            split: str,\n",
    "            src: str,  # train or test\n",
    "            tokenizer: AutoTokenizer,\n",
    "            max_length: int = 256,\n",
    "            gt_only: bool = False,\n",
    "            device: torch.device = None,\n",
    "            base_dirpath: str = \"/data/zhihao/TU/GitTables/semtab_gittables/2022\",\n",
    "            base_tag: str = '', # blank, comma\n",
    "            small_tag: str = \"\",\n",
    "            train_ratio: float = 1.0,\n",
    "            max_unlabeled=8,\n",
    "            adaptive_max_length=True,\n",
    "            random_sample=False, # TODO\n",
    "            train_only=False): # TODO\n",
    "        if device is None:\n",
    "            device = torch.device('cpu')\n",
    "        basename = small_tag+ \"_cv_{}.csv\"\n",
    "    \n",
    "        if split in [\"train\", \"valid\"]:\n",
    "            df_list = []\n",
    "            for i in range(5):\n",
    "                if i == cv:\n",
    "                    continue\n",
    "                filepath = os.path.join(base_dirpath, basename.format(i))\n",
    "                df_list.append(pd.read_csv(filepath))\n",
    "                print(split, i)\n",
    "            df = pd.concat(df_list, axis=0)\n",
    "        else:\n",
    "            # test\n",
    "            filepath = os.path.join(base_dirpath, basename.format(cv))\n",
    "            df = pd.read_csv(filepath)\n",
    "            print(split)\n",
    "\n",
    "\n",
    "        if gt_only:\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "        if train_only and split != \"train\":\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "\n",
    "        \n",
    "        data_list = []\n",
    "        \n",
    "        df['class_id'] = df['class_id'].astype(int)\n",
    "        df.drop(df[(df['data'].isna()) & (df['class_id'] == -1)].index, inplace=True)\n",
    "        df['col_idx'] = df['col_idx'].astype(int)\n",
    "        df['data'] = df['data'].astype(str)\n",
    "        \n",
    "        num_tables = len(df.groupby(\"table_id\"))\n",
    "        valid_index = int(num_tables * 0.8)\n",
    "        num_train = int(train_ratio * num_tables * 0.8)        \n",
    "        \n",
    "        # df.drop(df[(df['data'] == '') & (df['class_id'] == -1)].index, inplace=True)\n",
    "        total_num_cols = 0\n",
    "        for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "            if (split == \"train\") and ((i >= num_train) or (i >= valid_index)):\n",
    "                break\n",
    "            if split == \"valid\" and i < valid_index:\n",
    "                continue\n",
    "            #     break\n",
    "            labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "            for index, target_column in labeled_columns.iterrows():\n",
    "                target_col_idx = target_column[\"col_idx\"]\n",
    "                \n",
    "                other_columns = group_df.drop(index)\n",
    "                \n",
    "                other_columns['distance'] = abs(other_columns['col_idx'] - target_col_idx)\n",
    "                other_columns.sort_values(by='distance', inplace=True)\n",
    "                nearby_columns = other_columns.tail(max_unlabeled-1)\n",
    "                target_table = pd.concat([target_column.to_frame().T, nearby_columns], ignore_index=True)\n",
    "                \n",
    "                \n",
    "                \n",
    "                # other_labeled = other_columns[other_columns['class_id'] > -1].head(max_unlabeled-1)\n",
    "                # other_unlabeled = other_columns[other_columns['class_id'] == -1]\n",
    "                # other_unlabeled['distance'] = abs(other_unlabeled['col_idx'] - target_col_idx)\n",
    "                # other_unlabeled.sort_values(by='distance', inplace=True)\n",
    "                # nearby_columns = other_unlabeled.head(max_unlabeled-len(other_labeled)-1)\n",
    "                # target_table = pd.concat([target_column.to_frame().T, other_labeled, nearby_columns], ignore_index=True)\n",
    "\n",
    "                # other_columns['distance'] = abs(other_columns['col_idx'] - target_col_idx)\n",
    "                # other_columns.sort_values(by='distance', inplace=True)\n",
    "                # nearby_columns = other_columns.head(max_unlabeled-1)\n",
    "                # target_table = pd.concat([target_column.to_frame().T, nearby_columns], ignore_index=True)\n",
    "                \n",
    "                \n",
    "                target_cls = target_column[\"class_id\"]\n",
    "                target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "                col_idx_list = target_table[\"col_idx\"].tolist()\n",
    "\n",
    "                if max_length <= 128 and adaptive_max_length:\n",
    "                    cur_maxlen = min(max_length, 512 // len(target_table) - 1)\n",
    "                else:\n",
    "                    cur_maxlen = max_length\n",
    "                    \n",
    "                token_ids_list = target_table[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                    tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=cur_maxlen, truncation=True)).tolist(\n",
    "                    )\n",
    "                token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                                    token_ids_list)).to(device)\n",
    "\n",
    "                target_col_mask = []\n",
    "                cls_index_value = 0\n",
    "                context_id = 1\n",
    "                meet_target = False\n",
    "                for idx, col_i in enumerate(col_idx_list):\n",
    "                    if col_i == target_col_idx:\n",
    "                        target_col_mask += [0] * len(token_ids_list[idx])\n",
    "                        meet_target = True\n",
    "                    else:\n",
    "                        target_col_mask += [context_id] * len(token_ids_list[idx])\n",
    "                        context_id += 1\n",
    "                    if not meet_target:\n",
    "                        cls_index_value += len(token_ids_list[idx])\n",
    "                cls_index_list = [cls_index_value] \n",
    "                for cls_index in cls_index_list:\n",
    "                    assert token_ids[\n",
    "                        cls_index] == tokenizer.cls_token_id, \"cls_indexes validation\"\n",
    "                cls_indexes = torch.LongTensor(cls_index_list).to(device)\n",
    "                class_ids = torch.LongTensor(\n",
    "                    [target_cls]).to(device)\n",
    "                target_col_mask = torch.LongTensor(target_col_mask).to(device)\n",
    "                data_list.append(\n",
    "                    [index,\n",
    "                    len(target_table), token_ids, class_ids, cls_indexes, target_col_mask])                \n",
    "        print(split, len(data_list))\n",
    "        self.table_df = pd.DataFrame(data_list,\n",
    "                                     columns=[\n",
    "                                         \"table_id\", \"num_col\", \"data_tensor\",\n",
    "                                         \"label_tensor\", \"cls_indexes\", \"target_col_mask\"\n",
    "                                     ])\n",
    "        \"\"\"\n",
    "        # NOTE: msato contains a small portion of single-col tables. keep it to be consistent.  \n",
    "        if multicol_only:\n",
    "            # Check\n",
    "            num_all_tables = len(self.table_df)\n",
    "            self.table_df = self.table_df[self.table_df[\"num_col\"] > 1]\n",
    "            assert len(self.table_df) == num_all_tables\n",
    "        \"\"\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.table_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"data\": self.table_df.iloc[idx][\"data_tensor\"],\n",
    "            \"label\": self.table_df.iloc[idx][\"label_tensor\"],\n",
    "            \"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"],\n",
    "            \"target_col_mask\": self.table_df.iloc[idx][\"target_col_mask\"],\n",
    "        }\n",
    "        #\"idx\": torch.LongTensor([idx])}\n",
    "        #\"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GittablesTablewiseIterateAllDataset(data.Dataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            cv: int,\n",
    "            split: str,\n",
    "            src: str,  # train or test\n",
    "            tokenizer: AutoTokenizer,\n",
    "            max_length: int = 256,\n",
    "            gt_only: bool = False,\n",
    "            device: torch.device = None,\n",
    "            base_dirpath: str = \"/data/zhihao/TU/GitTables/semtab_gittables/2022\",\n",
    "            base_tag: str = '', # blank, comma\n",
    "            small_tag: str = \"\",\n",
    "            train_ratio: float = 1.0,\n",
    "            max_unlabeled=8,\n",
    "            adaptive_max_length=True,\n",
    "            random_sample=False, # TODO\n",
    "            train_only=False): # TODO\n",
    "        if device is None:\n",
    "            device = torch.device('cpu')\n",
    "        basename = small_tag+ \"_cv_{}.csv\"\n",
    "    \n",
    "        if split in [\"train\", \"valid\"]:\n",
    "            df_list = []\n",
    "            for i in range(5):\n",
    "                if i == cv:\n",
    "                    continue\n",
    "                filepath = os.path.join(base_dirpath, basename.format(i))\n",
    "                df_list.append(pd.read_csv(filepath))\n",
    "                print(split, i)\n",
    "            df = pd.concat(df_list, axis=0)\n",
    "        else:\n",
    "            # test\n",
    "            filepath = os.path.join(base_dirpath, basename.format(cv))\n",
    "            df = pd.read_csv(filepath)\n",
    "            print(split)\n",
    "\n",
    "\n",
    "        if gt_only:\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "        if train_only and split != \"train\":\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "\n",
    "        \n",
    "        data_list = []\n",
    "        \n",
    "        df['class_id'] = df['class_id'].astype(int)\n",
    "        df.drop(df[(df['data'].isna()) & (df['class_id'] == -1)].index, inplace=True)\n",
    "        df['col_idx'] = df['col_idx'].astype(int)\n",
    "        df['data'] = df['data'].astype(str)\n",
    "        \n",
    "        num_tables = len(df.groupby(\"table_id\"))\n",
    "        valid_index = int(num_tables * 0.8)\n",
    "        num_train = int(train_ratio * num_tables * 0.8)        \n",
    "        \n",
    "        # df.drop(df[(df['data'] == '') & (df['class_id'] == -1)].index, inplace=True)\n",
    "        total_num_cols = 0\n",
    "        for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "            if (split == \"train\") and ((i >= num_train) or (i >= valid_index)):\n",
    "                break\n",
    "            if split == \"valid\" and i < valid_index:\n",
    "                continue\n",
    "            #     break\n",
    "            labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "            for index, target_column in labeled_columns.iterrows():\n",
    "                target_col_idx = target_column[\"col_idx\"]\n",
    "                \n",
    "\n",
    "                target_table = group_df\n",
    "                \n",
    "                \n",
    "                \n",
    "                # other_labeled = other_columns[other_columns['class_id'] > -1].head(max_unlabeled-1)\n",
    "                # other_unlabeled = other_columns[other_columns['class_id'] == -1]\n",
    "                # other_unlabeled['distance'] = abs(other_unlabeled['col_idx'] - target_col_idx)\n",
    "                # other_unlabeled.sort_values(by='distance', inplace=True)\n",
    "                # nearby_columns = other_unlabeled.head(max_unlabeled-len(other_labeled)-1)\n",
    "                # target_table = pd.concat([target_column.to_frame().T, other_labeled, nearby_columns], ignore_index=True)\n",
    "\n",
    "                # other_columns['distance'] = abs(other_columns['col_idx'] - target_col_idx)\n",
    "                # other_columns.sort_values(by='distance', inplace=True)\n",
    "                # nearby_columns = other_columns.head(max_unlabeled-1)\n",
    "                # target_table = pd.concat([target_column.to_frame().T, nearby_columns], ignore_index=True)\n",
    "                \n",
    "                \n",
    "                target_cls = target_column[\"class_id\"]\n",
    "                target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "                col_idx_list = target_table[\"col_idx\"].tolist()\n",
    "\n",
    "                if max_length <= 128 and adaptive_max_length:\n",
    "                    cur_maxlen = min(max_length, 512 // len(target_table) - 1)\n",
    "                else:\n",
    "                    cur_maxlen = max_length\n",
    "                    \n",
    "                token_ids_list = target_table[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                    tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=cur_maxlen, truncation=True)).tolist(\n",
    "                    )\n",
    "                token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                                    token_ids_list)).to(device)\n",
    "\n",
    "                target_col_mask = []\n",
    "                cls_index_value = 0\n",
    "                context_id = 1\n",
    "                meet_target = False\n",
    "                for idx, col_i in enumerate(col_idx_list):\n",
    "                    if col_i == target_col_idx:\n",
    "                        target_col_mask += [0] * len(token_ids_list[idx])\n",
    "                        meet_target = True\n",
    "                    else:\n",
    "                        target_col_mask += [context_id] * len(token_ids_list[idx])\n",
    "                        context_id += 1\n",
    "                    if not meet_target:\n",
    "                        cls_index_value += len(token_ids_list[idx])\n",
    "                cls_index_list = [cls_index_value] \n",
    "                for cls_index in cls_index_list:\n",
    "                    assert token_ids[\n",
    "                        cls_index] == tokenizer.cls_token_id, \"cls_indexes validation\"\n",
    "                cls_indexes = torch.LongTensor(cls_index_list).to(device)\n",
    "                class_ids = torch.LongTensor(\n",
    "                    [target_cls]).to(device)\n",
    "                target_col_mask = torch.LongTensor(target_col_mask).to(device)\n",
    "                data_list.append(\n",
    "                    [index,\n",
    "                    len(target_table), token_ids, class_ids, cls_indexes, target_col_mask])                \n",
    "        print(split, len(data_list))\n",
    "        self.table_df = pd.DataFrame(data_list,\n",
    "                                     columns=[\n",
    "                                         \"table_id\", \"num_col\", \"data_tensor\",\n",
    "                                         \"label_tensor\", \"cls_indexes\", \"target_col_mask\"\n",
    "                                     ])\n",
    "        \"\"\"\n",
    "        # NOTE: msato contains a small portion of single-col tables. keep it to be consistent.  \n",
    "        if multicol_only:\n",
    "            # Check\n",
    "            num_all_tables = len(self.table_df)\n",
    "            self.table_df = self.table_df[self.table_df[\"num_col\"] > 1]\n",
    "            assert len(self.table_df) == num_all_tables\n",
    "        \"\"\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.table_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"data\": self.table_df.iloc[idx][\"data_tensor\"],\n",
    "            \"label\": self.table_df.iloc[idx][\"label_tensor\"],\n",
    "            \"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"],\n",
    "            \"target_col_mask\": self.table_df.iloc[idx][\"target_col_mask\"],\n",
    "        }\n",
    "        #\"idx\": torch.LongTensor([idx])}\n",
    "        #\"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GittablesTablewiseIterateNearbyFirstDataset(data.Dataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            cv: int,\n",
    "            split: str,\n",
    "            src: str,  # train or test\n",
    "            tokenizer: AutoTokenizer,\n",
    "            max_length: int = 256,\n",
    "            gt_only: bool = False,\n",
    "            device: torch.device = None,\n",
    "            base_dirpath: str = \"/data/zhihao/TU/GitTables/semtab_gittables/2022\",\n",
    "            base_tag: str = '', # blank, comma\n",
    "            small_tag: str = \"\",\n",
    "            train_ratio: float = 1.0,\n",
    "            max_unlabeled=8,\n",
    "            adaptive_max_length=True,\n",
    "            random_sample=False, # TODO\n",
    "            train_only=False,\n",
    "            nearby_num=2): # TODO\n",
    "        if device is None:\n",
    "            device = torch.device('cpu')\n",
    "        basename = small_tag+ \"_cv_{}.csv\"\n",
    "    \n",
    "        if split in [\"train\", \"valid\"]:\n",
    "            df_list = []\n",
    "            for i in range(5):\n",
    "                if i == cv:\n",
    "                    continue\n",
    "                filepath = os.path.join(base_dirpath, basename.format(i))\n",
    "                df_list.append(pd.read_csv(filepath))\n",
    "                print(split, i)\n",
    "            df = pd.concat(df_list, axis=0)\n",
    "        else:\n",
    "            # test\n",
    "            filepath = os.path.join(base_dirpath, basename.format(cv))\n",
    "            df = pd.read_csv(filepath)\n",
    "            print(split)\n",
    "\n",
    "\n",
    "        if gt_only:\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "        if train_only and split != \"train\":\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "\n",
    "        \n",
    "        data_list = []\n",
    "        \n",
    "        df['class_id'] = df['class_id'].astype(int)\n",
    "        df.drop(df[(df['data'].isna()) & (df['class_id'] == -1)].index, inplace=True)\n",
    "        df['col_idx'] = df['col_idx'].astype(int)\n",
    "        df['data'] = df['data'].astype(str)\n",
    "        \n",
    "        num_tables = len(df.groupby(\"table_id\"))\n",
    "        valid_index = int(num_tables * 0.8)\n",
    "        num_train = int(train_ratio * num_tables * 0.8)        \n",
    "        \n",
    "        # df.drop(df[(df['data'] == '') & (df['class_id'] == -1)].index, inplace=True)\n",
    "        total_num_cols = 0\n",
    "        for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "            if (split == \"train\") and ((i >= num_train) or (i >= valid_index)):\n",
    "                break\n",
    "            if split == \"valid\" and i < valid_index:\n",
    "                continue\n",
    "            #     break\n",
    "            labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "            for index, target_column in labeled_columns.iterrows():\n",
    "                target_col_idx = target_column[\"col_idx\"]\n",
    "                \n",
    "                other_columns = group_df.drop(index)\n",
    "                \n",
    "                other_columns['distance'] = abs(other_columns['col_idx'] - target_col_idx)\n",
    "                other_columns.sort_values(by='distance', inplace=True)\n",
    "                nearby_columns = other_columns.head(min(nearby_num, max_unlabeled-1))\n",
    "                other_columns = other_columns.drop(nearby_columns.index)\n",
    "                other_columns.sort_values(by=['col_idx'], inplace=True)\n",
    "                first_columns = other_columns.head(max(max_unlabeled-1-nearby_num, 0))\n",
    "                target_table = pd.concat([target_column.to_frame().T, nearby_columns, first_columns], ignore_index=True)\n",
    "                \n",
    "                \n",
    "                \n",
    "                # other_labeled = other_columns[other_columns['class_id'] > -1].head(max_unlabeled-1)\n",
    "                # other_unlabeled = other_columns[other_columns['class_id'] == -1]\n",
    "                # other_unlabeled['distance'] = abs(other_unlabeled['col_idx'] - target_col_idx)\n",
    "                # other_unlabeled.sort_values(by='distance', inplace=True)\n",
    "                # nearby_columns = other_unlabeled.head(max_unlabeled-len(other_labeled)-1)\n",
    "                # target_table = pd.concat([target_column.to_frame().T, other_labeled, nearby_columns], ignore_index=True)\n",
    "\n",
    "                # other_columns['distance'] = abs(other_columns['col_idx'] - target_col_idx)\n",
    "                # other_columns.sort_values(by='distance', inplace=True)\n",
    "                # nearby_columns = other_columns.head(max_unlabeled-1)\n",
    "                # target_table = pd.concat([target_column.to_frame().T, nearby_columns], ignore_index=True)\n",
    "                \n",
    "                \n",
    "                target_cls = target_column[\"class_id\"]\n",
    "                target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "                col_idx_list = target_table[\"col_idx\"].tolist()\n",
    "\n",
    "                if max_length <= 128 and adaptive_max_length:\n",
    "                    cur_maxlen = min(max_length, 512 // len(target_table) - 1)\n",
    "                else:\n",
    "                    cur_maxlen = max_length\n",
    "                    \n",
    "                token_ids_list = target_table[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                    tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=cur_maxlen, truncation=True)).tolist(\n",
    "                    )\n",
    "                token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                                    token_ids_list)).to(device)\n",
    "\n",
    "                target_col_mask = []\n",
    "                cls_index_value = 0\n",
    "                context_id = 1\n",
    "                meet_target = False\n",
    "                for idx, col_i in enumerate(col_idx_list):\n",
    "                    if col_i == target_col_idx:\n",
    "                        target_col_mask += [0] * len(token_ids_list[idx])\n",
    "                        meet_target = True\n",
    "                    else:\n",
    "                        target_col_mask += [context_id] * len(token_ids_list[idx])\n",
    "                        context_id += 1\n",
    "                    if not meet_target:\n",
    "                        cls_index_value += len(token_ids_list[idx])\n",
    "                cls_index_list = [cls_index_value] \n",
    "                for cls_index in cls_index_list:\n",
    "                    assert token_ids[\n",
    "                        cls_index] == tokenizer.cls_token_id, \"cls_indexes validation\"\n",
    "                cls_indexes = torch.LongTensor(cls_index_list).to(device)\n",
    "                class_ids = torch.LongTensor(\n",
    "                    [target_cls]).to(device)\n",
    "                target_col_mask = torch.LongTensor(target_col_mask).to(device)\n",
    "                data_list.append(\n",
    "                    [index,\n",
    "                    len(target_table), token_ids, class_ids, cls_indexes, target_col_mask])                \n",
    "        print(split, len(data_list))\n",
    "        self.table_df = pd.DataFrame(data_list,\n",
    "                                     columns=[\n",
    "                                         \"table_id\", \"num_col\", \"data_tensor\",\n",
    "                                         \"label_tensor\", \"cls_indexes\", \"target_col_mask\"\n",
    "                                     ])\n",
    "        \"\"\"\n",
    "        # NOTE: msato contains a small portion of single-col tables. keep it to be consistent.  \n",
    "        if multicol_only:\n",
    "            # Check\n",
    "            num_all_tables = len(self.table_df)\n",
    "            self.table_df = self.table_df[self.table_df[\"num_col\"] > 1]\n",
    "            assert len(self.table_df) == num_all_tables\n",
    "        \"\"\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.table_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"data\": self.table_df.iloc[idx][\"data_tensor\"],\n",
    "            \"label\": self.table_df.iloc[idx][\"label_tensor\"],\n",
    "            \"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"],\n",
    "            \"target_col_mask\": self.table_df.iloc[idx][\"target_col_mask\"],\n",
    "        }\n",
    "        #\"idx\": torch.LongTensor([idx])}\n",
    "        #\"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GittablesTablewiseIterateNearbyDataset(data.Dataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            cv: int,\n",
    "            split: str,\n",
    "            src: str,  # train or test\n",
    "            tokenizer: AutoTokenizer,\n",
    "            max_length: int = 256,\n",
    "            gt_only: bool = False,\n",
    "            device: torch.device = None,\n",
    "            base_dirpath: str = \"/data/zhihao/TU/GitTables/semtab_gittables/2022\",\n",
    "            base_tag: str = '', # blank, comma\n",
    "            small_tag: str = \"\",\n",
    "            train_ratio: float = 1.0,\n",
    "            max_unlabeled=8,\n",
    "            adaptive_max_length=True,\n",
    "            random_sample=False, # TODO\n",
    "            train_only=False): # TODO\n",
    "        if device is None:\n",
    "            device = torch.device('cpu')\n",
    "        basename = small_tag+ \"_cv_{}.csv\"\n",
    "    \n",
    "        if split in [\"train\", \"valid\"]:\n",
    "            df_list = []\n",
    "            for i in range(5):\n",
    "                if i == cv:\n",
    "                    continue\n",
    "                filepath = os.path.join(base_dirpath, basename.format(i))\n",
    "                df_list.append(pd.read_csv(filepath))\n",
    "                print(split, i)\n",
    "            df = pd.concat(df_list, axis=0)\n",
    "        else:\n",
    "            # test\n",
    "            filepath = os.path.join(base_dirpath, basename.format(cv))\n",
    "            df = pd.read_csv(filepath)\n",
    "            print(split)\n",
    "\n",
    "\n",
    "        if gt_only:\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "        if train_only and split != \"train\":\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "\n",
    "        \n",
    "        data_list = []\n",
    "        \n",
    "        df['class_id'] = df['class_id'].astype(int)\n",
    "        df.drop(df[(df['data'].isna()) & (df['class_id'] == -1)].index, inplace=True)\n",
    "        df['col_idx'] = df['col_idx'].astype(int)\n",
    "        df['data'] = df['data'].astype(str)\n",
    "        \n",
    "        num_tables = len(df.groupby(\"table_id\"))\n",
    "        valid_index = int(num_tables * 0.8)\n",
    "        num_train = int(train_ratio * num_tables * 0.8)        \n",
    "        \n",
    "        # df.drop(df[(df['data'] == '') & (df['class_id'] == -1)].index, inplace=True)\n",
    "        total_num_cols = 0\n",
    "        for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "            if (split == \"train\") and ((i >= num_train) or (i >= valid_index)):\n",
    "                break\n",
    "            if split == \"valid\" and i < valid_index:\n",
    "                continue\n",
    "            #     break\n",
    "            labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "            for index, target_column in labeled_columns.iterrows():\n",
    "                target_col_idx = target_column[\"col_idx\"]\n",
    "                \n",
    "                other_columns = group_df.drop(index)\n",
    "                \n",
    "                other_columns['distance'] = abs(other_columns['col_idx'] - target_col_idx)\n",
    "                other_columns.sort_values(by='distance', inplace=True)\n",
    "                nearby_columns = other_columns.head(max_unlabeled-1)\n",
    "                target_table = pd.concat([target_column.to_frame().T, nearby_columns], ignore_index=True)\n",
    "                \n",
    "                \n",
    "                \n",
    "                # other_labeled = other_columns[other_columns['class_id'] > -1].head(max_unlabeled-1)\n",
    "                # other_unlabeled = other_columns[other_columns['class_id'] == -1]\n",
    "                # other_unlabeled['distance'] = abs(other_unlabeled['col_idx'] - target_col_idx)\n",
    "                # other_unlabeled.sort_values(by='distance', inplace=True)\n",
    "                # nearby_columns = other_unlabeled.head(max_unlabeled-len(other_labeled)-1)\n",
    "                # target_table = pd.concat([target_column.to_frame().T, other_labeled, nearby_columns], ignore_index=True)\n",
    "\n",
    "                # other_columns['distance'] = abs(other_columns['col_idx'] - target_col_idx)\n",
    "                # other_columns.sort_values(by='distance', inplace=True)\n",
    "                # nearby_columns = other_columns.head(max_unlabeled-1)\n",
    "                # target_table = pd.concat([target_column.to_frame().T, nearby_columns], ignore_index=True)\n",
    "                \n",
    "                \n",
    "                target_cls = target_column[\"class_id\"]\n",
    "                target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "                col_idx_list = target_table[\"col_idx\"].tolist()\n",
    "\n",
    "                if max_length <= 128 and adaptive_max_length:\n",
    "                    cur_maxlen = min(max_length, 512 // len(target_table) - 1)\n",
    "                else:\n",
    "                    cur_maxlen = max_length\n",
    "                    \n",
    "                token_ids_list = target_table[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                    tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=cur_maxlen, truncation=True)).tolist(\n",
    "                    )\n",
    "                token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                                    token_ids_list)).to(device)\n",
    "\n",
    "                target_col_mask = []\n",
    "                cls_index_value = 0\n",
    "                context_id = 1\n",
    "                meet_target = False\n",
    "                for idx, col_i in enumerate(col_idx_list):\n",
    "                    if col_i == target_col_idx:\n",
    "                        target_col_mask += [0] * len(token_ids_list[idx])\n",
    "                        meet_target = True\n",
    "                    else:\n",
    "                        target_col_mask += [context_id] * len(token_ids_list[idx])\n",
    "                        context_id += 1\n",
    "                    if not meet_target:\n",
    "                        cls_index_value += len(token_ids_list[idx])\n",
    "                cls_index_list = [cls_index_value] \n",
    "                for cls_index in cls_index_list:\n",
    "                    assert token_ids[\n",
    "                        cls_index] == tokenizer.cls_token_id, \"cls_indexes validation\"\n",
    "                cls_indexes = torch.LongTensor(cls_index_list).to(device)\n",
    "                class_ids = torch.LongTensor(\n",
    "                    [target_cls]).to(device)\n",
    "                target_col_mask = torch.LongTensor(target_col_mask).to(device)\n",
    "                data_list.append(\n",
    "                    [index,\n",
    "                    len(target_table), token_ids, class_ids, cls_indexes, target_col_mask])                \n",
    "        print(split, len(data_list))\n",
    "        self.table_df = pd.DataFrame(data_list,\n",
    "                                     columns=[\n",
    "                                         \"table_id\", \"num_col\", \"data_tensor\",\n",
    "                                         \"label_tensor\", \"cls_indexes\", \"target_col_mask\"\n",
    "                                     ])\n",
    "        \"\"\"\n",
    "        # NOTE: msato contains a small portion of single-col tables. keep it to be consistent.  \n",
    "        if multicol_only:\n",
    "            # Check\n",
    "            num_all_tables = len(self.table_df)\n",
    "            self.table_df = self.table_df[self.table_df[\"num_col\"] > 1]\n",
    "            assert len(self.table_df) == num_all_tables\n",
    "        \"\"\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.table_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"data\": self.table_df.iloc[idx][\"data_tensor\"],\n",
    "            \"label\": self.table_df.iloc[idx][\"label_tensor\"],\n",
    "            \"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"],\n",
    "            \"target_col_mask\": self.table_df.iloc[idx][\"target_col_mask\"],\n",
    "        }\n",
    "        #\"idx\": torch.LongTensor([idx])}\n",
    "        #\"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get first 8 columns, put target column in the last\n",
    "class GittablesTablewiseIterateNearbyLastDataset(data.Dataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            cv: int,\n",
    "            split: str,\n",
    "            src: str,  # train or test\n",
    "            tokenizer: AutoTokenizer,\n",
    "            max_length: int = 256,\n",
    "            gt_only: bool = False,\n",
    "            device: torch.device = None,\n",
    "            base_dirpath: str = \"/data/zhihao/TU/GitTables/semtab_gittables/2022\",\n",
    "            base_tag: str = '', # blank, comma\n",
    "            small_tag: str = \"\",\n",
    "            train_ratio: float = 1.0,\n",
    "            max_unlabeled=8,\n",
    "            adaptive_max_length=True,\n",
    "            random_sample=False, # TODO\n",
    "            train_only=False): # TODO\n",
    "        if device is None:\n",
    "            device = torch.device('cpu')\n",
    "        basename = small_tag+ \"_cv_{}.csv\"\n",
    "    \n",
    "        if split in [\"train\", \"valid\"]:\n",
    "            df_list = []\n",
    "            for i in range(5):\n",
    "                if i == cv:\n",
    "                    continue\n",
    "                filepath = os.path.join(base_dirpath, basename.format(i))\n",
    "                df_list.append(pd.read_csv(filepath))\n",
    "                print(split, i)\n",
    "            df = pd.concat(df_list, axis=0)\n",
    "        else:\n",
    "            # test\n",
    "            filepath = os.path.join(base_dirpath, basename.format(cv))\n",
    "            df = pd.read_csv(filepath)\n",
    "            print(split)\n",
    "\n",
    "\n",
    "        if gt_only:\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "        if train_only and split != \"train\":\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "\n",
    "        \n",
    "        data_list = []\n",
    "        \n",
    "        df['class_id'] = df['class_id'].astype(int)\n",
    "        df.drop(df[(df['data'].isna()) & (df['class_id'] == -1)].index, inplace=True)\n",
    "        df['col_idx'] = df['col_idx'].astype(int)\n",
    "        df['data'] = df['data'].astype(str)\n",
    "        \n",
    "        num_tables = len(df.groupby(\"table_id\"))\n",
    "        valid_index = int(num_tables * 0.8)\n",
    "        num_train = int(train_ratio * num_tables * 0.8)        \n",
    "        \n",
    "        # df.drop(df[(df['data'] == '') & (df['class_id'] == -1)].index, inplace=True)\n",
    "        total_num_cols = 0\n",
    "        for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "            if (split == \"train\") and ((i >= num_train) or (i >= valid_index)):\n",
    "                break\n",
    "            if split == \"valid\" and i < valid_index:\n",
    "                continue\n",
    "            #     break\n",
    "            labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "            for index, target_column in labeled_columns.iterrows():\n",
    "                target_col_idx = target_column[\"col_idx\"]\n",
    "                \n",
    "                other_columns = group_df.drop(index)\n",
    "                \n",
    "                # other_columns['distance'] = abs(other_columns['col_idx'] - target_col_idx)\n",
    "                # other_columns.sort_values(by='distance', inplace=True)\n",
    "                # nearby_columns = other_columns.head(max_unlabeled-1)\n",
    "                # target_table = pd.concat([target_column.to_frame().T, nearby_columns], ignore_index=True)\n",
    "                \n",
    "                \n",
    "                \n",
    "                # other_labeled = other_columns[other_columns['class_id'] > -1].head(max_unlabeled-1)\n",
    "                # other_unlabeled = other_columns[other_columns['class_id'] == -1]\n",
    "                # other_unlabeled['distance'] = abs(other_unlabeled['col_idx'] - target_col_idx)\n",
    "                # other_unlabeled.sort_values(by='distance', inplace=True)\n",
    "                # nearby_columns = other_unlabeled.head(max_unlabeled-len(other_labeled)-1)\n",
    "                # target_table = pd.concat([target_column.to_frame().T, other_labeled, nearby_columns], ignore_index=True)\n",
    "\n",
    "                other_columns['distance'] = abs(other_columns['col_idx'] - target_col_idx)\n",
    "                other_columns.sort_values(by='distance', inplace=True)\n",
    "                nearby_columns = other_columns.head(max_unlabeled-1)\n",
    "                nearby_columns.sort_values(by=['col_idx'], inplace=True)\n",
    "                target_table = pd.concat([ target_column.to_frame().T, nearby_columns], ignore_index=True)\n",
    "                \n",
    "                \n",
    "                target_cls = target_table[\"class_id\"].values[0]\n",
    "                \n",
    "                \n",
    "                # target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "                col_idx_list = target_table[\"col_idx\"].tolist()\n",
    "\n",
    "                if max_length <= 128 and adaptive_max_length:\n",
    "                    cur_maxlen = min(max_length, 512 // len(target_table) - 1)\n",
    "                else:\n",
    "                    cur_maxlen = max_length\n",
    "                    \n",
    "                token_ids_list = target_table[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                    tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=cur_maxlen, truncation=True)).tolist(\n",
    "                    )\n",
    "                token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                                    token_ids_list)).to(device)\n",
    "\n",
    "                target_col_mask = []\n",
    "                cls_index_value = 0\n",
    "                context_id = 1\n",
    "                meet_target = False\n",
    "                for idx, col_i in enumerate(col_idx_list):\n",
    "                    if col_i == target_col_idx:\n",
    "                        target_col_mask += [0] * len(token_ids_list[idx])\n",
    "                        meet_target = True\n",
    "                    else:\n",
    "                        target_col_mask += [context_id] * len(token_ids_list[idx])\n",
    "                        context_id += 1\n",
    "                    if not meet_target:\n",
    "                        cls_index_value += len(token_ids_list[idx])\n",
    "                cls_index_list = [cls_index_value] \n",
    "                for cls_index in cls_index_list:\n",
    "                    assert token_ids[\n",
    "                        cls_index] == tokenizer.cls_token_id, \"cls_indexes validation\"\n",
    "                cls_indexes = torch.LongTensor(cls_index_list).to(device)\n",
    "                class_ids = torch.LongTensor(\n",
    "                    [target_cls]).to(device)\n",
    "                target_col_mask = torch.LongTensor(target_col_mask).to(device)\n",
    "                data_list.append(\n",
    "                    [index,\n",
    "                    len(target_table), token_ids, class_ids, cls_indexes, target_col_mask])                \n",
    "        print(split, len(data_list))\n",
    "        self.table_df = pd.DataFrame(data_list,\n",
    "                                     columns=[\n",
    "                                         \"table_id\", \"num_col\", \"data_tensor\",\n",
    "                                         \"label_tensor\", \"cls_indexes\", \"target_col_mask\"\n",
    "                                     ])\n",
    "        \"\"\"\n",
    "        # NOTE: msato contains a small portion of single-col tables. keep it to be consistent.  \n",
    "        if multicol_only:\n",
    "            # Check\n",
    "            num_all_tables = len(self.table_df)\n",
    "            self.table_df = self.table_df[self.table_df[\"num_col\"] > 1]\n",
    "            assert len(self.table_df) == num_all_tables\n",
    "        \"\"\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.table_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"data\": self.table_df.iloc[idx][\"data_tensor\"],\n",
    "            \"label\": self.table_df.iloc[idx][\"label_tensor\"],\n",
    "            \"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"],\n",
    "            \"target_col_mask\": self.table_df.iloc[idx][\"target_col_mask\"],\n",
    "        }\n",
    "        #\"idx\": torch.LongTensor([idx])}\n",
    "        #\"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GittablesTablewiseIterateHybridDataset(data.Dataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            cv: int,\n",
    "            split: str,\n",
    "            src: str,  # train or test\n",
    "            tokenizer: AutoTokenizer,\n",
    "            max_length: int = 256,\n",
    "            gt_only: bool = False,\n",
    "            device: torch.device = None,\n",
    "            base_dirpath: str = \"/data/zhihao/TU/GitTables/semtab_gittables/2022\",\n",
    "            base_tag: str = '', # blank, comma\n",
    "            small_tag: str = \"\",\n",
    "            train_ratio: float = 1.0,\n",
    "            max_unlabeled=8,\n",
    "            adaptive_max_length=True,\n",
    "            random_sample=False, # TODO\n",
    "            train_only=False): # TODO\n",
    "        if device is None:\n",
    "            device = torch.device('cpu')\n",
    "        basename = small_tag+ \"_cv_{}.csv\"\n",
    "    \n",
    "        if split in [\"train\", \"valid\"]:\n",
    "            df_list = []\n",
    "            for i in range(5):\n",
    "                if i == cv:\n",
    "                    continue\n",
    "                filepath = os.path.join(base_dirpath, basename.format(i))\n",
    "                df_list.append(pd.read_csv(filepath))\n",
    "                print(split, i)\n",
    "            df = pd.concat(df_list, axis=0)\n",
    "        else:\n",
    "            # test\n",
    "            filepath = os.path.join(base_dirpath, basename.format(cv))\n",
    "            df = pd.read_csv(filepath)\n",
    "            print(split)\n",
    "\n",
    "\n",
    "        if gt_only:\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "        if train_only and split != \"train\":\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "\n",
    "        \n",
    "        data_list = []\n",
    "        \n",
    "        df['class_id'] = df['class_id'].astype(int)\n",
    "        df.drop(df[(df['data'].isna()) & (df['class_id'] == -1)].index, inplace=True)\n",
    "        df['col_idx'] = df['col_idx'].astype(int)\n",
    "        df['data'] = df['data'].astype(str)\n",
    "        \n",
    "        num_tables = len(df.groupby(\"table_id\"))\n",
    "        valid_index = int(num_tables * 0.8)\n",
    "        num_train = int(train_ratio * num_tables * 0.8)        \n",
    "        \n",
    "        # df.drop(df[(df['data'] == '') & (df['class_id'] == -1)].index, inplace=True)\n",
    "        total_num_cols = 0\n",
    "        for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "            if (split == \"train\") and ((i >= num_train) or (i >= valid_index)):\n",
    "                break\n",
    "            if split == \"valid\" and i < valid_index:\n",
    "                continue\n",
    "            #     break\n",
    "            labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "            # if len(group_df) > 10:\n",
    "            #     print(i, len(group_df))\n",
    "            for index, target_column in labeled_columns.iterrows():\n",
    "                first_col_num = 3\n",
    "                target_col_idx = target_column[\"col_idx\"]\n",
    "                \n",
    "                other_columns = group_df.drop(index).sort_values(by=['col_idx'])\n",
    "                first_columns = other_columns.head(first_col_num)\n",
    "                other_columns = other_columns.drop(first_columns.index.values)\n",
    "                \n",
    "                # if len(other_columns) > 0:\n",
    "                other_columns['distance'] = abs(other_columns['col_idx'] - target_col_idx)\n",
    "                other_columns.sort_values(by='distance', inplace=True)\n",
    "                nearby_columns = other_columns.head(max_unlabeled-1-first_col_num)\n",
    "                target_table = pd.concat([target_column.to_frame().T, first_columns, nearby_columns], ignore_index=True)\n",
    "                \n",
    "                \n",
    "                target_cls = target_table[\"class_id\"].values[0]\n",
    "                target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "                col_idx_list = target_table[\"col_idx\"].tolist()\n",
    "                # target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "\n",
    "                if max_length <= 128 and adaptive_max_length:\n",
    "                    cur_maxlen = min(max_length, 512 // len(target_table) - 1)\n",
    "                else:\n",
    "                    cur_maxlen = max_length\n",
    "                    \n",
    "                token_ids_list = target_table[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                    tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=cur_maxlen, truncation=True)).tolist(\n",
    "                    )\n",
    "                token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                                    token_ids_list)).to(device)\n",
    "\n",
    "                target_col_mask = []\n",
    "                cls_index_value = 0\n",
    "                context_id = 1\n",
    "                meet_target = False\n",
    "                for idx, col_i in enumerate(col_idx_list):\n",
    "                    if col_i == target_col_idx:\n",
    "                        target_col_mask += [0] * len(token_ids_list[idx])\n",
    "                        meet_target = True\n",
    "                    else:\n",
    "                        target_col_mask += [context_id] * len(token_ids_list[idx])\n",
    "                        context_id += 1\n",
    "                    if not meet_target:\n",
    "                        cls_index_value += len(token_ids_list[idx])\n",
    "                cls_index_list = [cls_index_value] \n",
    "                for cls_index in cls_index_list:\n",
    "                    assert token_ids[\n",
    "                        cls_index] == tokenizer.cls_token_id, \"cls_indexes validation\"\n",
    "                cls_indexes = torch.LongTensor(cls_index_list).to(device)\n",
    "                class_ids = torch.LongTensor(\n",
    "                    [target_cls]).to(device)\n",
    "                target_col_mask = torch.LongTensor(target_col_mask).to(device)\n",
    "                data_list.append(\n",
    "                    [index,\n",
    "                    len(target_table), token_ids, class_ids, cls_indexes, target_col_mask])                \n",
    "        print(split, len(data_list))\n",
    "        self.table_df = pd.DataFrame(data_list,\n",
    "                                     columns=[\n",
    "                                         \"table_id\", \"num_col\", \"data_tensor\",\n",
    "                                         \"label_tensor\", \"cls_indexes\", \"target_col_mask\"\n",
    "                                     ])\n",
    "        \"\"\"\n",
    "        # NOTE: msato contains a small portion of single-col tables. keep it to be consistent.  \n",
    "        if multicol_only:\n",
    "            # Check\n",
    "            num_all_tables = len(self.table_df)\n",
    "            self.table_df = self.table_df[self.table_df[\"num_col\"] > 1]\n",
    "            assert len(self.table_df) == num_all_tables\n",
    "        \"\"\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.table_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"data\": self.table_df.iloc[idx][\"data_tensor\"],\n",
    "            \"label\": self.table_df.iloc[idx][\"label_tensor\"],\n",
    "            \"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"],\n",
    "            \"target_col_mask\": self.table_df.iloc[idx][\"target_col_mask\"],\n",
    "        }\n",
    "        #\"idx\": torch.LongTensor([idx])}\n",
    "        #\"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_columns = group_df.sort_values(by=['col_idx'])\n",
    "first_columns = other_columns.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_columns.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_columns = other_columns.drop(first_columns.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(labeled_columns.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sentence_transformers import SentenceTransformer\n",
    "# sb_model = SentenceTransformer(\"all-mpnet-base-v2\", cache_folder=\"/data/zhihao/TU/Watchog/sentence_transformers_cache\")\n",
    "\n",
    "class GittablesTablewiseIterateSentenceDataset(data.Dataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            cv: int,\n",
    "            split: str,\n",
    "            src: str,  # train or test\n",
    "            tokenizer: AutoTokenizer,\n",
    "            max_length: int = 256,\n",
    "            gt_only: bool = False,\n",
    "            device: torch.device = None,\n",
    "            base_dirpath: str = \"/data/zhihao/TU/GitTables/semtab_gittables/2022\",\n",
    "            base_tag: str = '', # blank, comma\n",
    "            small_tag: str = \"\",\n",
    "            train_ratio: float = 1.0,\n",
    "            max_unlabeled=8,\n",
    "            adaptive_max_length=True,\n",
    "            random_sample=False, # TODO\n",
    "            train_only=False): # TODO\n",
    "        if device is None:\n",
    "            device = torch.device('cpu')\n",
    "        basename = small_tag+ \"_cv_{}.csv\"\n",
    "    \n",
    "        if split in [\"train\", \"valid\"]:\n",
    "            df_list = []\n",
    "            for i in range(5):\n",
    "                if i == cv:\n",
    "                    continue\n",
    "                filepath = os.path.join(base_dirpath, basename.format(i))\n",
    "                df_list.append(pd.read_csv(filepath))\n",
    "                print(split, i)\n",
    "            df = pd.concat(df_list, axis=0)\n",
    "        else:\n",
    "            # test\n",
    "            filepath = os.path.join(base_dirpath, basename.format(cv))\n",
    "            df = pd.read_csv(filepath)\n",
    "            print(split)\n",
    "\n",
    "\n",
    "        if gt_only:\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "        if train_only and split != \"train\":\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "\n",
    "        \n",
    "        data_list = []\n",
    "        \n",
    "        df['class_id'] = df['class_id'].astype(int)\n",
    "        df.drop(df[(df['data'].isna()) & (df['class_id'] == -1)].index, inplace=True)\n",
    "        df['col_idx'] = df['col_idx'].astype(int)\n",
    "        df['data'] = df['data'].astype(str)\n",
    "        \n",
    "        num_tables = len(df.groupby(\"table_id\"))\n",
    "        valid_index = int(num_tables * 0.8)\n",
    "        num_train = int(train_ratio * num_tables * 0.8)        \n",
    "        \n",
    "        # df.drop(df[(df['data'] == '') & (df['class_id'] == -1)].index, inplace=True)\n",
    "        total_num_cols = 0\n",
    "        for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "            if (split == \"train\") and ((i >= num_train) or (i >= valid_index)):\n",
    "                break\n",
    "            if split == \"valid\" and i < valid_index:\n",
    "                continue\n",
    "            #     break\n",
    "            group_df.sort_values(by=[\"col_idx\"], inplace=True)\n",
    "            unlabeled_columns = group_df[group_df['class_id'] == -1]\n",
    "            labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "            unlabeled_columns = unlabeled_columns.drop_duplicates(subset=['data'], keep='last')\n",
    "            group_df = pd.concat([labeled_columns, unlabeled_columns])\n",
    "            group_df.sort_values(by=['col_idx'], inplace=True)\n",
    "            group_df = group_df.reset_index(drop=True)\n",
    "            col_embs = torch.tensor(sb_model.encode(group_df[\"data\"].to_list()))\n",
    "            labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "            unlabeled_columns = group_df[group_df['class_id'] == -1]\n",
    "            col_embs_unlabeled = col_embs[torch.tensor(unlabeled_columns.index.values)]\n",
    "            for index_i, target_column in labeled_columns.iterrows():\n",
    "                \n",
    "                chosen_columns_idx = F.cosine_similarity(col_embs[index_i].reshape(1,-1), col_embs).argsort(descending=True)[:max_unlabeled+1].tolist()\n",
    "                chosen_columns_idx = chosen_columns_idx[1:]\n",
    "                target_table = group_df.iloc[chosen_columns_idx]\n",
    "                target_table = pd.concat([target_column.to_frame().T, target_table], ignore_index=True)\n",
    "                \n",
    "                # other_labeled = labeled_columns.drop(index_i)\n",
    "                # chosen_columns_idx = F.cosine_similarity(col_embs[index_i].reshape(1,-1), col_embs_unlabeled).argsort(descending=True)[:max_unlabeled-len(other_labeled)-1].tolist()\n",
    "                # target_table = unlabeled_columns.iloc[chosen_columns_idx]\n",
    "                # target_table = pd.concat([target_column.to_frame().T, other_labeled, target_table], ignore_index=True)\n",
    "                \n",
    "                \n",
    "                target_col_idx = target_table[\"col_idx\"].values[0]\n",
    "                target_cls = target_table[\"class_id\"].values[0]\n",
    "                target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "                col_idx_list = target_table[\"col_idx\"].tolist()\n",
    "                # target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "\n",
    "                if max_length <= 128 and adaptive_max_length:\n",
    "                    cur_maxlen = min(max_length, 512 // len(target_table) - 1)\n",
    "                else:\n",
    "                    cur_maxlen = max_length\n",
    "                    \n",
    "                token_ids_list = target_table[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                    tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=cur_maxlen, truncation=True)).tolist(\n",
    "                    )\n",
    "                token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                                    token_ids_list)).to(device)\n",
    "\n",
    "                target_col_mask = []\n",
    "                cls_index_value = 0\n",
    "                context_id = 1\n",
    "                meet_target = False\n",
    "                for idx, col_i in enumerate(col_idx_list):\n",
    "                    if col_i == target_col_idx:\n",
    "                        target_col_mask += [0] * len(token_ids_list[idx])\n",
    "                        meet_target = True\n",
    "                    else:\n",
    "                        target_col_mask += [context_id] * len(token_ids_list[idx])\n",
    "                        context_id += 1\n",
    "                    if not meet_target:\n",
    "                        cls_index_value += len(token_ids_list[idx])\n",
    "                cls_index_list = [cls_index_value] \n",
    "                for cls_index in cls_index_list:\n",
    "                    assert token_ids[\n",
    "                        cls_index] == tokenizer.cls_token_id, \"cls_indexes validation\"\n",
    "                cls_indexes = torch.LongTensor(cls_index_list).to(device)\n",
    "                class_ids = torch.LongTensor(\n",
    "                    [target_cls]).to(device)\n",
    "                target_col_mask = torch.LongTensor(target_col_mask).to(device)\n",
    "                data_list.append(\n",
    "                    [index,\n",
    "                    len(target_table), token_ids, class_ids, cls_indexes, target_col_mask])                \n",
    "        print(split, len(data_list))\n",
    "        self.table_df = pd.DataFrame(data_list,\n",
    "                                     columns=[\n",
    "                                         \"table_id\", \"num_col\", \"data_tensor\",\n",
    "                                         \"label_tensor\", \"cls_indexes\", \"target_col_mask\"\n",
    "                                     ])\n",
    "        \"\"\"\n",
    "        # NOTE: msato contains a small portion of single-col tables. keep it to be consistent.  \n",
    "        if multicol_only:\n",
    "            # Check\n",
    "            num_all_tables = len(self.table_df)\n",
    "            self.table_df = self.table_df[self.table_df[\"num_col\"] > 1]\n",
    "            assert len(self.table_df) == num_all_tables\n",
    "        \"\"\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.table_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"data\": self.table_df.iloc[idx][\"data_tensor\"],\n",
    "            \"label\": self.table_df.iloc[idx][\"label_tensor\"],\n",
    "            \"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"],\n",
    "            \"target_col_mask\": self.table_df.iloc[idx][\"target_col_mask\"],\n",
    "        }\n",
    "        #\"idx\": torch.LongTensor([idx])}\n",
    "        #\"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sentence_transformers import SentenceTransformer\n",
    "# sb_model = SentenceTransformer(\"all-mpnet-base-v2\", cache_folder=\"/data/zhihao/TU/Watchog/sentence_transformers_cache\")\n",
    "\n",
    "class GittablesTablewiseCorrelationDataset(data.Dataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            cv: int,\n",
    "            split: str,\n",
    "            src: str,  # train or test\n",
    "            tokenizer: AutoTokenizer,\n",
    "            max_length: int = 256,\n",
    "            gt_only: bool = False,\n",
    "            device: torch.device = None,\n",
    "            base_dirpath: str = \"/data/zhihao/TU/GitTables/semtab_gittables/2022\",\n",
    "            base_tag: str = '', # blank, comma\n",
    "            small_tag: str = \"\",\n",
    "            train_ratio: float = 1.0,\n",
    "            max_unlabeled=8,\n",
    "            adaptive_max_length=True,\n",
    "            random_sample=False, # TODO\n",
    "            train_only=False): # TODO\n",
    "        if device is None:\n",
    "            device = torch.device('cpu')\n",
    "        basename = small_tag+ \"_cv_{}.csv\"\n",
    "    \n",
    "        if split in [\"train\", \"valid\"]:\n",
    "            df_list = []\n",
    "            for i in range(5):\n",
    "                if i == cv:\n",
    "                    continue\n",
    "                filepath = os.path.join(base_dirpath, basename.format(i))\n",
    "                df_list.append(pd.read_csv(filepath))\n",
    "                print(split, i)\n",
    "            df = pd.concat(df_list, axis=0)\n",
    "        else:\n",
    "            # test\n",
    "            filepath = os.path.join(base_dirpath, basename.format(cv))\n",
    "            df = pd.read_csv(filepath)\n",
    "            print(split)\n",
    "\n",
    "\n",
    "        if gt_only:\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "        if train_only and split != \"train\":\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "\n",
    "        \n",
    "        data_list = []\n",
    "        \n",
    "        df['class_id'] = df['class_id'].astype(int)\n",
    "        df.drop(df[(df['data'].isna()) & (df['class_id'] == -1)].index, inplace=True)\n",
    "        df['col_idx'] = df['col_idx'].astype(int)\n",
    "        df['data'] = df['data'].astype(str)\n",
    "        \n",
    "        num_tables = len(df.groupby(\"table_id\"))\n",
    "        valid_index = int(num_tables * 0.8)\n",
    "        num_train = int(train_ratio * num_tables * 0.8)        \n",
    "        \n",
    "        # df.drop(df[(df['data'] == '') & (df['class_id'] == -1)].index, inplace=True)\n",
    "        total_num_cols = 0\n",
    "        for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "            if (split == \"train\") and ((i >= num_train) or (i >= valid_index)):\n",
    "                break\n",
    "            if split == \"valid\" and i < valid_index:\n",
    "                continue\n",
    "            #     break\n",
    "            group_df.sort_values(by=['col_idx'], inplace=True)\n",
    "            group_df = group_df.reset_index(drop=True)\n",
    "            labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "            # if len(group_df) > 10:\n",
    "            #     print(i, len(group_df))\n",
    "            for index, target_column in labeled_columns.iterrows():\n",
    "                other_columns = group_df.drop(index)\n",
    "                # other_columns = group_df.drop(labeled_columns.index) # TODO\n",
    "                target_col_idx = target_column[\"col_idx\"]\n",
    "                if len(other_columns) ==  0:\n",
    "                    target_table = group_df\n",
    "                else:\n",
    "                    column_pairs = []\n",
    "                    for index in range(len(other_columns)):\n",
    "                        if other_columns.iloc[index][\"col_idx\"] <= target_col_idx:\n",
    "                            column_pairs.append((other_columns.iloc[index][\"data\"], target_column[\"data\"]))\n",
    "                        else:\n",
    "                            column_pairs.append((target_column[\"data\"], other_columns.iloc[index][\"data\"]))\n",
    "                    encoded_pairs = tokenizer.batch_encode_plus(\n",
    "                        column_pairs,\n",
    "                        return_tensors='pt',  # Return PyTorch tensors\n",
    "                        max_length=512,  # Set a maximum length for each pair\n",
    "                        truncation=True,  # Enable truncation\n",
    "                        padding=True  # Pad to the longest sequence in the batch\n",
    "                    )\n",
    "                    with torch.no_grad():\n",
    "                        outputs = next_predictor(**encoded_pairs)\n",
    "                    scores = torch.softmax(outputs.logits, dim=1)[:, 0]\n",
    "                    selected_idx = scores.topk(min(max_unlabeled, len(group_df))-1).indices.tolist()\n",
    "                    target_table = pd.concat([target_column.to_frame().T, other_columns.iloc[selected_idx]], ignore_index=True) \n",
    "                    # selected_idx = scores.topk(min(max_unlabeled, len(group_df))-1-len(labeled_columns)).indices.tolist() # TODO\n",
    "                    # target_table = pd.concat([labeled_columns, other_columns.iloc[selected_idx]], ignore_index=True) # TODO\n",
    "                target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "                \n",
    "                target_cls = target_column[\"class_id\"]\n",
    "                col_idx_list = target_table[\"col_idx\"].tolist()\n",
    "                assert target_col_idx in col_idx_list\n",
    "                target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "\n",
    "                if max_length <= 128 and adaptive_max_length:\n",
    "                    cur_maxlen = min(max_length, 512 // len(target_table) - 1)\n",
    "                else:\n",
    "                    cur_maxlen = max_length\n",
    "                    \n",
    "                token_ids_list = target_table[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                    tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=cur_maxlen, truncation=True)).tolist(\n",
    "                    )\n",
    "                token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                                    token_ids_list)).to(device)\n",
    "\n",
    "                target_col_mask = []\n",
    "                cls_index_value = 0\n",
    "                context_id = 1\n",
    "                meet_target = False\n",
    "                for idx, col_i in enumerate(col_idx_list):\n",
    "                    if col_i == target_col_idx:\n",
    "                        target_col_mask += [0] * len(token_ids_list[idx])\n",
    "                        meet_target = True\n",
    "                    else:\n",
    "                        target_col_mask += [context_id] * len(token_ids_list[idx])\n",
    "                        context_id += 1\n",
    "                    if not meet_target:\n",
    "                        cls_index_value += len(token_ids_list[idx])\n",
    "                cls_index_list = [cls_index_value] \n",
    "                for cls_index in cls_index_list:\n",
    "                    assert token_ids[\n",
    "                        cls_index] == tokenizer.cls_token_id, \"cls_indexes validation\"\n",
    "                cls_indexes = torch.LongTensor(cls_index_list).to(device)\n",
    "                class_ids = torch.LongTensor(\n",
    "                    [target_cls]).to(device)\n",
    "                target_col_mask = torch.LongTensor(target_col_mask).to(device)\n",
    "                data_list.append(\n",
    "                    [index,\n",
    "                    len(target_table), token_ids, class_ids, cls_indexes, target_col_mask])                \n",
    "        print(split, len(data_list))\n",
    "        self.table_df = pd.DataFrame(data_list,\n",
    "                                     columns=[\n",
    "                                         \"table_id\", \"num_col\", \"data_tensor\",\n",
    "                                         \"label_tensor\", \"cls_indexes\", \"target_col_mask\"\n",
    "                                     ])\n",
    "        \"\"\"\n",
    "        # NOTE: msato contains a small portion of single-col tables. keep it to be consistent.  \n",
    "        if multicol_only:\n",
    "            # Check\n",
    "            num_all_tables = len(self.table_df)\n",
    "            self.table_df = self.table_df[self.table_df[\"num_col\"] > 1]\n",
    "            assert len(self.table_df) == num_all_tables\n",
    "        \"\"\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.table_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"data\": self.table_df.iloc[idx][\"data_tensor\"],\n",
    "            \"label\": self.table_df.iloc[idx][\"label_tensor\"],\n",
    "            \"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"],\n",
    "            \"target_col_mask\": self.table_df.iloc[idx][\"target_col_mask\"],\n",
    "        }\n",
    "        #\"idx\": torch.LongTensor([idx])}\n",
    "        #\"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column[\"class_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok = False\n",
    "for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "    group_df.sort_values(by=[\"col_idx\"], inplace=True)\n",
    "    group_df = group_df.reset_index(drop=True)\n",
    "    labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "    # if len(group_df) > 10:\n",
    "    #     print(i, len(group_df))\n",
    "    for index, target_column in labeled_columns.iterrows():\n",
    "\n",
    "        target_col_idx = target_column[\"col_idx\"]\n",
    "        column_pairs = []\n",
    "        for index in range(len(group_df)):\n",
    "            if group_df.iloc[index][\"col_idx\"] <= target_col_idx:\n",
    "                column_pairs.append((group_df.iloc[index][\"data\"], target_column[\"data\"]))\n",
    "            else:\n",
    "                column_pairs.append((target_column[\"data\"], group_df.iloc[index][\"data\"]))\n",
    "        encoded_pairs = tokenizer.batch_encode_plus(\n",
    "            column_pairs,\n",
    "            return_tensors='pt',  # Return PyTorch tensors\n",
    "            max_length=512,  # Set a maximum length for each pair\n",
    "            truncation=True,  # Enable truncation\n",
    "            padding=True  # Pad to the longest sequence in the batch\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            outputs = next_predictor(**encoded_pairs)\n",
    "        scores = torch.softmax(outputs.logits, dim=1)[:, 0]\n",
    "        selected_idx = scores.topk(min(max_unlabeled, len(group_df))).indices.tolist()\n",
    "        if min(selected_idx) < target_col_idx and max(selected_idx) > target_col_idx and len(group_df) > 10:\n",
    "            ok = True\n",
    "        target_table = group_df.iloc[selected_idx]\n",
    "\n",
    "        target_table.sort_values(by=['col_idx'], inplace=True) \n",
    "    \n",
    "        \n",
    "    #     if target_col_idx != 0 and target_col_idx < len(group_df)-1 and len(group_df) > 10:\n",
    "    #         ok = True\n",
    "    #         break\n",
    "    if ok:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptive_max_length=True\n",
    "global_i = 0 \n",
    "for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "    group_df.sort_values(by=['class_id'], inplace=True)\n",
    "    unlabeled_columns = group_df[group_df['class_id'] == -1]\n",
    "    labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "    unlabeled_columns = unlabeled_columns.drop_duplicates(subset=['data'], keep='last')\n",
    "    group_df = pd.concat([labeled_columns, unlabeled_columns])\n",
    "    group_df.sort_values(by=['col_idx'], inplace=True)\n",
    "    group_df = group_df.reset_index(drop=True)\n",
    "    col_embs = torch.tensor(sb_model.encode(group_df[\"data\"].to_list()))\n",
    "    labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "    for index_i, target_column in labeled_columns.iterrows():\n",
    "        \n",
    "        chosen_columns_idx = F.cosine_similarity(col_embs[index_i].reshape(1,-1), col_embs).argsort(descending=True)[:max_unlabeled+1].tolist()\n",
    "        chosen_columns_idx.remove(index_i)\n",
    "        target_table = group_df.iloc[chosen_columns_idx]\n",
    "        target_table = pd.concat([target_column.to_frame().T, target_table], ignore_index=True)\n",
    "\n",
    "        # other_labeled = labeled_columns.drop(index_i)\n",
    "        # target_table = group_df.iloc[F.cosine_similarity(col_embs[index_i].reshape(1,-1), col_embs).argsort(descending=True)[:max_unlabeled-len(other_labeled)].tolist()]\n",
    "        # target_table = pd.concat([target_table, other_labeled], ignore_index=True)\n",
    "        \n",
    "        target_col_idx = target_table[\"col_idx\"].values[0]\n",
    "        target_cls = target_table[\"class_id\"].values[0]\n",
    "        if target_cls != labels_test_original[global_i]:\n",
    "            print(i, target_cls, labels_test_original[global_i].item())\n",
    "            raise ValueError(\"target_cls != labels_test_original[global_i]\")\n",
    "        \n",
    "        target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "        col_idx_list = target_table[\"col_idx\"].tolist()\n",
    "        # target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "\n",
    "        if max_length <= 128 and adaptive_max_length:\n",
    "            cur_maxlen = min(max_length, 512 // len(target_table) - 1)\n",
    "        else:\n",
    "            cur_maxlen = max_length\n",
    "            \n",
    "        token_ids_list = target_table[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "            tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=cur_maxlen, truncation=True)).tolist(\n",
    "            )\n",
    "        token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                            token_ids_list)).to(device)\n",
    "\n",
    "        target_col_mask = []\n",
    "        cls_index_value = 0\n",
    "        context_id = 1\n",
    "        meet_target = False\n",
    "        for idx, col_i in enumerate(col_idx_list):\n",
    "            if col_i == target_col_idx:\n",
    "                target_col_mask += [0] * len(token_ids_list[idx])\n",
    "                meet_target = True\n",
    "            else:\n",
    "                target_col_mask += [context_id] * len(token_ids_list[idx])\n",
    "                context_id += 1\n",
    "            if not meet_target:\n",
    "                cls_index_value += len(token_ids_list[idx])\n",
    "        cls_index_list = [cls_index_value] \n",
    "        for cls_index in cls_index_list:\n",
    "            assert token_ids[\n",
    "                cls_index] == tokenizer.cls_token_id, \"cls_indexes validation\"\n",
    "        cls_indexes = torch.LongTensor(cls_index_list).to(device)\n",
    "        class_ids = torch.LongTensor(\n",
    "            [target_cls]).to(device)\n",
    "        target_col_mask = torch.LongTensor(target_col_mask).to(device)\n",
    "        global_i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "for index, target_column in labeled_columns.iterrows():\n",
    "    target_col_idx = target_column[\"col_idx\"]\n",
    "    \n",
    "    other_columns = group_df.drop(index).drop_duplicates(subset=['data'], keep='first')\n",
    "    \n",
    "    # other_columns['distance'] = abs(other_columns['col_idx'] - target_col_idx)\n",
    "    # other_columns.sort_values(by='distance', inplace=True)\n",
    "    # nearby_columns = other_columns.head(max_unlabeled-1)\n",
    "    # target_table = pd.concat([target_column.to_frame().T, nearby_columns], ignore_index=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    other_labeled = other_columns[other_columns['class_id'] > -1].head(max_unlabeled-1)\n",
    "    other_unlabeled = other_columns[other_columns['class_id'] == -1]\n",
    "    other_unlabeled['distance'] = abs(other_unlabeled['col_idx'] - target_col_idx)\n",
    "    other_unlabeled.sort_values(by='distance', inplace=True)\n",
    "    nearby_columns = other_unlabeled.head(max_unlabeled-len(other_labeled)-1)\n",
    "    target_table = pd.concat([target_column.to_frame().T, other_labeled, nearby_columns], ignore_index=True)\n",
    "    i += 1\n",
    "    if i == 2:\n",
    "        break\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df= group_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df_reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "for index, target_column in labeled_columns.iterrows():\n",
    "    top_columns = group_df.iloc[F.cosine_similarity(col_embs[index].reshape(1,-1), col_embs).argsort(descending=True)[:8].tolist()]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_unlabeled = 8\n",
    "labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "for index, target_column in labeled_columns.iterrows():\n",
    "    other_labeled = labeled_columns.drop(index)\n",
    "    target_table = group_df.iloc[F.cosine_similarity(col_embs[index].reshape(1,-1), col_embs).argsort(descending=True)[:max_unlabeled-len(other_labeled)].tolist()]\n",
    "    target_table = pd.concat([target_table, other_labeled], ignore_index=True)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "sb_model = SentenceTransformer(\"all-mpnet-base-v2\", cache_folder=\"/data/zhihao/TU/Watchog/sentence_transformers_cache\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "import os\n",
    "# Set the cache directory\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/data/zhihao/TU/Watchog/sentence_transformers_cache'\n",
    "cross_encoder = CrossEncoder(\"cross-encoder/stsb-roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_encoder.predict([\n",
    "    (\"2014;2014;2014;2014;2014;2014;2014;2014;2014\", \"2014R1G1MW;2014R1G2MW;2014R1G3MW;2014R1G4MW;\"),\n",
    "    (\"2014-03-17;2014-03-17;2014-03-17;2014-03-18;\", \"2014;2014;2014;2014;2014;2014;2014;2014;2014\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left right\n",
    "max_unlabeled = 8\n",
    "first_scores = []\n",
    "for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "    group_df.sort_values(by=['col_idx'], inplace=True)\n",
    "    group_df = group_df.reset_index(drop=True)\n",
    "    labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "    labeled_columns.sort_values(by=['col_idx'], inplace=True)\n",
    "    for index, target_column in labeled_columns.iterrows():\n",
    "        other_columns = group_df.drop(index).head(max_unlabeled-1)\n",
    "        target_col_idx = target_column[\"col_idx\"]\n",
    "        left_columns = other_columns[other_columns['col_idx'] < target_col_idx]\n",
    "        right_columns = other_columns[other_columns['col_idx'] > target_col_idx]\n",
    "        left_scores = torch.tensor(left_columns[\"data\"].apply(lambda x: cross_encoder.predict([\n",
    "                (target_column[\"data\"], x)\n",
    "        ])).tolist())\n",
    "        right_scores = torch.tensor(right_columns[\"data\"].apply(lambda x: cross_encoder.predict([\n",
    "                (x, target_column[\"data\"])\n",
    "        ])).tolist())\n",
    "        scores = torch.cat([left_scores,  right_scores], dim=0)\n",
    "        assert len(scores) == len(other_columns)\n",
    "        scores = scores.mean()\n",
    "        first_scores.append(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left right\n",
    "max_unlabeled = 8\n",
    "last_scores = []\n",
    "for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "    group_df.sort_values(by=['col_idx'], inplace=True)\n",
    "    group_df = group_df.reset_index(drop=True)\n",
    "    labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "    labeled_columns.sort_values(by=['col_idx'], inplace=True)\n",
    "    for index, target_column in labeled_columns.iterrows():\n",
    "        other_columns = group_df.drop(index).tail(max_unlabeled-1)\n",
    "        target_col_idx = target_column[\"col_idx\"]\n",
    "        left_columns = other_columns[other_columns['col_idx'] < target_col_idx]\n",
    "        right_columns = other_columns[other_columns['col_idx'] > target_col_idx]\n",
    "        left_scores = torch.tensor(left_columns[\"data\"].apply(lambda x: cross_encoder.predict([\n",
    "                (target_column[\"data\"], x)\n",
    "        ])).tolist())\n",
    "        right_scores = torch.tensor(right_columns[\"data\"].apply(lambda x: cross_encoder.predict([\n",
    "                (x, target_column[\"data\"])\n",
    "        ])).tolist())\n",
    "        scores = torch.cat([left_scores,  right_scores], dim=0)\n",
    "        assert len(scores) == len(other_columns)\n",
    "        scores = scores.mean()\n",
    "        last_scores.append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left right\n",
    "max_unlabeled = 8\n",
    "best_scores = []\n",
    "for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "    group_df.sort_values(by=['col_idx'], inplace=True)\n",
    "    group_df = group_df.reset_index(drop=True)\n",
    "    labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "    labeled_columns.sort_values(by=['col_idx'], inplace=True)\n",
    "    for index, target_column in labeled_columns.iterrows():\n",
    "        other_labeled = labeled_columns.drop(index)\n",
    "        other_columns = group_df.drop(index).head(max_unlabeled-1-len(other_labeled))\n",
    "        target_col_idx = target_column[\"col_idx\"]\n",
    "        target_table = pd.concat([other_labeled, other_columns], ignore_index=True)\n",
    "        target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "        left_columns = target_table[target_table['col_idx'] < target_col_idx]\n",
    "        right_columns = target_table[target_table['col_idx'] > target_col_idx]\n",
    "        left_scores = torch.tensor(left_columns[\"data\"].apply(lambda x: cross_encoder.predict([\n",
    "                (target_column[\"data\"], x)\n",
    "        ])).tolist())\n",
    "        right_scores = torch.tensor(right_columns[\"data\"].apply(lambda x: cross_encoder.predict([\n",
    "                (x, target_column[\"data\"])\n",
    "        ])).tolist())\n",
    "        scores = torch.cat([left_scores, right_scores], dim=0)\n",
    "        assert len(scores) == len(target_table)\n",
    "        scores = scores.mean()\n",
    "        best_scores.append(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_scores.isnan().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_scores = torch.tensor(first_scores)\n",
    "first_scores = first_scores[first_scores.isnan() == False]\n",
    "print(len(first_scores), first_scores.mean(), first_scores.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_scores = torch.tensor(last_scores)\n",
    "last_scores = last_scores[last_scores.isnan() == False]\n",
    "print(len(last_scores), last_scores.mean(), last_scores.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_scores = torch.tensor(best_scores)\n",
    "best_scores = best_scores[best_scores.isnan() == False]\n",
    "print(len(best_scores), best_scores.mean(), best_scores.median())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_unlabeled = 8\n",
    "frist_scores = []\n",
    "for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "    group_df.sort_values(by=['col_idx'], inplace=True)\n",
    "    group_df = group_df.reset_index(drop=True)\n",
    "    labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "    labeled_columns.sort_values(by=['col_idx'], inplace=True)\n",
    "    for index, target_column in labeled_columns.iterrows():\n",
    "        other_columns = group_df.drop(index).head(max_unlabeled-1)\n",
    "        target_col_idx = target_column[\"col_idx\"]\n",
    "        target_table = pd.concat([target_column.to_frame().T, other_columns], ignore_index=True)\n",
    "        target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "        res_i = []\n",
    "        for index in range(len(target_table)-1):\n",
    "            res = cross_encoder.predict([\n",
    "                (target_table.iloc[index][\"data\"], target_table.iloc[index+1][\"data\"])\n",
    "            ])\n",
    "            res_i.append(res)\n",
    "        res_i = torch.tensor(res_i).mean()\n",
    "        frist_scores.append(res_i)\n",
    "frist_scores = torch.tensor(frist_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_unlabeled = 8\n",
    "last_scores = []\n",
    "for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "    group_df.sort_values(by=['col_idx'], inplace=True)\n",
    "    group_df = group_df.reset_index(drop=True)\n",
    "    labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "    labeled_columns.sort_values(by=['col_idx'], inplace=True)\n",
    "    for index, target_column in labeled_columns.iterrows():\n",
    "        other_columns = group_df.drop(index).tail(max_unlabeled-1)\n",
    "        target_col_idx = target_column[\"col_idx\"]\n",
    "        target_table = pd.concat([target_column.to_frame().T, other_columns], ignore_index=True)\n",
    "        target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "        res_i = []\n",
    "        for index in range(len(target_table)-1):\n",
    "            res = cross_encoder.predict([\n",
    "                (target_table.iloc[index][\"data\"], target_table.iloc[index+1][\"data\"])\n",
    "            ])\n",
    "            res_i.append(res)\n",
    "        res_i = torch.tensor(res_i).mean()\n",
    "        last_scores.append(res_i)\n",
    "last_scores = torch.tensor(last_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_unlabeled = 8\n",
    "best_scores = []\n",
    "for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "    group_df.sort_values(by=['col_idx'], inplace=True)\n",
    "    group_df = group_df.reset_index(drop=True)\n",
    "    labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "    labeled_columns.sort_values(by=['col_idx'], inplace=True)\n",
    "    for index, target_column in labeled_columns.iterrows():\n",
    "        other_labeled = labeled_columns.drop(index)\n",
    "        other_columns = group_df.drop(index).head(max_unlabeled-1-len(other_labeled))\n",
    "        target_col_idx = target_column[\"col_idx\"]\n",
    "        target_table = pd.concat([target_column.to_frame().T, other_labeled, other_columns], ignore_index=True)\n",
    "        target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "        res_i = []\n",
    "        for index in range(len(target_table)-1):\n",
    "            res = cross_encoder.predict([\n",
    "                (target_table.iloc[index][\"data\"], target_table.iloc[index+1][\"data\"])\n",
    "            ])\n",
    "            res_i.append(res)\n",
    "        res_i = torch.tensor(res_i).mean()\n",
    "        best_scores.append(res_i)\n",
    "best_scores = torch.tensor(best_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_encoder.predict([\n",
    "                (target_table.iloc[index][\"data\"], target_table.iloc[index+1][\"data\"])\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_table.iloc[1]['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frist_scores = torch.tensor(frist_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frist_scores = frist_scores[frist_scores.isnan() == False]\n",
    "print(frist_scores.mean(), frist_scores.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearby_scores = torch.tensor(nearby_scores)\n",
    "nearby_scores = nearby_scores[nearby_scores.isnan() == False]\n",
    "print(nearby_scores.mean(), nearby_scores.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_scores = torch.tensor(best_scores)\n",
    "best_scores = best_scores[best_scores.isnan() == False]\n",
    "print(best_scores.mean(), best_scores.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_scores = torch.tensor(last_scores)\n",
    "last_scores = last_scores[last_scores.isnan() == False]\n",
    "print(last_scores.mean(), last_scores.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nearby_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(nearby_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearby_scores = []\n",
    "for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "    labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "    for index, target_column in labeled_columns.iterrows():\n",
    "        target_col_idx = target_column[\"col_idx\"]\n",
    "        \n",
    "        other_columns = group_df.drop(index)\n",
    "\n",
    "        other_columns['distance'] = abs(other_columns['col_idx'] - target_col_idx)\n",
    "        other_columns.sort_values(by='distance', inplace=True)\n",
    "        other_columns = other_columns.head(max_unlabeled-1)\n",
    "        other_columns.sort_values(by=['col_idx'], inplace=True)\n",
    "        \n",
    "        target_table = pd.concat([target_column.to_frame().T, other_columns], ignore_index=True)\n",
    "        target_cls = target_table[\"class_id\"].values[0]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearby_scores = []\n",
    "for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "    labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "    for index, target_column in labeled_columns.iterrows():\n",
    "        target_col_idx = target_column[\"col_idx\"]\n",
    "        \n",
    "        other_columns = group_df.drop(index)\n",
    "\n",
    "        other_columns['distance'] = abs(other_columns['col_idx'] - target_col_idx)\n",
    "        other_columns.sort_values(by='distance', inplace=True)\n",
    "        other_columns = other_columns.head(max_unlabeled-1)\n",
    "        target_table = pd.concat([target_column.to_frame().T, other_columns], ignore_index=True)\n",
    "        \n",
    "        target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "        res_i = []\n",
    "        for index in range(len(target_table)-1):\n",
    "            res = cross_encoder.predict([\n",
    "                (target_table.iloc[index][\"data\"], target_table.iloc[index+1][\"data\"])\n",
    "            ])\n",
    "            res_i.append(res)\n",
    "        res_i = torch.tensor(res_i).mean()\n",
    "        nearby_scores.append(res_i)\n",
    "nearby_scores = torch.tensor(nearby_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BertForNextSentencePrediction.from_pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForNextSentencePrediction\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Load the pre-trained model and tokenizer\n",
    "next_predictor = BertForNextSentencePrediction.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Define two sentences\n",
    "sentence_a = \"11.1;12.2;2.0\"\n",
    "sentence_b = \"2014;2002;2001\"\n",
    "\n",
    "# Tokenize and encode the sentences\n",
    "inputs = tokenizer.encode_plus(sentence_a, sentence_b, return_tensors='pt')\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    outputs = next_predictor(**inputs)\n",
    "    logits = outputs.logits\n",
    "\n",
    "# Determine if the second sentence follows the first\n",
    "print(torch.softmax(logits, dim=1)[0][0].item())\n",
    "# print(\"Next Sentence Prediction:\", \"Yes\" if predicted_label == 0 else \"No\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_predictor.load_state_dict(best_state_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define two sentences\n",
    "sentence_a = \"11.1;12.2;2.0\"\n",
    "sentence_b = \"A;B;C\"\n",
    "\n",
    "# Tokenize and encode the sentences\n",
    "inputs = tokenizer.encode_plus(sentence_a, sentence_b, return_tensors='pt')\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    outputs = next_predictor(**inputs)\n",
    "    logits = outputs.logits\n",
    "\n",
    "# Determine if the second sentence follows the first\n",
    "print(torch.softmax(logits, dim=1)[0][0].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define two sentences\n",
    "sentence_a = \"11.1;12.2;2.0\"\n",
    "sentence_b = \"2014;2002;2001\"\n",
    "\n",
    "# Tokenize and encode the sentences\n",
    "inputs = tokenizer.encode_plus(sentence_a, sentence_b, return_tensors='pt')\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    outputs = next_predictor(**inputs)\n",
    "    logits = outputs.logits\n",
    "\n",
    "# Determine if the second sentence follows the first\n",
    "print(torch.softmax(logits, dim=1)[0][0].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define two sentences\n",
    "sentence_a = \"USD; USD; USD\"\n",
    "sentence_b = \"USD; USD; USD\"\n",
    "\n",
    "# Tokenize and encode the sentences\n",
    "inputs = tokenizer.encode_plus(sentence_a, sentence_b, return_tensors='pt')\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    outputs = next_predictor(**inputs)\n",
    "    logits = outputs.logits\n",
    "\n",
    "# Determine if the second sentence follows the first\n",
    "print(torch.softmax(logits, dim=1)[0][0].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.encode_plus(target_table.iloc[index][\"data\"], target_table.iloc[index+1][\"data\"], return_tensors='pt', max_length=256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_unlabeled = 8\n",
    "# best_scores = []\n",
    "# for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "#     group_df.sort_values(by=['col_idx'], inplace=True)\n",
    "#     group_df = group_df.reset_index(drop=True)\n",
    "#     labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "#     labeled_columns.sort_values(by=['col_idx'], inplace=True)\n",
    "#     for index, target_column in labeled_columns.iterrows():\n",
    "#         other_labeled = labeled_columns.drop(index)\n",
    "#         other_columns = group_df.drop(index).head(max_unlabeled-1-len(other_labeled))\n",
    "#         target_col_idx = target_column[\"col_idx\"]\n",
    "#         target_table = pd.concat([target_column.to_frame().T, other_labeled, other_columns], ignore_index=True)\n",
    "#         target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "#         res_i = []\n",
    "#         for index in range(len(target_table)-1):\n",
    "#             # Tokenize and encode the sentences\n",
    "#             inputs = tokenizer.encode_plus(target_table.iloc[index][\"data\"], target_table.iloc[index+1][\"data\"], return_tensors='pt', truncation='longest_first', max_length=512)\n",
    "\n",
    "#             # Make predictions\n",
    "#             with torch.no_grad():\n",
    "#                 outputs = next_predictor(**inputs)\n",
    "#                 logits = outputs.logits\n",
    "\n",
    "#             res = torch.softmax(logits, dim=1)[0][0].item()\n",
    "#             res_i.append(res)\n",
    "#         res_i = torch.tensor(res_i).mean()\n",
    "#         best_scores.append(res_i)\n",
    "# best_scores = torch.tensor(best_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.encode_plus(target_table.iloc[index][\"data\"], target_table.iloc[index+1][\"data\"], return_tensors='pt', truncation='longest_first', max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # left right\n",
    "# max_unlabeled = 8\n",
    "# best_scores = []\n",
    "# for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "#     group_df.sort_values(by=['col_idx'], inplace=True)\n",
    "#     group_df = group_df.reset_index(drop=True)\n",
    "#     labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "#     labeled_columns.sort_values(by=['col_idx'], inplace=True)\n",
    "#     for index, target_column in labeled_columns.iterrows():\n",
    "#         other_labeled = labeled_columns.drop(index)\n",
    "#         other_columns = group_df.drop(index).head(max_unlabeled-1-len(other_labeled))\n",
    "#         target_col_idx = target_column[\"col_idx\"]\n",
    "#         target_table = pd.concat([other_labeled, other_columns], ignore_index=True)\n",
    "#         target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "#         left_columns = target_table[target_table['col_idx'] < target_col_idx]\n",
    "#         right_columns = target_table[target_table['col_idx'] > target_col_idx]\n",
    "#         left_pairs = left_columns[\"data\"].apply(lambda x: tokenizer.encode_plus(x, \n",
    "#                     target_column[\"data\"], return_tensors='pt', truncation='longest_first', max_length=512)).tolist()\n",
    "#         right_pairs = right_columns[\"data\"].apply(lambda x: tokenizer.encode_plus(target_column[\"data\"], x, \n",
    "#                    return_tensors='pt', truncation='longest_first', max_length=512))\n",
    "#         res_i = []\n",
    "#         left_pairs.extend(right_pairs)\n",
    "#         assert len(left_pairs) == len(target_table)\n",
    "#         with torch.no_grad():\n",
    "#             for inputs in left_pairs:\n",
    "#                 outputs = next_predictor(**inputs)\n",
    "#                 logits = outputs.logits\n",
    "#                 res = torch.softmax(logits, dim=1)[0][0].item()\n",
    "#                 res_i.append(res)\n",
    "#         res_i = torch.tensor(res_i).mean()\n",
    "#         best_scores.append(res_i)\n",
    "# best_scores = torch.tensor(best_scores)\n",
    "\n",
    "# last_scores = []\n",
    "# for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "#     group_df.sort_values(by=['col_idx'], inplace=True)\n",
    "#     group_df = group_df.reset_index(drop=True)\n",
    "#     labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "#     labeled_columns.sort_values(by=['col_idx'], inplace=True)\n",
    "#     for index, target_column in labeled_columns.iterrows():\n",
    "#         other_columns = group_df.drop(index).tail(max_unlabeled-1)\n",
    "#         target_col_idx = target_column[\"col_idx\"]\n",
    "#         target_table = other_columns\n",
    "#         target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "#         left_columns = target_table[target_table['col_idx'] < target_col_idx]\n",
    "#         right_columns = target_table[target_table['col_idx'] > target_col_idx]\n",
    "#         left_pairs = left_columns[\"data\"].apply(lambda x: tokenizer.encode_plus(x, \n",
    "#                     target_column[\"data\"], return_tensors='pt', truncation='longest_first', max_length=512)).tolist()\n",
    "#         right_pairs = right_columns[\"data\"].apply(lambda x: tokenizer.encode_plus(target_column[\"data\"], x, \n",
    "#                    return_tensors='pt', truncation='longest_first', max_length=512))\n",
    "#         res_i = []\n",
    "#         left_pairs.extend(right_pairs)\n",
    "#         assert len(left_pairs) == len(target_table)\n",
    "#         with torch.no_grad():\n",
    "#             for inputs in left_pairs:\n",
    "#                 outputs = next_predictor(**inputs)\n",
    "#                 logits = outputs.logits\n",
    "#                 res = torch.softmax(logits, dim=1)[0][0].item()\n",
    "#                 res_i.append(res)\n",
    "#         res_i = torch.tensor(res_i).mean()\n",
    "#         last_scores.append(res_i)\n",
    "# last_scores = torch.tensor(last_scores)           \n",
    "\n",
    "# first_scores = []\n",
    "# for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "#     group_df.sort_values(by=['col_idx'], inplace=True)\n",
    "#     group_df = group_df.reset_index(drop=True)\n",
    "#     labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "#     labeled_columns.sort_values(by=['col_idx'], inplace=True)\n",
    "#     for index, target_column in labeled_columns.iterrows():\n",
    "#         other_columns = group_df.drop(index).head(max_unlabeled-1)\n",
    "#         target_col_idx = target_column[\"col_idx\"]\n",
    "#         target_table = other_columns\n",
    "#         target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "#         left_columns = target_table[target_table['col_idx'] < target_col_idx]\n",
    "#         right_columns = target_table[target_table['col_idx'] > target_col_idx]\n",
    "#         left_pairs = left_columns[\"data\"].apply(lambda x: tokenizer.encode_plus(x, \n",
    "#                     target_column[\"data\"], return_tensors='pt', truncation='longest_first', max_length=512)).tolist()\n",
    "#         right_pairs = right_columns[\"data\"].apply(lambda x: tokenizer.encode_plus(target_column[\"data\"], x, \n",
    "#                    return_tensors='pt', truncation='longest_first', max_length=512))\n",
    "#         res_i = []\n",
    "#         left_pairs.extend(right_pairs)\n",
    "#         assert len(left_pairs) == len(target_table)\n",
    "#         with torch.no_grad():\n",
    "#             for inputs in left_pairs:\n",
    "#                 outputs = next_predictor(**inputs)\n",
    "#                 logits = outputs.logits\n",
    "#                 res = torch.softmax(logits, dim=1)[0][0].item()\n",
    "#                 res_i.append(res)\n",
    "#         res_i = torch.tensor(res_i).mean()\n",
    "#         first_scores.append(res_i)\n",
    "# first_scores = torch.tensor(first_scores)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok = False\n",
    "for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "    group_df.sort_values(by=['col_idx'], inplace=True)\n",
    "    group_df = group_df.reset_index(drop=True)\n",
    "    labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "    labeled_columns.sort_values(by=['col_idx'], inplace=True)\n",
    "    for index, target_column in labeled_columns.iterrows():\n",
    "        target_col_idx = target_column[\"col_idx\"]\n",
    "        if target_col_idx != 0 and target_col_idx < len(group_df)-1:\n",
    "            ok = True\n",
    "            break\n",
    "    if ok:\n",
    "        break\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(column_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_table = pd.concat([target_column.to_frame().T, other_labeled, other_columns], ignore_index=True)\n",
    "column_pairs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.histplot(best_scores[best_scores.isnan() == False])\n",
    "print(best_scores[best_scores.isnan() == False].median(), best_scores[best_scores.isnan() == False].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.histplot(last_scores[last_scores.isnan() == False])\n",
    "print(last_scores[last_scores.isnan() == False].median(), last_scores[last_scores.isnan() == False].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(first_scores[first_scores.isnan() == False].median(), first_scores[first_scores.isnan() == False].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(first_scores[first_scores.isnan() == False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(last_scores[last_scores.isnan() == False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(best_scores[best_scores.isnan() == False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use doduo state_dict\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "# max_unlabeled = 8\n",
    "# frist_scores = []\n",
    "# for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "#     group_df.sort_values(by=['col_idx'], inplace=True)\n",
    "#     group_df = group_df.reset_index(drop=True)\n",
    "#     labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "#     labeled_columns.sort_values(by=['col_idx'], inplace=True)\n",
    "#     for index, target_column in labeled_columns.iterrows():\n",
    "#         other_columns = group_df.drop(index).head(max_unlabeled-1)\n",
    "#         target_col_idx = target_column[\"col_idx\"]\n",
    "#         target_table = pd.concat([target_column.to_frame().T, other_columns], ignore_index=True)\n",
    "#         target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "#         res_i = []\n",
    "#         for index in range(len(target_table)-1):\n",
    "#             # Tokenize and encode the sentences\n",
    "#             inputs = tokenizer.encode_plus(target_table.iloc[index][\"data\"], target_table.iloc[index+1][\"data\"], return_tensors='pt', truncation='longest_first', max_length=512)\n",
    "\n",
    "#             # Make predictions\n",
    "#             with torch.no_grad():\n",
    "#                 outputs = next_predictor(**inputs)\n",
    "#                 logits = outputs.logits\n",
    "\n",
    "#             res = torch.softmax(logits, dim=1)[0][0].item()\n",
    "#             res_i.append(res)\n",
    "#         res_i = torch.tensor(res_i).mean()\n",
    "#         frist_scores.append(res_i)\n",
    "# frist_scores = torch.tensor(frist_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use doduo state_dict\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "# max_unlabeled = 8\n",
    "# last_scores = []\n",
    "# for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "#     group_df.sort_values(by=['col_idx'], inplace=True)\n",
    "#     group_df = group_df.reset_index(drop=True)\n",
    "#     labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "#     labeled_columns.sort_values(by=['col_idx'], inplace=True)\n",
    "#     for index, target_column in labeled_columns.iterrows():\n",
    "#         other_columns = group_df.drop(index).tail(max_unlabeled-1)\n",
    "#         target_col_idx = target_column[\"col_idx\"]\n",
    "#         target_table = pd.concat([target_column.to_frame().T, other_columns], ignore_index=True)\n",
    "#         target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "#         res_i = []\n",
    "#         for index in range(len(target_table)-1):\n",
    "#             # Tokenize and encode the sentences\n",
    "#             inputs = tokenizer.encode_plus(target_table.iloc[index][\"data\"], target_table.iloc[index+1][\"data\"], return_tensors='pt', truncation='longest_first', max_length=512)\n",
    "\n",
    "#             # Make predictions\n",
    "#             with torch.no_grad():\n",
    "#                 outputs = next_predictor(**inputs)\n",
    "#                 logits = outputs.logits\n",
    "\n",
    "#             res = torch.softmax(logits, dim=1)[0][0].item()\n",
    "#             res_i.append(res)\n",
    "#         res_i = torch.tensor(res_i).mean()\n",
    "#         last_scores.append(res_i)\n",
    "# last_scores = torch.tensor(last_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_embs = torch.tensor(sb_model.encode(group_df[\"data\"].to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df.iloc[F.cosine_similarity(col_embs[11].reshape(1,-1), col_embs).argsort(descending=True)[:8].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_scores = group_df[\"data\"].apply(lambda x: classify_column(x)).tolist(\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for index, target_column in labeled_columns.iterrows():\n",
    "    target_col_idx = target_column[\"col_idx\"]\n",
    "    \n",
    "    other_columns = group_df.drop(index).drop_duplicates(subset=['data'], keep='first')\n",
    "    # other_labeled = other_columns[other_columns['class_id'] > -1].head(max_unlabeled-1)\n",
    "    # other_unlabeled = other_columns[other_columns['class_id'] == -1].head(max_unlabeled-len(other_labeled)-1)\n",
    "    other_columns['distance'] = abs(other_columns['col_idx'] - target_col_idx)\n",
    "    other_columns.sort_values(by='distance', inplace=True)\n",
    "    nearby_columns = other_columns.head(max_unlabeled-1)\n",
    "\n",
    "    target_table = pd.concat([target_column.to_frame().T, nearby_columns], ignore_index=True)\n",
    "    i += 1\n",
    "    if i == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column[\"col_idx\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df[\"semantic_scores\"] = semantic_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df.sort_values(by=['semantic_scores'], ascending=False, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(group_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "    labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "    if len(labeled_columns) >= 3 and len(group_df) >= 10:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_unlabeled = 8\n",
    "adaptive_max_length=False\n",
    "data_list = []\n",
    "\n",
    "\n",
    "semantic_scores = torch.tensor(group_df[\"data\"].apply(lambda x: classify_column(x.split(';'))).tolist())\n",
    "group_df[\"semantic_scores\"] = semantic_scores\n",
    "group_df.sort_values(by=['semantic_scores'], ascending=False, inplace=True) \n",
    "labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "row_count = 0\n",
    "for index, target_column in labeled_columns.iterrows():\n",
    "    other_columns = group_df.drop(index)\n",
    "    # Get the top K-1 rows\n",
    "    target_contexts = other_columns.head(max_unlabeled-1)\n",
    "\n",
    "    target_table = pd.concat([target_column.to_frame().T, target_contexts], ignore_index=True)\n",
    "    target_col_idx = target_table[\"col_idx\"].values[0]\n",
    "    target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "    col_idx_list = target_table[\"col_idx\"].tolist()\n",
    "    # target_table.sort_values(by=['col_idx'], inplace=True)\n",
    "\n",
    "    if max_length <= 128 and adaptive_max_length:\n",
    "        cur_maxlen = min(max_length, 512 // len(target_table) - 1)\n",
    "    else:\n",
    "        cur_maxlen = max_length\n",
    "        \n",
    "    token_ids_list = target_table[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "        tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=cur_maxlen, truncation=True)).tolist(\n",
    "        )\n",
    "    token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                        token_ids_list)).to(device)\n",
    "\n",
    "    target_col_mask = []\n",
    "    cls_index_value = 0\n",
    "    context_id = 1\n",
    "    meet_target = False\n",
    "    for idx, col_i in enumerate(col_idx_list):\n",
    "        if col_i == target_col_idx:\n",
    "            target_col_mask += [0] * len(token_ids_list[idx])\n",
    "            meet_target = True\n",
    "        else:\n",
    "            target_col_mask += [context_id] * len(token_ids_list[idx])\n",
    "            context_id += 1\n",
    "        if not meet_target:\n",
    "            cls_index_value += len(token_ids_list[idx])\n",
    "    cls_index_list = [cls_index_value] \n",
    "    for cls_index in cls_index_list:\n",
    "        assert token_ids[\n",
    "            cls_index] == tokenizer.cls_token_id, \"cls_indexes validation\"\n",
    "    cls_indexes = torch.LongTensor(cls_index_list).to(device)\n",
    "    class_ids = torch.LongTensor(\n",
    "        [target_table[\"class_id\"].values[0]]).to(device)\n",
    "    target_col_mask = torch.LongTensor(target_col_mask).to(device)\n",
    "    data_list.append(\n",
    "        [index,\n",
    "        len(target_table), token_ids, class_ids, cls_indexes, target_col_mask])   \n",
    "    row_count += 1\n",
    "    if row_count == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_table[\"col_idx\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_table = target_table.drop_duplicates(subset=['data'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_i in data_list:\n",
    "    print(tokenizer.decode(data_i[2].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(pad_token_id, data_only=True):\n",
    "    '''padder for input batch'''\n",
    "\n",
    "    def padder(samples):    \n",
    "        data = torch.nn.utils.rnn.pad_sequence(\n",
    "            [sample[\"data\"] for sample in samples], padding_value=pad_token_id)\n",
    "        if not data_only:\n",
    "            label = torch.nn.utils.rnn.pad_sequence(\n",
    "                [sample[\"label\"] for sample in samples], padding_value=-1)\n",
    "        else:\n",
    "            label = torch.cat([sample[\"label\"] for sample in samples])\n",
    "        batch = {\"data\": data, \"label\": label}\n",
    "        if \"idx\" in samples[0]:\n",
    "            batch[\"idx\"] = [sample[\"idx\"] for sample in samples]\n",
    "        if \"cls_indexes\" in samples[0]:\n",
    "            cls_indexes = torch.nn.utils.rnn.pad_sequence(\n",
    "                [sample[\"cls_indexes\"] for sample in samples], padding_value=0)\n",
    "            batch[\"cls_indexes\"] = cls_indexes\n",
    "        if \"target_col_mask\" in samples[0]:\n",
    "            target_col_mask = torch.nn.utils.rnn.pad_sequence(\n",
    "                [sample[\"target_col_mask\"] for sample in samples], padding_value=-1)\n",
    "            batch[\"target_col_mask\"] = target_col_mask\n",
    "        if \"table_embedding\" in samples[0]:\n",
    "            table_embeddings = [sample[\"table_embedding\"] for sample in samples]\n",
    "            batch[\"table_embedding\"] = torch.stack(table_embeddings, dim=0)\n",
    "        return batch\n",
    "        \n",
    "    return padder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "test 1085\n"
     ]
    }
   ],
   "source": [
    "src = None\n",
    "test_dataset_iter = GittablesTablewiseIterateDataset(cv=cv,\n",
    "                            split=\"test\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only='all' not in task,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\")\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "test_dataloader_iter = DataLoader(test_dataset_iter,\n",
    "                                batch_size=1,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels_iter = []\n",
    "for batch in test_dataloader_iter:\n",
    "    all_labels_iter += batch[\"label\"].cpu().tolist()\n",
    "all_labels_iter = torch.tensor(all_labels_iter)\n",
    "torch.equal(all_labels_iter, labels_test_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "test 1085\n"
     ]
    }
   ],
   "source": [
    "src = None\n",
    "test_dataset_lb = GittablesTablewiseIterateLabelDataset(cv=cv,\n",
    "                            split=\"test\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only='all' not in task,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\")\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "test_dataloader_lb = DataLoader(test_dataset_lb,\n",
    "                                batch_size=1,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(test_dataset_lb.correctness_checklist)/len(test_dataset_lb.correctness_checklist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels_lb = []\n",
    "for batch in test_dataloader_iter:\n",
    "    all_labels_lb += batch[\"label\"].cpu().tolist()\n",
    "all_labels_lb = torch.tensor(all_labels_lb)\n",
    "torch.equal(all_labels_lb, labels_test_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_pos_iter = []\n",
    "for batch in test_dataloader_iter:\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    init_permutation_i = get_permutation(target_col_mask)\n",
    "    labeled_pos_iter.append(init_permutation_i.index(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "test 1085\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "src = None\n",
    "test_dataset_first = GittablesTablewiseFirstDataset(cv=cv,\n",
    "                            split=\"test\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only='all' not in task,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\")\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "test_dataloader_first = DataLoader(test_dataset_first,\n",
    "                                batch_size=1,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "src = None\n",
    "test_dataset_nf = GittablesTablewiseIterateNearbyFirstDataset(cv=cv,\n",
    "                            split=\"test\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only='all' not in task,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\",\n",
    "                            nearby_num=2)\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "test_dataloader_nf = DataLoader(test_dataset_nf,\n",
    "                                batch_size=1,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels_f = []\n",
    "for batch in test_dataloader_first:\n",
    "    all_labels_f += batch[\"label\"].cpu().tolist()\n",
    "all_labels_f = torch.tensor(all_labels_f)\n",
    "torch.equal(all_labels_f, labels_test_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch['cls_indexes'].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    init_permutation_i = get_permutation(target_col_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_columns[\"col_idx\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_col_idx = []\n",
    "for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "    group_df.sort_values(by=[\"col_idx\"], inplace=True)\n",
    "    group_df = group_df.reset_index(drop=True)\n",
    "    labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "    # if len(group_df) > 10:\n",
    "    #     print(i, len(group_df))\n",
    "    labeled_col_idx.extend(labeled_columns[\"col_idx\"].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_col_idx = torch.tensor(labeled_col_idx)\n",
    "(labeled_col_idx<8).sum()/len(labeled_col_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(labeled_pos_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_pos_first = []\n",
    "for batch in test_dataloader_first:\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    init_permutation_i = get_permutation(target_col_mask)\n",
    "    labeled_pos_first.append(init_permutation_i.index(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(labeled_pos).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols_dataset = []\n",
    "for batch in test_dataloader_first:\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    init_permutation_i = get_permutation(target_col_mask)\n",
    "    num_cols_dataset.append(len(init_permutation_i))\n",
    "num_cols_dataset = torch.tensor(num_cols_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_pos_iter = torch.tensor(labeled_pos_iter)\n",
    "sns.histplot(labeled_pos_iter)\n",
    "print((labeled_pos_iter==0).sum()/len(labeled_pos_iter), (labeled_pos_iter==(num_cols_dataset-1)).sum()/len(labeled_pos_iter), 1-(labeled_pos_iter==0).sum()/len(labeled_pos_iter)-(labeled_pos_iter==(num_cols_dataset-1)).sum()/len(labeled_pos_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_pos_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(labeled_pos_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# src = None\n",
    "# test_dataset_cor = GittablesTablewiseCorrelationDataset(cv=cv,\n",
    "#                             split=\"test\", src=src,\n",
    "#                             tokenizer=tokenizer,\n",
    "#                             max_length=max_length,\n",
    "#                             gt_only='all' not in task,\n",
    "#                             device=device,\n",
    "#                             base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "#                             small_tag=\"semi1\")\n",
    "# padder = collate_fn(tokenizer.pad_token_id)\n",
    "# test_dataloader_cor = DataLoader(test_dataset_cor,\n",
    "#                                 batch_size=1,\n",
    "#                             #   collate_fn=collate_fn)\n",
    "#                             collate_fn=padder);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels_c = []\n",
    "for batch in test_dataloader_cor:\n",
    "    all_labels_c += batch[\"label\"].cpu().tolist()\n",
    "all_labels_c = torch.tensor(all_labels_c)\n",
    "torch.equal(all_labels_c, labels_test_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_idx = 0\n",
    "for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "    group_df.sort_values(by=['col_idx'], inplace=True)\n",
    "    group_df = group_df.reset_index(drop=True)\n",
    "    labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "    # if len(group_df) > 10:\n",
    "    #     print(i, len(group_df))\n",
    "    for index, target_column in labeled_columns.iterrows():\n",
    "        other_columns = group_df.drop(index)\n",
    "        target_col_idx = target_column[\"col_idx\"]\n",
    "        \n",
    "        target_cls = target_column[\"class_id\"]\n",
    "        assert target_cls == labels_test_original[label_idx]\n",
    "        label_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test_original[label_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column[\"class_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "src = None\n",
    "test_dataset_last = GittablesTablewiseLabelLastDataset(cv=cv,\n",
    "                            split=\"test\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only='all' not in task,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\")\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "test_dataloader_last = DataLoader(test_dataset_last,\n",
    "                                batch_size=1,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "src = None\n",
    "test_dataset_last_old = GittablesTablewiseLastDataset(cv=cv,\n",
    "                            split=\"test\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only='all' not in task,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\")\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "test_dataloader_last_old = DataLoader(test_dataset_last_old,\n",
    "                                batch_size=1,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data, data_old in zip(test_dataset_last, test_dataset_last_old):\n",
    "    assert torch.equal(torch.tensor(data['col_idx_list']), torch.tensor(data_old['col_idx_list']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['col_idx_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_old['col_idx_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data['data'] == 101).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data_old['data'] == 101).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_old['data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d, d_old in zip(test_dataset_last, test_dataset_last_old):\n",
    "    assert torch.equal(torch.tensor(d['data']), torch.tensor(d_old['data']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['col_idx_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_old['col_idx_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "src = None\n",
    "test_dataset_last = GittablesTablewiseLabelLastDataset(cv=cv,\n",
    "                            split=\"test\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only='all' not in task,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\")\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "test_dataloader_last = DataLoader(test_dataset_last,\n",
    "                                batch_size=1,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "src = None\n",
    "test_dataset_first = GittablesTablewiseLabelFirstDataset(cv=cv,\n",
    "                            split=\"test\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only='all' not in task,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\")\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "test_dataloader_first = DataLoader(test_dataset_first,\n",
    "                                batch_size=1,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels_l = []\n",
    "for batch in test_dataloader_last:\n",
    "    all_labels_l += batch[\"label\"].cpu().tolist()\n",
    "all_labels_l = torch.tensor(all_labels_l)\n",
    "torch.equal(all_labels_l, labels_test_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = None\n",
    "test_dataset_gt = GittablesTablewiseIterateDataset(cv=cv,\n",
    "                            split=\"test\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only=True,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\")\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "test_dataloader_gt = DataLoader(test_dataset_gt,\n",
    "                                batch_size=1,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset_gt = GittablesTablewiseIterateDataset(cv=cv,\n",
    "#                             split=\"train\", src=src,\n",
    "#                             tokenizer=tokenizer,\n",
    "#                             max_length=max_length,\n",
    "#                             gt_only=True,\n",
    "#                             device=device,\n",
    "#                             base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "#                             small_tag=\"semi1\")\n",
    "# padder = collate_fn(tokenizer.pad_token_id)\n",
    "# train_dataloader_gt= DataLoader(train_dataset_gt,\n",
    "#                                 batch_size=1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(train_dataset_gt[2][\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(test_dataset_gt[0][\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_gt[0][\"label\"].cpu().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_labeled = df_train[df_train[\"class_id\"] > -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_train_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_labeled[\"data\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_labeled_corpus = [train_dataset_gt[i][\"data\"].cpu().tolist() for i in range(len(train_dataset_gt))]\n",
    "training_labeled_class = [train_dataset_gt[i][\"label\"].cpu().item() for i in range(len(train_dataset_gt))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_labeled_corpus_ind = [tokenizer.encode(\n",
    "                tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=max_length, truncation=True) for x in df_train_labeled[\"data\"].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_gt[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(train_dataset_gt[i][\"data\"].cpu().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_corpus_embs = torch.tensor(sb_model.encode([tokenizer.decode(train_dataset_gt[i][\"data\"].cpu().tolist()) for i in range(len(train_dataset_gt))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_corpus_embs_ind = torch.tensor(sb_model.encode(df_train_labeled[\"data\"].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_corpus_embs_ind.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_corpus_embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labeled_data = df_labeled[\"data\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labeled_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_corpus_embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "bm25 = BM25Okapi(training_labeled_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_ind = BM25Okapi(training_labeled_corpus_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(training_labeled_corpus_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 3\n",
    "scores = bm25.get_scores(test_dataset_gt[idx][\"data\"].cpu().tolist())\n",
    "print(tokenizer.decode(test_dataset_gt[idx][\"data\"]))\n",
    "top_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:5]\n",
    "\n",
    "# Fetch the top 5 documents\n",
    "top_documents = [training_labeled_corpus[i] for i in top_indices]\n",
    "for i, doc in enumerate(top_documents):\n",
    "    print(f\"Rank {i+1}: Document: {tokenizer.decode(doc)} => BM25 Score: {scores[top_indices[i]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IND\n",
    "idx = 6\n",
    "scores = bm25_ind.get_scores(tokenizer.encode(tokenizer.encode(\n",
    "                tokenizer.cls_token + \" \" + df_labeled_data[idx], add_special_tokens=False, max_length=max_length, truncation=True)))\n",
    "print(df_labeled_data[idx])\n",
    "top_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:5]\n",
    "\n",
    "# Fetch the top 5 documents\n",
    "top_documents = [training_labeled_corpus_ind[i] for i in top_indices]\n",
    "for i, doc in enumerate(top_documents):\n",
    "    print(f\"Rank {i+1}: Document: {tokenizer.decode(doc)} => BM25 Score: {scores[top_indices[i]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_labeled_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 3\n",
    "scores = F.cosine_similarity(training_corpus_embs, torch.tensor(sb_model.encode([tokenizer.decode(test_dataset_gt[idx][\"data\"])])).cpu().reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IND\n",
    "idx = 21\n",
    "scores = F.cosine_similarity(training_corpus_embs_ind, torch.tensor(sb_model.encode([df_labeled_data[idx]])).cpu().reshape(1,-1))\n",
    "print(df_labeled_data[idx])\n",
    "top_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:5]\n",
    "\n",
    "# Fetch the top 5 documents\n",
    "top_documents = [training_labeled_corpus_ind[i] for i in top_indices]\n",
    "for i, doc in enumerate(top_documents):\n",
    "    print(f\"Rank {i+1}: Document: {tokenizer.decode(doc)} => BM25 Score: {scores[top_indices[i]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_iter = GittablesTablewiseIterateDataset(cv=cv,\n",
    "                            split=\"train\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only='all' not in task,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\",\n",
    "                            random_sample=True)\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "train_dataloader_iter = DataLoader(train_dataset_iter,\n",
    "                                batch_size=1,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_random = GittablesTablewiseIterateRandomDataset(cv=cv,\n",
    "                            split=\"train\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only='all' not in task,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\",\n",
    "                            random_sample=True)\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "train_dataloader_random = DataLoader(train_dataset_random,\n",
    "                                batch_size=1,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "src = None\n",
    "test_dataset_sem = GittablesTablewiseIterateSemanticDataset(cv=cv,\n",
    "                            split=\"test\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only='all' not in task,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\")\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "test_dataloader_sem = DataLoader(test_dataset_sem,\n",
    "                                batch_size=1,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels_sem = []\n",
    "for batch in test_dataloader_sem:\n",
    "    all_labels_sem += batch[\"label\"].cpu().tolist()\n",
    "all_labels_sem = torch.tensor(all_labels_sem)\n",
    "torch.equal(all_labels_sem, labels_test_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(all_labels_sem == labels_test_original).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = None\n",
    "test_dataset_all = GittablesTablewiseIterateAllDataset(cv=cv,\n",
    "                            split=\"test\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only='all' not in task,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\")\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "test_dataloader_all = DataLoader(test_dataset_all,\n",
    "                                batch_size=1,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "test 1085\n"
     ]
    }
   ],
   "source": [
    "src = None\n",
    "test_dataset_near = GittablesTablewiseIterateNearbyDataset(cv=cv,\n",
    "                            split=\"test\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only='all' not in task,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\")\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "test_dataloader_near = DataLoader(test_dataset_near,\n",
    "                                batch_size=1,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = None\n",
    "valid_dataset_near = GittablesTablewiseIterateNearbyDataset(cv=cv,\n",
    "                            split=\"valid\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only='all' not in task,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\")\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "valid_dataloader_near = DataLoader(valid_dataset_near,\n",
    "                                batch_size=1,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "test 1085\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "src = None\n",
    "test_dataset_cluster = GittablesTablewiseIterateClusterDataset(cv=cv,\n",
    "                            split=\"test\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only='all' not in task,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\")\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "test_dataloader_cluster = DataLoader(test_dataset_cluster,\n",
    "                                batch_size=1,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "src = None\n",
    "valid_dataset_cluster = GittablesTablewiseIterateClusterDataset(cv=cv,\n",
    "                            split=\"valid\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only='all' not in task,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\")\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "valid_dataloader_cluster = DataLoader(valid_dataset_cluster,\n",
    "                                batch_size=1,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=max_unlabeled-1, random_state=0).fit(training_corpus_embs_doduo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "src = None\n",
    "max_unlabeled = 8\n",
    "test_dataset_extra = GittablesTablewiseIterateClusterExtraDataset(cv=cv,\n",
    "                            split=\"test\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only='all' not in task,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\",\n",
    "                            kmeans=kmeans,\n",
    "                            df_train_labeled=df_train_labeled,\n",
    "                            training_corpus_embs_doduo=training_corpus_embs_doduo)\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "test_dataloader_extra = DataLoader(test_dataset_extra,\n",
    "                                batch_size=1,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "src = None\n",
    "max_unlabeled = 8\n",
    "kmeans = KMeans(n_clusters=max_unlabeled-1, random_state=0).fit(training_corpus_embs_doduo_all)\n",
    "test_dataset_extra = GittablesTablewiseIterateClusterExtraDataset(cv=cv,\n",
    "                            split=\"test\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only='all' not in task,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\",\n",
    "                            kmeans=kmeans,\n",
    "                            df_train_labeled=df_train,\n",
    "                            training_corpus_embs_doduo=training_corpus_embs_doduo_all)\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "test_dataloader_extra = DataLoader(test_dataset_extra,\n",
    "                                batch_size=1,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src = None\n",
    "# test_dataset_dist = GittablesTablewiseIterateDistantDataset(cv=cv,\n",
    "#                             split=\"test\", src=src,\n",
    "#                             tokenizer=tokenizer,\n",
    "#                             max_length=max_length,\n",
    "#                             gt_only='all' not in task,\n",
    "#                             device=device,\n",
    "#                             base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "#                             small_tag=\"semi1\")\n",
    "# padder = collate_fn(tokenizer.pad_token_id)\n",
    "# test_dataloader_dist = DataLoader(test_dataset_dist,\n",
    "#                                 batch_size=1,\n",
    "#                             #   collate_fn=collate_fn)\n",
    "#                             collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels_near = []\n",
    "for batch in test_dataloader_near:\n",
    "    all_labels_near += batch[\"label\"].cpu().tolist()\n",
    "all_labels_near = torch.tensor(all_labels_near)\n",
    "torch.equal(all_labels_near, labels_test_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "src = None\n",
    "test_dataset_nearlast = GittablesTablewiseIterateNearbyLastDataset(cv=cv,\n",
    "                            split=\"test\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only='all' not in task,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\")\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "test_dataloader_nearlast = DataLoader(test_dataset_nearlast,\n",
    "                                batch_size=1,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels_nearlast = []\n",
    "for batch in test_dataloader_nearlast:\n",
    "    all_labels_nearlast += batch[\"label\"].cpu().tolist()\n",
    "all_labels_nearlast = torch.tensor(all_labels_nearlast)\n",
    "torch.equal(all_labels_nearlast, labels_test_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = None\n",
    "test_dataset_hy = GittablesTablewiseIterateHybridDataset(cv=cv,\n",
    "                            split=\"test\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only='all' not in task,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\")\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "test_dataloader_hy = DataLoader(test_dataset_hy,\n",
    "                                batch_size=1,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels_hy = []\n",
    "for batch in test_dataloader_hy:\n",
    "    all_labels_hy += batch[\"label\"].cpu().tolist()\n",
    "all_labels_hy = torch.tensor(all_labels_hy)\n",
    "torch.equal(all_labels_hy, labels_test_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "src = None\n",
    "test_dataset_set = GittablesTablewiseIterateSentenceDataset(cv=cv,\n",
    "                            split=\"test\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only='all' not in task,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\")\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "test_dataloader_set = DataLoader(test_dataset_set,\n",
    "                                batch_size=1,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels_set = []\n",
    "for batch in test_dataloader_set:\n",
    "    all_labels_set += batch[\"label\"].cpu().tolist()\n",
    "all_labels_set = torch.tensor(all_labels_set)\n",
    "torch.equal(all_labels_set, labels_test_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(all_labels_set==labels_test_original).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_set[0][\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_set[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(train_dataloader_iter):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    num_cols.append(batch[\"target_col_mask\"].max().item()+1)\n",
    "num_cols = torch.tensor(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(num_cols.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = None\n",
    "valid_dataset_iter = GittablesTablewiseIterateDataset(cv=cv,\n",
    "                            split=\"valid\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only='all' not in task,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\",\n",
    "                            random_sample=True)\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "valid_dataloader_iter = DataLoader(valid_dataset_iter,\n",
    "                                batch_size=1,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = None\n",
    "valid_dataset_random = GittablesTablewiseIterateRandomDataset(cv=cv,\n",
    "                            split=\"valid\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only='all' not in task,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\",\n",
    "                            random_sample=True)\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "valid_dataloader_random = DataLoader(valid_dataset_random,\n",
    "                                batch_size=1,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_micro_f1=0.5355, ts_macro_f1=0.2745\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test_original = []\n",
    "logits_test = []\n",
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    labels_test_original.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "    num_cols.append(test_dataset_iter[batch_idx]['initial_num_col'])\n",
    "    ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "labels_test_original = torch.cat(labels_test_original, dim=0)\n",
    "logits_test = torch.stack(logits_test, dim=0)\n",
    "preds_test = torch.argmax(logits_test, dim=1)\n",
    "num_cols = torch.tensor(num_cols)\n",
    "ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "mask = num_cols > 0\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "full_f1_init = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=None)\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test_original[num_cols==6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_col in np.arange(1, 10):\n",
    "    if n_col <= 8:\n",
    "        mask = num_cols == n_col\n",
    "    else:\n",
    "        mask = num_cols > 8\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach()[mask].numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    print(\"num_cols={} num_samples={} ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(n_col, sum(mask), ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_micro_f1=0.5207, ts_macro_f1=0.2366\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test_original = []\n",
    "logits_test = []\n",
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(test_dataloader_cluster):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    # target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    labels_test_original.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "    num_cols.append(test_dataset_iter[batch_idx]['initial_num_col'])\n",
    "    ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "labels_test_original = torch.cat(labels_test_original, dim=0)\n",
    "logits_test = torch.stack(logits_test, dim=0)\n",
    "preds_test = torch.argmax(logits_test, dim=1)\n",
    "num_cols = torch.tensor(num_cols)\n",
    "ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "mask = num_cols > 0\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test_original = []\n",
    "logits_test = []\n",
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(test_dataloader_cluster):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    # target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    labels_test_original.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "    num_cols.append(test_dataset_iter[batch_idx]['initial_num_col'])\n",
    "    ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "labels_test_original = torch.cat(labels_test_original, dim=0)\n",
    "logits_test = torch.stack(logits_test, dim=0)\n",
    "preds_test = torch.argmax(logits_test, dim=1)\n",
    "num_cols = torch.tensor(num_cols)\n",
    "ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "mask = num_cols < 8\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1)[mask].cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test_original[mask].reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test_original[mask].reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_col in np.arange(1, 10):\n",
    "    if n_col <= 8:\n",
    "        mask = num_cols == n_col\n",
    "    else:\n",
    "        mask = num_cols > 8\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach()[mask].numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test_original.reshape(-1)[mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test_original.reshape(-1)[mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    print(\"num_cols={} num_samples={} ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(n_col, sum(mask), ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test_original = []\n",
    "logits_test = []\n",
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(test_dataloader_extra):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    # target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    labels_test_original.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "    num_cols.append(test_dataset_iter[batch_idx]['initial_num_col'])\n",
    "    ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "labels_test_original = torch.cat(labels_test_original, dim=0)\n",
    "logits_test = torch.stack(logits_test, dim=0)\n",
    "preds_test = torch.argmax(logits_test, dim=1)\n",
    "num_cols = torch.tensor(num_cols)\n",
    "ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "mask = num_cols > 0\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "mask = num_cols < 8\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1)[mask].cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test_original[mask].reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test_original[mask].reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_col in np.arange(1, 10):\n",
    "    if n_col <= 8:\n",
    "        mask = num_cols == n_col\n",
    "    else:\n",
    "        mask = num_cols > 8\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach()[mask].numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test_original.reshape(-1)[mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test_original.reshape(-1)[mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    print(\"num_cols={} num_samples={} ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(n_col, sum(mask), ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for max_unlabeled in [32]:\n",
    "    for n_sample in [1, 2,3,4,5,6]:\n",
    "        print(f\"******************{ max_unlabeled, n_sample}******************\")\n",
    "        src = None\n",
    "        test_dataset_cluster = GittablesTablewiseIterateClusterDataset(cv=cv,\n",
    "                                    split=\"test\", src=src,\n",
    "                                    tokenizer=tokenizer,\n",
    "                                    max_length=max_length,\n",
    "                                    gt_only='all' not in task,\n",
    "                                    device=device,\n",
    "                                    base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                                    small_tag=\"semi1\",\n",
    "                                    max_unlabeled=max_unlabeled,\n",
    "                                    samples_per_cluster=n_sample)\n",
    "        padder = collate_fn(tokenizer.pad_token_id)\n",
    "        test_dataloader_cluster = DataLoader(test_dataset_cluster,\n",
    "                                        batch_size=1,\n",
    "                                    #   collate_fn=collate_fn)\n",
    "                                    collate_fn=padder)\n",
    "        model.eval()\n",
    "        model = model.to(device)\n",
    "        ft_embs_test = []\n",
    "        labels_test_original = []\n",
    "        logits_test = []\n",
    "        num_cols = []\n",
    "        for batch_idx, batch in enumerate(test_dataloader_cluster):\n",
    "            cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "            # target_col_mask = batch[\"target_col_mask\"].T\n",
    "            logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "            labels_test_original.append(batch[\"label\"].cpu())\n",
    "            logits_test.append(logits.detach().cpu())\n",
    "            num_cols.append(test_dataset_iter[batch_idx]['initial_num_col'])\n",
    "            ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "        labels_test_original = torch.cat(labels_test_original, dim=0)\n",
    "        logits_test = torch.stack(logits_test, dim=0)\n",
    "        preds_test = torch.argmax(logits_test, dim=1)\n",
    "        num_cols = torch.tensor(num_cols)\n",
    "        ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "        from sklearn.metrics import confusion_matrix, f1_score\n",
    "        mask = num_cols > 0\n",
    "        ts_pred_list = logits_test.argmax(\n",
    "                                    1).cpu().detach().numpy().tolist()\n",
    "        ts_micro_f1 = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                            ts_pred_list,\n",
    "                            average=\"micro\")\n",
    "        ts_macro_f1 = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                            ts_pred_list,\n",
    "                            average=\"macro\")\n",
    "        print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_col in np.arange(1, 10):\n",
    "    if n_col <= 8:\n",
    "        mask = num_cols == n_col\n",
    "    else:\n",
    "        mask = num_cols > 8\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach()[mask].numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test_original.reshape(-1)[mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test_original.reshape(-1)[mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    print(\"num_cols={} num_samples={} ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(n_col, sum(mask), ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_micro_f1=0.5272, ts_macro_f1=0.2394\n"
     ]
    }
   ],
   "source": [
    "# Cosine distance to all labeled training columns\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test = []\n",
    "logits_test_eu = []\n",
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(test_dataloader_lb):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    # target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    labels_test.append(batch[\"label\"].cpu())\n",
    "    logits_test_eu.append(logits.detach().cpu())\n",
    "    num_cols.append(test_dataset_iter[batch_idx]['initial_num_col'])\n",
    "    ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "labels_test = torch.cat(labels_test, dim=0)\n",
    "logits_test_eu = torch.stack(logits_test_eu, dim=0)\n",
    "preds_test_eu = torch.argmax(logits_test_eu, dim=1)\n",
    "num_cols = torch.tensor(num_cols)\n",
    "ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "mask = num_cols > 0\n",
    "ts_pred_list_eu = logits_test_eu.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list_eu,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list_eu,\n",
    "                    average=\"macro\")\n",
    "full_f1_eu = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list_eu,\n",
    "                    average=None)\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EU distance to all labeled training columns\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test_original = []\n",
    "logits_test = []\n",
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(test_dataloader_lb):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    # target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    labels_test_original.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "    num_cols.append(test_dataset_iter[batch_idx]['initial_num_col'])\n",
    "    ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "labels_test_original = torch.cat(labels_test_original, dim=0)\n",
    "logits_test = torch.stack(logits_test, dim=0)\n",
    "preds_test = torch.argmax(logits_test, dim=1)\n",
    "num_cols = torch.tensor(num_cols)\n",
    "ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "mask = num_cols > 0\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "full_f1_init = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=None)\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EU distance to class center\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test_original = []\n",
    "logits_test = []\n",
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(test_dataloader_lb):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    # target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    labels_test_original.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "    num_cols.append(test_dataset_iter[batch_idx]['initial_num_col'])\n",
    "    ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "labels_test_original = torch.cat(labels_test_original, dim=0)\n",
    "logits_test = torch.stack(logits_test, dim=0)\n",
    "preds_test = torch.argmax(logits_test, dim=1)\n",
    "num_cols = torch.tensor(num_cols)\n",
    "ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "mask = num_cols > 0\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "full_f1_init = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=None)\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COS distance to class center\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test_original = []\n",
    "logits_test = []\n",
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(test_dataloader_lb):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    # target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    labels_test_original.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "    num_cols.append(test_dataset_iter[batch_idx]['initial_num_col'])\n",
    "    ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "labels_test_original = torch.cat(labels_test_original, dim=0)\n",
    "logits_test = torch.stack(logits_test, dim=0)\n",
    "preds_test = torch.argmax(logits_test, dim=1)\n",
    "num_cols = torch.tensor(num_cols)\n",
    "ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "mask = num_cols > 0\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "full_f1_init = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=None)\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MD distance\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test_original = []\n",
    "logits_test = []\n",
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(test_dataloader_lb):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    # target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    labels_test_original.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "    num_cols.append(test_dataset_iter[batch_idx]['initial_num_col'])\n",
    "    ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "labels_test_original = torch.cat(labels_test_original, dim=0)\n",
    "logits_test = torch.stack(logits_test, dim=0)\n",
    "preds_test = torch.argmax(logits_test, dim=1)\n",
    "num_cols = torch.tensor(num_cols)\n",
    "ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "mask = num_cols > 0\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "full_f1_init = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=None)\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_col in np.arange(1, 10):\n",
    "    if n_col <= 8:\n",
    "        mask = num_cols == n_col\n",
    "    else:\n",
    "        mask = num_cols > 8\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach()[mask].numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    print(\"num_cols={} num_samples={} ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(n_col, sum(mask), ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(test_dataloader_gt):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    labels_test.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "    num_cols.append(batch[\"target_col_mask\"].max().item())\n",
    "    ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "labels_test = torch.cat(labels_test, dim=0)\n",
    "logits_test = torch.stack(logits_test, dim=0)\n",
    "preds_test = torch.argmax(logits_test, dim=1)\n",
    "num_cols = torch.tensor(num_cols)\n",
    "ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "mask = num_cols > 0\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "full_f1_init = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=None)\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach()[mask].numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach()[~mask].numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_col in np.arange(1, 10):\n",
    "    if n_col <= 8:\n",
    "        mask = num_cols == n_col\n",
    "    else:\n",
    "        mask = num_cols > 8\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach()[mask].numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    print(\"num_cols={} num_samples={} ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(n_col, sum(mask), ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_micro_f1=0.5355, ts_macro_f1=0.2683\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(test_dataloader_first):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    labels_test.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "    num_cols.append(test_dataset_iter[batch_idx]['initial_num_col'])\n",
    "    ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "labels_test = torch.cat(labels_test, dim=0)\n",
    "logits_test_first = torch.stack(logits_test, dim=0)\n",
    "preds_test_first = torch.argmax(logits_test_first, dim=1)\n",
    "num_cols = torch.tensor(num_cols)\n",
    "ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "mask = num_cols > 0\n",
    "ts_pred_list_first = logits_test_first.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list_first,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list_first,\n",
    "                    average=\"macro\")\n",
    "full_f1_init = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list_first,\n",
    "                    average=None)\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[\"cls_indexes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_train_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_train_labeled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [51]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m training_corpus_labels \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m label, x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[43mdf_train_labeled\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass_id\u001b[39m\u001b[38;5;124m\"\u001b[39m], df_train_labeled[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m      3\u001b[0m     training_corpus_labels\u001b[38;5;241m.\u001b[39mappend(label)\n\u001b[1;32m      4\u001b[0m training_corpus_labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(training_corpus_labels)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_train_labeled' is not defined"
     ]
    }
   ],
   "source": [
    "training_corpus_labels = []\n",
    "for label, x in zip(df_train_labeled[\"class_id\"], df_train_labeled[\"data\"]):\n",
    "    training_corpus_labels.append(label)\n",
    "training_corpus_labels = torch.tensor(training_corpus_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "training_corpus_embs_doduo = []\n",
    "\n",
    "for label, x in zip(df_train_labeled[\"class_id\"], df_train_labeled[\"data\"]):\n",
    "    cls_indexes = torch.LongTensor([[0, 0]]).to(device)\n",
    "    x = torch.LongTensor( tokenizer.encode(\n",
    "                tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=max_length, truncation=True)).to(device).reshape(1, -1)\n",
    "    logits, embs = model(x, cls_indexes=cls_indexes, get_enc=True)\n",
    "    training_corpus_embs_doduo.append(embs.detach().cpu().reshape(1, -1))\n",
    "training_corpus_embs_doduo = torch.cat(training_corpus_embs_doduo, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "training_corpus_embs_doduo_all = []\n",
    "\n",
    "for label, x in zip(df_train[\"class_id\"], df_train[\"data\"]):\n",
    "    cls_indexes = torch.LongTensor([[0, 0]]).to(device)\n",
    "    x = torch.LongTensor( tokenizer.encode(\n",
    "                tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=max_length, truncation=True)).to(device).reshape(1, -1)\n",
    "    logits, embs = model(x, cls_indexes=cls_indexes, get_enc=True)\n",
    "    training_corpus_embs_doduo_all.append(embs.detach().cpu().reshape(1, -1))\n",
    "training_corpus_embs_doduo_all = torch.cat(training_corpus_embs_doduo_all, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_corpus_labels.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_corpus_embs_doduo[training_corpus_labels==0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model = model.to(device)\n",
    "training_corpus_embs_doduo_center = []\n",
    "for label in training_corpus_labels.unique():\n",
    "    class_center = training_corpus_embs_doduo[training_corpus_labels==label].mean(dim=0, keepdim=True)\n",
    "    training_corpus_embs_doduo_center.append(class_center)\n",
    "training_corpus_embs_doduo_center = torch.cat(training_corpus_embs_doduo_center, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "training_corpus_embs_doduo_all = []\n",
    "\n",
    "for label, x in zip(df_train[\"class_id\"], df_train[\"data\"]):\n",
    "    cls_indexes = torch.LongTensor([[0, 0]]).to(device)\n",
    "    x = torch.LongTensor( tokenizer.encode(\n",
    "                tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=max_length, truncation=True)).to(device).reshape(1, -1)\n",
    "    logits, embs = model(x, cls_indexes=cls_indexes, get_enc=True)\n",
    "    training_corpus_embs_doduo_all.append(embs.detach().cpu().reshape(1, -1))\n",
    "training_corpus_embs_doduo_all = torch.cat(training_corpus_embs_doduo_all, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(training_corpus_embs_doduo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(training_corpus_embs_doduo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[\"data\"].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(test_dataset_lb):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T.reshape(1,-1), cls_indexes=cls_indexes, get_enc=True)\n",
    "    labels_test.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "    num_cols.append(test_dataset_iter[batch_idx]['initial_num_col'])\n",
    "    ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "labels_test = torch.cat(labels_test, dim=0)\n",
    "logits_test_first = torch.stack(logits_test, dim=0)\n",
    "preds_test_first = torch.argmax(logits_test_first, dim=1)\n",
    "num_cols = torch.tensor(num_cols)\n",
    "ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "mask = num_cols > 0\n",
    "ts_pred_list_first = logits_test_first.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list_first,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list_first,\n",
    "                    average=\"macro\")\n",
    "full_f1_init = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list_first,\n",
    "                    average=None)\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[\"data\"].T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get first columns, put target column at the head\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(test_dataloader_first):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    labels_test.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "    num_cols.append(test_dataset_iter[batch_idx]['initial_num_col'])\n",
    "    ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "labels_test = torch.cat(labels_test, dim=0)\n",
    "logits_test_first = torch.stack(logits_test, dim=0)\n",
    "preds_test_first = torch.argmax(logits_test_first, dim=1)\n",
    "num_cols = torch.tensor(num_cols)\n",
    "ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "mask = num_cols > 0\n",
    "ts_pred_list_first = logits_test_first.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list_first,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list_first,\n",
    "                    average=\"macro\")\n",
    "full_f1_init = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list_first,\n",
    "                    average=None)\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nearby_num in [1,2,4,8]:\n",
    "    print(\"nearby_num={}\".format(nearby_num))\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    src = None\n",
    "    test_dataset_nf = GittablesTablewiseIterateNearbyFirstDataset(cv=cv,\n",
    "                                split=\"test\", src=src,\n",
    "                                tokenizer=tokenizer,\n",
    "                                max_length=max_length,\n",
    "                                gt_only='all' not in task,\n",
    "                                device=device,\n",
    "                                base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                                small_tag=\"semi1\",\n",
    "                                nearby_num=nearby_num)\n",
    "    padder = collate_fn(tokenizer.pad_token_id)\n",
    "    test_dataloader_nf = DataLoader(test_dataset_nf,\n",
    "                                    batch_size=1,\n",
    "                                #   collate_fn=collate_fn)\n",
    "                                collate_fn=padder)\n",
    "\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    num_cols = []\n",
    "    for batch_idx, batch in enumerate(test_dataloader_nf):\n",
    "        cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "        # target_col_mask = batch[\"target_col_mask\"].T\n",
    "        logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "        labels_test.append(batch[\"label\"].cpu())\n",
    "        logits_test.append(logits.detach().cpu())\n",
    "        num_cols.append(test_dataset_iter[batch_idx]['initial_num_col'])\n",
    "        ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "    labels_test = torch.cat(labels_test, dim=0)\n",
    "    logits_test_first = torch.stack(logits_test, dim=0)\n",
    "    preds_test_first = torch.argmax(logits_test_first, dim=1)\n",
    "    num_cols = torch.tensor(num_cols)\n",
    "    ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "    from sklearn.metrics import confusion_matrix, f1_score\n",
    "    mask = num_cols > 0\n",
    "    ts_pred_list_first = logits_test_first.argmax(\n",
    "                                1).cpu().detach().numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list_first,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list_first,\n",
    "                        average=\"macro\")\n",
    "    full_f1_init = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list_first,\n",
    "                        average=None)\n",
    "    print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(test_dataloader_last):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    labels_test.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "    num_cols.append(len(target_col_mask.unique()))\n",
    "    ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "labels_test = torch.cat(labels_test, dim=0)\n",
    "logits_test_first = torch.stack(logits_test, dim=0)\n",
    "preds_test_first = torch.argmax(logits_test_first, dim=1)\n",
    "num_cols = torch.tensor(num_cols)\n",
    "ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "mask = num_cols > 0\n",
    "ts_pred_list_first = logits_test_first.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list_first,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list_first,\n",
    "                    average=\"macro\")\n",
    "full_f1_init = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list_first,\n",
    "                    average=None)\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[\"data\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_num_cols = []\n",
    "for i, (batch_old, batch) in enumerate(zip(test_dataloader_last_old, test_dataloader_last)):\n",
    "    if not torch.equal(batch_old[\"data\"], batch[\"data\"]):\n",
    "        bad_num_cols.append(num_cols[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(bad_num_cols).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bad_num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(num_cols==8).sum() - 93"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.equal(num_cols, num_cols_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "num_cols_old = []\n",
    "for batch_idx, batch in enumerate(test_dataloader_last_old):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    # target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    labels_test.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "    # num_cols_old.append(len(target_col_mask.unique()))\n",
    "    ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "labels_test = torch.cat(labels_test, dim=0)\n",
    "logits_test_first = torch.stack(logits_test, dim=0)\n",
    "preds_test_first = torch.argmax(logits_test_first, dim=1)\n",
    "# num_cols_old = torch.tensor(num_cols_old)\n",
    "ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "mask = num_cols > 0\n",
    "ts_pred_list_first = logits_test_first.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list_first,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list_first,\n",
    "                    average=\"macro\")\n",
    "full_f1_init = f1_score(labels_test_original.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list_first,\n",
    "                    average=None)\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(preds_test_first == labels_test).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(preds_test_near == labels_test).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(((preds_test_near != labels_test)&(preds_test_first == labels_test)).nonzero()))\n",
    "print(((preds_test_near != labels_test)&(preds_test_first == labels_test)).nonzero())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 820\n",
    "print(types[test_dataset_near[idx]['label'].item()], tokenizer.decode(test_dataset_near[idx][\"data\"][test_dataset_near[idx]['target_col_mask']==0]))\n",
    "tokenizer.decode(test_dataset_near[idx][\"data\"]).split('[CLS]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 820\n",
    "print(types[test_dataset_first[idx]['label'].item()], tokenizer.decode(test_dataset_first[idx][\"data\"][test_dataset_first[idx]['target_col_mask']==0]))\n",
    "tokenizer.decode(test_dataset_first[idx][\"data\"]).split('[CLS]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(((preds_test_near == labels_test)&(preds_test_first != labels_test)).nonzero()))\n",
    "((preds_test_near == labels_test)&(preds_test_first != labels_test)).nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 152\n",
    "print(types[test_dataset_near[idx]['label'].item()], tokenizer.decode(test_dataset_near[idx][\"data\"][test_dataset_near[idx]['target_col_mask']==0]))\n",
    "tokenizer.decode(test_dataset_near[idx][\"data\"]).split('[CLS]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 152\n",
    "print(types[test_dataset_first[idx]['label'].item()], tokenizer.decode(test_dataset_first[idx][\"data\"][test_dataset_first[idx]['target_col_mask']==0]))\n",
    "tokenizer.decode(test_dataset_first[idx][\"data\"]).split('[CLS]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_col in np.arange(1, 10):\n",
    "    if n_col <= 8:\n",
    "        mask = num_cols == n_col\n",
    "    else:\n",
    "        mask = num_cols > 8\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach()[mask].numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    print(\"num_cols={} num_samples={} ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(n_col, sum(mask), ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(test_dataloader_sem):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    labels_test.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "    num_cols.append(test_dataset_iter[batch_idx]['initial_num_col'])\n",
    "    ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "labels_test = torch.cat(labels_test, dim=0)\n",
    "logits_test = torch.stack(logits_test, dim=0)\n",
    "preds_test = torch.argmax(logits_test, dim=1)\n",
    "num_cols = torch.tensor(num_cols)\n",
    "ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "mask = num_cols > 0\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "full_f1_init = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=None)\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach()[mask].numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach()[~mask].numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "preds_test_sem = preds_test.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(preds_test == labels_test).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_acc_origin = []\n",
    "for class_i in range(args.num_classes):\n",
    "    mask = labels_test == class_i\n",
    "    class_acc_origin.append((preds_test[mask] == labels_test[mask]).sum().item() / mask.sum().item())\n",
    "class_acc_origin = torch.tensor(class_acc_origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_acc_sem = []\n",
    "for class_i in range(args.num_classes):\n",
    "    mask = labels_test == class_i\n",
    "    class_acc_sem.append((preds_test_sem[mask] == labels_test[mask]).sum().item() / mask.sum().item())\n",
    "class_acc_sem = torch.tensor(class_acc_sem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((class_acc_origin > class_acc_sem).sum())\n",
    "print((class_acc_origin < class_acc_sem).sum())\n",
    "print((class_acc_origin == class_acc_sem).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coltypes[(class_acc_origin > class_acc_sem)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((class_acc_origin == 0).sum())\n",
    "print((class_acc_sem == 0).sum())\n",
    "print(((class_acc_sem == 0)&(class_acc_origin == 0)).sum())\n",
    "print(((class_acc_sem == 0)&(class_acc_origin != 0)).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(coltypes[((class_acc_sem == 0)&(class_acc_origin != 0))])\n",
    "print(class_acc_origin[((class_acc_sem == 0)&(class_acc_origin != 0))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(is_numerical[(class_acc_origin > class_acc_sem)].sum())\n",
    "print(is_categorical[(class_acc_origin > class_acc_sem)].sum())\n",
    "print(is_datetime[(class_acc_origin > class_acc_sem)].sum())\n",
    "print(is_other[(class_acc_origin > class_acc_sem)].sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coltypes[(class_acc_origin < class_acc_sem)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(is_numerical[(class_acc_origin < class_acc_sem)].sum())\n",
    "print(is_categorical[(class_acc_origin < class_acc_sem)].sum())\n",
    "print(is_datetime[(class_acc_origin < class_acc_sem)].sum())\n",
    "print(is_other[(class_acc_origin < class_acc_sem)].sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = coltypes\n",
    "type2id = {t: i for i, t in enumerate(types)}\n",
    "id2type = {i: t for i, t in enumerate(types)}\n",
    "column_categories = {\n",
    "    \"Numerical\": ['start', 'duration', 'frequency', 'age', 'value', 'price', 'weight', 'score', 'rank', 'height', 'population', 'order', 'length', 'max', 'min', 'number', 'cost', 'elevation', 'depth', 'width', 'percentage'],\n",
    "    \"Categorical\": ['project', 'id', 'name', 'description', 'type', 'title', 'state', 'status', 'code', 'city', 'source', 'country', 'county', 'comment', 'notes', 'category', 'address', 'gender', 'location', 'version', 'sex', 'class', 'field', 'region', 'note', 'race', 'species', 'position', 'language', 'filename', 'model', 'role', 'series', 'family', 'currency', 'definition', 'format', 'author', 'area', 'domain', 'rating', 'parent', 'alias', 'postalCode', 'reference', 'publisher', 'treatment', 'company', 'district', 'project', 'scientificName', 'abbreviation', 'part', 'countryCode', 'topic', 'road', 'prefix', 'route', 'department', 'zipCode', 'abstract', 'event', 'creator', 'genus', 'tag', 'owner', 'party', 'result'],\n",
    "    \"Datetime\": ['date', 'time', 'startDate', 'endDate', 'birthDate', 'created', 'day', 'end', 'month', 'period', 'releaseDate', 'season'],\n",
    "    # \"Other\": ['start', 'duration', 'project', 'frequency']\n",
    "}\n",
    "is_numerical = np.array([t in column_categories[\"Numerical\"] for t in types])\n",
    "is_categorical = np.array([t in column_categories[\"Categorical\"] for t in types])\n",
    "is_datetime = np.array([t in column_categories[\"Datetime\"] for t in types])\n",
    "# is_other = np.array([t in column_categories[\"Other\"] for t in types])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(class_acc_origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Example class-wise accuracy for two models\n",
    "classes = [f'Class {i}' for i in range(101)]  # 101 class labels\n",
    "acc_model_1 = class_acc_origin  # Random accuracy values for model 1 (replace with actual data)\n",
    "acc_model_2 = class_acc_sem  # Random accuracy values for model 2 (replace with actual data)\n",
    "\n",
    "# Define the number of classes and the width of the bars\n",
    "num_classes = len(classes)\n",
    "bar_width = 0.35\n",
    "\n",
    "# Set positions for the bars on the x-axis\n",
    "index = np.arange(num_classes)\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(20, 8))  # Increase figure size for better visualization of 101 classes\n",
    "\n",
    "# Plot the bars for each model\n",
    "bar1 = ax.bar(index, acc_model_1, bar_width, label='Model 1')\n",
    "bar2 = ax.bar(index + bar_width, acc_model_2, bar_width, label='Model 2')\n",
    "\n",
    "# Add labels and title\n",
    "ax.set_xlabel('Class')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Class-wise Accuracy Comparison')\n",
    "ax.set_xticks(index + bar_width / 2)\n",
    "\n",
    "# To prevent cluttering, only show some x-tick labels (adjust as needed)\n",
    "ax.set_xticklabels(classes, rotation=90, fontsize=8)\n",
    "\n",
    "# Add legend\n",
    "ax.legend()\n",
    "\n",
    "# Adjust the layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(preds_test_sem == labels_test).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = preds_test == labels_test\n",
    "(preds_test_sem[mask] == labels_test[mask]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_col in np.arange(1, 10):\n",
    "    if n_col <= 8:\n",
    "        mask = num_cols == n_col\n",
    "    else:\n",
    "        mask = num_cols > 8\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach()[mask].numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    print(\"num_cols={} num_samples={} ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(n_col, sum(mask), ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(test_dataloader_all):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    labels_test.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "    num_cols.append(test_dataset_iter[batch_idx]['initial_num_col'])\n",
    "    ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "labels_test = torch.cat(labels_test, dim=0)\n",
    "logits_test = torch.stack(logits_test, dim=0)\n",
    "preds_test = torch.argmax(logits_test, dim=1)\n",
    "num_cols = torch.tensor(num_cols)\n",
    "ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "mask = num_cols > 0\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "full_f1_init = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=None)\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for max_unlabeled in [4, 8, 16, 32]:\n",
    "    print(\"max_unlabeled={}\".format(max_unlabeled))\n",
    "    src = None\n",
    "    test_dataset_near = GittablesTablewiseIterateNearbyDataset(cv=cv,\n",
    "                                split=\"test\", src=src,\n",
    "                                tokenizer=tokenizer,\n",
    "                                max_length=max_length,\n",
    "                                gt_only='all' not in task,\n",
    "                                device=device,\n",
    "                                base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                                small_tag=\"semi1\", \n",
    "                                max_unlabeled=max_unlabeled)\n",
    "    padder = collate_fn(tokenizer.pad_token_id)\n",
    "    test_dataloader_near = DataLoader(test_dataset_near,\n",
    "                                    batch_size=1,\n",
    "                                #   collate_fn=collate_fn)\n",
    "                                collate_fn=padder)\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    num_cols = []\n",
    "    for batch_idx, batch in enumerate(test_dataloader_near):\n",
    "        cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "        target_col_mask = batch[\"target_col_mask\"].T\n",
    "        logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "        labels_test.append(batch[\"label\"].cpu())\n",
    "        logits_test.append(logits.detach().cpu())\n",
    "        num_cols.append(test_dataset_iter[batch_idx]['initial_num_col'])\n",
    "        ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "    labels_test = torch.cat(labels_test, dim=0)\n",
    "    logits_test = torch.stack(logits_test, dim=0)\n",
    "    preds_test = torch.argmax(logits_test, dim=1)\n",
    "    num_cols = torch.tensor(num_cols)\n",
    "    ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "    from sklearn.metrics import confusion_matrix, f1_score\n",
    "    mask = num_cols > 0\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach().numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    full_f1_init = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=None)\n",
    "    print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_micro_f1=0.5300, ts_macro_f1=0.2442\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(test_dataloader_near):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    labels_test.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "    num_cols.append(test_dataset_iter[batch_idx]['initial_num_col'])\n",
    "    ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "labels_test = torch.cat(labels_test, dim=0)\n",
    "logits_test = torch.stack(logits_test, dim=0)\n",
    "preds_test = torch.argmax(logits_test, dim=1)\n",
    "num_cols = torch.tensor(num_cols)\n",
    "ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "mask = num_cols > 0\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "full_f1_init = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=None)\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(test_dataloader_near):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    labels_test.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "    num_cols.append(test_dataset_iter[batch_idx]['initial_num_col'])\n",
    "    ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "labels_test = torch.cat(labels_test, dim=0)\n",
    "logits_test = torch.stack(logits_test, dim=0)\n",
    "preds_test = torch.argmax(logits_test, dim=1)\n",
    "num_cols = torch.tensor(num_cols)\n",
    "ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "mask = num_cols > 0\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "full_f1_init = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=None)\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(test_dataloader_dist):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    labels_test.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "    num_cols.append(test_dataset_iter[batch_idx]['initial_num_col'])\n",
    "    ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "labels_test = torch.cat(labels_test, dim=0)\n",
    "logits_test = torch.stack(logits_test, dim=0)\n",
    "preds_test = torch.argmax(logits_test, dim=1)\n",
    "num_cols = torch.tensor(num_cols)\n",
    "ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "mask = num_cols > 0\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "full_f1_init = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=None)\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nearby + labeled\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test = []\n",
    "logits_test_near = []\n",
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(test_dataloader_near):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    labels_test.append(batch[\"label\"].cpu())\n",
    "    logits_test_near.append(logits.detach().cpu())\n",
    "    num_cols.append(test_dataset_iter[batch_idx]['initial_num_col'])\n",
    "    ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "labels_test = torch.cat(labels_test, dim=0)\n",
    "logits_test_near = torch.stack(logits_test_near, dim=0)\n",
    "preds_test_near = torch.argmax(logits_test_near, dim=1)\n",
    "num_cols = torch.tensor(num_cols)\n",
    "ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "mask = num_cols > 0\n",
    "ts_pred_list_near = logits_test_near.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list_near,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list_near,\n",
    "                    average=\"macro\")\n",
    "full_f1_near = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list_near,\n",
    "                    average=None)\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_col in np.arange(1, 10):\n",
    "    if n_col <= 8:\n",
    "        mask = num_cols == n_col\n",
    "    else:\n",
    "        mask = num_cols > 8\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach()[mask].numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    print(\"num_cols={} num_samples={} ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(n_col, sum(mask), ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(test_dataloader_nearlast):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    labels_test.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "    num_cols.append(test_dataset_iter[batch_idx]['initial_num_col'])\n",
    "    ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "labels_test = torch.cat(labels_test, dim=0)\n",
    "logits_test = torch.stack(logits_test, dim=0)\n",
    "preds_test = torch.argmax(logits_test, dim=1)\n",
    "num_cols = torch.tensor(num_cols)\n",
    "ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "mask = num_cols > 0\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "full_f1_init = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=None)\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "# ts_pred_list = logits_test.argmax(\n",
    "#                             1).cpu().detach()[mask].numpy().tolist()\n",
    "# ts_micro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "#                     ts_pred_list,\n",
    "#                     average=\"micro\")\n",
    "# ts_macro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "#                     ts_pred_list,\n",
    "#                     average=\"macro\")\n",
    "# print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "# ts_pred_list = logits_test.argmax(\n",
    "#                             1).cpu().detach()[~mask].numpy().tolist()\n",
    "# ts_micro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "#                     ts_pred_list,\n",
    "#                     average=\"micro\")\n",
    "# ts_macro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "#                     ts_pred_list,\n",
    "#                     average=\"macro\")\n",
    "# print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(test_dataloader_near):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    labels_test.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "    num_cols.append(batch[\"target_col_mask\"].max().item())\n",
    "    ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "labels_test = torch.cat(labels_test, dim=0)\n",
    "logits_test_near = torch.stack(logits_test, dim=0)\n",
    "preds_test_near = torch.argmax(logits_test_near, dim=1)\n",
    "num_cols = torch.tensor(num_cols)\n",
    "ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "mask = num_cols > 0\n",
    "ts_pred_list_near = logits_test_near.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list_near,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list_near,\n",
    "                    average=\"macro\")\n",
    "full_f1_init = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list_near,\n",
    "                    average=None)\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(test_dataloader_hy):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    labels_test.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "    num_cols.append(test_dataset_iter[batch_idx]['initial_num_col'])\n",
    "    ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "labels_test = torch.cat(labels_test, dim=0)\n",
    "logits_test = torch.stack(logits_test, dim=0)\n",
    "preds_test = torch.argmax(logits_test, dim=1)\n",
    "num_cols = torch.tensor(num_cols)\n",
    "ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "mask = num_cols > 0\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "full_f1_init = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=None)\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(test_dataloader_cor):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    # target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    labels_test.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "    num_cols.append(test_dataset_iter[batch_idx]['initial_num_col'])\n",
    "    ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "labels_test = torch.cat(labels_test, dim=0)\n",
    "logits_test = torch.stack(logits_test, dim=0)\n",
    "preds_test = torch.argmax(logits_test, dim=1)\n",
    "num_cols = torch.tensor(num_cols)\n",
    "ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "mask = num_cols > 0\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "full_f1_init = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=None)\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "16/58"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_micro_f1=0.5198, ts_macro_f1=0.2426 # first 5\n",
    "ts_micro_f1=0.5198, ts_macro_f1=0.2450 # first 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_col in np.arange(1, 10):\n",
    "    if n_col <= 8:\n",
    "        mask = num_cols == n_col\n",
    "    else:\n",
    "        mask = num_cols > 8\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach()[mask].numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    print(\"num_cols={} num_samples={} ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(n_col, sum(mask), ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(test_dataloader_set):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    labels_test.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "    num_cols.append(test_dataset_iter[batch_idx]['initial_num_col'])\n",
    "    ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "labels_test = torch.cat(labels_test, dim=0)\n",
    "logits_test = torch.stack(logits_test, dim=0)\n",
    "preds_test = torch.argmax(logits_test, dim=1)\n",
    "num_cols = torch.tensor(num_cols)\n",
    "ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "mask = num_cols > 0\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "full_f1_init = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=None)\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach()[mask].numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach()[~mask].numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(labels_test == labels_test_original).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test_original.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.equal(labels_test, labels_test_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_col in np.arange(1, 10):\n",
    "    if n_col <= 8:\n",
    "        mask = num_cols == n_col\n",
    "    else:\n",
    "        mask = num_cols > 8\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach()[mask].numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    print(\"num_cols={} num_samples={} ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(n_col, sum(mask), ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_macro = []\n",
    "results_micro = []\n",
    "for seed in range(5):\n",
    "    print(\"**********************************seed={}***************************\".format(seed))\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    src = None\n",
    "    test_dataset_rd = GittablesTablewiseLabelRandomDataset(cv=cv,\n",
    "                                split=\"test\", src=src,\n",
    "                                tokenizer=tokenizer,\n",
    "                                max_length=max_length,\n",
    "                                gt_only='all' not in task,\n",
    "                                device=device,\n",
    "                                base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                                small_tag=\"semi1\",\n",
    "                                seed=seed)\n",
    "    padder = collate_fn(tokenizer.pad_token_id)\n",
    "    test_dataloader_rd = DataLoader(test_dataset_rd,\n",
    "                                    batch_size=1,\n",
    "                                #   collate_fn=collate_fn)\n",
    "                                collate_fn=padder)\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    num_cols = []\n",
    "    for batch_idx, batch in enumerate(test_dataloader_rd):\n",
    "        cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "        target_col_mask = batch[\"target_col_mask\"].T\n",
    "        logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "        labels_test.append(batch[\"label\"].cpu())\n",
    "        logits_test.append(logits.detach().cpu())\n",
    "        num_cols.append(test_dataset_iter[batch_idx]['initial_num_col'])\n",
    "        ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "    labels_test = torch.cat(labels_test, dim=0)\n",
    "    logits_test = torch.stack(logits_test, dim=0)\n",
    "    preds_test = torch.argmax(logits_test, dim=1)\n",
    "    num_cols = torch.tensor(num_cols)\n",
    "    ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "    from sklearn.metrics import confusion_matrix, f1_score\n",
    "    mask = num_cols > 0\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach().numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    full_f1_init = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=None)\n",
    "    print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "    results_micro.append(ts_micro_f1)\n",
    "    results_macro.append(ts_macro_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(results_micro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(results_macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_macro = []\n",
    "results_micro = []\n",
    "for seed in range(20):\n",
    "    print(\"**********************************seed={}***************************\".format(seed))\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    src = None\n",
    "    test_dataset_rd = GittablesTablewiseRandomDataset(cv=cv,\n",
    "                                split=\"test\", src=src,\n",
    "                                tokenizer=tokenizer,\n",
    "                                max_length=max_length,\n",
    "                                gt_only='all' not in task,\n",
    "                                device=device,\n",
    "                                base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                                small_tag=\"semi1\",\n",
    "                                seed=seed)\n",
    "    padder = collate_fn(tokenizer.pad_token_id)\n",
    "    test_dataloader_rd = DataLoader(test_dataset_rd,\n",
    "                                    batch_size=1,\n",
    "                                #   collate_fn=collate_fn)\n",
    "                                collate_fn=padder)\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    num_cols = []\n",
    "    for batch_idx, batch in enumerate(test_dataloader_rd):\n",
    "        cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "        target_col_mask = batch[\"target_col_mask\"].T\n",
    "        logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "        labels_test.append(batch[\"label\"].cpu())\n",
    "        logits_test.append(logits.detach().cpu())\n",
    "        num_cols.append(test_dataset_iter[batch_idx]['initial_num_col'])\n",
    "        ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "    labels_test = torch.cat(labels_test, dim=0)\n",
    "    logits_test = torch.stack(logits_test, dim=0)\n",
    "    preds_test = torch.argmax(logits_test, dim=1)\n",
    "    num_cols = torch.tensor(num_cols)\n",
    "    ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "    from sklearn.metrics import confusion_matrix, f1_score\n",
    "    mask = num_cols > 0\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach().numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    full_f1_init = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=None)\n",
    "    print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "    results_micro.append(ts_micro_f1)\n",
    "    results_macro.append(ts_macro_f1)\n",
    "print(np.mean(results_micro))\n",
    "print(np.mean(results_macro))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brute force perumate in validation TODO: restrict mamimus length of permutation\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "\n",
    "ft_embs_test = []\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "log = defaultdict(list)\n",
    "num_cols = []\n",
    "corrected = 0\n",
    "total_mistakes = 0\n",
    "num_permutations = {}\n",
    "init_permutation = {}\n",
    "init_correctness = {}\n",
    "score_init = {}\n",
    "score_permutation = defaultdict(list)\n",
    "permutation_correctness = defaultdict(list)\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in enumerate(test_dataloader_sem):\n",
    "        cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "        target_col_mask = batch[\"target_col_mask\"].T\n",
    "        init_permutation_i = get_permutation(target_col_mask)\n",
    "        init_permutation[batch_idx] = init_permutation_i\n",
    "\n",
    "\n",
    "        num_cols.append(len(init_permutation_i))\n",
    "        col_idx_set = target_col_mask.unique().tolist()\n",
    "        \n",
    "        max_score = -float(\"inf\")\n",
    "        assert -1 not in col_idx_set\n",
    "        for r in range(len(init_permutation_i), max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "            for x in itertools.combinations(init_permutation_i, r):\n",
    "                if 0 not in x:\n",
    "                    continue\n",
    "\n",
    "                new_batch_data = []\n",
    "                if len(x) != len(init_permutation_i):\n",
    "                    drop_idx = (set(init_permutation_i)-set(x)).pop()\n",
    "                else:\n",
    "                    drop_idx = -1\n",
    "                for col_i in x:\n",
    "                    if col_i == 0:\n",
    "                        if len(new_batch_data) == 0:\n",
    "                            cls_indexes_value = 0\n",
    "                        else:\n",
    "                            cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                    new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                scores_temp = verifier(embs_temp.reshape(1,-1)).item()\n",
    "                predict_temp = logits_temp.argmax().item()\n",
    "\n",
    "                if scores_temp > max_score:\n",
    "                    max_score = scores_temp\n",
    "                    logits = logits_temp.clone()\n",
    "        labels_test.append(batch[\"label\"].cpu())\n",
    "        logits_test.append(logits.detach().cpu())\n",
    "    labels_test = torch.cat(labels_test, dim=0)\n",
    "    logits_test = torch.stack(logits_test, dim=0)\n",
    "    preds_test = torch.argmax(logits_test, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "ts_f1_full = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=None)\n",
    "# full_f1_init\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brute force perumate in validation TODO: restrict mamimus length of permutation\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brute force perumate in validation TODO: restrict mamimus length of permutation\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "verifier.load_state_dict(veri_state_dict)\n",
    "verifier.eval()\n",
    "verifier = verifier.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "\n",
    "ft_embs_test = []\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "log = defaultdict(list)\n",
    "num_cols = []\n",
    "corrected = 0\n",
    "total_mistakes = 0\n",
    "num_permutations = {}\n",
    "init_permutation = {}\n",
    "init_correctness = {}\n",
    "score_init = {}\n",
    "score_permutation = defaultdict(list)\n",
    "permutation_correctness = defaultdict(list)\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in enumerate(test_dataloader_near):\n",
    "        cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "        target_col_mask = batch[\"target_col_mask\"].T\n",
    "        init_permutation_i = get_permutation(target_col_mask)\n",
    "        init_permutation[batch_idx] = init_permutation_i\n",
    "\n",
    "\n",
    "        num_cols.append(len(init_permutation_i))\n",
    "        col_idx_set = target_col_mask.unique().tolist()\n",
    "        \n",
    "        max_score = -float(\"inf\")\n",
    "        assert -1 not in col_idx_set\n",
    "        for r in range(len(init_permutation_i), max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "            for x in itertools.combinations(init_permutation_i, r):\n",
    "                if 0 not in x:\n",
    "                    continue\n",
    "\n",
    "                new_batch_data = []\n",
    "                if len(x) != len(init_permutation_i):\n",
    "                    drop_idx = (set(init_permutation_i)-set(x)).pop()\n",
    "                else:\n",
    "                    drop_idx = -1\n",
    "                for col_i in x:\n",
    "                    if col_i == 0:\n",
    "                        if len(new_batch_data) == 0:\n",
    "                            cls_indexes_value = 0\n",
    "                        else:\n",
    "                            cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                    new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                scores_temp = verifier(embs_temp.reshape(1,-1)).item()\n",
    "                predict_temp = logits_temp.argmax().item()\n",
    "\n",
    "                if scores_temp > max_score:\n",
    "                    max_score = scores_temp\n",
    "                    logits = logits_temp.clone()\n",
    "        labels_test.append(batch[\"label\"].cpu())\n",
    "        logits_test.append(logits.detach().cpu())\n",
    "    labels_test = torch.cat(labels_test, dim=0)\n",
    "    logits_test = torch.stack(logits_test, dim=0)\n",
    "    preds_test = torch.argmax(logits_test, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "ts_f1_full = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=None)\n",
    "# full_f1_init\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "\n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "verifier.load_state_dict(veri_state_dict)\n",
    "verifier.eval()\n",
    "verifier = verifier.to(device)\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "init_scores = []\n",
    "init_correctness = []\n",
    "final_scores = []\n",
    "final_correctness = []\n",
    "num_cols = []\n",
    "total_steps = []\n",
    "final_steps = []\n",
    "correct_scores = defaultdict(list)\n",
    "correct_steps = defaultdict(list)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "        target_col_mask = batch[\"target_col_mask\"].T\n",
    "        embs = test_embs[batch_idx][0].reshape(1,-1).to(device)\n",
    "        logits = test_logits[batch_idx][0].reshape(-1).to(device)\n",
    "        scores_init = verifier(embs)\n",
    "        max_score = -float(\"inf\")\n",
    "\n",
    "        init_scores.append(scores_init.item())\n",
    "        init_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "        init_permutation_i = get_permutation(target_col_mask)\n",
    "        col_idx_set = target_col_mask.unique().tolist()\n",
    "        early_stop = False\n",
    "        i = 0\n",
    "        final_step = 0\n",
    "        total_steps.append(len(init_permutation_i) - max(len(init_permutation_i)//2, len(init_permutation_i)-3) -1)\n",
    "        num_cols.append(len(init_permutation_i))\n",
    "        for r in range(len(init_permutation_i), max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "            for x in itertools.combinations(init_permutation_i, r):\n",
    "                if 0 not in x:\n",
    "                    continue\n",
    "                logits_temp = test_logits[batch_idx][i].reshape(-1).to(device)\n",
    "                embs_temp = test_embs[batch_idx][i].reshape(1,-1).to(device)\n",
    "                scores_temp = verifier(embs_temp).item()\n",
    "                predict_temp = logits_temp.argmax().item()\n",
    "                i += 1\n",
    "                if scores_temp > max_score:\n",
    "                    max_score = scores_temp\n",
    "                    logits = logits_temp.clone()\n",
    "                    final_step = len(init_permutation_i) - r\n",
    "                if logits_temp.argmax().item() == batch[\"label\"].item():\n",
    "                    correct_scores[batch_idx].append(scores_temp)\n",
    "                    correct_steps[batch_idx].append(len(init_permutation_i) - r)\n",
    "                    \n",
    "        final_scores.append(max_score)\n",
    "        final_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "        final_steps.append(final_step)\n",
    "        labels_test.append(batch[\"label\"].cpu())\n",
    "        logits_test.append(logits.detach().cpu())\n",
    "    labels_test = torch.cat(labels_test, dim=0)\n",
    "    logits_test = torch.stack(logits_test, dim=0)\n",
    "    preds_test = torch.argmax(logits_test, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "ts_f1_full = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=None)\n",
    "# full_f1_init\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_embedding = nn.Embedding(2, 768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_embedding(torch.ones(32).long()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_f1_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(valid_dataloader_iter):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    labels_test.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "    num_cols.append(batch[\"target_col_mask\"].max().item())\n",
    "    ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "labels_test = torch.cat(labels_test, dim=0)\n",
    "logits_test = torch.stack(logits_test, dim=0)\n",
    "preds_test = torch.argmax(logits_test, dim=1)\n",
    "num_cols = torch.tensor(num_cols)\n",
    "ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "mask = num_cols > 0\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach()[mask].numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach()[~mask].numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_freq = torch.zeros(args.num_classes)\n",
    "for batch_idx, batch in enumerate(train_dataloader_iter):\n",
    "    class_freq[batch[\"label\"].item()] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def reweight_logits(logits, class_weights):\n",
    "#     # Reweight the logits by multiplying with class weights\n",
    "#     reweighted_logits = logits * torch.sqrt(class_weights)\n",
    "    \n",
    "#     # Apply softmax to the reweighted logits\n",
    "#     reweighted_probs = F.softmax(reweighted_logits, dim=-1)\n",
    "    \n",
    "#     return reweighted_probs\n",
    "def reweight_logits(logits, class_weights):\n",
    "    # Step 1: Apply exp(logits)\n",
    "    exp_logits = torch.exp(logits)\n",
    "    \n",
    "    # Step 2: Multiply by class weights\n",
    "    # reweighted_exp = exp_logits * torch.sqrt(class_weights)\n",
    "    reweighted_exp = exp_logits * class_weights\n",
    "    # Step 3: Normalize to get valid probabilities (like softmax)\n",
    "    reweighted_probs = reweighted_exp / reweighted_exp.sum(dim=-1, keepdim=True)\n",
    "    \n",
    "    return reweighted_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# brute force perumate, find uncertain init prediction, weighted msp\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "idx_list = []\n",
    "uncertain_init_mask = []\n",
    "uncertain_target_mask = []\n",
    "correct_init_mask = []\n",
    "correct_target_mask = []\n",
    "correct_permutation_mask = []\n",
    "correct_permutation_confident_mask = []\n",
    "correct_permutation_confident_scores = []\n",
    "correct_msp_mask = []\n",
    "init_target_mask = []\n",
    "ood_score_init_list = []\n",
    "ood_score_target_list = []\n",
    "ood_score_final_list = []\n",
    "msp_predicts = []\n",
    "max_col_length = 3\n",
    "\n",
    "alpha = 0\n",
    "# class_weights = (1.0 / class_freq) ** alpha\n",
    "# debias_threshold = 1.0\n",
    "# # Normalize the weights\n",
    "# class_weights /= class_weights.sum()\n",
    "for threshold in [0.9]:\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    log = defaultdict(list)\n",
    "    num_cols = []\n",
    "    corrected = 0\n",
    "    total_mistakes = 0\n",
    "\n",
    "    for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "        target_col_mask = batch[\"target_col_mask\"].T\n",
    "        if 1 in target_col_mask:\n",
    "            idx_list.append(batch_idx)\n",
    "\n",
    "            cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "            logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "            # logits = reweight_logits(logits.detach().cpu(), class_weights)\n",
    "            logits = F.softmax(logits, dim=-1)\n",
    "            num_cols.append(batch[\"target_col_mask\"].max().item())         \n",
    "            ood_score_init = logits.max().item()\n",
    "            ood_score_init_list.append(ood_score_init)\n",
    "            uncertain_init_mask.append(ood_score_init < threshold)\n",
    "            predict_init = logits.argmax().item()\n",
    "            correct_init_mask.append(predict_init == batch[\"label\"].item())\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            \n",
    "            correct_permutation = False\n",
    "            correct_permutation_ood_score = 0.0\n",
    "            correct_permutation_confident = False\n",
    "            ood_score_max = max_msp = 0\n",
    "            max_msp_debiased = 0\n",
    "            debias_class = []\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            assert -1 not in col_idx_set\n",
    "            for r in range(len(col_idx_set)-1, len(col_idx_set)//2, -1):\n",
    "                for subset in itertools.combinations(col_idx_set, r):\n",
    "                    if 0 not in subset and r != 1:\n",
    "                        continue\n",
    "                    for x in itertools.permutations(subset):\n",
    "                        if not is_sublist(x, init_permutation_i):\n",
    "                            continue\n",
    "                        new_batch_data = []\n",
    "                        for col_i in x:\n",
    "                            if col_i == 0:\n",
    "                                if len(new_batch_data) == 0:\n",
    "                                    cls_indexes_value = 0\n",
    "                                else:\n",
    "                                    cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                            new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                        if 0 not in x:\n",
    "                            cls_indexes_value = 0\n",
    "                        new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                        cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                        logits_temp = model(new_batch_data, cls_indexes=cls_indexes,)\n",
    "                        logits_temp = F.softmax(logits_temp, dim=-1)\n",
    "                        # logits_temp = reweight_logits(logits_temp.detach().cpu(), class_weights)\n",
    "                        msp_temp = logits_temp.max().item()\n",
    "                        predict_temp = logits_temp.argmax().item()\n",
    "                        # if 0 not in x and msp_temp > debias_threshold and (predict_temp!=predict_target or predict_temp!=predict_init):\n",
    "                        #     debias_class.append(predict_temp)\n",
    "                        #     continue\n",
    "                        # print(x, msp_temp, predict_temp)\n",
    "                        # if msp_temp > max_msp and 0 in x and predict_temp not in debias_class:\n",
    "                        if msp_temp > max_msp and 0 in x:\n",
    "                            max_msp = msp_temp\n",
    "                            msp_predict = predict_temp\n",
    "                        if predict_temp == batch[\"label\"].item():\n",
    "                            correct_permutation = True\n",
    "                            if msp_temp > correct_permutation_ood_score:\n",
    "                                correct_permutation_ood_score = msp_temp\n",
    "            msp_predicts.append(msp_predict)\n",
    "            ood_score_final_list.append(max_msp)\n",
    "            correct_permutation_mask.append(correct_permutation)\n",
    "            correct_permutation_confident_scores.append(correct_permutation_ood_score)\n",
    "            correct_msp_mask.append(msp_predict == batch[\"label\"].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "idx_list = torch.tensor(idx_list).reshape(-1)\n",
    "uncertain_init_mask = torch.tensor(uncertain_init_mask).reshape(-1)\n",
    "uncertain_target_mask = torch.tensor(uncertain_target_mask).reshape(-1)\n",
    "correct_init_mask = torch.tensor(correct_init_mask).reshape(-1)\n",
    "correct_target_mask = torch.tensor(correct_target_mask).reshape(-1)\n",
    "correct_permutation_mask = torch.tensor(correct_permutation_mask).reshape(-1)\n",
    "correct_permutation_confident_scores = torch.tensor(correct_permutation_confident_scores).reshape(-1)\n",
    "correct_msp_mask = torch.tensor(correct_msp_mask).reshape(-1)\n",
    "init_target_mask = torch.tensor(init_target_mask).reshape(-1)\n",
    "ood_score_init_list = torch.tensor(ood_score_init_list).reshape(-1)\n",
    "ood_score_target_list = torch.tensor(ood_score_target_list).reshape(-1)\n",
    "ood_score_final_list = torch.tensor(ood_score_final_list).reshape(-1)\n",
    "msp_predicts = torch.tensor(msp_predicts).reshape(-1)\n",
    "print(len(idx_list), len(init_target_mask), len(correct_init_mask), len(correct_target_mask), len(correct_permutation_mask))\n",
    "torch.save({\"idx_list\": idx_list, \"uncertain_init_mask\": uncertain_init_mask, \"uncertain_target_mask\": uncertain_target_mask, \"correct_init_mask\": correct_init_mask, \"correct_target_mask\": correct_target_mask, \"correct_permutation_mask\": correct_permutation_mask, \"correct_msp_mask\": correct_msp_mask, \"init_target_mask\": init_target_mask, \"ood_score_init_list\": ood_score_init_list, \"ood_score_target_list\": ood_score_target_list, \"ood_score_final_list\": ood_score_final_list}, f\"./results/brute_force_permutation_alpha@{alpha}_drop.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# brute force perumate, find uncertain init prediction, weighted msp\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "idx_list = []\n",
    "uncertain_init_mask = []\n",
    "uncertain_target_mask = []\n",
    "correct_init_mask = []\n",
    "correct_target_mask = []\n",
    "correct_permutation_mask = []\n",
    "correct_permutation_confident_mask = []\n",
    "correct_permutation_confident_scores = []\n",
    "correct_msp_mask = []\n",
    "init_target_mask = []\n",
    "ood_score_init_list = []\n",
    "ood_score_target_list = []\n",
    "ood_score_final_list = []\n",
    "msp_predicts = []\n",
    "max_col_length = 3\n",
    "\n",
    "alpha = 0.25\n",
    "class_weights = (1.0 / class_freq) ** alpha\n",
    "debias_threshold = 1.0\n",
    "# Normalize the weights\n",
    "class_weights /= class_weights.sum()\n",
    "for threshold in [0.9]:\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    log = defaultdict(list)\n",
    "    num_cols = []\n",
    "    corrected = 0\n",
    "    total_mistakes = 0\n",
    "\n",
    "    for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "        target_col_mask = batch[\"target_col_mask\"].T\n",
    "        if 1 in target_col_mask:\n",
    "            idx_list.append(batch_idx)\n",
    "\n",
    "            cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "            logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "            logits = reweight_logits(logits.detach().cpu(), class_weights)\n",
    "            num_cols.append(batch[\"target_col_mask\"].max().item())         \n",
    "            ood_score_init = logits.max().item()\n",
    "            ood_score_init_list.append(ood_score_init)\n",
    "            uncertain_init_mask.append(ood_score_init < threshold)\n",
    "            predict_init = logits.argmax().item()\n",
    "            correct_init_mask.append(predict_init == batch[\"label\"].item())\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            \n",
    "            correct_permutation = False\n",
    "            correct_permutation_ood_score = 0.0\n",
    "            correct_permutation_confident = False\n",
    "            ood_score_max = max_msp = 0\n",
    "            max_msp_debiased = 0\n",
    "            debias_class = []\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            assert -1 not in col_idx_set\n",
    "            for r in range(len(col_idx_set)-1, len(col_idx_set)//2, -1):\n",
    "                for subset in itertools.combinations(col_idx_set, r):\n",
    "                    if 0 not in subset and r != 1:\n",
    "                        continue\n",
    "                    for x in itertools.permutations(subset):\n",
    "                        if not is_sublist(x, init_permutation_i):\n",
    "                            continue\n",
    "                        new_batch_data = []\n",
    "                        for col_i in x:\n",
    "                            if col_i == 0:\n",
    "                                if len(new_batch_data) == 0:\n",
    "                                    cls_indexes_value = 0\n",
    "                                else:\n",
    "                                    cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                            new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                        if 0 not in x:\n",
    "                            cls_indexes_value = 0\n",
    "                        new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                        cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                        logits_temp = model(new_batch_data, cls_indexes=cls_indexes,)\n",
    "                        logits_temp = reweight_logits(logits_temp.detach().cpu(), class_weights)\n",
    "                        msp_temp = logits_temp.max().item()\n",
    "                        predict_temp = logits_temp.argmax().item()\n",
    "                        # if 0 not in x and msp_temp > debias_threshold and (predict_temp!=predict_target or predict_temp!=predict_init):\n",
    "                        #     debias_class.append(predict_temp)\n",
    "                        #     continue\n",
    "                        # print(x, msp_temp, predict_temp)\n",
    "                        # if msp_temp > max_msp and 0 in x and predict_temp not in debias_class:\n",
    "                        if msp_temp > max_msp and 0 in x:\n",
    "                            max_msp = msp_temp\n",
    "                            msp_predict = predict_temp\n",
    "                        if predict_temp == batch[\"label\"].item():\n",
    "                            correct_permutation = True\n",
    "                            if msp_temp > correct_permutation_ood_score:\n",
    "                                correct_permutation_ood_score = msp_temp\n",
    "            msp_predicts.append(msp_predict)\n",
    "            ood_score_final_list.append(max_msp)\n",
    "            correct_permutation_mask.append(correct_permutation)\n",
    "            correct_permutation_confident_scores.append(correct_permutation_ood_score)\n",
    "            correct_msp_mask.append(msp_predict == batch[\"label\"].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "idx_list = torch.tensor(idx_list).reshape(-1)\n",
    "uncertain_init_mask = torch.tensor(uncertain_init_mask).reshape(-1)\n",
    "uncertain_target_mask = torch.tensor(uncertain_target_mask).reshape(-1)\n",
    "correct_init_mask = torch.tensor(correct_init_mask).reshape(-1)\n",
    "correct_target_mask = torch.tensor(correct_target_mask).reshape(-1)\n",
    "correct_permutation_mask = torch.tensor(correct_permutation_mask).reshape(-1)\n",
    "correct_permutation_confident_scores = torch.tensor(correct_permutation_confident_scores).reshape(-1)\n",
    "correct_msp_mask = torch.tensor(correct_msp_mask).reshape(-1)\n",
    "init_target_mask = torch.tensor(init_target_mask).reshape(-1)\n",
    "ood_score_init_list = torch.tensor(ood_score_init_list).reshape(-1)\n",
    "ood_score_target_list = torch.tensor(ood_score_target_list).reshape(-1)\n",
    "ood_score_final_list = torch.tensor(ood_score_final_list).reshape(-1)\n",
    "msp_predicts = torch.tensor(msp_predicts).reshape(-1)\n",
    "print(len(idx_list), len(init_target_mask), len(correct_init_mask), len(correct_target_mask), len(correct_permutation_mask))\n",
    "torch.save({\"idx_list\": idx_list, \"uncertain_init_mask\": uncertain_init_mask, \"uncertain_target_mask\": uncertain_target_mask, \"correct_init_mask\": correct_init_mask, \"correct_target_mask\": correct_target_mask, \"correct_permutation_mask\": correct_permutation_mask, \"correct_msp_mask\": correct_msp_mask, \"init_target_mask\": init_target_mask, \"ood_score_init_list\": ood_score_init_list, \"ood_score_target_list\": ood_score_target_list, \"ood_score_final_list\": ood_score_final_list}, f\"./results/brute_force_permutation_alpha@{alpha}_drop.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weighted, only uncertain init\n",
    "\n",
    "for threshold in [0.8, 0.9, 0.99]:\n",
    "    correct_permutation_confident_mask = correct_permutation_confident_scores>threshold\n",
    "    uncertain_init_mask = ood_score_init_list < threshold\n",
    "    uncertain_target_mask = ood_score_target_list < threshold\n",
    "    condition_mask = ~uncertain_init_mask\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    print(\"Init\")\n",
    "    # init prediction\n",
    "    print((condition_mask&correct_init_mask).sum().item(), \n",
    "        (condition_mask).sum().item(), \n",
    "        (condition_mask&correct_init_mask).sum().item()/(condition_mask).sum().item())\n",
    "    # init prediction\n",
    "    print((~condition_mask&correct_init_mask).sum().item(), \n",
    "        (~condition_mask).sum().item(), \n",
    "       (~condition_mask&correct_init_mask).sum().item()/(~condition_mask).sum().item())\n",
    "    print(\"MSP\")\n",
    "    # msp prediction\n",
    "    print((condition_mask&correct_msp_mask).sum().item(), \n",
    "        (condition_mask).sum().item(), \n",
    "        (condition_mask&correct_msp_mask).sum().item()/(condition_mask).sum().item())\n",
    "    # msp prediction\n",
    "    print((~condition_mask&correct_msp_mask).sum().item(), \n",
    "        (~condition_mask).sum().item(), \n",
    "        (~condition_mask&correct_msp_mask).sum().item()/(~condition_mask).sum().item())\n",
    "    print(\"MSP & Init\")\n",
    "    print(((condition_mask&correct_init_mask)&(condition_mask&correct_msp_mask)).sum().item())\n",
    "    # print(((~(init_target_mask&(~uncertain_init_mask & ~uncertain_target_mask))& correct_msp_mask)&(~(init_target_mask&(~uncertain_init_mask & ~uncertain_target_mask))& correct_init_mask)).sum().item())\n",
    "    print(((condition_mask&correct_init_mask)|(condition_mask&correct_msp_mask)).sum().item(),\n",
    "          (condition_mask).sum().item(), \n",
    "          ((condition_mask&correct_init_mask)|(condition_mask&correct_msp_mask)).sum().item()/(condition_mask).sum().item())\n",
    "    print(((~condition_mask&correct_init_mask)|(~condition_mask&correct_msp_mask)).sum().item(),\n",
    "          (~condition_mask).sum().item(), \n",
    "          ((~condition_mask&correct_init_mask)|(~condition_mask&correct_msp_mask)).sum().item()/(~condition_mask).sum().item())\n",
    "    print(\"Permutation\")\n",
    "    print((condition_mask&correct_permutation_mask).sum().item(), \n",
    "        (condition_mask).sum().item(), \n",
    "        (condition_mask&correct_permutation_mask).sum().item()/(condition_mask).sum().item())\n",
    "    print((~condition_mask&correct_permutation_mask).sum().item(), \n",
    "         (~condition_mask).sum().item(), \n",
    "        (~condition_mask&correct_permutation_mask).sum().item()/(~condition_mask).sum().item())\n",
    "    print(\"Permutation Confident\")\n",
    "    print((condition_mask&correct_permutation_confident_mask).sum().item(), \n",
    "        (condition_mask).sum().item(), \n",
    "        (condition_mask&correct_permutation_confident_mask).sum().item()/(condition_mask).sum().item())\n",
    "    print((~condition_mask&correct_permutation_confident_mask).sum().item(),\n",
    "            (~condition_mask).sum().item(), \n",
    "            (~condition_mask&correct_permutation_confident_mask).sum().item()/(~condition_mask).sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weighted, only uncertain init\n",
    "\n",
    "for threshold in [0.82]:\n",
    "    correct_permutation_confident_mask = correct_permutation_confident_scores>threshold\n",
    "    uncertain_init_mask = ood_score_init_list < threshold\n",
    "    uncertain_target_mask = ood_score_target_list < threshold\n",
    "    condition_mask = ~uncertain_init_mask\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    print(\"Init\")\n",
    "    # init prediction\n",
    "    print((condition_mask&correct_init_mask).sum().item(), \n",
    "        (condition_mask).sum().item(), \n",
    "        (condition_mask&correct_init_mask).sum().item()/(condition_mask).sum().item())\n",
    "    # init prediction\n",
    "    print((~condition_mask&correct_init_mask).sum().item(), \n",
    "        (~condition_mask).sum().item(), \n",
    "       (~condition_mask&correct_init_mask).sum().item()/(~condition_mask).sum().item())\n",
    "    print(\"MSP\")\n",
    "    # msp prediction\n",
    "    print((condition_mask&correct_msp_mask).sum().item(), \n",
    "        (condition_mask).sum().item(), \n",
    "        (condition_mask&correct_msp_mask).sum().item()/(condition_mask).sum().item())\n",
    "    # msp prediction\n",
    "    print((~condition_mask&correct_msp_mask).sum().item(), \n",
    "        (~condition_mask).sum().item(), \n",
    "        (~condition_mask&correct_msp_mask).sum().item()/(~condition_mask).sum().item())\n",
    "    print(\"MSP & Init\")\n",
    "    print(((condition_mask&correct_init_mask)&(condition_mask&correct_msp_mask)).sum().item())\n",
    "    # print(((~(init_target_mask&(~uncertain_init_mask & ~uncertain_target_mask))& correct_msp_mask)&(~(init_target_mask&(~uncertain_init_mask & ~uncertain_target_mask))& correct_init_mask)).sum().item())\n",
    "    print(((condition_mask&correct_init_mask)|(condition_mask&correct_msp_mask)).sum().item(),\n",
    "          (condition_mask).sum().item(), \n",
    "          ((condition_mask&correct_init_mask)|(condition_mask&correct_msp_mask)).sum().item()/(condition_mask).sum().item())\n",
    "    print(((~condition_mask&correct_init_mask)|(~condition_mask&correct_msp_mask)).sum().item(),\n",
    "          (~condition_mask).sum().item(), \n",
    "          ((~condition_mask&correct_init_mask)|(~condition_mask&correct_msp_mask)).sum().item()/(~condition_mask).sum().item())\n",
    "    print(\"Permutation\")\n",
    "    print((condition_mask&correct_permutation_mask).sum().item(), \n",
    "        (condition_mask).sum().item(), \n",
    "        (condition_mask&correct_permutation_mask).sum().item()/(condition_mask).sum().item())\n",
    "    print((~condition_mask&correct_permutation_mask).sum().item(), \n",
    "         (~condition_mask).sum().item(), \n",
    "        (~condition_mask&correct_permutation_mask).sum().item()/(~condition_mask).sum().item())\n",
    "    print(\"Permutation Confident\")\n",
    "    print((condition_mask&correct_permutation_confident_mask).sum().item(), \n",
    "        (condition_mask).sum().item(), \n",
    "        (condition_mask&correct_permutation_confident_mask).sum().item()/(condition_mask).sum().item())\n",
    "    print((~condition_mask&correct_permutation_confident_mask).sum().item(),\n",
    "            (~condition_mask).sum().item(), \n",
    "            (~condition_mask&correct_permutation_confident_mask).sum().item()/(~condition_mask).sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSP is wrong, but init is correct\n",
    "target_col_idx_msp_init = idx_list[~condition_mask&correct_msp_mask&correct_init_mask]\n",
    "target_col_idx_msp =  idx_list[~condition_mask&correct_msp_mask&~correct_init_mask]\n",
    "target_col_idx_init =  idx_list[~condition_mask&~correct_msp_mask&correct_init_mask]\n",
    "target_col_idx_permutation = idx_list[~condition_mask&correct_permutation_confident_mask&~correct_msp_mask&~correct_init_mask]\n",
    "target_col_idx_permutation_msp =  idx_list[~condition_mask&correct_permutation_confident_mask&~correct_msp_mask]\n",
    "target_col_idx_permutation_init =  idx_list[~condition_mask&correct_permutation_confident_mask&~correct_init_mask]\n",
    "\n",
    "print(\"Both correct\", (~condition_mask&correct_msp_mask&correct_init_mask).sum(), \n",
    "      ood_score_init_list[~condition_mask&correct_msp_mask&correct_init_mask].mean(), \n",
    "      # ood_score_target_list[~condition_mask&correct_msp_mask&correct_init_mask].mean(),\n",
    "      ood_score_final_list[~condition_mask&correct_msp_mask&correct_init_mask].mean())\n",
    "print(\"MSP correct \", (~condition_mask&correct_msp_mask&~correct_init_mask).sum(), \n",
    "      ood_score_init_list[~condition_mask&correct_msp_mask&~correct_init_mask].mean(),\n",
    "      #   ood_score_target_list[~condition_mask&correct_msp_mask&~correct_init_mask].mean(),\n",
    "        ood_score_final_list[~condition_mask&correct_msp_mask&~correct_init_mask].mean())\n",
    "print(\"Init correct\", (~condition_mask&~correct_msp_mask&correct_init_mask).sum(), \n",
    "      ood_score_init_list[~condition_mask&~correct_msp_mask&correct_init_mask].mean(),\n",
    "      #   ood_score_target_list[~condition_mask&~correct_msp_mask&correct_init_mask].mean(),\n",
    "        ood_score_final_list[~condition_mask&~correct_msp_mask&correct_init_mask].mean())\n",
    "print(\"Permutation correct\",(~condition_mask&correct_permutation_confident_mask&~correct_msp_mask&~correct_init_mask).sum(), \n",
    "      ood_score_init_list[~condition_mask&correct_permutation_confident_mask&~correct_msp_mask&~correct_init_mask].mean(),\n",
    "      #   ood_score_target_list[~condition_mask&correct_permutation_confident_mask&~correct_msp_mask&~correct_init_mask].mean(),\n",
    "        ood_score_final_list[~condition_mask&correct_permutation_confident_mask&~correct_msp_mask&~correct_init_mask].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col_idx_permutation_msp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use target as head, the MSP context\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "log = defaultdict(list)\n",
    "num_cols = []\n",
    "threshold = 0.8\n",
    "corrected = 0\n",
    "total_mistakes = 0\n",
    "init_permutation = defaultdict(list)\n",
    "corrected_permutation = defaultdict(list)\n",
    "init_logits = defaultdict(list)\n",
    "corrected_logits = defaultdict(list)\n",
    "max_col_length = 3\n",
    "msp_threshold = 0.9\n",
    "\n",
    "\n",
    "alpha = 0.25\n",
    "\n",
    "class_weights = (1.0 / class_freq) ** alpha\n",
    "\n",
    "# Normalize the weights\n",
    "class_weights /= class_weights.sum()\n",
    "\n",
    "for batch_idx, batch in enumerate(test_dataset_iter):\n",
    "    if batch_idx == 19:\n",
    "        break\n",
    "cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "target_col_mask = batch[\"target_col_mask\"].T\n",
    "col_idx_set = target_col_mask.unique().tolist()\n",
    "init_permutation_i = get_permutation(target_col_mask)\n",
    "successs = False\n",
    "# logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,).detach().cpu()\n",
    "# logits = reweight_logits(logits, class_weights)\n",
    "# logits_init = logits.clone()\n",
    "# num_cols.append(batch[\"target_col_mask\"].max().item())\n",
    "\n",
    "\n",
    "# col_idx_set = target_col_mask.unique().tolist()\n",
    "# successs = False\n",
    "# init_permutation_i = get_permutation(target_col_mask)\n",
    "# init_permutation[batch_idx].append(get_permutation(target_col_mask))\n",
    "# init_logits[batch_idx].append(logits_init.detach().cpu())     \n",
    "# init_msp = logits_init.max().item()\n",
    "# print(batch[\"label\"].item())\n",
    "# print(get_permutation(target_col_mask), init_msp, init_logits[batch_idx][0].argmax().item()) \n",
    "print(batch[\"label\"].item())  \n",
    "print(batch[\"target_col_mask\"].max().item(), get_permutation(target_col_mask))\n",
    "print(\"********************************************************\")\n",
    "assert -1 not in col_idx_set\n",
    "max_msp = 0 \n",
    "# for r in range(1, min(len(col_idx_set), max_col_length) + 1):\n",
    "enough = False\n",
    "# for r in range(len(col_idx_set)-1, 0, -1):\n",
    "for r in range(len(col_idx_set)-1, len(col_idx_set)//2, -1):\n",
    "    for subset in itertools.combinations(col_idx_set, r):\n",
    "        if 0 not in subset and r != 1:\n",
    "            continue\n",
    "        for x in itertools.permutations(subset):\n",
    "            if not is_sublist(x, init_permutation_i):\n",
    "                continue\n",
    "            new_batch_data = []\n",
    "            for col_i in x:\n",
    "                if col_i == 0:\n",
    "                    if len(new_batch_data) == 0:\n",
    "                        cls_indexes_value = 0\n",
    "                    else:\n",
    "                        cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "            if 0 not in x:\n",
    "                cls_indexes_value = 0\n",
    "            new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "            cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "            logits_temp = model(new_batch_data, cls_indexes=cls_indexes,).detach().cpu()\n",
    "            logits_temp = reweight_logits(logits_temp, class_weights)\n",
    "            msp_temp = logits_temp.max()\n",
    "            predict_temp = logits_temp.argmax()\n",
    "            # msp_temp = F.softmax(logits_temp).max().item()\n",
    "            # predict_temp = F.softmax(logits_temp).argmax().item()\n",
    "\n",
    "            print(x, msp_temp,predict_temp)\n",
    "            if msp_temp > max_msp and 0 in x:\n",
    "                max_msp = msp_temp\n",
    "                best_msp_perm = x\n",
    "                msp_predict = predict_temp\n",
    "        \n",
    "print(\"********************************************************\")\n",
    "print(best_msp_perm, max_msp, msp_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# brute force perumate, early stop\n",
    "import itertools\n",
    "\n",
    "\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "\n",
    "max_col_length = 3\n",
    "for alpha in [0.25]:\n",
    "    class_weights = (1.0 / class_freq) ** alpha\n",
    "    # Normalize the weights\n",
    "    class_weights /= class_weights.sum()\n",
    "    for uncertainty_threshold in [ 0.8]:\n",
    "        for msp_threshold in [ 0.8, 0.9, 0.99]:\n",
    "            for debias_threshold in [1.0]:\n",
    "                print(f\"*********************alpha: {alpha}; uncertain: {uncertainty_threshold}; debias: {debias_threshold}; msp: {msp_threshold}****************************\")\n",
    "                ft_embs_test = []\n",
    "                labels_test = []\n",
    "                logits_test = []\n",
    "                log = defaultdict(list)\n",
    "                num_cols = []\n",
    "                corrected = 0\n",
    "                total_mistakes = 0\n",
    "\n",
    "                for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "                    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "                    target_col_mask = batch[\"target_col_mask\"].T\n",
    "                    logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "                    logits = reweight_logits(logits.detach().cpu(), class_weights) # Here !!!!!!!!!!\n",
    "                    msp_init = logits.max().item()\n",
    "                    num_cols.append(batch[\"target_col_mask\"].max().item())\n",
    "                    predict_init = logits.argmax().item()\n",
    "                    max_msp = 0\n",
    "                    \n",
    "                    if 1 in target_col_mask and msp_init < uncertainty_threshold:\n",
    "                        init_permutation_i = get_permutation(target_col_mask)\n",
    "                        col_idx_set = target_col_mask.unique().tolist()\n",
    "                        debias_classes = []\n",
    "                        early_stop = False\n",
    "                        assert -1 not in col_idx_set\n",
    "                        for r in range(len(col_idx_set)-1, len(col_idx_set)//2, -1):\n",
    "                            round_classes = set()\n",
    "                            for subset in itertools.combinations(col_idx_set, r):\n",
    "                                if 0 not in subset and r != 1:\n",
    "                                    continue\n",
    "                                for x in itertools.permutations(subset):\n",
    "                                    if not is_sublist(x, init_permutation_i):\n",
    "                                        continue\n",
    "                                    new_batch_data = []\n",
    "                                    for col_i in x:\n",
    "                                        if col_i == 0:\n",
    "                                            if len(new_batch_data) == 0:\n",
    "                                                cls_indexes_value = 0\n",
    "                                            else:\n",
    "                                                cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                                        new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                                    if 0 not in x:\n",
    "                                        cls_indexes_value = 0\n",
    "                                    new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                                    cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                                    logits_temp = model(new_batch_data, cls_indexes=cls_indexes,)\n",
    "                                    logits_temp = reweight_logits(logits_temp.detach().cpu(), class_weights)\n",
    "                                    msp_temp = logits_temp.max().item()\n",
    "                                    predict_temp = logits_temp.argmax().item()\n",
    "                                    round_classes.add(predict_temp)\n",
    "                                    # if len(x) == 1 and 0 in x:\n",
    "                                    #     predict_target = predict_temp\n",
    "                                    #     msp_target = msp_temp\n",
    "                                    # # print(x, msp_temp, predict_temp)\n",
    "                                    # if 0 not in x and msp_temp > debias_threshold and (predict_temp != predict_target):\n",
    "                                    #     debias_classes.append(predict_temp)\n",
    "                                    #     continue\n",
    "                                    if msp_temp > max_msp and 0 in x and predict_temp not in debias_classes:\n",
    "                                        max_msp = msp_temp\n",
    "                                        best_msp_perm = x\n",
    "                                        msp_predict = predict_temp\n",
    "                                        logits_msp = logits_temp.clone()\n",
    "                                        if max_msp > msp_threshold and 0 in x and len(round_classes) > 1: # make sure the classes in one round is not homogenous \n",
    "                                            early_stop = True\n",
    "                            if early_stop:\n",
    "                                break\n",
    "                    if max_msp > msp_threshold:\n",
    "                        logits = logits_msp.clone()\n",
    "                    labels_test.append(batch[\"label\"].cpu())\n",
    "                    logits_test.append(logits.detach().cpu())\n",
    "                labels_test = torch.cat(labels_test, dim=0)\n",
    "                logits_test = torch.stack(logits_test, dim=0)\n",
    "                preds_test = torch.argmax(logits_test, dim=1)\n",
    "                num_cols = torch.tensor(num_cols)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                from sklearn.metrics import confusion_matrix, f1_score\n",
    "                mask = num_cols > 0\n",
    "                ts_pred_list = logits_test.argmax(\n",
    "                                            1).cpu().detach().numpy().tolist()\n",
    "                ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"micro\")\n",
    "                ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"macro\")\n",
    "                print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "                ts_pred_list = logits_test.argmax(\n",
    "                                            1).cpu().detach()[mask].numpy().tolist()\n",
    "                ts_micro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"micro\")\n",
    "                ts_macro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"macro\")\n",
    "                print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "                ts_pred_list = logits_test.argmax(\n",
    "                                            1).cpu().detach()[~mask].numpy().tolist()\n",
    "                ts_micro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"micro\")\n",
    "                ts_macro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"macro\")\n",
    "                print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# brute force perumate, early stop\n",
    "import itertools\n",
    "\n",
    "\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "\n",
    "max_col_length = 3\n",
    "for alpha in [0.25]:\n",
    "    class_weights = (1.0 / class_freq) ** alpha\n",
    "    # Normalize the weights\n",
    "    class_weights /= class_weights.sum()\n",
    "    for uncertainty_threshold in [ 0.8]:\n",
    "        for msp_threshold in [0.0]:\n",
    "            for debias_threshold in [1.0]:\n",
    "                print(f\"*********************alpha: {alpha}; uncertain: {uncertainty_threshold}; debias: {debias_threshold}; msp: {msp_threshold}****************************\")\n",
    "                ft_embs_test = []\n",
    "                labels_test = []\n",
    "                logits_test = []\n",
    "                log = defaultdict(list)\n",
    "                num_cols = []\n",
    "                corrected = 0\n",
    "                total_mistakes = 0\n",
    "\n",
    "                for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "                    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "                    target_col_mask = batch[\"target_col_mask\"].T\n",
    "                    logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "                    logits = reweight_logits(logits.detach().cpu(), class_weights) # Here !!!!!!!!!!\n",
    "                    msp_init = logits.max().item()\n",
    "                    num_cols.append(batch[\"target_col_mask\"].max().item())\n",
    "                    predict_init = logits.argmax().item()\n",
    "                    max_msp = 0\n",
    "                    \n",
    "                    if 1 in target_col_mask and msp_init < uncertainty_threshold:\n",
    "                        init_permutation_i = get_permutation(target_col_mask)\n",
    "                        col_idx_set = target_col_mask.unique().tolist()\n",
    "                        debias_classes = []\n",
    "                        early_stop = False\n",
    "                        assert -1 not in col_idx_set\n",
    "                        for r in range(len(col_idx_set)-1, len(col_idx_set)//2, -1):\n",
    "                            round_classes = set()\n",
    "                            for subset in itertools.combinations(col_idx_set, r):\n",
    "                                if 0 not in subset and r != 1:\n",
    "                                    continue\n",
    "                                for x in itertools.permutations(subset):\n",
    "                                    if not is_sublist(x, init_permutation_i):\n",
    "                                        continue\n",
    "                                    new_batch_data = []\n",
    "                                    for col_i in x:\n",
    "                                        if col_i == 0:\n",
    "                                            if len(new_batch_data) == 0:\n",
    "                                                cls_indexes_value = 0\n",
    "                                            else:\n",
    "                                                cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                                        new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                                    if 0 not in x:\n",
    "                                        cls_indexes_value = 0\n",
    "                                    new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                                    cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                                    logits_temp = model(new_batch_data, cls_indexes=cls_indexes,)\n",
    "                                    logits_temp = reweight_logits(logits_temp.detach().cpu(), class_weights)\n",
    "                                    msp_temp = logits_temp.max().item()\n",
    "                                    predict_temp = logits_temp.argmax().item()\n",
    "                                    round_classes.add(predict_temp)\n",
    "                                    # if len(x) == 1 and 0 in x:\n",
    "                                    #     predict_target = predict_temp\n",
    "                                    #     msp_target = msp_temp\n",
    "                                    # # print(x, msp_temp, predict_temp)\n",
    "                                    # if 0 not in x and msp_temp > debias_threshold and (predict_temp != predict_target):\n",
    "                                    #     debias_classes.append(predict_temp)\n",
    "                                    #     continue\n",
    "                                    if msp_temp > max_msp and 0 in x and predict_temp not in debias_classes:\n",
    "                                        max_msp = msp_temp\n",
    "                                        best_msp_perm = x\n",
    "                                        msp_predict = predict_temp\n",
    "                                        logits_msp = logits_temp.clone()\n",
    "                                        if max_msp > msp_threshold and 0 in x and len(round_classes) > 1: # make sure the classes in one round is not homogenous \n",
    "                                            early_stop = True\n",
    "                            if early_stop:\n",
    "                                break\n",
    "                    if max_msp > msp_threshold:\n",
    "                        logits = logits_msp.clone()\n",
    "                    labels_test.append(batch[\"label\"].cpu())\n",
    "                    logits_test.append(logits.detach().cpu())\n",
    "                labels_test = torch.cat(labels_test, dim=0)\n",
    "                logits_test = torch.stack(logits_test, dim=0)\n",
    "                preds_test = torch.argmax(logits_test, dim=1)\n",
    "                num_cols = torch.tensor(num_cols)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                from sklearn.metrics import confusion_matrix, f1_score\n",
    "                mask = num_cols > 0\n",
    "                ts_pred_list = logits_test.argmax(\n",
    "                                            1).cpu().detach().numpy().tolist()\n",
    "                ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"micro\")\n",
    "                ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"macro\")\n",
    "                print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "                ts_pred_list = logits_test.argmax(\n",
    "                                            1).cpu().detach()[mask].numpy().tolist()\n",
    "                ts_micro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"micro\")\n",
    "                ts_macro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"macro\")\n",
    "                print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "                ts_pred_list = logits_test.argmax(\n",
    "                                            1).cpu().detach()[~mask].numpy().tolist()\n",
    "                ts_micro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"micro\")\n",
    "                ts_macro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"macro\")\n",
    "                print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# brute force perumate, early stop\n",
    "import itertools\n",
    "\n",
    "\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "\n",
    "max_col_length = 3\n",
    "for alpha in [0.25]:\n",
    "    class_weights = (1.0 / class_freq) ** alpha\n",
    "    # Normalize the weights\n",
    "    class_weights /= class_weights.sum()\n",
    "    for uncertainty_threshold in [ 0.85]:\n",
    "        for msp_threshold in [0.9]:\n",
    "            for debias_threshold in [1.0]:\n",
    "                print(f\"*********************alpha: {alpha}; uncertain: {uncertainty_threshold}; debias: {debias_threshold}; msp: {msp_threshold}****************************\")\n",
    "                ft_embs_test = []\n",
    "                labels_test = []\n",
    "                logits_test = []\n",
    "                log = defaultdict(list)\n",
    "                num_cols = []\n",
    "                corrected = 0\n",
    "                total_mistakes = 0\n",
    "\n",
    "                for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "                    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "                    target_col_mask = batch[\"target_col_mask\"].T\n",
    "                    logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "                    logits = reweight_logits(logits.detach().cpu(), class_weights) # Here !!!!!!!!!!\n",
    "                    msp_init = logits.max().item()\n",
    "                    num_cols.append(batch[\"target_col_mask\"].max().item())\n",
    "                    predict_init = logits.argmax().item()\n",
    "                    max_msp = 0\n",
    "                    \n",
    "                    if 1 in target_col_mask and msp_init < uncertainty_threshold:\n",
    "                        init_permutation_i = get_permutation(target_col_mask)\n",
    "                        col_idx_set = target_col_mask.unique().tolist()\n",
    "                        debias_classes = []\n",
    "                        early_stop = False\n",
    "                        assert -1 not in col_idx_set\n",
    "                        for r in range(len(col_idx_set)-1, len(col_idx_set)//2, -1):\n",
    "                            round_classes = set()\n",
    "                            for subset in itertools.combinations(col_idx_set, r):\n",
    "                                if 0 not in subset and r != 1:\n",
    "                                    continue\n",
    "                                for x in itertools.permutations(subset):\n",
    "                                    if not is_sublist(x, init_permutation_i):\n",
    "                                        continue\n",
    "                                    new_batch_data = []\n",
    "                                    for col_i in x:\n",
    "                                        if col_i == 0:\n",
    "                                            if len(new_batch_data) == 0:\n",
    "                                                cls_indexes_value = 0\n",
    "                                            else:\n",
    "                                                cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                                        new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                                    if 0 not in x:\n",
    "                                        cls_indexes_value = 0\n",
    "                                    new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                                    cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                                    logits_temp = model(new_batch_data, cls_indexes=cls_indexes,)\n",
    "                                    logits_temp = reweight_logits(logits_temp.detach().cpu(), class_weights)\n",
    "                                    msp_temp = logits_temp.max().item()\n",
    "                                    predict_temp = logits_temp.argmax().item()\n",
    "                                    round_classes.add(predict_temp)\n",
    "                                    # if len(x) == 1 and 0 in x:\n",
    "                                    #     predict_target = predict_temp\n",
    "                                    #     msp_target = msp_temp\n",
    "                                    # # print(x, msp_temp, predict_temp)\n",
    "                                    # if 0 not in x and msp_temp > debias_threshold and (predict_temp != predict_target):\n",
    "                                    #     debias_classes.append(predict_temp)\n",
    "                                    #     continue\n",
    "                                    if msp_temp > max_msp and 0 in x and predict_temp not in debias_classes:\n",
    "                                        max_msp = msp_temp\n",
    "                                        best_msp_perm = x\n",
    "                                        msp_predict = predict_temp\n",
    "                                        logits_msp = logits_temp.clone()\n",
    "                                        if max_msp > msp_threshold and 0 in x and len(round_classes) > 1: # make sure the classes in one round is not homogenous \n",
    "                                            early_stop = True\n",
    "                            if early_stop:\n",
    "                                break\n",
    "                    if max_msp > msp_threshold:\n",
    "                        logits = logits_msp.clone()\n",
    "                    labels_test.append(batch[\"label\"].cpu())\n",
    "                    logits_test.append(logits.detach().cpu())\n",
    "                labels_test = torch.cat(labels_test, dim=0)\n",
    "                logits_test = torch.stack(logits_test, dim=0)\n",
    "                preds_test = torch.argmax(logits_test, dim=1)\n",
    "                num_cols = torch.tensor(num_cols)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                from sklearn.metrics import confusion_matrix, f1_score\n",
    "                mask = num_cols > 0\n",
    "                ts_pred_list = logits_test.argmax(\n",
    "                                            1).cpu().detach().numpy().tolist()\n",
    "                ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"micro\")\n",
    "                ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"macro\")\n",
    "                print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "                ts_pred_list = logits_test.argmax(\n",
    "                                            1).cpu().detach()[mask].numpy().tolist()\n",
    "                ts_micro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"micro\")\n",
    "                ts_macro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"macro\")\n",
    "                print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "                ts_pred_list = logits_test.argmax(\n",
    "                                            1).cpu().detach()[~mask].numpy().tolist()\n",
    "                ts_micro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"micro\")\n",
    "                ts_macro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"macro\")\n",
    "                print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# brute force perumate, early stop\n",
    "import itertools\n",
    "\n",
    "\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "\n",
    "max_col_length = 3\n",
    "for alpha in [0.25]:\n",
    "    class_weights = (1.0 / class_freq) ** alpha\n",
    "    # Normalize the weights\n",
    "    class_weights /= class_weights.sum()\n",
    "    for uncertainty_threshold in [ 0.85, 0.8]:\n",
    "        for msp_threshold in [0.0, 0.8, 0.85, 0.9]:\n",
    "            for debias_threshold in [1.0]:\n",
    "                print(f\"*********************alpha: {alpha}; uncertain: {uncertainty_threshold}; debias: {debias_threshold}; msp: {msp_threshold}****************************\")\n",
    "                ft_embs_test = []\n",
    "                labels_test = []\n",
    "                logits_test = []\n",
    "                log = defaultdict(list)\n",
    "                num_cols = []\n",
    "                corrected = 0\n",
    "                total_mistakes = 0\n",
    "\n",
    "                for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "                    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "                    target_col_mask = batch[\"target_col_mask\"].T\n",
    "                    logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "                    logits = reweight_logits(logits.detach().cpu(), class_weights) # Here !!!!!!!!!!\n",
    "                    msp_init = logits.max().item()\n",
    "                    num_cols.append(batch[\"target_col_mask\"].max().item())\n",
    "                    predict_init = logits.argmax().item()\n",
    "                    max_msp = 0\n",
    "                    \n",
    "                    if 1 in target_col_mask and msp_init < uncertainty_threshold:\n",
    "                        init_permutation_i = get_permutation(target_col_mask)\n",
    "                        col_idx_set = target_col_mask.unique().tolist()\n",
    "                        debias_classes = []\n",
    "                        early_stop = False\n",
    "                        assert -1 not in col_idx_set\n",
    "                        for r in range(len(col_idx_set)-1, len(col_idx_set)//2, -1):\n",
    "                            round_classes = set()\n",
    "                            for subset in itertools.combinations(col_idx_set, r):\n",
    "                                if 0 not in subset and r != 1:\n",
    "                                    continue\n",
    "                                for x in itertools.permutations(subset):\n",
    "                                    if not is_sublist(x, init_permutation_i):\n",
    "                                        continue\n",
    "                                    new_batch_data = []\n",
    "                                    for col_i in x:\n",
    "                                        if col_i == 0:\n",
    "                                            if len(new_batch_data) == 0:\n",
    "                                                cls_indexes_value = 0\n",
    "                                            else:\n",
    "                                                cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                                        new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                                    if 0 not in x:\n",
    "                                        cls_indexes_value = 0\n",
    "                                    new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                                    cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                                    logits_temp = model(new_batch_data, cls_indexes=cls_indexes,)\n",
    "                                    logits_temp = reweight_logits(logits_temp.detach().cpu(), class_weights)\n",
    "                                    msp_temp = logits_temp.max().item()\n",
    "                                    predict_temp = logits_temp.argmax().item()\n",
    "                                    round_classes.add(predict_temp)\n",
    "                                    # if len(x) == 1 and 0 in x:\n",
    "                                    #     predict_target = predict_temp\n",
    "                                    #     msp_target = msp_temp\n",
    "                                    # # print(x, msp_temp, predict_temp)\n",
    "                                    # if 0 not in x and msp_temp > debias_threshold and (predict_temp != predict_target):\n",
    "                                    #     debias_classes.append(predict_temp)\n",
    "                                    #     continue\n",
    "                                    if msp_temp > max_msp and 0 in x and predict_temp not in debias_classes:\n",
    "                                        max_msp = msp_temp\n",
    "                                        best_msp_perm = x\n",
    "                                        msp_predict = predict_temp\n",
    "                                        logits_msp = logits_temp.clone()\n",
    "                                        if max_msp > msp_threshold and 0 in x: # make sure the classes in one round is not homogenous \n",
    "                                            early_stop = True\n",
    "                            if early_stop:\n",
    "                                break\n",
    "                    if max_msp > msp_threshold:\n",
    "                        logits = logits_msp.clone()\n",
    "                    labels_test.append(batch[\"label\"].cpu())\n",
    "                    logits_test.append(logits.detach().cpu())\n",
    "                labels_test = torch.cat(labels_test, dim=0)\n",
    "                logits_test = torch.stack(logits_test, dim=0)\n",
    "                preds_test = torch.argmax(logits_test, dim=1)\n",
    "                num_cols = torch.tensor(num_cols)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                from sklearn.metrics import confusion_matrix, f1_score\n",
    "                mask = num_cols > 0\n",
    "                ts_pred_list = logits_test.argmax(\n",
    "                                            1).cpu().detach().numpy().tolist()\n",
    "                ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"micro\")\n",
    "                ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"macro\")\n",
    "                print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "                ts_pred_list = logits_test.argmax(\n",
    "                                            1).cpu().detach()[mask].numpy().tolist()\n",
    "                ts_micro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"micro\")\n",
    "                ts_macro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"macro\")\n",
    "                print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "                ts_pred_list = logits_test.argmax(\n",
    "                                            1).cpu().detach()[~mask].numpy().tolist()\n",
    "                ts_micro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"micro\")\n",
    "                ts_macro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"macro\")\n",
    "                print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *********************alpha: 0.25; uncertain: 0.85; debias: 1.0; msp: 0.9****************************\n",
    "# ts_micro_f1=0.5456, ts_macro_f1=0.2627\n",
    "# ts_micro_f1=0.5452, ts_macro_f1=0.2626\n",
    "# ts_micro_f1=1.0000, ts_macro_f1=1.0000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# brute force perumate, early stop\n",
    "import itertools\n",
    "\n",
    "\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "\n",
    "max_col_length = 3\n",
    "for alpha in [0.0]:\n",
    "    # class_weights = (1.0 / class_freq) ** alpha\n",
    "    # # Normalize the weights\n",
    "    # class_weights /= class_weights.sum()\n",
    "    for uncertainty_threshold in [ 0.85, 0.8, 0.9]:\n",
    "        for msp_threshold in [0.0, 0.8, 0.85, 0.9]:\n",
    "            for debias_threshold in [1.0]:\n",
    "                print(f\"*********************alpha: {alpha}; uncertain: {uncertainty_threshold}; debias: {debias_threshold}; msp: {msp_threshold}****************************\")\n",
    "                ft_embs_test = []\n",
    "                labels_test = []\n",
    "                logits_test = []\n",
    "                log = defaultdict(list)\n",
    "                num_cols = []\n",
    "                corrected = 0\n",
    "                total_mistakes = 0\n",
    "\n",
    "                for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "                    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "                    target_col_mask = batch[\"target_col_mask\"].T\n",
    "                    logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "                    # logits = reweight_logits(logits.detach().cpu(), class_weights) # Here !!!!!!!!!!\n",
    "                    logits = F.softmax(logits, dim=-1)\n",
    "                    msp_init = logits.max().item()\n",
    "                    num_cols.append(batch[\"target_col_mask\"].max().item())\n",
    "                    predict_init = logits.argmax().item()\n",
    "                    max_msp = 0\n",
    "                    \n",
    "                    if 1 in target_col_mask and msp_init < uncertainty_threshold:\n",
    "                        init_permutation_i = get_permutation(target_col_mask)\n",
    "                        col_idx_set = target_col_mask.unique().tolist()\n",
    "                        debias_classes = []\n",
    "                        early_stop = False\n",
    "                        assert -1 not in col_idx_set\n",
    "                        for r in range(len(col_idx_set)-1, len(col_idx_set)//2, -1):\n",
    "                            round_classes = set()\n",
    "                            for subset in itertools.combinations(col_idx_set, r):\n",
    "                                if 0 not in subset and r != 1:\n",
    "                                    continue\n",
    "                                for x in itertools.permutations(subset):\n",
    "                                    if not is_sublist(x, init_permutation_i):\n",
    "                                        continue\n",
    "                                    new_batch_data = []\n",
    "                                    for col_i in x:\n",
    "                                        if col_i == 0:\n",
    "                                            if len(new_batch_data) == 0:\n",
    "                                                cls_indexes_value = 0\n",
    "                                            else:\n",
    "                                                cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                                        new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                                    if 0 not in x:\n",
    "                                        cls_indexes_value = 0\n",
    "                                    new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                                    cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                                    logits_temp = model(new_batch_data, cls_indexes=cls_indexes,)\n",
    "                                    # logits_temp = reweight_logits(logits_temp.detach().cpu(), class_weights)\n",
    "                                    logits_temp = F.softmax(logits_temp, dim=-1)\n",
    "                                    msp_temp = logits_temp.max().item()\n",
    "                                    predict_temp = logits_temp.argmax().item()\n",
    "                                    round_classes.add(predict_temp)\n",
    "                                    # if len(x) == 1 and 0 in x:\n",
    "                                    #     predict_target = predict_temp\n",
    "                                    #     msp_target = msp_temp\n",
    "                                    # # print(x, msp_temp, predict_temp)\n",
    "                                    # if 0 not in x and msp_temp > debias_threshold and (predict_temp != predict_target):\n",
    "                                    #     debias_classes.append(predict_temp)\n",
    "                                    #     continue\n",
    "                                    if msp_temp > max_msp and 0 in x and predict_temp not in debias_classes:\n",
    "                                        max_msp = msp_temp\n",
    "                                        best_msp_perm = x\n",
    "                                        msp_predict = predict_temp\n",
    "                                        logits_msp = logits_temp.clone()\n",
    "                                        if max_msp > msp_threshold and 0 in x: # make sure the classes in one round is not homogenous \n",
    "                                            early_stop = True\n",
    "                            if early_stop:\n",
    "                                break\n",
    "                    if max_msp > msp_threshold:\n",
    "                        logits = logits_msp.clone()\n",
    "                    labels_test.append(batch[\"label\"].cpu())\n",
    "                    logits_test.append(logits.detach().cpu())\n",
    "                labels_test = torch.cat(labels_test, dim=0)\n",
    "                logits_test = torch.stack(logits_test, dim=0)\n",
    "                preds_test = torch.argmax(logits_test, dim=1)\n",
    "                num_cols = torch.tensor(num_cols)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                from sklearn.metrics import confusion_matrix, f1_score\n",
    "                mask = num_cols > 0\n",
    "                ts_pred_list = logits_test.argmax(\n",
    "                                            1).cpu().detach().numpy().tolist()\n",
    "                ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"micro\")\n",
    "                ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"macro\")\n",
    "                print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "                ts_pred_list = logits_test.argmax(\n",
    "                                            1).cpu().detach()[mask].numpy().tolist()\n",
    "                ts_micro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"micro\")\n",
    "                ts_macro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"macro\")\n",
    "                print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "                ts_pred_list = logits_test.argmax(\n",
    "                                            1).cpu().detach()[~mask].numpy().tolist()\n",
    "                ts_micro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"micro\")\n",
    "                ts_macro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"macro\")\n",
    "                print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brute force perumate in training TODO: restrict mamimus length of permutation\n",
    "import itertools\n",
    "import torch.nn.functional as F\n",
    "\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "for threshold in [1.5]:\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    log = defaultdict(list)\n",
    "    num_cols = []\n",
    "    corrected = 0\n",
    "    total_mistakes = 0\n",
    "    num_permutations = {}\n",
    "    init_permutation = {}\n",
    "    init_correctness = {}\n",
    "    score_init = {}\n",
    "    score_permutation = defaultdict(list)\n",
    "    permutation_correctness = defaultdict(list)\n",
    "    for batch_idx, batch in enumerate(train_dataloader_iter):\n",
    "        cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "        target_col_mask = batch[\"target_col_mask\"].T\n",
    "        logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "        score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
    "        label_i = batch[\"label\"].item()\n",
    "        predict_init = logits.argmax().item()\n",
    "        init_permutation_i = get_permutation(target_col_mask)\n",
    "        init_permutation[batch_idx] = init_permutation_i\n",
    "        if predict_init == label_i:\n",
    "            init_correctness[batch_idx] = True\n",
    "        else:\n",
    "            init_correctness[batch_idx] = False\n",
    "        num_permutations[batch_idx] = 0\n",
    "        if 1 in target_col_mask:\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            assert -1 not in col_idx_set\n",
    "            for r in range(len(init_permutation_i)-1, len(init_permutation_i)//2, -1): # not \n",
    "                for x in itertools.combinations(init_permutation_i, r):\n",
    "                    if 0 not in x:\n",
    "                        continue\n",
    "\n",
    "                    num_permutations[batch_idx] += 1\n",
    "                    new_batch_data = []\n",
    "                    for col_i in x:\n",
    "                        if col_i == 0:\n",
    "                            if len(new_batch_data) == 0:\n",
    "                                cls_indexes_value = 0\n",
    "                            else:\n",
    "                                cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                        new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                    new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                    cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                    logits_temp = model(new_batch_data, cls_indexes=cls_indexes,)\n",
    "                    ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n",
    "                    score_permutation[batch_idx].append(ood_score_temp)\n",
    "                    predict_temp = logits_temp.argmax().item()\n",
    "                    permutation_correctness[batch_idx].append(predict_temp == label_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation_correctness_ratio = []\n",
    "score_permutation_avg = []\n",
    "for i in score_init:\n",
    "    permutation_correctness_ratio.append(np.mean(permutation_correctness[i]))\n",
    "    score_permutation_avg.append(np.mean(score_permutation[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(score_permutation_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(permutation_correctness_ratio)\n",
    "permutation_correctness_ratio = np.array(permutation_correctness_ratio)\n",
    "print(np.mean(permutation_correctness_ratio[~np.isnan(permutation_correctness_ratio)]), sum(permutation_correctness_ratio==1)/len(permutation_correctness_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation_correctness[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(permutation_correctness[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in score_init:\n",
    "    print(score_init[i], init_correctness[i], num_permutations[i], init_permutation[i])\n",
    "    for score, correct in zip(score_permutation[i], permutation_correctness[i], ):\n",
    "        print(score, correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(i, score_init[i], init_correctness[i], num_permutations[i], init_permutation[i])\n",
    "    print(np.mean(score_permutation[i]), np.mean(permutation_correctness[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation_correctness[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_valid = []\n",
    "for batch_idx, batch in enumerate(valid_dataloader_iter):\n",
    "    labels_valid.append(batch[\"label\"].cpu())\n",
    "labels_valid = torch.tensor(labels_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(labels_valid.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, batch in enumerate(valid_dataloader_iter):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[\"target_col_mask\"].T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " batch[\"cls_indexes\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brute force perumate in validation TODO: restrict mamimus length of permutation\n",
    "import itertools\n",
    "import torch.nn.functional as F\n",
    "\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "for threshold in [1.5]:\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    log = defaultdict(list)\n",
    "    num_cols = []\n",
    "    corrected = 0\n",
    "    total_mistakes = 0\n",
    "    num_permutations = {}\n",
    "    init_permutation = {}\n",
    "    init_correctness = {}\n",
    "    score_init = {}\n",
    "    score_permutation = defaultdict(list)\n",
    "    permutation_correctness = defaultdict(list)\n",
    "    for batch_idx, batch in enumerate(valid_dataloader_iter):\n",
    "        cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "        target_col_mask = batch[\"target_col_mask\"].T\n",
    "        logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "        score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
    "        label_i = batch[\"label\"].item()\n",
    "        predict_init = logits.argmax().item()\n",
    "        init_permutation_i = get_permutation(target_col_mask)\n",
    "        init_permutation[batch_idx] = init_permutation_i\n",
    "        if predict_init == label_i:\n",
    "            init_correctness[batch_idx] = True\n",
    "        else:\n",
    "            init_correctness[batch_idx] = False\n",
    "        num_permutations[batch_idx] = 0\n",
    "        if 1 in target_col_mask:\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            assert -1 not in col_idx_set\n",
    "            for r in range(len(init_permutation_i), max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "                for subset in itertools.combinations(init_permutation_i, r):\n",
    "                    if 0 not in subset and r != 1:\n",
    "                        continue\n",
    "                    for x in itertools.permutations(subset):\n",
    "                    num_permutations[batch_idx] += 1\n",
    "                    new_batch_data = []\n",
    "                    for col_i in x:\n",
    "                        if col_i == 0:\n",
    "                            if len(new_batch_data) == 0:\n",
    "                                cls_indexes_value = 0\n",
    "                            else:\n",
    "                                cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                        new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                    new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                    cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                    logits_temp = model(new_batch_data, cls_indexes=cls_indexes,)\n",
    "                    ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n",
    "                    score_permutation[batch_idx].append(ood_score_temp)\n",
    "                    predict_temp = logits_temp.argmax().item()\n",
    "                    permutation_correctness[batch_idx].append(predict_temp == label_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brute force perumate in validation TODO: restrict mamimus length of permutation\n",
    "import itertools\n",
    "import torch.nn.functional as F\n",
    "\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "for threshold in [1.5]:\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    log = defaultdict(list)\n",
    "    num_cols = []\n",
    "    corrected = 0\n",
    "    total_mistakes = 0\n",
    "    num_permutations = {}\n",
    "    init_permutation = {}\n",
    "    init_correctness = {}\n",
    "    score_init = {}\n",
    "    score_permutation = defaultdict(list)\n",
    "    permutation_correctness = defaultdict(list)\n",
    "    for batch_idx, batch in enumerate(valid_dataloader_iter):\n",
    "        cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "        target_col_mask = batch[\"target_col_mask\"].T\n",
    "        logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "        score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
    "        label_i = batch[\"label\"].item()\n",
    "        predict_init = logits.argmax().item()\n",
    "        init_permutation_i = get_permutation(target_col_mask)\n",
    "        init_permutation[batch_idx] = init_permutation_i\n",
    "        if predict_init == label_i:\n",
    "            init_correctness[batch_idx] = True\n",
    "        else:\n",
    "            init_correctness[batch_idx] = False\n",
    "        num_permutations[batch_idx] = 0\n",
    "        if 1 in target_col_mask:\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            assert -1 not in col_idx_set\n",
    "            for r in range(len(init_permutation_i), max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "                for x in itertools.combinations(init_permutation_i, r):\n",
    "                    if 0 not in x:\n",
    "                        continue\n",
    "\n",
    "                    num_permutations[batch_idx] += 1\n",
    "                    new_batch_data = []\n",
    "                    for col_i in x:\n",
    "                        if col_i == 0:\n",
    "                            if len(new_batch_data) == 0:\n",
    "                                cls_indexes_value = 0\n",
    "                            else:\n",
    "                                cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                        new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                    new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                    cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                    logits_temp = model(new_batch_data, cls_indexes=cls_indexes,)\n",
    "                    ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n",
    "                    score_permutation[batch_idx].append(ood_score_temp)\n",
    "                    predict_temp = logits_temp.argmax().item()\n",
    "                    permutation_correctness[batch_idx].append(predict_temp == label_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation_correctness_ratio = []\n",
    "score_permutation_avg = []\n",
    "for i in score_init:\n",
    "    permutation_correctness_ratio.append(np.mean(permutation_correctness[i]))\n",
    "    score_permutation_avg.append(np.mean(score_permutation[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(permutation_correctness_ratio)\n",
    "permutation_correctness_ratio = np.array(permutation_correctness_ratio)\n",
    "print(np.mean(permutation_correctness_ratio[~np.isnan(permutation_correctness_ratio)]), sum(permutation_correctness_ratio==1)/len(permutation_correctness_ratio), sum(permutation_correctness_ratio==0)/len(permutation_correctness_ratio), (sum(permutation_correctness_ratio==0)+sum(permutation_correctness_ratio==1))/len(permutation_correctness_ratio))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(labels_valid[permutation_correctness_ratio==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(labels_valid[permutation_correctness_ratio==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(labels_valid[(permutation_correctness_ratio==1)|(permutation_correctness_ratio==0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation_correctness_ratio.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_init = torch.tensor(list(score_init.values()))\n",
    "score_init.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation_correctness_ratio = torch.tensor(permutation_correctness_ratio)\n",
    "print(score_init[permutation_correctness_ratio==1].mean())\n",
    "False in torch.tensor(list(init_correctness.values()))[permutation_correctness_ratio==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(score_init[permutation_correctness_ratio==0].mean())\n",
    "True in torch.tensor(list(init_correctness.values()))[permutation_correctness_ratio==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_permutations_all = num_permutations.values()\n",
    "sns.histplot(num_permutations_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_permutations.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(num_permutations[i], len(init_permutation[i]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_correct_permutations = [sum(permutation_correctness[i]) for i in permutation_correctness]\n",
    "num_wrong_permutations = [len(permutation_correctness[i])-sum(permutation_correctness[i]) for i in permutation_correctness]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.median(num_correct_permutations))\n",
    "print(torch.tensor(num_correct_permutations).unique())\n",
    "sns.histplot(num_correct_permutations )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.median(num_wrong_permutations))\n",
    "sns.histplot(num_wrong_permutations )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(num_wrong_permutations).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, batch in enumerate(valid_dataloader_iter):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "            veri_data[batch_idx].append(new_batch_data.cpu())\n",
    "            veri_label[batch_idx].append(torch.tensor(predict_temp == label_i).long())\n",
    "            veri_cls_indexes[batch_idx].append(cls_indexes_value)\n",
    "            veri_embs[batch_idx].append(embs_temp.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1 in target_col_mask:\n",
    "    col_idx_set = target_col_mask.unique().tolist()\n",
    "    assert -1 not in col_idx_set\n",
    "    for r in range(len(init_permutation_i), max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "        for x in itertools.combinations(init_permutation_i, r):\n",
    "            if 0 not in x:\n",
    "                continue\n",
    "\n",
    "            num_permutations[batch_idx] += 1\n",
    "            new_batch_data = []\n",
    "            for col_i in x:\n",
    "                if col_i == 0:\n",
    "                    if len(new_batch_data) == 0:\n",
    "                        cls_indexes_value = 0\n",
    "                    else:\n",
    "                        cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "            new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "            cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "            logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "            logits_temp = logits_temp.detach().cpu()\n",
    "            ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n",
    "            score_permutation[batch_idx].append(ood_score_temp)\n",
    "            predict_temp = logits_temp.argmax().item()\n",
    "            permutation_correctness[batch_idx].append(predict_temp == label_i)\n",
    "            \n",
    "            # veri_data[batch_idx].append(new_batch_data.cpu())\n",
    "            # veri_label[batch_idx].append(torch.tensor(predict_temp == label_i).long())\n",
    "            # veri_cls_indexes[batch_idx].append(cls_indexes_value)\n",
    "            # veri_embs[batch_idx].append(embs_temp.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_iter[batch_idx][\"col_idx\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_iter[batch_idx][\"col_idx\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "train_dataset_iter = GittablesTablewiseIterateDataset(cv=cv,\n",
    "                            split=\"train\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only='all' not in task,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\",\n",
    "                            random_sample=True)\n",
    "\n",
    "for batch_idx, batch in enumerate(train_dataloader_iter):\n",
    "    \n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    init_permutation_i = get_permutation(target_col_mask)\n",
    "    if len(init_permutation_i) > 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_permutation_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brute force perumate in validation TODO: restrict mamimus length of permutation\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "import torch.nn.functional as F\n",
    "train_data = defaultdict(list)\n",
    "train_logits = defaultdict(list)\n",
    "train_cls_indexes = defaultdict(list)\n",
    "train_target_col_mask = defaultdict(list)\n",
    "train_embs = defaultdict(list)\n",
    "train_col_num = defaultdict(list)\n",
    "train_label = defaultdict(list)\n",
    "train_class = defaultdict(list)\n",
    "train_target_embs = defaultdict(list)\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "for threshold in [1.5]:\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    log = defaultdict(list)\n",
    "    num_cols = []\n",
    "    corrected = 0\n",
    "    total_mistakes = 0\n",
    "    num_permutations = {}\n",
    "    init_permutation = {}\n",
    "    init_correctness = {}\n",
    "    score_init = {}\n",
    "    score_permutation = defaultdict(list)\n",
    "    permutation_correctness = defaultdict(list)\n",
    "    with torch.no_grad():\n",
    "        # for batch_idx, batch in enumerate(train_dataloader_iter):\n",
    "        for batch_idx, batch in enumerate(train_dataloader_random):\n",
    "            cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "            target_col_mask = batch[\"target_col_mask\"].T\n",
    "            logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "            score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
    "            label_i = batch[\"label\"].item()\n",
    "            predict_init = logits.argmax().item()\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            init_permutation[batch_idx] = init_permutation_i\n",
    "            if predict_init == label_i:\n",
    "                init_correctness[batch_idx] = True\n",
    "            else:\n",
    "                init_correctness[batch_idx] = False\n",
    "            num_permutations[batch_idx] = 0\n",
    "\n",
    "            train_data[batch_idx].append(batch[\"data\"].T.cpu())\n",
    "            train_logits[batch_idx].append(logits.detach().cpu())\n",
    "            train_cls_indexes[batch_idx].append(batch[\"cls_indexes\"].cpu().item())\n",
    "            train_embs[batch_idx].append(embs.cpu())\n",
    "            train_col_num[batch_idx].append(len(init_permutation_i))\n",
    "            train_label[batch_idx].append(torch.tensor(predict_init == label_i).long()) # indicate whether the permutation is correct or not\n",
    "            train_class[batch_idx].append(label_i)\n",
    "\n",
    "\n",
    "            x = [0]\n",
    "            new_batch_data = []\n",
    "            for col_i in x:\n",
    "                if col_i == 0:\n",
    "                    if len(new_batch_data) == 0:\n",
    "                        cls_indexes_value = 0\n",
    "                    else:\n",
    "                        cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "            new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "            cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "            logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "            train_target_embs[batch_idx].append(embs_temp.cpu())\n",
    "\n",
    "            num_cols.append(len(init_permutation_i))\n",
    "            labels_test.append(batch[\"label\"].cpu().item())\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            assert -1 not in col_idx_set\n",
    "            for r in range(len(init_permutation_i)-1,  max(len(init_permutation_i)//2, len(init_permutation_i)-2) -1, -1): # not \n",
    "                for x in itertools.combinations(init_permutation_i, r):\n",
    "                    if 0 not in x:\n",
    "                        continue\n",
    "\n",
    "                    num_permutations[batch_idx] += 1\n",
    "                    new_batch_data = []\n",
    "                    for col_i in x:\n",
    "                        if col_i == 0:\n",
    "                            if len(new_batch_data) == 0:\n",
    "                                cls_indexes_value = 0\n",
    "                            else:\n",
    "                                cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                        new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                    new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                    cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                    logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                    ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n",
    "                    score_permutation[batch_idx].append(ood_score_temp)\n",
    "                    predict_temp = logits_temp.argmax().item()\n",
    "                    permutation_correctness[batch_idx].append(predict_temp == label_i)\n",
    "                    \n",
    "                    \n",
    "                    train_data[batch_idx].append(new_batch_data.cpu())\n",
    "                    train_logits[batch_idx].append(logits_temp.detach().cpu())\n",
    "                    train_cls_indexes[batch_idx].append(cls_indexes_value)\n",
    "                    train_embs[batch_idx].append(embs_temp.cpu())\n",
    "                    train_col_num[batch_idx].append(len(x))\n",
    "                    train_label[batch_idx].append(torch.tensor(predict_temp == label_i).long()) # indicate whether the permutation is correct or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_all = torch.cat([torch.tensor(train_label[i]) for i in train_label], dim=0)\n",
    "print(len(train_labels_all))\n",
    "train_labels_all.sum()/len(train_labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for threshold in [1.5]:\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    log = defaultdict(list)\n",
    "    num_cols = []\n",
    "    corrected = 0\n",
    "    total_mistakes = 0\n",
    "    num_permutations = {}\n",
    "    init_permutation = {}\n",
    "    init_correctness = {}\n",
    "    score_init = {}\n",
    "    score_permutation = defaultdict(list)\n",
    "    permutation_correctness = defaultdict(list)\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(train_dataloader_iter):\n",
    "            cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "            target_col_mask = batch[\"target_col_mask\"].T\n",
    "            logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "            score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
    "            label_i = batch[\"label\"].item()\n",
    "            predict_init = logits.argmax().item()\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            init_permutation[batch_idx] = init_permutation_i\n",
    "            if predict_init == label_i:\n",
    "                init_correctness[batch_idx] = True\n",
    "            else:\n",
    "                init_correctness[batch_idx] = False\n",
    "            num_permutations[batch_idx] = 0\n",
    "\n",
    "            train_data[batch_idx].append(batch[\"data\"].T.cpu())\n",
    "            train_logits[batch_idx].append(logits.detach().cpu())\n",
    "            train_cls_indexes[batch_idx].append(batch[\"cls_indexes\"].cpu().item())\n",
    "            train_embs[batch_idx].append(embs.cpu())\n",
    "            train_col_num[batch_idx].append(len(init_permutation_i))\n",
    "            train_label[batch_idx].append(torch.tensor(predict_init == label_i).long()) # indicate whether the permutation is correct or not\n",
    "            train_class[batch_idx].append(label_i)\n",
    "\n",
    "\n",
    "            x = [0]\n",
    "            new_batch_data = []\n",
    "            for col_i in x:\n",
    "                if col_i == 0:\n",
    "                    if len(new_batch_data) == 0:\n",
    "                        cls_indexes_value = 0\n",
    "                    else:\n",
    "                        cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "            new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "            cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "            logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "            train_target_embs[batch_idx].append(embs_temp.cpu())\n",
    "\n",
    "            num_cols.append(len(init_permutation_i))\n",
    "            labels_test.append(batch[\"label\"].cpu().item())\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            assert -1 not in col_idx_set\n",
    "            for r in range(max(len(init_permutation_i)//2, len(init_permutation_i)-2) -1, 1, -1): # not \n",
    "                for x in itertools.combinations(init_permutation_i, r):\n",
    "                    if 0 not in x:\n",
    "                        continue\n",
    "\n",
    "                    num_permutations[batch_idx] += 1\n",
    "                    new_batch_data = []\n",
    "                    for col_i in x:\n",
    "                        if col_i == 0:\n",
    "                            if len(new_batch_data) == 0:\n",
    "                                cls_indexes_value = 0\n",
    "                            else:\n",
    "                                cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                        new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                    new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                    cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                    logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                    ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n",
    "                    score_permutation[batch_idx].append(ood_score_temp)\n",
    "                    predict_temp = logits_temp.argmax().item()\n",
    "                    permutation_correctness[batch_idx].append(predict_temp == label_i)\n",
    "                    if predict_temp == label_i:\n",
    "                        continue\n",
    "                    \n",
    "                    train_data[batch_idx].append(new_batch_data.cpu())\n",
    "                    train_logits[batch_idx].append(logits_temp.detach().cpu())\n",
    "                    train_cls_indexes[batch_idx].append(cls_indexes_value)\n",
    "                    train_embs[batch_idx].append(embs_temp.cpu())\n",
    "                    train_col_num[batch_idx].append(len(x))\n",
    "                    train_label[batch_idx].append(torch.tensor(predict_temp == label_i).long()) # indicate whether the permutation is correct or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_all = torch.cat([torch.tensor(train_label[i]) for i in train_label], dim=0)\n",
    "print(len(train_labels_all))\n",
    "train_labels_all.sum()/len(train_labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brute force perumate in validation TODO: restrict mamimus length of permutation\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "import torch.nn.functional as F\n",
    "train_data = defaultdict(list)\n",
    "train_logits = defaultdict(list)\n",
    "train_cls_indexes = defaultdict(list)\n",
    "train_target_col_mask = defaultdict(list)\n",
    "train_embs = defaultdict(list)\n",
    "train_col_num = defaultdict(list)\n",
    "train_label = defaultdict(list)\n",
    "train_class = defaultdict(list)\n",
    "train_target_embs = defaultdict(list)\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "max_col_length = 3\n",
    "for threshold in [1.5]:\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    log = defaultdict(list)\n",
    "    num_cols = []\n",
    "    corrected = 0\n",
    "    total_mistakes = 0\n",
    "    num_permutations = {}\n",
    "    init_permutation = {}\n",
    "    init_correctness = {}\n",
    "    score_init = {}\n",
    "    score_permutation = defaultdict(list)\n",
    "    permutation_correctness = defaultdict(list)\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(train_dataloader_iter):\n",
    "            cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "            target_col_mask = batch[\"target_col_mask\"].T\n",
    "            logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "            score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
    "            label_i = batch[\"label\"].item()\n",
    "            predict_init = logits.argmax().item()\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            init_permutation[batch_idx] = init_permutation_i\n",
    "            if predict_init == label_i:\n",
    "                init_correctness[batch_idx] = True\n",
    "            else:\n",
    "                init_correctness[batch_idx] = False\n",
    "            num_permutations[batch_idx] = 0\n",
    "\n",
    "            train_data[batch_idx].append(batch[\"data\"].T.cpu())\n",
    "            train_logits[batch_idx].append(logits.detach().cpu())\n",
    "            train_cls_indexes[batch_idx].append(batch[\"cls_indexes\"].cpu().item())\n",
    "            train_embs[batch_idx].append(embs.cpu())\n",
    "            train_col_num[batch_idx].append(len(init_permutation_i))\n",
    "            train_label[batch_idx].append(torch.tensor(predict_init == label_i).long()) # indicate whether the permutation is correct or not\n",
    "            train_class[batch_idx].append(label_i)\n",
    "\n",
    "\n",
    "            x = [0]\n",
    "            new_batch_data = []\n",
    "            for col_i in x:\n",
    "                if col_i == 0:\n",
    "                    if len(new_batch_data) == 0:\n",
    "                        cls_indexes_value = 0\n",
    "                    else:\n",
    "                        cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "            new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "            cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "            logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "            train_target_embs[batch_idx].append(embs_temp.cpu())\n",
    "\n",
    "            num_cols.append(len(init_permutation_i))\n",
    "            labels_test.append(batch[\"label\"].cpu().item())\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            assert -1 not in col_idx_set\n",
    "            for r in range(1, min(len(col_idx_set), max_col_length) + 1):\n",
    "                for subset in itertools.combinations(col_idx_set, r):\n",
    "                    if 0 not in subset:\n",
    "                        continue\n",
    "                    for x in itertools.permutations(subset):\n",
    "                        num_permutations[batch_idx] += 1\n",
    "                        new_batch_data = []\n",
    "                        for col_i in x:\n",
    "                            if col_i == 0:\n",
    "                                if len(new_batch_data) == 0:\n",
    "                                    cls_indexes_value = 0\n",
    "                                else:\n",
    "                                    cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                            new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                        new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                        cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                        logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                        ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n",
    "                        score_permutation[batch_idx].append(ood_score_temp)\n",
    "                        predict_temp = logits_temp.argmax().item()\n",
    "                        permutation_correctness[batch_idx].append(predict_temp == label_i)\n",
    "                        if predict_temp == label_i:\n",
    "                            continue\n",
    "                        \n",
    "                        \n",
    "                        train_data[batch_idx].append(new_batch_data.cpu())\n",
    "                        train_logits[batch_idx].append(logits_temp.detach().cpu())\n",
    "                        train_cls_indexes[batch_idx].append(cls_indexes_value)\n",
    "                        train_embs[batch_idx].append(embs_temp.cpu())\n",
    "                        train_col_num[batch_idx].append(len(x))\n",
    "                        train_label[batch_idx].append(torch.tensor(predict_temp == label_i).long()) # indicate whether the permutation is correct or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_columns.iloc[:len(other_columns)//2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_columns.iloc[:len(other_columns)//2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v1: random once\n",
    "# v2: random all\n",
    "import os\n",
    "os.makedirs(\"/data/zhihao/TU/Watchog/trainfication\", exist_ok=True)\n",
    "torch.save({\"data\": train_data, \"label\": train_label, \"logits\": train_logits, \"cls_indexes\": train_cls_indexes, \"embs\": train_embs, \"target_embs\":train_target_embs , \"col_num\": train_col_num}, f\"/data/zhihao/TU/Watchog/trainfication/{args.task}_train_data_random2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brute force perumate in validation TODO: restrict mamimus length of permutation\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "import torch.nn.functional as F\n",
    "train_data = defaultdict(list)\n",
    "train_logits = defaultdict(list)\n",
    "train_cls_indexes = defaultdict(list)\n",
    "train_target_col_mask = defaultdict(list)\n",
    "train_embs = defaultdict(list)\n",
    "train_col_num = defaultdict(list)\n",
    "train_label = defaultdict(list)\n",
    "train_class = defaultdict(list)\n",
    "train_target_embs = defaultdict(list)\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "max_col_length = 3\n",
    "for threshold in [1.5]:\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    log = defaultdict(list)\n",
    "    num_cols = []\n",
    "    corrected = 0\n",
    "    total_mistakes = 0\n",
    "    num_permutations = {}\n",
    "    init_permutation = {}\n",
    "    init_correctness = {}\n",
    "    score_init = {}\n",
    "    score_permutation = defaultdict(list)\n",
    "    permutation_correctness = defaultdict(list)\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(train_dataloader_iter):\n",
    "            cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "            target_col_mask = batch[\"target_col_mask\"].T\n",
    "            logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "            score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
    "            label_i = batch[\"label\"].item()\n",
    "            predict_init = logits.argmax().item()\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            init_permutation[batch_idx] = init_permutation_i\n",
    "            if predict_init == label_i:\n",
    "                init_correctness[batch_idx] = True\n",
    "            else:\n",
    "                init_correctness[batch_idx] = False\n",
    "            num_permutations[batch_idx] = 0\n",
    "\n",
    "            train_data[batch_idx].append(batch[\"data\"].T.cpu())\n",
    "            train_logits[batch_idx].append(logits.detach().cpu())\n",
    "            train_cls_indexes[batch_idx].append(batch[\"cls_indexes\"].cpu().item())\n",
    "            train_embs[batch_idx].append(embs.cpu())\n",
    "            train_col_num[batch_idx].append(len(init_permutation_i))\n",
    "            train_label[batch_idx].append(torch.tensor(predict_init == label_i).long()) # indicate whether the permutation is correct or not\n",
    "            train_class[batch_idx].append(label_i)\n",
    "\n",
    "\n",
    "            x = [0]\n",
    "            new_batch_data = []\n",
    "            for col_i in x:\n",
    "                if col_i == 0:\n",
    "                    if len(new_batch_data) == 0:\n",
    "                        cls_indexes_value = 0\n",
    "                    else:\n",
    "                        cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "            new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "            cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "            logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "            train_target_embs[batch_idx].append(embs_temp.cpu())\n",
    "\n",
    "            num_cols.append(len(init_permutation_i))\n",
    "            labels_test.append(batch[\"label\"].cpu().item())\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            assert -1 not in col_idx_set\n",
    "            for r in range(1, min(len(col_idx_set), max_col_length) + 1):\n",
    "                for subset in itertools.combinations(col_idx_set, r):\n",
    "                    if 0 not in subset:\n",
    "                        continue\n",
    "                    for x in itertools.permutations(subset):\n",
    "                        num_permutations[batch_idx] += 1\n",
    "                        new_batch_data = []\n",
    "                        for col_i in x:\n",
    "                            if col_i == 0:\n",
    "                                if len(new_batch_data) == 0:\n",
    "                                    cls_indexes_value = 0\n",
    "                                else:\n",
    "                                    cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                            new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                        new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                        cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                        logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                        ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n",
    "                        score_permutation[batch_idx].append(ood_score_temp)\n",
    "                        predict_temp = logits_temp.argmax().item()\n",
    "                        permutation_correctness[batch_idx].append(predict_temp == label_i)\n",
    "\n",
    "                        \n",
    "                        \n",
    "                        train_data[batch_idx].append(new_batch_data.cpu())\n",
    "                        train_logits[batch_idx].append(logits_temp.detach().cpu())\n",
    "                        train_cls_indexes[batch_idx].append(cls_indexes_value)\n",
    "                        train_embs[batch_idx].append(embs_temp.cpu())\n",
    "                        train_col_num[batch_idx].append(len(x))\n",
    "                        train_label[batch_idx].append(torch.tensor(predict_temp == label_i).long()) # indicate whether the permutation is correct or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataloader_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_dataloader_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"/data/zhihao/TU/Watchog/trainfication\", exist_ok=True)\n",
    "torch.save({\"data\": train_data, \"label\": train_label, \"logits\": train_logits, \"cls_indexes\": train_cls_indexes, \"embs\": train_embs, \"target_embs\":train_target_embs , \"col_num\": train_col_num}, f\"/data/zhihao/TU/Watchog/trainfication/{args.task}_train_data_8.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = torch.load(\"/data/zhihao/TU/Watchog/trainfication/gt-semtab22-dbpedia-all0_train_data_random1.pth\")\n",
    "train_data = res[\"data\"]\n",
    "train_label = res[\"label\"]\n",
    "train_logits = res[\"logits\"]\n",
    "train_cls_indexes = res[\"cls_indexes\"]\n",
    "train_embs = res[\"embs\"]\n",
    "train_target_embs = res[\"target_embs\"]\n",
    "train_col_num = res[\"col_num\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V2\n",
    "train_labels_all = torch.cat([torch.tensor(train_label[i]) for i in train_label], dim=0)\n",
    "print(len(train_labels_all))\n",
    "train_labels_all.sum()/len(train_labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V8\n",
    "train_labels_all = torch.cat([torch.tensor(train_label[i]) for i in train_label], dim=0)\n",
    "print(len(train_labels_all))\n",
    "train_labels_all.sum()/len(train_labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V4\n",
    "train_labels_all = torch.cat([torch.tensor(train_label[i]) for i in train_label], dim=0)\n",
    "print(len(train_labels_all))\n",
    "train_labels_all.sum()/len(train_labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"/data/zhihao/TU/Watchog/verification\", exist_ok=True)\n",
    "# {args.task}_veri_data: min length: max(len(init_permutation_i)//2, len(init_permutation_i)-3)\n",
    "# {args.task}_veri_data_1: min length: for those without correct permutation, \n",
    "veri_results = torch.load( f\"/data/zhihao/TU/Watchog/verification/{args.task}_veri_data_3.pth\")\n",
    "veri_data = veri_results[\"data\"]\n",
    "veri_label = veri_results[\"label\"]\n",
    "veri_logits = veri_results[\"logits\"]\n",
    "veri_cls_indexes = veri_results[\"cls_indexes\"]\n",
    "veri_embs = veri_results[\"embs\"]\n",
    "veri_target_embs = veri_results[\"target_embs\"]\n",
    "veri_col_num = veri_results[\"col_num\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = len(train_data)\n",
    "for i in veri_data:\n",
    "    train_data[num_train+i] = veri_data[i]\n",
    "    train_label[num_train+i] = veri_label[i]\n",
    "    train_logits[num_train+i] = veri_logits[i]\n",
    "    train_cls_indexes[num_train+i] = veri_cls_indexes[i]\n",
    "    train_embs[num_train+i] = veri_embs[i]\n",
    "    train_target_embs[num_train+i] = veri_target_embs[i]\n",
    "    train_col_num[num_train+i] = veri_col_num[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(veri_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V0\n",
    "train_labels_all = torch.cat([torch.tensor(train_label[i]) for i in train_label], dim=0)\n",
    "print(len(train_labels_all))\n",
    "train_labels_all.sum()/len(train_labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V5\n",
    "train_labels_all = torch.cat([torch.tensor(train_label[i]) for i in train_label], dim=0)\n",
    "print(len(train_labels_all))\n",
    "train_labels_all.sum()/len(train_labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V3\n",
    "train_labels_all = torch.cat([torch.tensor(train_label[i]) for i in train_label], dim=0)\n",
    "print(len(train_labels_all))\n",
    "train_labels_all.sum()/len(train_labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# veri V5\n",
    "train_labels_all = torch.cat([torch.tensor(train_label[i]) for i in train_label], dim=0)\n",
    "print(len(train_labels_all))\n",
    "train_labels_all.sum()/len(train_labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_init_mask = []\n",
    "for i in train_label:\n",
    "    k = 0\n",
    "    for j in train_label[i]:\n",
    "        if k == 0:\n",
    "            train_init_mask.append(True)\n",
    "        else:\n",
    "            train_init_mask.append(False)\n",
    "        k += 1\n",
    "train_init_mask = torch.tensor(train_init_mask)\n",
    "train_labels_all[train_init_mask] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_init_idx = train_init_mask.nonzero().reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((train_labels_all==2).sum(), (train_labels_all==2).sum()/len(train_labels_all))\n",
    "print((train_labels_all==1).sum(), (train_labels_all==1).sum()/len(train_labels_all))\n",
    "print((train_labels_all==0).sum(), (train_labels_all==0).sum()/len(train_labels_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# veri V5\n",
    "train_embs_all = torch.cat([torch.stack(train_embs[i], dim=0) for i in train_embs], dim=0)\n",
    "print(train_embs_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4348"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# veri V5 init\n",
    "\n",
    "train_embs_all_init = torch.stack([train_embs[i][0] for i in train_embs], dim=0)\n",
    "print(train_embs_all_init.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_idx = torch.randperm(len(train_embs_all))[:1000]\n",
    "chosen_embs = train_embs_all[chosen_idx]\n",
    "chosen_labels = train_labels_all[chosen_idx]\n",
    "# umap \n",
    "import umap\n",
    "reducer = umap.UMAP()\n",
    "embedding = reducer.fit_transform(chosen_embs)\n",
    "chosen_colors = []\n",
    "for label in chosen_labels:\n",
    "    if label == 0:\n",
    "        chosen_colors.append(\"red\")\n",
    "    elif label == 1:\n",
    "        chosen_colors.append(\"blue\")\n",
    "    else:\n",
    "        chosen_colors.append(\"green\")\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1], c=chosen_colors, s=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_init_mask.nonzero().reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_idx = torch.randperm(len(train_embs_all))[:1000]\n",
    "chosen_init_idx = torch.randperm(len(train_init_idx))[:500]\n",
    "chosen_idx = torch.cat([chosen_idx, train_init_idx[chosen_init_idx]])\n",
    "chosen_embs = train_embs_all[chosen_idx]\n",
    "chosen_labels = train_labels_all[chosen_idx]\n",
    "# umap \n",
    "import umap\n",
    "reducer = umap.UMAP()\n",
    "embedding = reducer.fit_transform(chosen_embs)\n",
    "chosen_colors = []\n",
    "for label in chosen_labels:\n",
    "    if label == 0:\n",
    "        chosen_colors.append(\"red\")\n",
    "    elif label == 1:\n",
    "        chosen_colors.append(\"blue\")\n",
    "    else:\n",
    "        chosen_colors.append(\"green\")\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1], c=chosen_colors, s=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.makedirs(\"/data/zhihao/TU/Watchog/trainfication\", exist_ok=True)\n",
    "veri_results = torch.load( f\"/data/zhihao/TU/Watchog/verification/{args.task}_veri_data_4.pth\")\n",
    "veri_embs_4 = veri_results[\"embs\"]\n",
    "veri_label_4 = veri_results[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# veri V4\n",
    "veri_labels_all_4 = torch.cat([torch.tensor(veri_label_4[i]) for i in veri_label_4], dim=0)\n",
    "print(len(veri_labels_all_4))\n",
    "veri_labels_all_4.sum()/len(veri_labels_all_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# veri V4\n",
    "veri_embs_all_4 = torch.cat([torch.stack(veri_embs_4[i], dim=0) for i in veri_embs_4], dim=0)\n",
    "print(veri_embs_all_4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_idx = torch.randperm(len(veri_embs_all_4))[:1000]\n",
    "chosen_embs = veri_embs_all_4[chosen_idx]\n",
    "chosen_labels = veri_labels_all_4[chosen_idx]\n",
    "# umap \n",
    "import umap\n",
    "reducer = umap.UMAP()\n",
    "embedding = reducer.fit_transform(chosen_embs)\n",
    "chosen_colors = ['red' if label == 0 else 'blue' for label in chosen_labels]\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1], c=chosen_colors, s=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random train + random veri\n",
    "import os\n",
    "os.makedirs(f\"/data/zhihao/TU/Watchog/verification/{args.task}\", exist_ok=True)\n",
    "torch.save({\"data\": train_data, \"label\": train_label, \"logits\": train_logits, \"cls_indexes\": train_cls_indexes, \"embs\": train_embs, \"target_embs\":train_target_embs , \"col_num\": train_col_num}, f\"/data/zhihao/TU/Watchog/verification/{args.task}/random1_veri_data_0.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random train + cluster veri (all negs)\n",
    "import os\n",
    "os.makedirs(f\"/data/zhihao/TU/Watchog/verification/{args.task}\", exist_ok=True)\n",
    "torch.save({\"data\": train_data, \"label\": train_label, \"logits\": train_logits, \"cls_indexes\": train_cls_indexes, \"embs\": train_embs, \"target_embs\":train_target_embs , \"col_num\": train_col_num}, f\"/data/zhihao/TU/Watchog/verification/{args.task}/random1_veri_data_5.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random train + nearby veri (all negs)\n",
    "import os\n",
    "os.makedirs(f\"/data/zhihao/TU/Watchog/verification/{args.task}\", exist_ok=True)\n",
    "torch.save({\"data\": train_data, \"label\": train_label, \"logits\": train_logits, \"cls_indexes\": train_cls_indexes, \"embs\": train_embs, \"target_embs\":train_target_embs , \"col_num\": train_col_num}, f\"/data/zhihao/TU/Watchog/verification/{args.task}/random1_veri_data_1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random train + random iterate veri\n",
    "import os\n",
    "os.makedirs(f\"/data/zhihao/TU/Watchog/verification/{args.task}\", exist_ok=True)\n",
    "torch.save({\"data\": train_data, \"label\": train_label, \"logits\": train_logits, \"cls_indexes\": train_cls_indexes, \"embs\": train_embs, \"target_embs\":train_target_embs , \"col_num\": train_col_num}, f\"/data/zhihao/TU/Watchog/verification/{args.task}/random1_veri_data_2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random iterate train  + random iterate veri\n",
    "import os\n",
    "os.makedirs(f\"/data/zhihao/TU/Watchog/verification/{args.task}\", exist_ok=True)\n",
    "torch.save({\"data\": train_data, \"label\": train_label, \"logits\": train_logits, \"cls_indexes\": train_cls_indexes, \"embs\": train_embs, \"target_embs\":train_target_embs , \"col_num\": train_col_num}, f\"/data/zhihao/TU/Watchog/verification/{args.task}/random1_veri_data_3.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.randperm(len(train_labels_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V5\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "import torch.nn.functional as F\n",
    "veri_data = defaultdict(list)\n",
    "veri_logits = defaultdict(list)\n",
    "veri_cls_indexes = defaultdict(list)\n",
    "veri_target_col_mask = defaultdict(list)\n",
    "veri_embs = defaultdict(list)\n",
    "veri_target_embs = defaultdict(list)\n",
    "veri_col_num = defaultdict(list)\n",
    "veri_label = defaultdict(list)\n",
    "veri_class = defaultdict(list)\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "for threshold in [1.5]:\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    log = defaultdict(list)\n",
    "    num_cols = []\n",
    "    corrected = 0\n",
    "    total_mistakes = 0\n",
    "    num_permutations = {}\n",
    "    init_permutation = {}\n",
    "    init_correctness = {}\n",
    "    score_init = {}\n",
    "    score_permutation = defaultdict(list)\n",
    "    permutation_correctness = defaultdict(list)\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(valid_dataloader_cluster):\n",
    "            cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "            target_col_mask = batch[\"target_col_mask\"].T\n",
    "            logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "            score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
    "            label_i = batch[\"label\"].item()\n",
    "            predict_init = logits.argmax().item()\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            init_permutation[batch_idx] = init_permutation_i\n",
    "            if predict_init == label_i:\n",
    "                init_correctness[batch_idx] = True\n",
    "            else:\n",
    "                init_correctness[batch_idx] = False\n",
    "            num_permutations[batch_idx] = 0\n",
    "            \n",
    "            x = [0]\n",
    "            new_batch_data = []\n",
    "            for col_i in x:\n",
    "                if col_i == 0:\n",
    "                    if len(new_batch_data) == 0:\n",
    "                        cls_indexes_value = 0\n",
    "                    else:\n",
    "                        cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "            new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "            cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "            logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "            veri_target_embs[batch_idx].append(embs_temp.cpu())\n",
    "\n",
    "\n",
    "            num_cols.append(len(init_permutation_i))\n",
    "            labels_test.append(batch[\"label\"].cpu().item())\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            assert -1 not in col_idx_set\n",
    "            for r in range(len(init_permutation_i), 1, -1): # not \n",
    "                for x in itertools.combinations(init_permutation_i, r):\n",
    "                    if 0 not in x:\n",
    "                        continue\n",
    "\n",
    "                    num_permutations[batch_idx] += 1\n",
    "                    new_batch_data = []\n",
    "                    for col_i in x:\n",
    "                        if col_i == 0:\n",
    "                            if len(new_batch_data) == 0:\n",
    "                                cls_indexes_value = 0\n",
    "                            else:\n",
    "                                cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                        new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                    new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                    cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                    logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                    ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n",
    "                    score_permutation[batch_idx].append(ood_score_temp)\n",
    "                    predict_temp = logits_temp.argmax().item()\n",
    "                    permutation_correctness[batch_idx].append(predict_temp == label_i)\n",
    "                    # v3: add more neg examples\n",
    "                    if predict_temp == label_i and len(x) < max(len(init_permutation_i)//2, len(init_permutation_i)-2):\n",
    "                        continue\n",
    "                    \n",
    "                    veri_data[batch_idx].append(new_batch_data.cpu())\n",
    "                    veri_logits[batch_idx].append(logits_temp.detach().cpu())\n",
    "                    veri_cls_indexes[batch_idx].append(cls_indexes_value)\n",
    "                    veri_embs[batch_idx].append(embs_temp.cpu())\n",
    "                    veri_col_num[batch_idx].append(len(x))\n",
    "                    veri_label[batch_idx].append(torch.tensor(predict_temp == label_i).long()) # indicate whether the permutation is correct or not\n",
    "                    veri_class[batch_idx].append(label_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V2\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "import torch.nn.functional as F\n",
    "veri_data = defaultdict(list)\n",
    "veri_logits = defaultdict(list)\n",
    "veri_cls_indexes = defaultdict(list)\n",
    "veri_target_col_mask = defaultdict(list)\n",
    "veri_embs = defaultdict(list)\n",
    "veri_target_embs = defaultdict(list)\n",
    "veri_col_num = defaultdict(list)\n",
    "veri_label = defaultdict(list)\n",
    "veri_class = defaultdict(list)\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "for threshold in [1.5]:\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    log = defaultdict(list)\n",
    "    num_cols = []\n",
    "    corrected = 0\n",
    "    total_mistakes = 0\n",
    "    num_permutations = {}\n",
    "    init_permutation = {}\n",
    "    init_correctness = {}\n",
    "    score_init = {}\n",
    "    score_permutation = defaultdict(list)\n",
    "    permutation_correctness = defaultdict(list)\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(valid_dataloader_random):\n",
    "            cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "            target_col_mask = batch[\"target_col_mask\"].T\n",
    "            logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "            score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
    "            label_i = batch[\"label\"].item()\n",
    "            predict_init = logits.argmax().item()\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            init_permutation[batch_idx] = init_permutation_i\n",
    "            if predict_init == label_i:\n",
    "                init_correctness[batch_idx] = True\n",
    "            else:\n",
    "                init_correctness[batch_idx] = False\n",
    "            num_permutations[batch_idx] = 0\n",
    "            \n",
    "            x = [0]\n",
    "            new_batch_data = []\n",
    "            for col_i in x:\n",
    "                if col_i == 0:\n",
    "                    if len(new_batch_data) == 0:\n",
    "                        cls_indexes_value = 0\n",
    "                    else:\n",
    "                        cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "            new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "            cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "            logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "            veri_target_embs[batch_idx].append(embs_temp.cpu())\n",
    "\n",
    "\n",
    "            num_cols.append(len(init_permutation_i))\n",
    "            labels_test.append(batch[\"label\"].cpu().item())\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            assert -1 not in col_idx_set\n",
    "            for r in range(len(init_permutation_i), 1, -1): # not \n",
    "                for x in itertools.combinations(init_permutation_i, r):\n",
    "                    if 0 not in x:\n",
    "                        continue\n",
    "\n",
    "                    num_permutations[batch_idx] += 1\n",
    "                    new_batch_data = []\n",
    "                    for col_i in x:\n",
    "                        if col_i == 0:\n",
    "                            if len(new_batch_data) == 0:\n",
    "                                cls_indexes_value = 0\n",
    "                            else:\n",
    "                                cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                        new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                    new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                    cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                    logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                    ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n",
    "                    score_permutation[batch_idx].append(ood_score_temp)\n",
    "                    predict_temp = logits_temp.argmax().item()\n",
    "                    permutation_correctness[batch_idx].append(predict_temp == label_i)\n",
    "                    # v3: add more neg examples\n",
    "                    if predict_temp == label_i and len(x) < max(len(init_permutation_i)//2, len(init_permutation_i)-2):\n",
    "                        continue\n",
    "                    \n",
    "                    veri_data[batch_idx].append(new_batch_data.cpu())\n",
    "                    veri_logits[batch_idx].append(logits_temp.detach().cpu())\n",
    "                    veri_cls_indexes[batch_idx].append(cls_indexes_value)\n",
    "                    veri_embs[batch_idx].append(embs_temp.cpu())\n",
    "                    veri_col_num[batch_idx].append(len(x))\n",
    "                    veri_label[batch_idx].append(torch.tensor(predict_temp == label_i).long()) # indicate whether the permutation is correct or not\n",
    "                    veri_class[batch_idx].append(label_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V1: near valid\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "import torch.nn.functional as F\n",
    "veri_data = defaultdict(list)\n",
    "veri_logits = defaultdict(list)\n",
    "veri_cls_indexes = defaultdict(list)\n",
    "veri_target_col_mask = defaultdict(list)\n",
    "veri_embs = defaultdict(list)\n",
    "veri_target_embs = defaultdict(list)\n",
    "veri_col_num = defaultdict(list)\n",
    "veri_label = defaultdict(list)\n",
    "veri_class = defaultdict(list)\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "for threshold in [1.5]:\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    log = defaultdict(list)\n",
    "    num_cols = []\n",
    "    corrected = 0\n",
    "    total_mistakes = 0\n",
    "    num_permutations = {}\n",
    "    init_permutation = {}\n",
    "    init_correctness = {}\n",
    "    score_init = {}\n",
    "    score_permutation = defaultdict(list)\n",
    "    permutation_correctness = defaultdict(list)\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(valid_dataloader_near):\n",
    "            cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "            target_col_mask = batch[\"target_col_mask\"].T\n",
    "            logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "            score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
    "            label_i = batch[\"label\"].item()\n",
    "            predict_init = logits.argmax().item()\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            init_permutation[batch_idx] = init_permutation_i\n",
    "            if predict_init == label_i:\n",
    "                init_correctness[batch_idx] = True\n",
    "            else:\n",
    "                init_correctness[batch_idx] = False\n",
    "            num_permutations[batch_idx] = 0\n",
    "            \n",
    "            x = [0]\n",
    "            new_batch_data = []\n",
    "            for col_i in x:\n",
    "                if col_i == 0:\n",
    "                    if len(new_batch_data) == 0:\n",
    "                        cls_indexes_value = 0\n",
    "                    else:\n",
    "                        cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "            new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "            cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "            logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "            veri_target_embs[batch_idx].append(embs_temp.cpu())\n",
    "\n",
    "\n",
    "            num_cols.append(len(init_permutation_i))\n",
    "            labels_test.append(batch[\"label\"].cpu().item())\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            assert -1 not in col_idx_set\n",
    "            for r in range(len(init_permutation_i), 1, -1): # not \n",
    "                for x in itertools.combinations(init_permutation_i, r):\n",
    "                    if 0 not in x:\n",
    "                        continue\n",
    "\n",
    "                    num_permutations[batch_idx] += 1\n",
    "                    new_batch_data = []\n",
    "                    for col_i in x:\n",
    "                        if col_i == 0:\n",
    "                            if len(new_batch_data) == 0:\n",
    "                                cls_indexes_value = 0\n",
    "                            else:\n",
    "                                cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                        new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                    new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                    cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                    logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                    ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n",
    "                    score_permutation[batch_idx].append(ood_score_temp)\n",
    "                    predict_temp = logits_temp.argmax().item()\n",
    "                    permutation_correctness[batch_idx].append(predict_temp == label_i)\n",
    "                    # v3: add more neg examples\n",
    "                    if predict_temp == label_i and len(x) < max(len(init_permutation_i)//2, len(init_permutation_i)-2):\n",
    "                        continue\n",
    "                    \n",
    "                    veri_data[batch_idx].append(new_batch_data.cpu())\n",
    "                    veri_logits[batch_idx].append(logits_temp.detach().cpu())\n",
    "                    veri_cls_indexes[batch_idx].append(cls_indexes_value)\n",
    "                    veri_embs[batch_idx].append(embs_temp.cpu())\n",
    "                    veri_col_num[batch_idx].append(len(x))\n",
    "                    veri_label[batch_idx].append(torch.tensor(predict_temp == label_i).long()) # indicate whether the permutation is correct or not\n",
    "                    veri_class[batch_idx].append(label_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V1\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "import torch.nn.functional as F\n",
    "veri_data = defaultdict(list)\n",
    "veri_logits = defaultdict(list)\n",
    "veri_cls_indexes = defaultdict(list)\n",
    "veri_target_col_mask = defaultdict(list)\n",
    "veri_embs = defaultdict(list)\n",
    "veri_target_embs = defaultdict(list)\n",
    "veri_col_num = defaultdict(list)\n",
    "veri_label = defaultdict(list)\n",
    "veri_class = defaultdict(list)\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "for threshold in [1.5]:\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    log = defaultdict(list)\n",
    "    num_cols = []\n",
    "    corrected = 0\n",
    "    total_mistakes = 0\n",
    "    num_permutations = {}\n",
    "    init_permutation = {}\n",
    "    init_correctness = {}\n",
    "    score_init = {}\n",
    "    score_permutation = defaultdict(list)\n",
    "    permutation_correctness = defaultdict(list)\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(valid_dataloader_iter):\n",
    "            cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "            target_col_mask = batch[\"target_col_mask\"].T\n",
    "            logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "            score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
    "            label_i = batch[\"label\"].item()\n",
    "            predict_init = logits.argmax().item()\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            init_permutation[batch_idx] = init_permutation_i\n",
    "            if predict_init == label_i:\n",
    "                init_correctness[batch_idx] = True\n",
    "            else:\n",
    "                init_correctness[batch_idx] = False\n",
    "            num_permutations[batch_idx] = 0\n",
    "            \n",
    "            x = [0]\n",
    "            new_batch_data = []\n",
    "            for col_i in x:\n",
    "                if col_i == 0:\n",
    "                    if len(new_batch_data) == 0:\n",
    "                        cls_indexes_value = 0\n",
    "                    else:\n",
    "                        cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "            new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "            cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "            logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "            veri_target_embs[batch_idx].append(embs_temp.cpu())\n",
    "\n",
    "\n",
    "            num_cols.append(len(init_permutation_i))\n",
    "            labels_test.append(batch[\"label\"].cpu().item())\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            assert -1 not in col_idx_set\n",
    "            for r in range(len(init_permutation_i), 1, -1): # not \n",
    "                for x in itertools.combinations(init_permutation_i, r):\n",
    "                    if 0 not in x:\n",
    "                        continue\n",
    "\n",
    "                    num_permutations[batch_idx] += 1\n",
    "                    new_batch_data = []\n",
    "                    for col_i in x:\n",
    "                        if col_i == 0:\n",
    "                            if len(new_batch_data) == 0:\n",
    "                                cls_indexes_value = 0\n",
    "                            else:\n",
    "                                cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                        new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                    new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                    cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                    logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                    ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n",
    "                    score_permutation[batch_idx].append(ood_score_temp)\n",
    "                    predict_temp = logits_temp.argmax().item()\n",
    "                    permutation_correctness[batch_idx].append(predict_temp == label_i)\n",
    "                    # v3: add more neg examples\n",
    "                    if predict_temp == label_i and len(x) < max(len(init_permutation_i)//2, len(init_permutation_i)-2):\n",
    "                        continue\n",
    "                    \n",
    "                    veri_data[batch_idx].append(new_batch_data.cpu())\n",
    "                    veri_logits[batch_idx].append(logits_temp.detach().cpu())\n",
    "                    veri_cls_indexes[batch_idx].append(cls_indexes_value)\n",
    "                    veri_embs[batch_idx].append(embs_temp.cpu())\n",
    "                    veri_col_num[batch_idx].append(len(x))\n",
    "                    veri_label[batch_idx].append(torch.tensor(predict_temp == label_i).long()) # indicate whether the permutation is correct or not\n",
    "                    veri_class[batch_idx].append(label_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V0\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "import torch.nn.functional as F\n",
    "veri_data = defaultdict(list)\n",
    "veri_logits = defaultdict(list)\n",
    "veri_cls_indexes = defaultdict(list)\n",
    "veri_target_col_mask = defaultdict(list)\n",
    "veri_embs = defaultdict(list)\n",
    "veri_col_num = defaultdict(list)\n",
    "veri_label = defaultdict(list)\n",
    "veri_class = defaultdict(list)\n",
    "veri_target_embs = defaultdict(list)\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "for threshold in [1.5]:\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    log = defaultdict(list)\n",
    "    num_cols = []\n",
    "    corrected = 0\n",
    "    total_mistakes = 0\n",
    "    num_permutations = {}\n",
    "    init_permutation = {}\n",
    "    init_correctness = {}\n",
    "    score_init = {}\n",
    "    score_permutation = defaultdict(list)\n",
    "    permutation_correctness = defaultdict(list)\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(valid_dataloader_iter):\n",
    "            cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "            target_col_mask = batch[\"target_col_mask\"].T\n",
    "            logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "            score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
    "            label_i = batch[\"label\"].item()\n",
    "            predict_init = logits.argmax().item()\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            init_permutation[batch_idx] = init_permutation_i\n",
    "            if predict_init == label_i:\n",
    "                init_correctness[batch_idx] = True\n",
    "            else:\n",
    "                init_correctness[batch_idx] = False\n",
    "            num_permutations[batch_idx] = 0\n",
    "\n",
    "            x = [0]\n",
    "            new_batch_data = []\n",
    "            for col_i in x:\n",
    "                if col_i == 0:\n",
    "                    if len(new_batch_data) == 0:\n",
    "                        cls_indexes_value = 0\n",
    "                    else:\n",
    "                        cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "            new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "            cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "            logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "            veri_target_embs[batch_idx].append(embs_temp.cpu())\n",
    "\n",
    "            num_cols.append(len(init_permutation_i))\n",
    "            labels_test.append(batch[\"label\"].cpu().item())\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            assert -1 not in col_idx_set\n",
    "            for r in range(len(init_permutation_i), max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "                for x in itertools.combinations(init_permutation_i, r):\n",
    "                    if 0 not in x:\n",
    "                        continue\n",
    "\n",
    "                    num_permutations[batch_idx] += 1\n",
    "                    new_batch_data = []\n",
    "                    for col_i in x:\n",
    "                        if col_i == 0:\n",
    "                            if len(new_batch_data) == 0:\n",
    "                                cls_indexes_value = 0\n",
    "                            else:\n",
    "                                cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                        new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                    new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                    cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                    logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                    ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n",
    "                    score_permutation[batch_idx].append(ood_score_temp)\n",
    "                    predict_temp = logits_temp.argmax().item()\n",
    "                    permutation_correctness[batch_idx].append(predict_temp == label_i)\n",
    "                    \n",
    "                    veri_data[batch_idx].append(new_batch_data.cpu())\n",
    "                    veri_logits[batch_idx].append(logits_temp.detach().cpu())\n",
    "                    veri_cls_indexes[batch_idx].append(cls_indexes_value)\n",
    "                    veri_embs[batch_idx].append(embs_temp.cpu())\n",
    "                    veri_col_num[batch_idx].append(len(x))\n",
    "                    veri_label[batch_idx].append(torch.tensor(predict_temp == label_i).long()) # indicate whether the permutation is correct or not\n",
    "                    veri_class[batch_idx].append(label_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one single random\n",
    "veri_labels_all = torch.cat([torch.tensor(veri_label[i]) for i in veri_label], dim=0)\n",
    "print(len(veri_labels_all))\n",
    "veri_labels_all.sum()/len(veri_labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster + more negs\n",
    "veri_labels_all = torch.cat([torch.tensor(veri_label[i]) for i in veri_label], dim=0)\n",
    "print(len(veri_labels_all))\n",
    "veri_labels_all.sum()/len(veri_labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2\n",
    "veri_labels_all = torch.cat([torch.tensor(veri_label[i]) for i in veri_label], dim=0)\n",
    "print(len(veri_labels_all))\n",
    "veri_labels_all.sum()/len(veri_labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nearby + more negs\n",
    "veri_labels_all = torch.cat([torch.tensor(veri_label[i]) for i in veri_label], dim=0)\n",
    "print(len(veri_labels_all))\n",
    "veri_labels_all.sum()/len(veri_labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols_valid = []\n",
    "for i in range(len(valid_dataset_iter)):\n",
    "    num_cols_valid.append(valid_dataset_iter[i]['initial_num_col'])\n",
    "num_cols_valid = torch.tensor(num_cols_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(num_cols_valid>16).sum()/len(num_cols_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(num_cols_valid>12).sum()/len(num_cols_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(num_cols_valid>8).sum()/len(num_cols_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(num_cols_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop one column for column correlation\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "import torch.nn.functional as F\n",
    "veri_data = defaultdict(list)\n",
    "veri_logits = defaultdict(list)\n",
    "veri_cls_indexes = defaultdict(list)\n",
    "veri_target_col_mask = defaultdict(list)\n",
    "veri_embs = defaultdict(list)\n",
    "veri_col_num = defaultdict(list)\n",
    "veri_label = defaultdict(list)\n",
    "veri_class = defaultdict(list)\n",
    "veri_target_embs = defaultdict(list)\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "for threshold in [1.5]:\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    log = defaultdict(list)\n",
    "    num_cols = []\n",
    "    corrected = 0\n",
    "    total_mistakes = 0\n",
    "    num_permutations = {}\n",
    "    init_permutation = {}\n",
    "    init_correctness = {}\n",
    "    score_init = {}\n",
    "    score_permutation = defaultdict(list)\n",
    "    permutation_correctness = defaultdict(list)\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(valid_dataloader_iter):\n",
    "            cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "            target_col_mask = batch[\"target_col_mask\"].T\n",
    "            logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "            score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
    "            label_i = batch[\"label\"].item()\n",
    "            predict_init = logits.argmax().item()\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            init_permutation[batch_idx] = init_permutation_i\n",
    "            if predict_init == label_i:\n",
    "                init_correctness[batch_idx] = True\n",
    "            else:\n",
    "                init_correctness[batch_idx] = False\n",
    "            num_permutations[batch_idx] = 0\n",
    "\n",
    "            x = [0]\n",
    "            new_batch_data = []\n",
    "            for col_i in x:\n",
    "                if col_i == 0:\n",
    "                    if len(new_batch_data) == 0:\n",
    "                        cls_indexes_value = 0\n",
    "                    else:\n",
    "                        cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "            new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "            cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "            logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "            veri_target_embs[batch_idx].append(embs_temp.cpu())\n",
    "\n",
    "            num_cols.append(len(init_permutation_i))\n",
    "            labels_test.append(batch[\"label\"].cpu().item())\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            assert -1 not in col_idx_set\n",
    "            for r in range(len(init_permutation_i), len(init_permutation_i)-2, -1): # not \n",
    "                for x in itertools.combinations(init_permutation_i, r):\n",
    "                    if 0 not in x:\n",
    "                        continue\n",
    "\n",
    "                    num_permutations[batch_idx] += 1\n",
    "                    new_batch_data = []\n",
    "                    for col_i in x:\n",
    "                        if col_i == 0:\n",
    "                            if len(new_batch_data) == 0:\n",
    "                                cls_indexes_value = 0\n",
    "                            else:\n",
    "                                cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                        new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                    new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                    cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                    logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                    ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n",
    "                    score_permutation[batch_idx].append(ood_score_temp)\n",
    "                    predict_temp = logits_temp.argmax().item()\n",
    "                    permutation_correctness[batch_idx].append(predict_temp == label_i)\n",
    "                    \n",
    "                    veri_data[batch_idx].append(new_batch_data.cpu())\n",
    "                    veri_logits[batch_idx].append(logits_temp.detach().cpu())\n",
    "                    veri_cls_indexes[batch_idx].append(cls_indexes_value)\n",
    "                    veri_embs[batch_idx].append(embs_temp.cpu())\n",
    "                    veri_col_num[batch_idx].append(len(x))\n",
    "                    if predict_init != label_i and predict_temp == label_i:\n",
    "                        veri_label[batch_idx].append(torch.tensor(1).long())\n",
    "                    elif predict_init == label_i and predict_temp != label_i:\n",
    "                        veri_label[batch_idx].append(torch.tensor(0).long())\n",
    "                    elif predict_init == label_i and predict_temp == label_i:\n",
    "                        veri_label[batch_idx].append(torch.tensor(2).long())\n",
    "                    else:\n",
    "                        veri_label[batch_idx].append(torch.tensor(3).long())\n",
    "                    veri_class[batch_idx].append(label_i)\n",
    "            assert len(veri_label[batch_idx]) == len(init_permutation_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"/data/zhihao/TU/Watchog/verification\", exist_ok=True)\n",
    "torch.save({\"data\": veri_data, \"label\": veri_label, \"logits\": veri_logits, \"cls_indexes\": veri_cls_indexes, \"embs\": veri_embs, \"target_embs\":veri_target_embs , \"col_num\": veri_col_num}, f\"/data/zhihao/TU/Watchog/verification/{args.task}_veri_drop_data_0.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for veri_i in veri_label:\n",
    "    context_embs = veri_embs[veri_i][0].reshape(-1)\n",
    "    for veri_j in range(1, len(veri_label[veri_i])):\n",
    "        if label_version == 0:\n",
    "            if veri_label[veri_i][veri_j] != 0 or veri_label[veri_i][veri_j-1] != 1:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "veri_labels_all = torch.cat([torch.tensor(veri_label[i]) for i in veri_label], dim=0)\n",
    "print(len(veri_labels_all))\n",
    "for i in range(4):\n",
    "    print((veri_labels_all==i).sum(), (veri_labels_all==i).sum()/len(veri_labels_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "veri_labels_all = torch.cat([torch.tensor(veri_label[i])[1:] for i in veri_label], dim=0)\n",
    "print(len(veri_labels_all))\n",
    "for i in range(4):\n",
    "    print((veri_labels_all==i).sum(), (veri_labels_all==i).sum()/len(veri_labels_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "        self.pos_iter[anchor_idx] = iter(self.veri_pos_embs[anchor_idx])\n",
    "        self.neg_iter[anchor_idx] = iter(self.veri_neg_embs[anchor_idx])\n",
    "        # Shuffle for randomness\n",
    "        random.shuffle(self.pos_embeddings[anchor_idx])\n",
    "        random.shuffle(self.neg_embeddings[anchor_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"/data/zhihao/TU/Watchog/verification\", exist_ok=True)\n",
    "torch.save({\"data\": veri_data, \"label\": veri_label, \"logits\": veri_logits, \"cls_indexes\": veri_cls_indexes, \"embs\": veri_embs, \"target_embs\":veri_target_embs , \"col_num\": veri_col_num}, f\"/data/zhihao/TU/Watchog/verification/{args.task}_veri_data.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = torch.load(f\"/data/zhihao/TU/Watchog/verification/SOTAB_veri_data.pth\")\n",
    "veri_label_sotab = res[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "veri_label_sotab_all = []\n",
    "for i in veri_label_sotab:\n",
    "    veri_label_sotab_all += veri_label_sotab[i]\n",
    "veri_label_sotab_all = torch.tensor(veri_label_sotab_all).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(veri_label_sotab_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veri_label_sotab_all.sum()/len(veri_label_sotab_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = torch.load(f\"/data/zhihao/TU/Watchog/verification/{args.task}_veri_data.pth\")\n",
    "veri_label_old = res[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = torch.load(f\"/data/zhihao/TU/Watchog/verification/{args.task}_veri_data_1.pth\")\n",
    "veri_label_1 = res1[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "veri_label_old_all = []\n",
    "for i in veri_label_old:\n",
    "    veri_label_old_all += veri_label_old[i]\n",
    "veri_label_old_all = torch.tensor(veri_label_old_all).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "veri_label_1_all = []\n",
    "for i in veri_label_1:\n",
    "    veri_label_1_all += veri_label_1[i]\n",
    "veri_label_1_all = torch.tensor(veri_label_1_all).reshape(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(veri_label_old_all))\n",
    "print(veri_label_old_all.sum()/len(veri_label_old_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(veri_label_1_all))\n",
    "print(veri_label_1_all.sum()/len(veri_label_1_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def veri_collate_fn(pad_token_id, binary=False):\n",
    "    '''padder for input batch'''\n",
    "    \n",
    "    def padder(samples):    \n",
    "        batch = {}\n",
    "        if \"embs\" in samples[0]:\n",
    "            embs = torch.stack([sample[\"embs\"] for sample in samples], dim=0)\n",
    "            batch[\"embs\"] = embs\n",
    "        \n",
    "        if \"data\" in samples[0]:\n",
    "            data = []\n",
    "            for sample in samples:\n",
    "                data.extend(sample[\"data\"])\n",
    "            data =torch.nn.utils.rnn.pad_sequence(\n",
    "                data, padding_value=pad_token_id)\n",
    "            batch[\"data\"] = data\n",
    "        if \"label\" in samples[0]:\n",
    "            label = torch.cat([sample[\"label\"] for sample in samples], dim=-1)\n",
    "            batch[\"label\"] = label\n",
    "        if \"cls_indexes\" in samples[0]:\n",
    "            i = 0\n",
    "            cls_indexes = []\n",
    "            for sample in samples:\n",
    "                for value in sample[\"cls_indexes\"]:\n",
    "                    cls_indexes.append(torch.tensor([i, value]))\n",
    "                    i += 1\n",
    "            cls_indexes = torch.stack(cls_indexes, dim=0).long()\n",
    "            batch[\"cls_indexes\"] = cls_indexes\n",
    "        return batch\n",
    "    \n",
    "    def padder_binary(samples):   \n",
    "\n",
    "        label = torch.cat([sample[\"label\"] for sample in samples], dim=-1)\n",
    "        batch = {\"label\": label}\n",
    "        if  \"data\" in samples[0]:\n",
    "            data = torch.nn.utils.rnn.pad_sequence(\n",
    "                [sample[\"data\"] for sample in samples], padding_value=pad_token_id)\n",
    "            batch[\"data\"] = data\n",
    "        if \"cls_indexes\" in samples[0]:\n",
    "            i = 0\n",
    "            cls_indexes = []\n",
    "            for sample in samples:\n",
    "                value =  sample[\"cls_indexes\"]\n",
    "                cls_indexes.append(torch.tensor([i, value]))\n",
    "                i += 1\n",
    "            cls_indexes = torch.stack(cls_indexes, dim=0).long()\n",
    "            batch[\"cls_indexes\"] = cls_indexes\n",
    "        if \"embs\" in samples[0]:\n",
    "            embs = torch.stack([sample[\"embs\"] for sample in samples], dim=0)\n",
    "            batch[\"embs\"] = embs\n",
    "        if \"logits\" in samples[0]:\n",
    "            logits = torch.stack([sample[\"logits\"] for sample in samples], dim=0)\n",
    "            batch[\"logits\"] = logits\n",
    "        return batch\n",
    "    if binary:\n",
    "        return padder_binary\n",
    "    else:\n",
    "        return padder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VerificationCompareDataset(data.Dataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            data_path: str = \"/data/zhihao/TU/Watchog/verification/gt-semtab22-dbpedia-all0_veri_data.pth\",\n",
    "            pos_ratio = None, # clone the negative samples\n",
    "            context = None,\n",
    "            ): \n",
    "        \n",
    "        self.num_neg = int((1-pos_ratio)/pos_ratio)\n",
    "        self.context = context\n",
    "        \n",
    "        data_raw = torch.load(data_path)\n",
    "        veri_label = data_raw[\"label\"]\n",
    "        veri_data = data_raw[\"data\"]\n",
    "        veri_cls_indexes = data_raw[\"cls_indexes\"]\n",
    "        veri_embs = data_raw[\"embs\"]\n",
    "        veri_target_embs = data_raw[\"target_embs\"]\n",
    "        veri_logits = data_raw[\"logits\"]\n",
    "        \n",
    "        \n",
    "        self.veri_pos_embs = defaultdict(list)\n",
    "        self.veri_neg_embs = defaultdict(list)\n",
    "        self.veri_anchor_embs = defaultdict(list)\n",
    "        \n",
    "        # self.veri_label = {}\n",
    "        # self.veri_logits = {}\n",
    "        # self.veri_cls_indexes = {}\n",
    "        # self.veri_logits = {}\n",
    "        i = 0\n",
    "        for veri_i in veri_label:\n",
    "            if 1 not in veri_label[veri_i] or 0 not in veri_label[veri_i]:\n",
    "                continue\n",
    "            # save anchor emb\n",
    "            if context is None or context == \"None\" or context == \"init\":\n",
    "                self.veri_anchor_embs[i].append(veri_embs[veri_i][0])\n",
    "            elif context == \"target\":\n",
    "                self.veri_anchor_embs[i].append(veri_target_embs[veri_i][0])        \n",
    "            else:\n",
    "                raise ValueError(\"context {} is not supported\".format(context))\n",
    "            # save pos and neg embs\n",
    "            for veri_j in range(len(veri_label[veri_i])):\n",
    "                if veri_label[veri_i][veri_j] == 1:\n",
    "                    self.veri_pos_embs[i].append(veri_embs[veri_i][veri_j])\n",
    "                else:\n",
    "                    self.veri_neg_embs[i].append(veri_embs[veri_i][veri_j])\n",
    "            i += 1\n",
    "\n",
    "        # Maintain the iteration state for each anchor\n",
    "        self.pos_iter = {anchor_idx: iter(pos_embs) for anchor_idx, pos_embs in self.veri_pos_embs.items()}\n",
    "        self.neg_iter = {anchor_idx: iter(neg_embs) for anchor_idx, neg_embs in self.veri_neg_embs.items()}\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.veri_anchor_embs)\n",
    "\n",
    "    def reset_iterators(self, anchor_idx, type=\"pos\"):\n",
    "        \"\"\"Reset the iterator for the given anchor when all positives or negatives are iterated through.\"\"\"\n",
    "        if type == \"pos\":\n",
    "            self.pos_iter[anchor_idx] = iter(self.veri_pos_embs[anchor_idx])\n",
    "            random.shuffle(self.veri_pos_embs[anchor_idx])\n",
    "        else:\n",
    "            self.neg_iter[anchor_idx] = iter(self.veri_neg_embs[anchor_idx])\n",
    "            random.shuffle(self.veri_neg_embs[anchor_idx])\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        anchor_emb = self.veri_anchor_embs[idx]\n",
    "\n",
    "        # Get one positive embedding\n",
    "        try:\n",
    "            pos_emb = next(self.pos_iter[idx])\n",
    "        except StopIteration:\n",
    "            # If we've exhausted all positives, reset and shuffle\n",
    "            self.reset_iterators(idx, type=\"pos\")\n",
    "            pos_emb = next(self.pos_iter[idx])\n",
    "\n",
    "        # Get N negative embeddings\n",
    "        neg_embs = []\n",
    "        for _ in range(self.num_neg):\n",
    "            try:\n",
    "                neg_emb = next(self.neg_iter[idx])\n",
    "                neg_embs.append(neg_emb)\n",
    "            except StopIteration:\n",
    "                # If we've exhausted all negatives, reset and shuffle\n",
    "                self.reset_iterators(idx, type=\"neg\")\n",
    "                neg_emb = next(self.neg_iter[idx])\n",
    "                neg_embs.append(neg_emb)\n",
    "        if self.context is None or self.context == \"None\":\n",
    "            embs = [pos_emb] + neg_embs\n",
    "        else:\n",
    "            embs = [anchor_emb, pos_emb] + neg_embs\n",
    "        embs = torch.stack(embs, dim=0)\n",
    "        \n",
    "        \n",
    "        \n",
    "        return {\n",
    "            # \"data\": self.veri_data[idx].reshape(-1),\n",
    "            \"embs\": embs,\n",
    "            # \"label\": self.veri_label[idx],\n",
    "            # \"logits\": self.veri_logits[idx],\n",
    "            # \"cls_indexes\": self.veri_cls_indexes[idx], \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_comp = VerificationCompareDataset(pos_ratio=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "veri_comp_padder = veri_collate_fn(0)\n",
    "veri_comp_dataloader = data.DataLoader(\n",
    "    dataset_comp, batch_size=5, shuffle=True, num_workers=4, collate_fn=veri_comp_padder\n",
    ")\n",
    "num = 0\n",
    "for batch_idx, batch in enumerate(veri_comp_dataloader):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[\"embs\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = nn.MultiheadAttention(embed_dim=128, num_heads=2, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = torch.randn(32, 2, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = torch.randn(32, 1, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = attention(q, embs, embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = ffn(batch[\"embs\"])\n",
    "pos_scores, neg_scores = scores[:, 0], scores[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "margin = 0.1\n",
    "loss = torch.clamp(pos_scores - neg_scores + margin, min=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_comp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "labels_test = []\n",
    "for batch in veri_class:\n",
    "    labels_test.append(batch[0])\n",
    "sns.histplot(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, test_counts = np.unique(labels_test, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, veri_counts = np.unique(labels_all, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max(test_counts)/min(test_counts), )\n",
    "veri_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "labels_all = []\n",
    "for batch in veri_class:\n",
    "    for label in veri_class[batch]:\n",
    "        labels_all.append(label)\n",
    "sns.histplot(labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs_temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_batch_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_indexes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[\"data\"].T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in veri_data:\n",
    "    assert len(veri_data[i]) == len(veri_label[i]) == len(veri_cls_indexes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_drop_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brute force perumate in validation TODO: restrict mamimus length of permutation\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "import torch.nn.functional as F\n",
    "test_data = defaultdict(list)\n",
    "test_logits = defaultdict(list)\n",
    "test_cls_indexes = defaultdict(list)\n",
    "test_target_col_mask = defaultdict(list)\n",
    "test_embs = defaultdict(list)\n",
    "test_col_num = defaultdict(list)\n",
    "test_label = defaultdict(list)\n",
    "test_class = defaultdict(list)\n",
    "test_target_embs = defaultdict(list)\n",
    "test_drop_idx = defaultdict(list)\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "for threshold in [1.5]:\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    log = defaultdict(list)\n",
    "    num_cols = []\n",
    "    corrected = 0\n",
    "    total_mistakes = 0\n",
    "    num_permutations = {}\n",
    "    init_permutation = {}\n",
    "    init_correctness = {}\n",
    "    score_init = {}\n",
    "    score_permutation = defaultdict(list)\n",
    "    permutation_correctness = defaultdict(list)\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(test_dataloader_cluster):\n",
    "            cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "            target_col_mask = batch[\"target_col_mask\"].T\n",
    "            logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "            score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
    "            label_i = batch[\"label\"].item()\n",
    "            predict_init = logits.argmax().item()\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            init_permutation[batch_idx] = init_permutation_i\n",
    "            if predict_init == label_i:\n",
    "                init_correctness[batch_idx] = True\n",
    "            else:\n",
    "                init_correctness[batch_idx] = False\n",
    "            num_permutations[batch_idx] = 0\n",
    "\n",
    "\n",
    "            x = [0]\n",
    "            new_batch_data = []\n",
    "            for col_i in x:\n",
    "                if col_i == 0:\n",
    "                    if len(new_batch_data) == 0:\n",
    "                        cls_indexes_value = 0\n",
    "                    else:\n",
    "                        cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "            new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "            cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "            logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "            test_target_embs[batch_idx].append(embs_temp.cpu())\n",
    "\n",
    "\n",
    "            num_cols.append(len(init_permutation_i))\n",
    "            labels_test.append(batch[\"label\"].cpu())\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            assert -1 not in col_idx_set\n",
    "            for r in range(len(init_permutation_i), len(init_permutation_i)-2, -1): # not \n",
    "                for x in itertools.combinations(init_permutation_i, r):\n",
    "                    if 0 not in x:\n",
    "                        continue\n",
    "\n",
    "                    num_permutations[batch_idx] += 1\n",
    "                    new_batch_data = []\n",
    "                    if len(x) != len(init_permutation_i):\n",
    "                        drop_idx = (set(init_permutation_i)-set(x)).pop()\n",
    "                    else:\n",
    "                        drop_idx = -1\n",
    "                    for col_i in x:\n",
    "                        if col_i == 0:\n",
    "                            if len(new_batch_data) == 0:\n",
    "                                cls_indexes_value = 0\n",
    "                            else:\n",
    "                                cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                        new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                    new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                    cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                    logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                    ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n",
    "                    score_permutation[batch_idx].append(ood_score_temp)\n",
    "                    predict_temp = logits_temp.argmax().item()\n",
    "                    permutation_correctness[batch_idx].append(predict_temp == label_i)\n",
    "                    \n",
    "                    test_data[batch_idx].append(new_batch_data.cpu())\n",
    "                    test_logits[batch_idx].append(logits_temp.detach().cpu())\n",
    "                    test_cls_indexes[batch_idx].append(cls_indexes_value)\n",
    "                    test_embs[batch_idx].append(embs_temp.cpu())\n",
    "                    test_col_num[batch_idx].append(len(x))\n",
    "                    test_label[batch_idx].append(torch.tensor(predict_temp == label_i).long()) # indicate whether the permutation is correct or not\n",
    "                    test_class[batch_idx].append(label_i)\n",
    "                    test_drop_idx[batch_idx].append(drop_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"/data/zhihao/TU/Watchog/verification\", exist_ok=True)\n",
    "torch.save({\"data\": test_data, \"logits\": test_logits, \"cls_indexes\": test_cls_indexes, \n",
    "            \"embs\": test_embs, \"target_embs\":test_target_embs, \"col_num\": test_col_num, \"label\": test_label, \"class\": test_class}, f\"/data/zhihao/TU/Watchog/verification/{args.task}/random1_test_data_0.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_veri = torch.load(f\"/data/zhihao/TU/Watchog/verification/{args.task}_test_data.pth\")\n",
    "test_data = test_veri[\"data\"]\n",
    "test_logits = test_veri[\"logits\"]\n",
    "test_cls_indexes = test_veri[\"cls_indexes\"]\n",
    "test_embs = test_veri[\"embs\"]\n",
    "test_col_num = test_veri[\"col_num\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_col_num[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test = []\n",
    "logits_test = []\n",
    "col_scores = defaultdict(list)\n",
    "verifier = Verifier(norm=\"batch_norm\").to(device)\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "        embs = test_embs[batch_idx][0].reshape(-1).to(device)\n",
    "        logits = test_logits[batch_idx][0].reshape(-1).to(device)\n",
    "        # scores_init = verifier(embs)\n",
    "        max_score = -float(\"inf\")\n",
    "        target_col_mask = batch[\"target_col_mask\"].T\n",
    "        init_permutation_i = get_permutation(target_col_mask)\n",
    "        num_cols_to_drop = min(2, len(init_permutation_i)//2)\n",
    "        if len(init_permutation_i) ==1:\n",
    "            labels_test.append(batch[\"label\"].cpu())\n",
    "            logits_test.append(logits.detach().cpu())\n",
    "            continue\n",
    "        \n",
    "        for i in range(1, len(test_embs[batch_idx])):\n",
    "            logits_temp = test_logits[batch_idx][i].reshape(-1).to(device)\n",
    "            embs_temp = test_embs[batch_idx][i].reshape(-1).to(device)\n",
    "\n",
    "            scores_temp = np.random.rand()\n",
    "            predict_temp = logits_temp.argmax().item()\n",
    "            col_scores[batch_idx].append(scores_temp)\n",
    "            \n",
    "            \n",
    "        cols_to_drop = torch.tensor(col_scores[batch_idx]).argsort()[:num_cols_to_drop]\n",
    "        x = deepcopy(init_permutation_i)\n",
    "        for col_i in cols_to_drop:\n",
    "            x.remove(col_i)\n",
    "        new_batch_data = []\n",
    "        if len(x) != len(init_permutation_i):\n",
    "            drop_idx = (set(init_permutation_i)-set(x)).pop()\n",
    "        else:\n",
    "            drop_idx = -1\n",
    "        for col_i in x:\n",
    "            if col_i == 0:\n",
    "                if len(new_batch_data) == 0:\n",
    "                    cls_indexes_value = 0\n",
    "                else:\n",
    "                    cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "            new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "        new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "        cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "        logits_topk, embs_topk = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "        if len(init_permutation_i) > 4: \n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test = []\n",
    "logits_test = []\n",
    "col_scores = defaultdict(list)\n",
    "verifier = Verifier(norm=\"batch_norm\").to(device)\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "        embs = test_embs[batch_idx][0].reshape(-1).to(device)\n",
    "        logits = test_logits[batch_idx][0].reshape(-1).to(device)\n",
    "        ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "        logits_test.append(logits.detach().cpu())\n",
    "        labels_test.append(batch[\"label\"].cpu())\n",
    "    labels_test = torch.cat(labels_test, dim=0)\n",
    "    logits_test = torch.stack(logits_test, dim=0)\n",
    "    preds_test = torch.argmax(logits_test, dim=1)\n",
    "    num_cols = torch.tensor(num_cols)\n",
    "    ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "    from sklearn.metrics import confusion_matrix, f1_score\n",
    "    mask = num_cols > 0\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach().numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    full_f1_init = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=None)\n",
    "    print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_permutation_i = torch.tensor(init_permutation_i)\n",
    "init_permutation_i[init_permutation_i!=0][:num_cols_to_drop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(col_scores[batch_idx]).argsort(descending=True)[: ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(col_scores[batch_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(init_permutation_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_idx = (set(init_permutation_i)-set(x)).pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"/data/zhihao/TU/Watchog/verification\", exist_ok=True)\n",
    "torch.save({\"data\": test_data, \"logits\": test_logits, \"cls_indexes\": test_cls_indexes, \n",
    "            \"embs\": test_embs, \"target_embs\":test_target_embs, \"col_num\": test_col_num, \"label\": test_label, \"class\": test_class}, f\"/data/zhihao/TU/Watchog/verification/{args.task}_test_data_2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, r in enumerate(test_dataloader_iter):\n",
    "    try:\n",
    "        res = test_embs[i][0]\n",
    "    except:\n",
    "        print(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = torch.load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = []\n",
    "for i in veri_label:\n",
    "    all_labels.extend(veri_label[i])\n",
    "all_labels = torch.tensor(all_labels).reshape(-1)\n",
    "all_labels.sum()/len(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veri_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VerificationDataset(data.Dataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            data_path: str = \"/data/zhihao/TU/Watchog/verification/veri_data.pth\",\n",
    "            max_list_length: int = 10,\n",
    "            pos_ratio : int = 0.5, # None: only control pos_ratio to be less than 0.5\n",
    "            label_padding_value: int = -1,\n",
    "            data_padding_value: int = 0,\n",
    "            ): \n",
    "        data_raw = torch.load(data_path)\n",
    "        veri_label = data_raw[\"label\"]\n",
    "        veri_data = data_raw[\"data\"]\n",
    "        veri_cls_indexes = data_raw[\"cls_indexes\"]\n",
    "        self.label_padding_value = label_padding_value\n",
    "        self.data_padding_value = data_padding_value\n",
    "        self.max_list_length = max_list_length\n",
    "        self.pos_ratio = pos_ratio\n",
    "        self.veri_label = {}\n",
    "        self.veri_data = {}\n",
    "        self.veri_cls_indexes = {}\n",
    "        i = 0\n",
    "        for veri_i in veri_label:\n",
    "            labels_i = torch.tensor(veri_label[veri_i]).reshape(-1)\n",
    "            \n",
    "            if 0 not in labels_i or 1 not in labels_i:\n",
    "                continue\n",
    "            self.veri_data[i] = veri_data[veri_i]\n",
    "            self.veri_label[i] = labels_i\n",
    "            self.veri_cls_indexes[i] = veri_cls_indexes[veri_i]\n",
    "            i += 1\n",
    "    def sample(self, labels):\n",
    "        labels = labels.tolist()  # Convert tensor to list for easier manipulation\n",
    "        positive_indices = [i for i, label in enumerate(labels) if label == 1]\n",
    "        negative_indices = [i for i, label in enumerate(labels) if label == 0]\n",
    "\n",
    "        # Determine how many positives we can sample, respecting the ratio requirement\n",
    "        max_num_positives = max_num_negatives = min(len(positive_indices), len(negative_indices), self.max_list_length // 2)\n",
    "        \n",
    "        # Randomly sample the positives and negatives\n",
    "        sampled_positives = random.sample(positive_indices, max_num_positives)\n",
    "        sampled_negatives = random.sample(negative_indices, max_num_negatives)\n",
    "\n",
    "        # Combine and shuffle the indices\n",
    "        sampled_indices = sampled_positives + sampled_negatives\n",
    "\n",
    "        return sampled_indices\n",
    "        # {\"data\": veri_data, \"label\": veri_label, \"cls_indexes\": veri_cls_indexes}\n",
    "    def __len__(self):\n",
    "        return len(self.veri_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        labels = self.veri_label[idx]\n",
    "        sampled_indices = self.sample(labels)\n",
    "        sampled_labels = torch.tensor([labels[i] for i in sampled_indices]).reshape(-1)\n",
    "        sampled_data = [self.veri_data[idx][i].reshape(-1) for i in sampled_indices]\n",
    "        sampled_cls_indexes = torch.tensor([self.veri_cls_indexes[idx][i] for i in sampled_indices], dtype=torch.long)\n",
    "        if len(sampled_indices) < self.max_list_length:\n",
    "            sampled_labels = torch.cat([sampled_labels, torch.ones(self.max_list_length - len(sampled_labels))*self.label_padding_value])\n",
    "            sampled_data.extend([torch.tensor([self.data_padding_value]) for _ in range(self.max_list_length - len(sampled_data))])\n",
    "            sampled_cls_indexes = torch.cat([sampled_cls_indexes, torch.zeros(self.max_list_length - len(sampled_cls_indexes))])\n",
    "        return {\n",
    "            \"data\": sampled_data,\n",
    "            \"label\": sampled_labels,\n",
    "            \"cls_indexes\": sampled_cls_indexes, \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VerificationBinaryDataset(data.Dataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            data_path: str = \"/data/zhihao/TU/Watchog/verification/veri_data.pth\",\n",
    "            pos_ratio = None, # clone the negative samples\n",
    "            ): \n",
    "        data_raw = torch.load(data_path)\n",
    "        veri_label = data_raw[\"label\"]\n",
    "        veri_data = data_raw[\"data\"]\n",
    "        veri_cls_indexes = data_raw[\"cls_indexes\"]\n",
    "        veri_embs = data_raw[\"embs\"]\n",
    "        veri_logits = data_raw[\"logits\"]\n",
    "        self.neg_expand = int(1/pos_ratio)-1 if pos_ratio is not None else 1\n",
    "        self.veri_label = {}\n",
    "        self.veri_data = {}\n",
    "        self.veri_embs = {}\n",
    "        self.veri_cls_indexes = {}\n",
    "        self.veri_logits = {}\n",
    "        i = 0\n",
    "        for veri_i in veri_label:\n",
    "            for veri_j in range(len(veri_label[veri_i])):\n",
    "                if veri_label[veri_i][veri_j] == 1:\n",
    "                    labels_i = torch.tensor([1]).reshape(-1)\n",
    "                    self.veri_data[i] = veri_data[veri_i][veri_j]\n",
    "                    self.veri_label[i] = labels_i\n",
    "                    self.veri_cls_indexes[i] = veri_cls_indexes[veri_i][veri_j]\n",
    "                    self.veri_embs[i] = veri_embs[veri_i][veri_j]\n",
    "                    self.veri_logits[i] = veri_logits[veri_i][veri_j]\n",
    "                    i += 1\n",
    "                else:\n",
    "                    for _ in range(self.neg_expand):\n",
    "                        labels_i = torch.tensor([0]).reshape(-1)\n",
    "                        self.veri_data[i] = veri_data[veri_i][veri_j]\n",
    "                        self.veri_label[i] = labels_i\n",
    "                        self.veri_cls_indexes[i] = veri_cls_indexes[veri_i][veri_j]\n",
    "                        self.veri_embs[i] = veri_embs[veri_i][veri_j]\n",
    "                        self.veri_logits[i] = veri_logits[veri_i][veri_j]\n",
    "                        i += 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.veri_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            # \"data\": self.veri_data[idx].reshape(-1),\n",
    "            \"embs\": self.veri_embs[idx].reshape(-1),\n",
    "            \"label\": self.veri_label[idx],\n",
    "            \"logits\": self.veri_logits[idx],\n",
    "            # \"cls_indexes\": self.veri_cls_indexes[idx], \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(veri_dataset), len(veri_dataset.veri_data), len(veri_dataset.veri_label), len(veri_dataset.veri_cls_indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verit_binary_dataset = VerificationBinaryDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(verit_binary_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.nn.utils.rnn.pad_sequence(\n",
    "            [verit_binary_dataset[i][\"data\"] for i in range(10)], padding_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verit_binary_dataset[0][\"embs\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "verit_labels = []\n",
    "for i in range(len(verit_binary_dataset)):\n",
    "    verit_labels.append(verit_binary_dataset[i][\"label\"].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(verit_labels).sum()/len(verit_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(veri_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veri_dataset = VerificationDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(veri_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = veri_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(res[\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[\"data\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[\"label\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = []\n",
    "for i in range(len(veri_dataset)):\n",
    "    data_test.extend(veri_dataset[i][\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def veri_collate_fn(pad_token_id, binary=False):\n",
    "    '''padder for input batch'''\n",
    "    \n",
    "    def padder(samples):    \n",
    "        data = []\n",
    "        for sample in samples:\n",
    "            data.extend(sample[\"data\"])\n",
    "        data =torch.nn.utils.rnn.pad_sequence(\n",
    "            data, padding_value=pad_token_id)\n",
    "\n",
    "        label = torch.cat([sample[\"label\"] for sample in samples], dim=-1)\n",
    "        batch = {\"data\": data, \"label\": label}\n",
    "        if \"cls_indexes\" in samples[0]:\n",
    "            i = 0\n",
    "            cls_indexes = []\n",
    "            for sample in samples:\n",
    "                for value in sample[\"cls_indexes\"]:\n",
    "                    cls_indexes.append(torch.tensor([i, value]))\n",
    "                    i += 1\n",
    "            cls_indexes = torch.stack(cls_indexes, dim=0).long()\n",
    "            batch[\"cls_indexes\"] = cls_indexes\n",
    "        return batch\n",
    "    \n",
    "    def padder_binary(samples):   \n",
    "\n",
    "        label = torch.cat([sample[\"label\"] for sample in samples], dim=-1)\n",
    "        batch = {\"label\": label}\n",
    "        if  \"data\" in samples[0]:\n",
    "            data = torch.nn.utils.rnn.pad_sequence(\n",
    "                [sample[\"data\"] for sample in samples], padding_value=pad_token_id)\n",
    "            batch[\"data\"] = data\n",
    "        if \"cls_indexes\" in samples[0]:\n",
    "            i = 0\n",
    "            cls_indexes = []\n",
    "            for sample in samples:\n",
    "                value =  sample[\"cls_indexes\"]\n",
    "                cls_indexes.append(torch.tensor([i, value]))\n",
    "                i += 1\n",
    "            cls_indexes = torch.stack(cls_indexes, dim=0).long()\n",
    "            batch[\"cls_indexes\"] = cls_indexes\n",
    "        if \"embs\" in samples[0]:\n",
    "            embs = torch.stack([sample[\"embs\"] for sample in samples], dim=0)\n",
    "            batch[\"embs\"] = embs\n",
    "        if \"logits\" in samples[0]:\n",
    "            logits = torch.stack([sample[\"logits\"] for sample in samples], dim=0)\n",
    "            batch[\"logits\"] = logits\n",
    "        return batch\n",
    "    if binary:\n",
    "        return padder_binary\n",
    "    else:\n",
    "        return padder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veri_padder = veri_collate_fn(0)\n",
    "veri_dataloader = data.DataLoader(\n",
    "    veri_dataset, batch_size=args.batch_size, shuffle=True, num_workers=4, collate_fn=veri_padder\n",
    ")\n",
    "for batch in veri_dataloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "veri_binary_padder = veri_collate_fn(0, binary=True)\n",
    "veri_binary_dataloader = data.DataLoader(\n",
    "    verit_binary_dataset, batch_size=args.batch_size, shuffle=True, num_workers=4, collate_fn=veri_binary_padder\n",
    ")\n",
    "for batch_idx, batch in enumerate(veri_binary_dataloader):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[\"embs\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[\"logits\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[\"label\"].to(device).squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model = model.to(device)\n",
    "verifier.train()\n",
    "verifier = verifier.to(device)\n",
    "pos_ratio = 0.1\n",
    "pos_weight = torch.tensor([(1-pos_ratio)/pos_ratio]).to(device)\n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "for batch_idx, batch in enumerate(veri_binary_dataloader ):\n",
    "    cls_indexes = batch[\"cls_indexes\"].to(device)\n",
    "    input_data = batch[\"data\"].T.to(device)\n",
    "    logits, embs = model(input_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "    scores = verifier(embs).squeeze()\n",
    "    loss = loss_fn(scores, batch[\"label\"].to(device).squeeze().float())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " batch[\"label\"].to(device).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[\"data\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[\"data\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[\"label\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[\"cls_indexes\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "verifier = Verifier(norm=\"batch_norm\", num_layers=None).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# veri_state_dict = torch.load(\"/data/zhihao/TU/Watchog/outputs/gt-semtab22-dbpedia-all0/bert-base-uncased-fromscratch-semi1-mode@ffn-context@None-data@5-lr@5e-05-warmup@0.0-dp@0.0-norm@batch_norm-pos@0.1-poolv0-unlabeled8-randFalse-bs64-ml128-ne200-do0.0_verifier_binary_best_f1_macro.pt\")\n",
    "# veri_state_dict = torch.load(\"/data/zhihao/TU/Watchog/outputs/gt-semtab22-dbpedia-all0/bert-base-uncased-fromscratch-semi1-mode@ffn-context@None-data@5-lr@5e-05-warmup@0.0-dp@0.0-norm@batch_norm-pos@0.2-poolv0-unlabeled8-randFalse-bs64-ml128-ne200-do0.0_verifier_binary_best_f1_micro.pt\")\n",
    "# veri_state_dict = torch.load(\"/data/zhihao/TU/Watchog/outputs/gt-semtab22-dbpedia-all0/bert-base-uncased-fromscratch-semi1-mode@ffn-context@None-data@5-lr@5e-05-warmup@0.0-dp@0.0-norm@batch_norm-pos@0.1-poolv0-unlabeled8-randFalse-bs64-ml128-ne200-do0.0_verifier_binary_best_f1_micro.pt\")\n",
    "# veri_state_dict = torch.load(\"/data/zhihao/TU/Watchog/outputs/gt-semtab22-dbpedia-all0/bert-base-uncased-fromscratch-semi1-mode@ffn-search@0-context@None-data@5-lr@5e-05-warmup@0.0-dp@0.0-norm@batch_norm-pos@0.2-poolv0-unlabeled8-randFalse-bs64-ml128-ne200-do0.0_verifier_binary_best_f1_micro.pt\")\n",
    "veri_state_dict = torch.load(\"/data/zhihao/TU/Watchog/outputs/gt-semtab22-dbpedia-all0/bert-base-uncased-fromscratch-semi1-mode@ffn-context@None-data@5-lr@5e-05-warmup@0.0-dp@0.0-norm@batch_norm-pos@0.2-poolv0-unlabeled8-randFalse-bs64-ml128-ne200-do0.0_verifier_binary_best_f1_micro.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verifier.load_state_dict(veri_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verifier.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(verifier.parameters(), lr=args.lr, eps=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.to(device)\n",
    "verifier.train()\n",
    "tr_loss = 0.0\n",
    "for batch_idx, batch in enumerate(veri_dataloader):\n",
    "    cls_indexes = batch[\"cls_indexes\"].to(device)\n",
    "    input_data = batch[\"data\"].T.to(device)\n",
    "    logits, embs = model(input_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "    scores = verifier(embs)\n",
    "    loss = listMLE(scores.reshape(args.batch_size, -1), batch[\"label\"].to(device).reshape(args.batch_size, -1))\n",
    "\n",
    "    accelerator.backward(loss)\n",
    "    # loss.backward()\n",
    "    tr_loss += loss.cpu().detach().item()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def listMLE(y_pred, y_true, eps=1e-10, padded_value_indicator=-1):\n",
    "    \"\"\"\n",
    "    ListMLE loss introduced in \"Listwise Approach to Learning to Rank - Theory and Algorithm\".\n",
    "    :param y_pred: predictions from the model, shape [batch_size, slate_length]\n",
    "    :param y_true: ground truth labels, shape [batch_size, slate_length]\n",
    "    :param eps: epsilon value, used for numerical stability\n",
    "    :param padded_value_indicator: an indicator of the y_true index containing a padded item, e.g. -1\n",
    "    :return: loss value, a torch.Tensor\n",
    "    \"\"\"\n",
    "    # shuffle for randomised tie resolution\n",
    "    random_indices = torch.randperm(y_pred.shape[-1])\n",
    "    y_pred_shuffled = y_pred[:, random_indices]\n",
    "    y_true_shuffled = y_true[:, random_indices]\n",
    "\n",
    "    y_true_sorted, indices = y_true_shuffled.sort(descending=True, dim=-1)\n",
    "\n",
    "    mask = y_true_sorted == padded_value_indicator\n",
    "\n",
    "    preds_sorted_by_true = torch.gather(y_pred_shuffled, dim=1, index=indices)\n",
    "    preds_sorted_by_true[mask] = float(\"-inf\")\n",
    "\n",
    "    max_pred_values, _ = preds_sorted_by_true.max(dim=1, keepdim=True)\n",
    "\n",
    "    preds_sorted_by_true_minus_max = preds_sorted_by_true - max_pred_values\n",
    "\n",
    "    cumsums = torch.cumsum(preds_sorted_by_true_minus_max.exp().flip(dims=[1]), dim=1).flip(dims=[1])\n",
    "\n",
    "    observation_loss = torch.log(cumsums + eps) - preds_sorted_by_true_minus_max\n",
    "\n",
    "    observation_loss[mask] = 0.0\n",
    "\n",
    "    return torch.mean(torch.sum(observation_loss, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "\n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "verifier.eval()\n",
    "verifier = verifier.to(device)\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "init_scores = []\n",
    "init_correctness = []\n",
    "final_scores = []\n",
    "final_correctness = []\n",
    "\n",
    "for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    scores_init = verifier(embs.reshape(1,-1))\n",
    "    max_score = -float(\"inf\")\n",
    "    if 1 in target_col_mask:\n",
    "        init_scores.append(scores_init.item())\n",
    "        init_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "        init_permutation_i = get_permutation(target_col_mask)\n",
    "        col_idx_set = target_col_mask.unique().tolist()\n",
    "        early_stop = False\n",
    "        assert -1 not in col_idx_set\n",
    "        for r in range(len(init_permutation_i), max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "            for x in itertools.combinations(init_permutation_i, r):\n",
    "                if 0 not in x:\n",
    "                    continue\n",
    "                new_batch_data = []\n",
    "                for col_i in x:\n",
    "                    if col_i == 0:\n",
    "                        if len(new_batch_data) == 0:\n",
    "                            cls_indexes_value = 0\n",
    "                        else:\n",
    "                            cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                    new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                if 0 not in x:\n",
    "                    cls_indexes_value = 0\n",
    "                new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                logits_temp, embs = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                scores_temp = verifier(embs.reshape(1,-1)).item()\n",
    "                predict_temp = logits_temp.argmax().item()\n",
    "                    # if len(x) == 1 and 0 in x:\n",
    "                    #     predict_target = predict_temp\n",
    "                    #     msp_target = msp_temp\n",
    "                    # # print(x, msp_temp, predict_temp)\n",
    "                    # if 0 not in x and msp_temp > debias_threshold and (predict_temp != predict_target):\n",
    "                    #     debias_classes.append(predict_temp)\n",
    "                    #     continue\n",
    "                if scores_temp > max_score:\n",
    "                    max_score = scores_temp\n",
    "                    logits = logits_temp.clone()\n",
    "        final_scores.append(max_score)\n",
    "        final_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "    labels_test.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "labels_test = torch.cat(labels_test, dim=0)\n",
    "logits_test = torch.stack(logits_test, dim=0)\n",
    "preds_test = torch.argmax(logits_test, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_micro_f1=0.5631, ts_macro_f1=0.3018\n"
     ]
    }
   ],
   "source": [
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_micro_f1=0.5631, ts_macro_f1=0.3062\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "\n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "verifier.eval()\n",
    "verifier = verifier.to(device)\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "init_scores = []\n",
    "init_correctness = []\n",
    "final_scores = []\n",
    "final_correctness = []\n",
    "\n",
    "for batch_idx, batch in enumerate(test_dataloader_first):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    scores_init = verifier(embs.reshape(1,-1))\n",
    "    max_score = -float(\"inf\")\n",
    "    if 1 in target_col_mask:\n",
    "        init_scores.append(scores_init.item())\n",
    "        init_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "        init_permutation_i = get_permutation(target_col_mask)\n",
    "        col_idx_set = target_col_mask.unique().tolist()\n",
    "        early_stop = False\n",
    "        assert -1 not in col_idx_set\n",
    "        for r in range(len(init_permutation_i), max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "            for x in itertools.combinations(init_permutation_i, r):\n",
    "                if 0 not in x:\n",
    "                    continue\n",
    "                new_batch_data = []\n",
    "                for col_i in x:\n",
    "                    if col_i == 0:\n",
    "                        if len(new_batch_data) == 0:\n",
    "                            cls_indexes_value = 0\n",
    "                        else:\n",
    "                            cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                    new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                if 0 not in x:\n",
    "                    cls_indexes_value = 0\n",
    "                new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                logits_temp, embs = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                scores_temp = verifier(embs.reshape(1,-1)).item()\n",
    "                predict_temp = logits_temp.argmax().item()\n",
    "                    # if len(x) == 1 and 0 in x:\n",
    "                    #     predict_target = predict_temp\n",
    "                    #     msp_target = msp_temp\n",
    "                    # # print(x, msp_temp, predict_temp)\n",
    "                    # if 0 not in x and msp_temp > debias_threshold and (predict_temp != predict_target):\n",
    "                    #     debias_classes.append(predict_temp)\n",
    "                    #     continue\n",
    "                if scores_temp > max_score:\n",
    "                    max_score = scores_temp\n",
    "                    logits = logits_temp.clone()\n",
    "        final_scores.append(max_score)\n",
    "        final_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "    labels_test.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "labels_test = torch.cat(labels_test, dim=0)\n",
    "logits_test = torch.stack(logits_test, dim=0)\n",
    "preds_test = torch.argmax(logits_test, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_micro_f1=0.5512, ts_macro_f1=0.2710\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "\n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "verifier.eval()\n",
    "verifier = verifier.to(device)\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "init_scores = []\n",
    "init_correctness = []\n",
    "final_scores = []\n",
    "final_correctness = []\n",
    "\n",
    "for batch_idx, batch in enumerate(test_dataloader_lb):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    scores_init = verifier(embs.reshape(1,-1))\n",
    "    max_score = -float(\"inf\")\n",
    "    if 1 in target_col_mask:\n",
    "        init_scores.append(scores_init.item())\n",
    "        init_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "        init_permutation_i = get_permutation(target_col_mask)\n",
    "        col_idx_set = target_col_mask.unique().tolist()\n",
    "        early_stop = False\n",
    "        assert -1 not in col_idx_set\n",
    "        for r in range(len(init_permutation_i), max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "            for x in itertools.combinations(init_permutation_i, r):\n",
    "                if 0 not in x:\n",
    "                    continue\n",
    "                new_batch_data = []\n",
    "                for col_i in x:\n",
    "                    if col_i == 0:\n",
    "                        if len(new_batch_data) == 0:\n",
    "                            cls_indexes_value = 0\n",
    "                        else:\n",
    "                            cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                    new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                if 0 not in x:\n",
    "                    cls_indexes_value = 0\n",
    "                new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                logits_temp, embs = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                scores_temp = verifier(embs.reshape(1,-1)).item()\n",
    "                predict_temp = logits_temp.argmax().item()\n",
    "                    # if len(x) == 1 and 0 in x:\n",
    "                    #     predict_target = predict_temp\n",
    "                    #     msp_target = msp_temp\n",
    "                    # # print(x, msp_temp, predict_temp)\n",
    "                    # if 0 not in x and msp_temp > debias_threshold and (predict_temp != predict_target):\n",
    "                    #     debias_classes.append(predict_temp)\n",
    "                    #     continue\n",
    "                if scores_temp > max_score:\n",
    "                    max_score = scores_temp\n",
    "                    logits = logits_temp.clone()\n",
    "        final_scores.append(max_score)\n",
    "        final_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "    labels_test.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "labels_test = torch.cat(labels_test, dim=0)\n",
    "logits_test = torch.stack(logits_test, dim=0)\n",
    "preds_test = torch.argmax(logits_test, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_micro_f1=0.5410, ts_macro_f1=0.2605\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "\n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "verifier.eval()\n",
    "verifier = verifier.to(device)\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "init_scores = []\n",
    "init_correctness = []\n",
    "final_scores = []\n",
    "final_correctness = []\n",
    "\n",
    "for batch_idx, batch in enumerate(test_dataloader_cluster):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    scores_init = verifier(embs.reshape(1,-1))\n",
    "    max_score = -float(\"inf\")\n",
    "    if 1 in target_col_mask:\n",
    "        init_scores.append(scores_init.item())\n",
    "        init_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "        init_permutation_i = get_permutation(target_col_mask)\n",
    "        col_idx_set = target_col_mask.unique().tolist()\n",
    "        early_stop = False\n",
    "        assert -1 not in col_idx_set\n",
    "        for r in range(len(init_permutation_i), max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "            for x in itertools.combinations(init_permutation_i, r):\n",
    "                if 0 not in x:\n",
    "                    continue\n",
    "                new_batch_data = []\n",
    "                for col_i in x:\n",
    "                    if col_i == 0:\n",
    "                        if len(new_batch_data) == 0:\n",
    "                            cls_indexes_value = 0\n",
    "                        else:\n",
    "                            cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                    new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                if 0 not in x:\n",
    "                    cls_indexes_value = 0\n",
    "                new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                logits_temp, embs = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                scores_temp = verifier(embs.reshape(1,-1)).item()\n",
    "                predict_temp = logits_temp.argmax().item()\n",
    "                    # if len(x) == 1 and 0 in x:\n",
    "                    #     predict_target = predict_temp\n",
    "                    #     msp_target = msp_temp\n",
    "                    # # print(x, msp_temp, predict_temp)\n",
    "                    # if 0 not in x and msp_temp > debias_threshold and (predict_temp != predict_target):\n",
    "                    #     debias_classes.append(predict_temp)\n",
    "                    #     continue\n",
    "                if scores_temp > max_score:\n",
    "                    max_score = scores_temp\n",
    "                    logits = logits_temp.clone()\n",
    "        final_scores.append(max_score)\n",
    "        final_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "    labels_test.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "labels_test = torch.cat(labels_test, dim=0)\n",
    "logits_test = torch.stack(logits_test, dim=0)\n",
    "preds_test = torch.argmax(logits_test, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_micro_f1=0.5521, ts_macro_f1=0.2695\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "\n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "verifier.eval()\n",
    "verifier = verifier.to(device)\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "init_scores = []\n",
    "init_correctness = []\n",
    "final_scores = []\n",
    "final_correctness = []\n",
    "\n",
    "for batch_idx, batch in enumerate(test_dataloader_near):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    scores_init = verifier(embs.reshape(1,-1))\n",
    "    max_score = -float(\"inf\")\n",
    "    if 1 in target_col_mask:\n",
    "        init_scores.append(scores_init.item())\n",
    "        init_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "        init_permutation_i = get_permutation(target_col_mask)\n",
    "        col_idx_set = target_col_mask.unique().tolist()\n",
    "        early_stop = False\n",
    "        assert -1 not in col_idx_set\n",
    "        for r in range(len(init_permutation_i), max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "            for x in itertools.combinations(init_permutation_i, r):\n",
    "                if 0 not in x:\n",
    "                    continue\n",
    "                new_batch_data = []\n",
    "                for col_i in x:\n",
    "                    if col_i == 0:\n",
    "                        if len(new_batch_data) == 0:\n",
    "                            cls_indexes_value = 0\n",
    "                        else:\n",
    "                            cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                    new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                if 0 not in x:\n",
    "                    cls_indexes_value = 0\n",
    "                new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                logits_temp, embs = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                scores_temp = verifier(embs.reshape(1,-1)).item()\n",
    "                predict_temp = logits_temp.argmax().item()\n",
    "                    # if len(x) == 1 and 0 in x:\n",
    "                    #     predict_target = predict_temp\n",
    "                    #     msp_target = msp_temp\n",
    "                    # # print(x, msp_temp, predict_temp)\n",
    "                    # if 0 not in x and msp_temp > debias_threshold and (predict_temp != predict_target):\n",
    "                    #     debias_classes.append(predict_temp)\n",
    "                    #     continue\n",
    "                if scores_temp > max_score:\n",
    "                    max_score = scores_temp\n",
    "                    logits = logits_temp.clone()\n",
    "        final_scores.append(max_score)\n",
    "        final_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "    labels_test.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "labels_test = torch.cat(labels_test, dim=0)\n",
    "logits_test = torch.stack(logits_test, dim=0)\n",
    "preds_test = torch.argmax(logits_test, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_correctness = torch.tensor(init_correctness)\n",
    "final_correctness = torch.tensor(final_correctness)\n",
    "init_scores = torch.tensor(init_scores)\n",
    "final_scores = torch.tensor(final_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(init_correctness | final_correctness).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(init_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(F.sigmoid(init_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.sigmoid(init_scores)[init_correctness].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.sigmoid(init_scores)[~init_correctness].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.sigmoid(final_scores)[init_correctness].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.sigmoid(final_scores)[~init_correctness].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(final_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(F.sigmoid(final_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_macro_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_init_mask = init_correctness\n",
    "correct_msp_mask = final_correctness\n",
    "for threshold in [ 0.9, 0.99, 0.999]:\n",
    "    uncertain_init_mask = F.sigmoid(init_scores) < threshold\n",
    "    condition_mask = ~uncertain_init_mask\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    print(\"Init\")\n",
    "    # init prediction\n",
    "    print((condition_mask&correct_init_mask).sum().item(), \n",
    "        (condition_mask).sum().item(), \n",
    "        (condition_mask&correct_init_mask).sum().item()/(condition_mask).sum().item())\n",
    "    # init prediction\n",
    "    print((~condition_mask&correct_init_mask).sum().item(), \n",
    "        (~condition_mask).sum().item(), \n",
    "       (~condition_mask&correct_init_mask).sum().item()/(~condition_mask).sum().item())\n",
    "    print(\"MSP\")\n",
    "    # msp prediction\n",
    "    print((condition_mask&correct_msp_mask).sum().item(), \n",
    "        (condition_mask).sum().item(), \n",
    "        (condition_mask&correct_msp_mask).sum().item()/(condition_mask).sum().item())\n",
    "    # msp prediction\n",
    "    print((~condition_mask&correct_msp_mask).sum().item(), \n",
    "        (~condition_mask).sum().item(), \n",
    "        (~condition_mask&correct_msp_mask).sum().item()/(~condition_mask).sum().item())\n",
    "    print(\"MSP & Init\")\n",
    "    print(((condition_mask&correct_init_mask)&(condition_mask&correct_msp_mask)).sum().item())\n",
    "    # print(((~(init_target_mask&(~uncertain_init_mask & ~uncertain_target_mask))& correct_msp_mask)&(~(init_target_mask&(~uncertain_init_mask & ~uncertain_target_mask))& correct_init_mask)).sum().item())\n",
    "    print(((condition_mask&correct_init_mask)|(condition_mask&correct_msp_mask)).sum().item(),\n",
    "          (condition_mask).sum().item(), \n",
    "          ((condition_mask&correct_init_mask)|(condition_mask&correct_msp_mask)).sum().item()/(condition_mask).sum().item())\n",
    "    print(((~condition_mask&correct_init_mask)|(~condition_mask&correct_msp_mask)).sum().item(),\n",
    "          (~condition_mask).sum().item(), \n",
    "          ((~condition_mask&correct_init_mask)|(~condition_mask&correct_msp_mask)).sum().item()/(~condition_mask).sum().item())\n",
    "    # print(\"Permutation\")\n",
    "    # print((condition_mask&correct_permutation_mask).sum().item(), \n",
    "    #     (condition_mask).sum().item(), \n",
    "    #     (condition_mask&correct_permutation_mask).sum().item()/(condition_mask).sum().item())\n",
    "    # print((~condition_mask&correct_permutation_mask).sum().item(), \n",
    "    #      (~condition_mask).sum().item(), \n",
    "    #     (~condition_mask&correct_permutation_mask).sum().item()/(~condition_mask).sum().item())\n",
    "    # print(\"Permutation Confident\")\n",
    "    # print((condition_mask&correct_permutation_confident_mask).sum().item(), \n",
    "    #     (condition_mask).sum().item(), \n",
    "    #     (condition_mask&correct_permutation_confident_mask).sum().item()/(condition_mask).sum().item())\n",
    "    # print((~condition_mask&correct_permutation_confident_mask).sum().item(),\n",
    "    #         (~condition_mask).sum().item(), \n",
    "    #         (~condition_mask&correct_permutation_confident_mask).sum().item()/(~condition_mask).sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "\n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "verifier.load_state_dict(veri_state_dict)\n",
    "verifier.eval()\n",
    "verifier = verifier.to(device)\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "init_scores = []\n",
    "init_correctness = []\n",
    "final_scores = []\n",
    "final_correctness = []\n",
    "num_cols = []\n",
    "total_steps = []\n",
    "final_steps = []\n",
    "correct_scores = defaultdict(list)\n",
    "correct_steps = defaultdict(list)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "        target_col_mask = batch[\"target_col_mask\"].T\n",
    "        embs = test_embs[batch_idx][0].reshape(1,-1).to(device)\n",
    "        logits = test_logits[batch_idx][0].reshape(-1).to(device)\n",
    "        scores_init = verifier(embs)\n",
    "        max_score = -float(\"inf\")\n",
    "\n",
    "        init_scores.append(scores_init.item())\n",
    "        init_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "        init_permutation_i = get_permutation(target_col_mask)\n",
    "        col_idx_set = target_col_mask.unique().tolist()\n",
    "        early_stop = False\n",
    "        i = 0\n",
    "        final_step = 0\n",
    "        total_steps.append(len(init_permutation_i) - max(len(init_permutation_i)//2, len(init_permutation_i)-3) -1)\n",
    "        num_cols.append(test_dataset_iter[batch_idx][\"initial_num_col\"].item())\n",
    "        for r in range(len(init_permutation_i), max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "            for x in itertools.combinations(init_permutation_i, r):\n",
    "                if 0 not in x:\n",
    "                    continue\n",
    "                logits_temp = test_logits[batch_idx][i].reshape(-1).to(device)\n",
    "                embs_temp = test_embs[batch_idx][i].reshape(1,-1).to(device)\n",
    "                scores_temp = verifier(embs_temp).item()\n",
    "                predict_temp = logits_temp.argmax().item()\n",
    "                i += 1\n",
    "                if scores_temp > max_score:\n",
    "                    max_score = scores_temp\n",
    "                    logits = logits_temp.clone()\n",
    "                    final_step = len(init_permutation_i) - r\n",
    "                if logits_temp.argmax().item() == batch[\"label\"].item():\n",
    "                    correct_scores[batch_idx].append(scores_temp)\n",
    "                    correct_steps[batch_idx].append(len(init_permutation_i) - r)\n",
    "                    \n",
    "        final_scores.append(max_score)\n",
    "        final_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "        final_steps.append(final_step)\n",
    "        labels_test.append(batch[\"label\"].cpu())\n",
    "        logits_test.append(logits.detach().cpu())\n",
    "    labels_test = torch.cat(labels_test, dim=0)\n",
    "    logits_test = torch.stack(logits_test, dim=0)\n",
    "    preds_test = torch.argmax(logits_test, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "ts_f1_full = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=None)\n",
    "# full_f1_init\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "\n",
    "final_correctness = torch.tensor(final_correctness)\n",
    "init_correctness = torch.tensor(init_correctness)\n",
    "init_scores = torch.tensor(init_scores)\n",
    "final_scores = torch.tensor(final_scores)\n",
    "final_steps = torch.tensor(final_steps)\n",
    "total_steps = torch.tensor(total_steps)\n",
    "final_scores_origin = F.sigmoid(torch.tensor(final_scores))\n",
    "init_scores = F.sigmoid(torch.tensor(init_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_final_scores_avg = []\n",
    "for i in range(args.num_classes):\n",
    "    class_final_scores_avg.append(final_scores_origin[labels_test==i].mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=torch.arange(len(class_final_scores_avg)), y=class_final_scores_avg)\n",
    "plt.xlabel('Class Label')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Class Frequency Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_f1_near.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_f1_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_near = (preds_test_near == labels_test).float().mean().item()\n",
    "acc_eu = (preds_test_eu == labels_test).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_near"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_f1_near.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mask in [is_numerical, is_categorical, is_datetime]:\n",
    "    mask = torch.tensor(mask)\n",
    "    print(mask.sum(), full_f1_near[mask].mean(), full_f1_eu[mask].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "f1_diff = full_f1_near - full_f1_eu\n",
    "data = pd.DataFrame({\n",
    "    'Class': np.arange(args.num_classes),\n",
    "    'F1 Difference (Model 1 - Model 3)': f1_diff\n",
    "})\n",
    "# Plot using seaborn\n",
    "plt.figure(figsize=(18, 8))\n",
    "sns.barplot(x='Class', y='F1 Difference (Model 1 - Model 3)', data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for threshold in [0.2, 0.5, 0.8, 0.9, 0.99]:\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    print(len(final_correctness[final_scores>threshold]), final_correctness[final_scores>threshold].sum().item()/len(final_correctness[final_scores>threshold]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_correctness[final_scores>threshold])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_scores.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(final_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = torch.tensor(num_cols)\n",
    "for n_col in np.arange(1, 10):\n",
    "    if n_col <= 8:\n",
    "        mask = num_cols == n_col\n",
    "    else:\n",
    "        mask = num_cols > 8\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach()[mask].numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    print(\"num_cols={} counts={} ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(n_col, mask.sum().item(), ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "for K in [1, 3, 5]:\n",
    "    print(f\"*********************K: {K}****************************\")\n",
    "    model.load_state_dict(best_state_dict, strict=False)\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    verifier.load_state_dict(veri_state_dict)\n",
    "    verifier.eval()\n",
    "    verifier = verifier.to(device)\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    init_scores = []\n",
    "    init_correctness = []\n",
    "    final_scores = []\n",
    "    final_correctness = []\n",
    "    num_cols = []\n",
    "    total_steps = []\n",
    "    final_steps = []\n",
    "    correct_scores = defaultdict(list)\n",
    "    correct_steps = defaultdict(list)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "            target_col_mask = batch[\"target_col_mask\"].T\n",
    "            embs = test_embs[batch_idx][0].reshape(1,-1).to(device)\n",
    "            logits = test_logits[batch_idx][0].reshape(-1).to(device)\n",
    "            scores_init = verifier(embs)\n",
    "            \n",
    "            scores = []\n",
    "            predictions = []\n",
    "\n",
    "            init_scores.append(scores_init.item())\n",
    "            init_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            early_stop = False\n",
    "            i = 0\n",
    "            final_step = 0\n",
    "            total_steps.append(len(init_permutation_i) - max(len(init_permutation_i)//2, len(init_permutation_i)-3) -1)\n",
    "            num_cols.append(test_dataset_iter[batch_idx][\"initial_num_col\"].item())\n",
    "            for r in range(len(init_permutation_i), max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "                for x in itertools.combinations(init_permutation_i, r):\n",
    "                    if 0 not in x:\n",
    "                        continue\n",
    "                    logits_temp = test_logits[batch_idx][i].reshape(-1).to(device)\n",
    "                    embs_temp = test_embs[batch_idx][i].reshape(1,-1).to(device)\n",
    "                    scores_temp = verifier(embs_temp).item()\n",
    "                    predict_temp = torch.zeros(args.num_classes)\n",
    "                    predict_temp[logits_temp.argmax().item()] = 1\n",
    "                    \n",
    "                    i += 1\n",
    "                    scores.append(scores_temp)\n",
    "                    predictions.append(predict_temp)\n",
    "\n",
    "            topk = torch.tensor(scores).topk(min(K, len(scores)))\n",
    "            logits = 0\n",
    "            for value, index in zip(*topk):\n",
    "                logits += torch.sigmoid(torch.tensor(value)) * predictions[index]\n",
    "            # final_scores.append(final_score)\n",
    "            final_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "            labels_test.append(batch[\"label\"].cpu())\n",
    "            logits_test.append(logits.detach().cpu())\n",
    "        labels_test = torch.cat(labels_test, dim=0)\n",
    "        logits_test = torch.stack(logits_test, dim=0)\n",
    "        preds_test = torch.argmax(logits_test, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix, f1_score\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach().numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    ts_f1_full = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=None)\n",
    "    # full_f1_init\n",
    "    print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "\n",
    "    final_correctness = torch.tensor(final_correctness)\n",
    "    init_correctness = torch.tensor(init_correctness)\n",
    "    init_scores = torch.tensor(init_scores)\n",
    "    # final_steps = torch.tensor(final_steps)\n",
    "    total_steps = torch.tensor(total_steps)\n",
    "    # final_scores_topk = F.sigmoid(torch.tensor(final_scores))\n",
    "    # init_scores = F.sigmoid(torch.tensor(init_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.equal(final_scores_origin, final_scores_topk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "coltypes = np.array(['id', 'name', 'description', 'type', 'title', 'state', 'status',\n",
    "       'date', 'code', 'city', 'value', 'source', 'year', 'time',\n",
    "       'country', 'county', 'comment', 'notes', 'category', 'address',\n",
    "       'age', 'gender', 'location', 'version', 'price', 'sex',\n",
    "       'startDate', 'weight', 'class', 'endDate', 'field', 'region',\n",
    "       'note', 'race', 'duration', 'species', 'score', 'position',\n",
    "       'start', 'language', 'rank', 'height', 'population', 'order',\n",
    "       'length', 'filename', 'model', 'role', 'series', 'max', 'min',\n",
    "       'family', 'currency', 'definition', 'format', 'author', 'area',\n",
    "       'domain', 'rating', 'parent', 'number', 'birthDate', 'alias',\n",
    "       'postalCode', 'reference', 'cost', 'publisher', 'treatment',\n",
    "       'created', 'company', 'district', 'elevation', 'project', 'day',\n",
    "       'end', 'scientificName', 'abbreviation', 'part', 'countryCode',\n",
    "       'season', 'topic', 'depth', 'road', 'prefix', 'month', 'route',\n",
    "       'width', 'department', 'percentage', 'zipCode', 'abstract',\n",
    "       'event', 'creator', 'frequency', 'releaseDate', 'genus', 'tag',\n",
    "       'owner', 'party', 'period', 'result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(coltypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_temp = torch.zeros(1, args.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topk = torch.rand(10).topk(5)\n",
    "for value, index in zip(*topk):\n",
    "    print(value, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "sb_model = SentenceTransformer(\"all-mpnet-base-v2\", cache_folder=\"/data/zhihao/TU/Watchog/sentence_transformers_cache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(training_aug_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_aug_embs_sb[0].device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "res0 = tokenizer.decode(batch[\"data\"].T[target_col_mask==0][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\";\".join(set([i.strip() for i in res0.split(\";\")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_sb = torch.tensor(sb_model.encode([res0, \n",
    "                                       res0.replace(\";\", \",\"),\n",
    "                                       res0.replace(\"female\", \"male\"), \n",
    "                                       \";\".join(set([i.strip() for i in res0.split(\";\")])), \n",
    "                                       res0.replace(\"female\", \"F\").replace(\"male\", \"M\"),\n",
    "                                       \"gender; gender; gender;\",\n",
    "                                       \"1997;2005\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_sb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.cosine_similarity(res_sb[0], res_sb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_sb = torch.tensor(sb_model.encode([\"2017; 2022; 1997\", \n",
    "                                       \"2007-11-04; 2007-11-04; 2007-11-04\",\n",
    "                                       \"100; 200; 300\",\n",
    "                                       \"23; 52; 48; 11\", \n",
    "                                       \"2017.11; 2022.54; 1997.54\", \n",
    "                                       \"11.11; 12.11; 0.124\"]))\n",
    "F.cosine_similarity(res_embs[0], res_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_data = [\"2017; 2022; 1997\", \n",
    "                                       \"2007-11-04; 2007-11-04; 2007-11-04\",\n",
    "                                       \"100; 200; 300\",\n",
    "                                       \"23; 52; 48; 11\", \n",
    "                                       \"2017.11; 2022.54; 1997.54\", \n",
    "                                       \"11.11; 12.11; 0.124\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids_list = [tokenizer.encode(\n",
    "    i, add_special_tokens=True) for i in res_data]\n",
    "\n",
    "\n",
    "# group_df[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "#     tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=cur_maxlen, truncation=True)).tolist(\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_embs = []\n",
    "for i in range(len(res_data)):\n",
    "    logits, embs = model(torch.tensor(token_ids_list[i]).reshape(1, -1).to(device), cls_indexes=torch.LongTensor([[0, 0]]).to(device), get_enc=True)\n",
    "    res_embs.append(embs.cpu())\n",
    "res_embs = torch.stack(res_embs, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.cosine_similarity(res_sb[0], res_sb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, batch in enumerate(train_dataloader_iter):\n",
    "    break\n",
    "cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "target_col_mask = batch[\"target_col_mask\"].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save good context\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "sb_model = SentenceTransformer(\"all-mpnet-base-v2\", cache_folder=\"/data/zhihao/TU/Watchog/sentence_transformers_cache\")\n",
    "\n",
    "\n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "num_single_fail = 0\n",
    "num_good_context = 0\n",
    "class_context = defaultdict(list)\n",
    "training_aug_embs = []\n",
    "training_aug_embs_target = []\n",
    "training_aug_embs_sb = []\n",
    "training_aug_labels = []\n",
    "training_aug_col_num = []\n",
    "training_aug_data = []\n",
    "training_aug_col_mask = []\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in enumerate(train_dataloader_iter):\n",
    "        cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "        target_col_mask = batch[\"target_col_mask\"].T\n",
    "        if 1 not in target_col_mask:\n",
    "            continue\n",
    "        init_permutation_i = get_permutation(target_col_mask)\n",
    "        training_aug_col_num.append(len(init_permutation_i))\n",
    "        \n",
    "        label_i = batch[\"label\"].item()\n",
    "        training_aug_labels.append(label_i)\n",
    "        \n",
    "        logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "        training_aug_embs.append(embs.detach().cpu())\n",
    "        \n",
    "        logits, embs = model(batch[\"data\"].T[target_col_mask==0].reshape(1, -1), cls_indexes=torch.LongTensor([[0, 0]]).to(device), get_enc=True)\n",
    "        training_aug_embs_target.append(embs.detach().cpu())\n",
    "        \n",
    "        string_data = tokenizer.decode(batch[\"data\"].T[target_col_mask==0][1:]).split(\";\")\n",
    "        string_data = \";\".join(set([i.strip() for i in string_data]))\n",
    "        sb_embs = torch.tensor(sb_model.encode([string_data]))\n",
    "        training_aug_embs_sb.append(sb_embs)\n",
    "        \n",
    "        training_aug_data.append(batch[\"data\"].T[target_col_mask!=0])\n",
    "        training_aug_col_mask.append(target_col_mask[target_col_mask!=0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_aug_embs = torch.stack(training_aug_embs, dim=0)\n",
    "training_aug_embs_sb = torch.stack(training_aug_embs_sb, dim=0).squeeze()\n",
    "training_aug_embs_target = torch.stack(training_aug_embs_target, dim=0)\n",
    "training_aug_labels = torch.tensor(training_aug_labels)\n",
    "training_aug_col_num = torch.tensor(training_aug_col_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "        for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "            target_col_mask = batch[\"target_col_mask\"].T\n",
    "            embs = test_embs[batch_idx][0].reshape(1,-1).to(device)\n",
    "            logits = test_logits[batch_idx][0].reshape(-1).to(device)\n",
    "            scores_init = verifier(embs)\n",
    "            max_score = -float(\"inf\")\n",
    "\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, indices = F.cosine_similarity(test_aug_embs_sb[batch_idx], training_aug_embs_sb).topk(K)\n",
    "for aug_idx in indices:\n",
    "    aug_data = training_aug_data[aug_idx]\n",
    "    aug_col_mask = training_aug_col_mask[aug_idx]\n",
    "    \n",
    "    aug_permutation_i = torch.tensor(get_permutation(aug_col_mask)) + len(init_permutation_i) -1\n",
    "    permutation_i = init_permutation_i + aug_permutation_i.tolist()\n",
    "    max_num_cols_i = min(len(permutation_i), args.max_num_col)\n",
    "    aug_data = torch.cat([batch[\"data\"].T, aug_data.reshape(1, -1)], dim=-1)\n",
    "    aug_target_col_mask = torch.cat([target_col_mask, aug_col_mask.reshape(1, -1)], dim=-1)\n",
    "    for r in range(max_num_cols_i, max(max_num_cols_i//2, max_num_cols_i-3), -1): # not \n",
    "        for x in itertools.combinations(permutation_i, r):\n",
    "            if 0 not in x:\n",
    "                continue\n",
    "\n",
    "            \n",
    "            new_batch_data = []\n",
    "            for col_i in x:\n",
    "                if col_i == 0:\n",
    "                    if len(new_batch_data) == 0:\n",
    "                        cls_indexes_value = 0\n",
    "                    else:\n",
    "                        cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                new_batch_data.append(aug_data[aug_target_col_mask==col_i])\n",
    "            new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "            cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "            logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "            ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n",
    "            score_permutation[batch_idx].append(ood_score_temp)\n",
    "            predict_temp = logits_temp.argmax().item()\n",
    "            permutation_correctness[batch_idx].append(predict_temp == label_i)\n",
    "            num_permutations[batch_idx] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_col_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, indices = F.cosine_similarity(test_aug_embs_sb[batch_idx], training_aug_embs_sb).topk(K)\n",
    "for aug_idx in indices:\n",
    "    aug_data = training_aug_data[aug_idx]\n",
    "    aug_col_mask = training_aug_col_mask[aug_idx]\n",
    "    \n",
    "    aug_permutation_i = torch.tensor(get_permutation(aug_col_mask)) + len(init_permutation_i) -1\n",
    "    permutation_i = init_permutation_i + aug_permutation_i.tolist()\n",
    "    max_num_cols_i = min(len(permutation_i), args.max_num_col)\n",
    "    aug_data = torch.cat([batch[\"data\"].T, aug_data.reshape(1, -1)], dim=-1)\n",
    "    aug_target_col_mask = torch.cat([target_col_mask, aug_col_mask.reshape(1, -1)], dim=-1)\n",
    "    for r in range(max_num_cols_i, max(max_num_cols_i//2, max_num_cols_i-3), -1): # not \n",
    "        for x in itertools.combinations(permutation_i, r):\n",
    "            if 0 not in x:\n",
    "                continue\n",
    "\n",
    "            \n",
    "            new_batch_data = []\n",
    "            for col_i in x:\n",
    "                if col_i == 0:\n",
    "                    if len(new_batch_data) == 0:\n",
    "                        cls_indexes_value = 0\n",
    "                    else:\n",
    "                        cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                new_batch_data.append(aug_data[aug_target_col_mask==col_i])\n",
    "            new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "            cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "            logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "            scores_temp = verifier(embs_temp).item()\n",
    "            predict_temp = logits_temp.argmax().item()\n",
    "            num_permutations[batch_idx] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save good context\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "sb_model = SentenceTransformer(\"all-mpnet-base-v2\", cache_folder=\"/data/zhihao/TU/Watchog/sentence_transformers_cache\")\n",
    "\n",
    "\n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "num_single_fail = 0\n",
    "num_good_context = 0\n",
    "class_context = defaultdict(list)\n",
    "test_aug_embs = []\n",
    "test_aug_embs_target = []\n",
    "test_aug_embs_sb = []\n",
    "test_aug_labels = []\n",
    "test_aug_col_num = []\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "        cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "        target_col_mask = batch[\"target_col_mask\"].T\n",
    "\n",
    "        init_permutation_i = get_permutation(target_col_mask)\n",
    "        test_aug_col_num.append(len(init_permutation_i))\n",
    "        \n",
    "        label_i = batch[\"label\"].item()\n",
    "        test_aug_labels.append(label_i)\n",
    "        \n",
    "        logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "        test_aug_embs.append(embs.detach().cpu())\n",
    "        \n",
    "        logits, embs = model(batch[\"data\"].T[target_col_mask==0].reshape(1, -1), cls_indexes=torch.LongTensor([[0, 0]]).to(device), get_enc=True)\n",
    "        test_aug_embs_target.append(embs.detach().cpu())\n",
    "        \n",
    "        string_data = tokenizer.decode(batch[\"data\"].T[target_col_mask==0][1:]).split(\";\")\n",
    "        string_data = \";\".join(set([i.strip() for i in string_data]))\n",
    "        sb_embs = torch.tensor(sb_model.encode([string_data]))\n",
    "        test_aug_embs_sb.append(sb_embs)\n",
    "        \n",
    "test_aug_embs = torch.stack(test_aug_embs, dim=0)\n",
    "test_aug_embs_sb = torch.stack(test_aug_embs_sb, dim=0)\n",
    "test_aug_embs_target = torch.stack(test_aug_embs_target, dim=0)\n",
    "test_aug_labels = torch.tensor(test_aug_labels)\n",
    "test_aug_col_num = torch.tensor(test_aug_col_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs_correctness = []\n",
    "embs_sim_scores = []\n",
    "embs_sb_correctness = []\n",
    "embs_sb_sim_scores = []\n",
    "embs_target_correctness = []\n",
    "embs_target_sim_scores = []\n",
    "for idx in (test_aug_col_num<8).nonzero().reshape(-1):\n",
    "    embs_correctness.append(training_aug_labels[F.cosine_similarity(test_aug_embs[idx], training_aug_embs).argmax()] == test_aug_labels[idx])\n",
    "    embs_sim_scores.append(F.cosine_similarity(test_aug_embs[idx], training_aug_embs).max().item())\n",
    "    embs_sb_correctness.append(training_aug_labels[F.cosine_similarity(test_aug_embs_sb[idx], training_aug_embs_sb).argmax()] == test_aug_labels[idx])\n",
    "    embs_sb_sim_scores.append(F.cosine_similarity(test_aug_embs_sb[idx], training_aug_embs_sb).max().item())\n",
    "    embs_target_correctness.append(training_aug_labels[F.cosine_similarity(test_aug_embs_target[idx], training_aug_embs_target).argmax()] == test_aug_labels[idx])\n",
    "    embs_target_sim_scores.append(F.cosine_similarity(test_aug_embs_target[idx], training_aug_embs_target).max().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_correctness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs_correctness = torch.tensor(embs_correctness).reshape(-1)\n",
    "embs_sb_correctness = torch.tensor(embs_sb_correctness).reshape(-1)\n",
    "embs_target_correctness = torch.tensor(embs_target_correctness).reshape(-1)\n",
    "embs_sim_scores = torch.tensor(embs_sim_scores).reshape(-1)\n",
    "embs_sb_sim_scores = torch.tensor(embs_sb_sim_scores).reshape(-1)\n",
    "embs_target_sim_scores = torch.tensor(embs_target_sim_scores).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embs_correctness.sum(), embs_correctness.shape[0], embs_correctness.sum()/embs_correctness.shape[0], embs_sim_scores[embs_correctness].mean(), embs_sim_scores[~embs_correctness].mean())\n",
    "print(embs_sb_correctness.sum(), embs_sb_correctness.shape[0], embs_sb_correctness.sum()/embs_sb_correctness.shape[0], embs_sb_sim_scores[embs_sb_correctness].mean(), embs_sb_sim_scores[~embs_sb_correctness].mean())\n",
    "print(embs_target_correctness.sum(), embs_target_correctness.shape[0], embs_target_correctness.sum()/embs_target_correctness.shape[0], embs_target_sim_scores[embs_target_correctness].mean(), embs_target_sim_scores[~embs_target_correctness].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_correctness_tocheck = final_correctness[test_aug_col_num<8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embs_correctness.sum(), final_correctness_tocheck.sum(), (embs_correctness&final_correctness_tocheck).sum(), (embs_correctness&final_correctness_tocheck).sum()/len(embs_correctness))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_aug_col_num<8).sum()/len(test_aug_col_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs_correctness = []\n",
    "embs_sim_scores = []\n",
    "embs_sb_correctness = []\n",
    "embs_sb_sim_scores = []\n",
    "embs_target_correctness = []\n",
    "embs_target_sim_scores = []\n",
    "K = 1\n",
    "for idx in (test_aug_col_num<8).nonzero().reshape(-1):\n",
    "    values, indices = F.cosine_similarity(test_aug_embs[idx], training_aug_embs).topk(K)\n",
    "    if test_aug_labels[idx].item() in training_aug_labels[indices]:\n",
    "        embs_correctness.append(True)\n",
    "    else:\n",
    "        embs_correctness.append(False)\n",
    "    values, indices = F.cosine_similarity(test_aug_embs_sb[idx], training_aug_embs_sb).topk(K)\n",
    "    if test_aug_labels[idx].item() in training_aug_labels[indices]:\n",
    "        embs_sb_correctness.append(True)\n",
    "    else:\n",
    "        embs_sb_correctness.append(False)\n",
    "    values, indices = F.cosine_similarity(test_aug_embs_target[idx], training_aug_embs_target).topk(K)\n",
    "    if test_aug_labels[idx].item() in training_aug_labels[indices]:\n",
    "        embs_target_correctness.append(True)\n",
    "    else:\n",
    "        embs_target_correctness.append(False)\n",
    "embs_correctness = torch.tensor(embs_correctness).reshape(-1)\n",
    "embs_sb_correctness = torch.tensor(embs_sb_correctness).reshape(-1)\n",
    "embs_target_correctness = torch.tensor(embs_target_correctness).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K = 1\n",
    "print(embs_correctness.sum(), embs_correctness.shape[0], embs_correctness.sum()/embs_correctness.shape[0],)\n",
    "print(embs_sb_correctness.sum(), embs_sb_correctness.shape[0], embs_sb_correctness.sum()/embs_sb_correctness.shape[0])\n",
    "print(embs_target_correctness.sum(), embs_target_correctness.shape[0], embs_target_correctness.sum()/embs_target_correctness.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K = 3\n",
    "print(embs_correctness.sum(), embs_correctness.shape[0], embs_correctness.sum()/embs_correctness.shape[0],)\n",
    "print(embs_sb_correctness.sum(), embs_sb_correctness.shape[0], embs_sb_correctness.sum()/embs_sb_correctness.shape[0])\n",
    "print(embs_target_correctness.sum(), embs_target_correctness.shape[0], embs_target_correctness.sum()/embs_target_correctness.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K = 5\n",
    "print(embs_correctness.sum(), embs_correctness.shape[0], embs_correctness.sum()/embs_correctness.shape[0],)\n",
    "print(embs_sb_correctness.sum(), embs_sb_correctness.shape[0], embs_sb_correctness.sum()/embs_sb_correctness.shape[0])\n",
    "print(embs_target_correctness.sum(), embs_target_correctness.shape[0], embs_target_correctness.sum()/embs_target_correctness.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K = 10\n",
    "print(embs_correctness.sum(), embs_correctness.shape[0], embs_correctness.sum()/embs_correctness.shape[0],)\n",
    "print(embs_sb_correctness.sum(), embs_sb_correctness.shape[0], embs_sb_correctness.sum()/embs_sb_correctness.shape[0])\n",
    "print(embs_target_correctness.sum(), embs_target_correctness.shape[0], embs_target_correctness.sum()/embs_target_correctness.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K = 20\n",
    "print(embs_correctness.sum(), embs_correctness.shape[0], embs_correctness.sum()/embs_correctness.shape[0],)\n",
    "print(embs_sb_correctness.sum(), embs_sb_correctness.shape[0], embs_sb_correctness.sum()/embs_sb_correctness.shape[0])\n",
    "print(embs_target_correctness.sum(), embs_target_correctness.shape[0], embs_target_correctness.sum()/embs_target_correctness.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "max_tokens_per_col = 512//args.max_num_col\n",
    "\n",
    "before_aug_results = []\n",
    "after_aug_results = []\n",
    "best_aug_label = []\n",
    "gt_lable = []\n",
    "import time \n",
    "for K in [1, 3, 5, 10]:\n",
    "    \n",
    "    before_aug_results.append({})\n",
    "    after_aug_results.append({})\n",
    "    best_aug_label.append({})\n",
    "    gt_lable.append({})\n",
    "    \n",
    "    ts = time.time()\n",
    "    print(f\"============================K={K}=============================\")\n",
    "    model.load_state_dict(best_state_dict, strict=False)\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    verifier.load_state_dict(veri_state_dict)\n",
    "    verifier.eval()\n",
    "    verifier = verifier.to(device)\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    init_scores = []\n",
    "    init_correctness = []\n",
    "    final_scores = []\n",
    "    final_correctness = []\n",
    "    num_cols = []\n",
    "    total_steps = []\n",
    "    final_steps = []\n",
    "    correct_scores = defaultdict(list)\n",
    "    correct_steps = defaultdict(list)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "            target_col_mask = batch[\"target_col_mask\"].T\n",
    "            embs = test_embs[batch_idx][0].reshape(1,-1).to(device)\n",
    "            logits = test_logits[batch_idx][0].reshape(-1).to(device)\n",
    "            scores_init = verifier(embs)\n",
    "            max_score = -float(\"inf\")\n",
    "\n",
    "            init_scores.append(scores_init.item())\n",
    "            init_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            \n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            early_stop = False\n",
    "            i = 0\n",
    "            final_step = 0\n",
    "            total_steps.append(len(init_permutation_i) - max(len(init_permutation_i)//2, len(init_permutation_i)-3) -1)\n",
    "            num_cols.append(len(init_permutation_i))\n",
    "\n",
    "            for r in range(len(init_permutation_i), max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "                for x in itertools.combinations(init_permutation_i, r):\n",
    "                    if 0 not in x:\n",
    "                        continue\n",
    "                    logits_temp = test_logits[batch_idx][i].reshape(-1).to(device)\n",
    "                    embs_temp = test_embs[batch_idx][i].reshape(1,-1).to(device)\n",
    "                    scores_temp = verifier(embs_temp).item()\n",
    "                    predict_temp = logits_temp.argmax().item()\n",
    "                    i += 1\n",
    "                    if scores_temp > max_score:\n",
    "                        max_score = scores_temp\n",
    "                        logits = logits_temp.clone()\n",
    "                        final_step = len(init_permutation_i) - r\n",
    "                    if logits_temp.argmax().item() == batch[\"label\"].item():\n",
    "                        correct_scores[batch_idx].append(scores_temp)\n",
    "                        correct_steps[batch_idx].append(len(init_permutation_i) - r)\n",
    "            \n",
    "            # extra columns for those with less than max_num_col columns\n",
    "            if len(init_permutation_i) < args.max_num_col:\n",
    "                before_aug_results[-1][batch_idx] = logits.argmax().item()\n",
    "                gt_lable[-1][batch_idx] = batch[\"label\"].item()\n",
    "                \n",
    "                values, indices = F.cosine_similarity(test_aug_embs_sb[batch_idx], training_aug_embs_sb).topk(K)\n",
    "                for aug_idx in indices:\n",
    "                    aug_data = training_aug_data[aug_idx]\n",
    "                    aug_col_mask = training_aug_col_mask[aug_idx]\n",
    "                    aug_permutation_i = get_permutation(aug_col_mask)[: args.max_num_col - len(init_permutation_i)]\n",
    "                    aug_col_mask, aug_data = aug_col_mask[aug_col_mask<=max(aug_permutation_i)], aug_data[aug_col_mask<=max(aug_permutation_i)]\n",
    "                    assert len(aug_col_mask.unique()) == len(aug_permutation_i) and len(aug_col_mask) == len(aug_data)\n",
    "                    \n",
    "                    \n",
    "                    aug_permutation_i = torch.tensor(get_permutation(aug_col_mask)) + len(init_permutation_i) -1\n",
    "                    permutation_i = init_permutation_i + aug_permutation_i.tolist()\n",
    "                    max_num_cols_i = min(len(permutation_i), args.max_num_col)\n",
    "                    aug_data = torch.cat([batch[\"data\"].T, aug_data.reshape(1, -1)], dim=-1)\n",
    "                    aug_target_col_mask = torch.cat([target_col_mask, aug_col_mask.reshape(1, -1)], dim=-1)\n",
    "                    for r in range(max_num_cols_i, max(max_num_cols_i//2, max_num_cols_i-3), -1): # not \n",
    "                        for x in itertools.combinations(permutation_i, r):\n",
    "                            if 0 not in x:\n",
    "                                continue\n",
    "\n",
    "                            \n",
    "                            new_batch_data = []\n",
    "                            for col_i in x:\n",
    "                                if col_i == 0:\n",
    "                                    if len(new_batch_data) == 0:\n",
    "                                        cls_indexes_value = 0\n",
    "                                    else:\n",
    "                                        cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                                new_batch_data.append(aug_data[aug_target_col_mask==col_i][:max_tokens_per_col])\n",
    "                            new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                            cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                            logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                            scores_temp = verifier(embs_temp.reshape(1,-1)).item()\n",
    "                            predict_temp = logits_temp.argmax().item()\n",
    "                            if scores_temp > max_score:\n",
    "                                max_score = scores_temp\n",
    "                                logits = logits_temp.clone()\n",
    "                                final_step = len(init_permutation_i) - r\n",
    "                                after_aug_results[-1][batch_idx] = logits.argmax().item()\n",
    "                                best_aug_label[-1][batch_idx] = training_aug_labels[aug_idx]\n",
    "                            # if logits_temp.argmax().item() == batch[\"label\"].item():\n",
    "                            #     correct_scores[batch_idx].append(scores_temp)\n",
    "                            #     correct_steps[batch_idx].append(len(init_permutation_i) - r)\n",
    "\n",
    "\n",
    "            final_scores.append(max_score)\n",
    "            final_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "            final_steps.append(final_step)\n",
    "            labels_test.append(batch[\"label\"].cpu())\n",
    "            logits_test.append(logits.detach().cpu())\n",
    "        labels_test = torch.cat(labels_test, dim=0)\n",
    "        logits_test = torch.stack(logits_test, dim=0)\n",
    "        preds_test = torch.argmax(logits_test, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix, f1_score\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach().numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    ts_f1_full = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=None)\n",
    "    # full_f1_init\n",
    "    print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "    print(f\"time={time.time()-ts}\")\n",
    "\n",
    "    final_correctness = torch.tensor(final_correctness)\n",
    "    init_correctness = torch.tensor(init_correctness)\n",
    "    init_scores = torch.tensor(init_scores)\n",
    "    final_scores = torch.tensor(final_scores)\n",
    "    final_steps = torch.tensor(final_steps)\n",
    "    total_steps = torch.tensor(total_steps)\n",
    "    final_scores = F.sigmoid(torch.tensor(final_scores))\n",
    "    init_scores = F.sigmoid(torch.tensor(init_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "max_tokens_per_col = 512//args.max_num_col\n",
    "\n",
    "before_aug_results = []\n",
    "after_aug_results = []\n",
    "best_aug_label = []\n",
    "gt_lable = []\n",
    "import time \n",
    "for K in [1, 5, 10]:\n",
    "    \n",
    "    before_aug_results.append({})\n",
    "    after_aug_results.append({})\n",
    "    best_aug_label.append({})\n",
    "    gt_lable.append({})\n",
    "    \n",
    "    ts = time.time()\n",
    "    print(f\"============================K={K}=============================\")\n",
    "    model.load_state_dict(best_state_dict, strict=False)\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    verifier.load_state_dict(veri_state_dict)\n",
    "    verifier.eval()\n",
    "    verifier = verifier.to(device)\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    init_scores = []\n",
    "    init_correctness = []\n",
    "    final_scores = []\n",
    "    final_correctness = []\n",
    "    num_cols = []\n",
    "    total_steps = []\n",
    "    final_steps = []\n",
    "    correct_scores = defaultdict(list)\n",
    "    correct_steps = defaultdict(list)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "            target_col_mask = batch[\"target_col_mask\"].T\n",
    "            embs = test_embs[batch_idx][0].reshape(1,-1).to(device)\n",
    "            logits = test_logits[batch_idx][0].reshape(-1).to(device)\n",
    "            scores_init = verifier(embs)\n",
    "            max_score = -float(\"inf\")\n",
    "\n",
    "            init_scores.append(scores_init.item())\n",
    "            init_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            \n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            early_stop = False\n",
    "            i = 0\n",
    "            final_step = 0\n",
    "            total_steps.append(len(init_permutation_i) - max(len(init_permutation_i)//2, len(init_permutation_i)-3) -1)\n",
    "            num_cols.append(len(init_permutation_i))\n",
    "\n",
    "            for r in range(len(init_permutation_i), max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "                for x in itertools.combinations(init_permutation_i, r):\n",
    "                    if 0 not in x:\n",
    "                        continue\n",
    "                    logits_temp = test_logits[batch_idx][i].reshape(-1).to(device)\n",
    "                    embs_temp = test_embs[batch_idx][i].reshape(1,-1).to(device)\n",
    "                    scores_temp = verifier(embs_temp).item()\n",
    "                    predict_temp = logits_temp.argmax().item()\n",
    "                    i += 1\n",
    "                    if scores_temp > max_score:\n",
    "                        max_score = scores_temp\n",
    "                        logits = logits_temp.clone()\n",
    "                        final_step = len(init_permutation_i) - r\n",
    "                    if logits_temp.argmax().item() == batch[\"label\"].item():\n",
    "                        correct_scores[batch_idx].append(scores_temp)\n",
    "                        correct_steps[batch_idx].append(len(init_permutation_i) - r)\n",
    "            \n",
    "            # extra columns for those with less than max_num_col columns\n",
    "            if len(init_permutation_i) in [3,4,5]:\n",
    "                before_aug_results[-1][batch_idx] = logits.argmax().item()\n",
    "                gt_lable[-1][batch_idx] = batch[\"label\"].item()\n",
    "                after_aug_results[-1][batch_idx] = -1\n",
    "                best_aug_label[-1][batch_idx] = -1\n",
    "                \n",
    "                values, indices = F.cosine_similarity(test_aug_embs_sb[batch_idx], training_aug_embs_sb).topk(K)\n",
    "                for aug_idx in indices:\n",
    "                    aug_data = training_aug_data[aug_idx]\n",
    "                    aug_col_mask = training_aug_col_mask[aug_idx]\n",
    "                    aug_permutation_i = get_permutation(aug_col_mask)[: args.max_num_col - len(init_permutation_i)]\n",
    "                    aug_col_mask, aug_data = aug_col_mask[aug_col_mask<=max(aug_permutation_i)], aug_data[aug_col_mask<=max(aug_permutation_i)]\n",
    "                    assert len(aug_col_mask.unique()) == len(aug_permutation_i) and len(aug_col_mask) == len(aug_data)\n",
    "                    \n",
    "                    \n",
    "                    aug_permutation_i = torch.tensor(get_permutation(aug_col_mask)) + len(init_permutation_i) -1\n",
    "                    permutation_i = init_permutation_i + aug_permutation_i.tolist()\n",
    "                    max_num_cols_i = min(len(permutation_i), args.max_num_col)\n",
    "                    aug_data = torch.cat([batch[\"data\"].T, aug_data.reshape(1, -1)], dim=-1)\n",
    "                    aug_target_col_mask = torch.cat([target_col_mask, aug_col_mask.reshape(1, -1)], dim=-1)\n",
    "                    for r in range(max_num_cols_i, max(max_num_cols_i//2, max_num_cols_i-3), -1): # not \n",
    "                        for x in itertools.combinations(permutation_i, r):\n",
    "                            if 0 not in x:\n",
    "                                continue\n",
    "\n",
    "                            \n",
    "                            new_batch_data = []\n",
    "                            for col_i in x:\n",
    "                                if col_i == 0:\n",
    "                                    if len(new_batch_data) == 0:\n",
    "                                        cls_indexes_value = 0\n",
    "                                    else:\n",
    "                                        cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                                new_batch_data.append(aug_data[aug_target_col_mask==col_i][:max_tokens_per_col])\n",
    "                            new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                            cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                            logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                            scores_temp = verifier(embs_temp.reshape(1,-1)).item()\n",
    "                            predict_temp = logits_temp.argmax().item()\n",
    "                            \n",
    "                            if scores_temp > max_score:\n",
    "                                max_score = scores_temp\n",
    "                                logits = logits_temp.clone()\n",
    "                                final_step = len(init_permutation_i) - r\n",
    "                                after_aug_results[-1][batch_idx] = logits.argmax().item()\n",
    "                                best_aug_label[-1][batch_idx] = training_aug_labels[aug_idx]\n",
    "                            # if logits_temp.argmax().item() == batch[\"label\"].item():\n",
    "                            #     correct_scores[batch_idx].append(scores_temp)\n",
    "                            #     correct_steps[batch_idx].append(len(init_permutation_i) - r)\n",
    "\n",
    "\n",
    "            final_scores.append(max_score)\n",
    "            final_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "            final_steps.append(final_step)\n",
    "            labels_test.append(batch[\"label\"].cpu())\n",
    "            logits_test.append(logits.detach().cpu())\n",
    "        labels_test = torch.cat(labels_test, dim=0)\n",
    "        logits_test = torch.stack(logits_test, dim=0)\n",
    "        preds_test = torch.argmax(logits_test, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix, f1_score\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach().numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    ts_f1_full = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=None)\n",
    "    # full_f1_init\n",
    "    print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "    print(f\"time={time.time()-ts}\")\n",
    "\n",
    "    final_correctness = torch.tensor(final_correctness)\n",
    "    init_correctness = torch.tensor(init_correctness)\n",
    "    init_scores = torch.tensor(init_scores)\n",
    "    final_scores = torch.tensor(final_scores)\n",
    "    final_steps = torch.tensor(final_steps)\n",
    "    total_steps = torch.tensor(total_steps)\n",
    "    final_scores = F.sigmoid(torch.tensor(final_scores))\n",
    "    init_scores = F.sigmoid(torch.tensor(init_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "max_tokens_per_col = 512//args.max_num_col\n",
    "\n",
    "before_aug_results = []\n",
    "after_aug_results = []\n",
    "best_aug_label = []\n",
    "gt_lable = []\n",
    "import time \n",
    "for K in [1]:\n",
    "    \n",
    "    before_aug_results.append({})\n",
    "    after_aug_results.append({})\n",
    "    best_aug_label.append({})\n",
    "    gt_lable.append({})\n",
    "    \n",
    "    ts = time.time()\n",
    "    print(f\"============================K={K}=============================\")\n",
    "    model.load_state_dict(best_state_dict, strict=False)\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    verifier.load_state_dict(veri_state_dict)\n",
    "    verifier.eval()\n",
    "    verifier = verifier.to(device)\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    init_scores = []\n",
    "    init_correctness = []\n",
    "    final_scores = []\n",
    "    final_correctness = []\n",
    "    num_cols = []\n",
    "    total_steps = []\n",
    "    final_steps = []\n",
    "    correct_scores = defaultdict(list)\n",
    "    correct_steps = defaultdict(list)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "            target_col_mask = batch[\"target_col_mask\"].T\n",
    "            embs = test_embs[batch_idx][0].reshape(1,-1).to(device)\n",
    "            logits = test_logits[batch_idx][0].reshape(-1).to(device)\n",
    "            scores_init = verifier(embs)\n",
    "            max_score = -float(\"inf\")\n",
    "\n",
    "            init_scores.append(scores_init.item())\n",
    "            init_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            \n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            early_stop = False\n",
    "            i = 0\n",
    "            final_step = 0\n",
    "            total_steps.append(len(init_permutation_i) - max(len(init_permutation_i)//2, len(init_permutation_i)-3) -1)\n",
    "            num_cols.append(len(init_permutation_i))\n",
    "\n",
    "            for r in range(len(init_permutation_i), max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "                for x in itertools.combinations(init_permutation_i, r):\n",
    "                    if 0 not in x:\n",
    "                        continue\n",
    "                    logits_temp = test_logits[batch_idx][i].reshape(-1).to(device)\n",
    "                    embs_temp = test_embs[batch_idx][i].reshape(1,-1).to(device)\n",
    "                    scores_temp = verifier(embs_temp).item()\n",
    "                    predict_temp = logits_temp.argmax().item()\n",
    "                    i += 1\n",
    "                    if scores_temp > max_score:\n",
    "                        max_score = scores_temp\n",
    "                        logits = logits_temp.clone()\n",
    "                        final_step = len(init_permutation_i) - r\n",
    "                    if logits_temp.argmax().item() == batch[\"label\"].item():\n",
    "                        correct_scores[batch_idx].append(scores_temp)\n",
    "                        correct_steps[batch_idx].append(len(init_permutation_i) - r)\n",
    "            \n",
    "            # extra columns for those with less than max_num_col columns\n",
    "            if len(init_permutation_i) in [4, 6]:\n",
    "                before_aug_results[-1][batch_idx] = logits.argmax().item()\n",
    "                gt_lable[-1][batch_idx] = batch[\"label\"].item()\n",
    "                after_aug_results[-1][batch_idx] = -1\n",
    "                best_aug_label[-1][batch_idx] = -1\n",
    "                \n",
    "                values, indices = F.cosine_similarity(test_aug_embs_sb[batch_idx], training_aug_embs_sb).topk(K)\n",
    "                for aug_idx in indices:\n",
    "                    aug_data = training_aug_data[aug_idx]\n",
    "                    aug_col_mask = training_aug_col_mask[aug_idx]\n",
    "                    aug_permutation_i = get_permutation(aug_col_mask)[: args.max_num_col - len(init_permutation_i)]\n",
    "                    aug_col_mask, aug_data = aug_col_mask[aug_col_mask<=max(aug_permutation_i)], aug_data[aug_col_mask<=max(aug_permutation_i)]\n",
    "                    assert len(aug_col_mask.unique()) == len(aug_permutation_i) and len(aug_col_mask) == len(aug_data)\n",
    "                    \n",
    "                    \n",
    "                    aug_permutation_i = torch.tensor(get_permutation(aug_col_mask)) + len(init_permutation_i) -1\n",
    "                    permutation_i = init_permutation_i + aug_permutation_i.tolist()\n",
    "                    max_num_cols_i = min(len(permutation_i), args.max_num_col)\n",
    "                    aug_data = torch.cat([batch[\"data\"].T, aug_data.reshape(1, -1)], dim=-1)\n",
    "                    aug_target_col_mask = torch.cat([target_col_mask, aug_col_mask.reshape(1, -1)], dim=-1)\n",
    "                    for r in range(max_num_cols_i, max(max_num_cols_i//2, max_num_cols_i-3), -1): # not \n",
    "                        for x in itertools.combinations(permutation_i, r):\n",
    "                            if 0 not in x:\n",
    "                                continue\n",
    "\n",
    "                            \n",
    "                            new_batch_data = []\n",
    "                            for col_i in x:\n",
    "                                if col_i == 0:\n",
    "                                    if len(new_batch_data) == 0:\n",
    "                                        cls_indexes_value = 0\n",
    "                                    else:\n",
    "                                        cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                                new_batch_data.append(aug_data[aug_target_col_mask==col_i][:max_tokens_per_col])\n",
    "                            new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                            cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                            logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                            scores_temp = verifier(embs_temp.reshape(1,-1)).item()\n",
    "                            predict_temp = logits_temp.argmax().item()\n",
    "                            \n",
    "                            if scores_temp > max_score:\n",
    "                                max_score = scores_temp\n",
    "                                logits = logits_temp.clone()\n",
    "                                final_step = len(init_permutation_i) - r\n",
    "                                after_aug_results[-1][batch_idx] = logits.argmax().item()\n",
    "                                best_aug_label[-1][batch_idx] = training_aug_labels[aug_idx]\n",
    "                            # if logits_temp.argmax().item() == batch[\"label\"].item():\n",
    "                            #     correct_scores[batch_idx].append(scores_temp)\n",
    "                            #     correct_steps[batch_idx].append(len(init_permutation_i) - r)\n",
    "\n",
    "\n",
    "            final_scores.append(max_score)\n",
    "            final_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "            final_steps.append(final_step)\n",
    "            labels_test.append(batch[\"label\"].cpu())\n",
    "            logits_test.append(logits.detach().cpu())\n",
    "        labels_test = torch.cat(labels_test, dim=0)\n",
    "        logits_test = torch.stack(logits_test, dim=0)\n",
    "        preds_test = torch.argmax(logits_test, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix, f1_score\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach().numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    ts_f1_full = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=None)\n",
    "    # full_f1_init\n",
    "    print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "    print(f\"time={time.time()-ts}\")\n",
    "\n",
    "    final_correctness = torch.tensor(final_correctness)\n",
    "    init_correctness = torch.tensor(init_correctness)\n",
    "    init_scores = torch.tensor(init_scores)\n",
    "    final_scores = torch.tensor(final_scores)\n",
    "    final_steps = torch.tensor(final_steps)\n",
    "    total_steps = torch.tensor(total_steps)\n",
    "    final_scores = F.sigmoid(torch.tensor(final_scores))\n",
    "    init_scores = F.sigmoid(torch.tensor(init_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(torch.tensor(list(before_aug_results[0].values())))/len(test_dataloader_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_aug_results_1 = torch.tensor(list(before_aug_results[0].values()))\n",
    "after_aug_results_1 = torch.tensor(list(after_aug_results[0].values()))\n",
    "gt_lable_1 = torch.tensor(list(gt_lable[0].values()))\n",
    "best_aug_label_1 = torch.tensor(list(best_aug_label[0].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "after_aug_results_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(before_aug_results_1 == gt_lable_1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(after_aug_results_1 == gt_lable_1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((after_aug_results_1 == gt_lable_1)|((after_aug_results_1==-1) & (before_aug_results_1 == gt_lable_1))).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((after_aug_results_1==-1) & (before_aug_results_1 == gt_lable_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((best_aug_label_1 == gt_lable_1).sum(), (best_aug_label_1 == gt_lable_1).sum()/len(best_aug_label_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "max_tokens_per_col = 512//args.max_num_col\n",
    "\n",
    "for K in [1, 3, 5, 10]:\n",
    "    ts = time.time()\n",
    "    print(f\"============================K={K}=============================\")\n",
    "    model.load_state_dict(best_state_dict, strict=False)\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    verifier.load_state_dict(veri_state_dict)\n",
    "    verifier.eval()\n",
    "    verifier = verifier.to(device)\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    init_scores = []\n",
    "    init_correctness = []\n",
    "    final_scores = []\n",
    "    final_correctness = []\n",
    "    num_cols = []\n",
    "    total_steps = []\n",
    "    final_steps = []\n",
    "    correct_scores = defaultdict(list)\n",
    "    correct_steps = defaultdict(list)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "            target_col_mask = batch[\"target_col_mask\"].T\n",
    "            embs = test_embs[batch_idx][0].reshape(1,-1).to(device)\n",
    "            logits = test_logits[batch_idx][0].reshape(-1).to(device)\n",
    "            scores_init = verifier(embs)\n",
    "            max_score = -float(\"inf\")\n",
    "\n",
    "            init_scores.append(scores_init.item())\n",
    "            init_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            \n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            early_stop = False\n",
    "            i = 0\n",
    "            final_step = 0\n",
    "            total_steps.append(len(init_permutation_i) - max(len(init_permutation_i)//2, len(init_permutation_i)-3) -1)\n",
    "            num_cols.append(len(init_permutation_i))\n",
    "\n",
    "            for r in range(len(init_permutation_i), max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "                for x in itertools.combinations(init_permutation_i, r):\n",
    "                    if 0 not in x:\n",
    "                        continue\n",
    "                    logits_temp = test_logits[batch_idx][i].reshape(-1).to(device)\n",
    "                    embs_temp = test_embs[batch_idx][i].reshape(1,-1).to(device)\n",
    "                    scores_temp = verifier(embs_temp).item()\n",
    "                    predict_temp = logits_temp.argmax().item()\n",
    "                    i += 1\n",
    "                    if scores_temp > max_score:\n",
    "                        max_score = scores_temp\n",
    "                        logits = logits_temp.clone()\n",
    "                        final_step = len(init_permutation_i) - r\n",
    "                    if logits_temp.argmax().item() == batch[\"label\"].item():\n",
    "                        correct_scores[batch_idx].append(scores_temp)\n",
    "                        correct_steps[batch_idx].append(len(init_permutation_i) - r)\n",
    "            \n",
    "            # extra columns for those with less than max_num_col columns\n",
    "            if len(init_permutation_i) < args.max_num_col:\n",
    "                values, indices = F.cosine_similarity(test_aug_embs_sb[batch_idx], training_aug_embs_sb).topk(K)\n",
    "                for aug_idx in indices:\n",
    "                    aug_data = training_aug_data[aug_idx]\n",
    "                    aug_col_mask = training_aug_col_mask[aug_idx]\n",
    "                    # aug_permutation_i = get_permutation(aug_col_mask)[: args.max_num_col - len(init_permutation_i)]\n",
    "                    aug_permutation_all = get_permutation(aug_col_mask)\n",
    "                    \n",
    "                    aug_col_mask, aug_data = aug_col_mask[aug_col_mask<=max(aug_permutation_i)], aug_data[aug_col_mask<=max(aug_permutation_i)]\n",
    "                    assert len(aug_col_mask.unique()) == len(aug_permutation_i) and len(aug_col_mask) == len(aug_data)\n",
    "                    \n",
    "                    \n",
    "                    aug_permutation_i = torch.tensor(get_permutation(aug_col_mask)) + len(init_permutation_i) -1\n",
    "                    permutation_i = init_permutation_i + aug_permutation_i.tolist()\n",
    "                    max_num_cols_i = min(len(permutation_i), args.max_num_col)\n",
    "                    aug_data = torch.cat([batch[\"data\"].T, aug_data.reshape(1, -1)], dim=-1)\n",
    "                    aug_target_col_mask = torch.cat([target_col_mask, aug_col_mask.reshape(1, -1)], dim=-1)\n",
    "                    for r in range(max_num_cols_i, max(max_num_cols_i//2, max_num_cols_i-3), -1): # not \n",
    "                        for x in itertools.combinations(permutation_i, r):\n",
    "                            if 0 not in x:\n",
    "                                continue\n",
    "\n",
    "                            \n",
    "                            new_batch_data = []\n",
    "                            for col_i in x:\n",
    "                                if col_i == 0:\n",
    "                                    if len(new_batch_data) == 0:\n",
    "                                        cls_indexes_value = 0\n",
    "                                    else:\n",
    "                                        cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                                new_batch_data.append(aug_data[aug_target_col_mask==col_i][:max_tokens_per_col])\n",
    "                            new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                            cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                            logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                            scores_temp = verifier(embs_temp.reshape(1,-1)).item()\n",
    "                            predict_temp = logits_temp.argmax().item()\n",
    "                            if scores_temp > max_score:\n",
    "                                max_score = scores_temp\n",
    "                                logits = logits_temp.clone()\n",
    "                                final_step = len(init_permutation_i) - r\n",
    "                            # if logits_temp.argmax().item() == batch[\"label\"].item():\n",
    "                            #     correct_scores[batch_idx].append(scores_temp)\n",
    "                            #     correct_steps[batch_idx].append(len(init_permutation_i) - r)\n",
    "\n",
    "\n",
    "            final_scores.append(max_score)\n",
    "            final_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "            final_steps.append(final_step)\n",
    "            labels_test.append(batch[\"label\"].cpu())\n",
    "            logits_test.append(logits.detach().cpu())\n",
    "        labels_test = torch.cat(labels_test, dim=0)\n",
    "        logits_test = torch.stack(logits_test, dim=0)\n",
    "        preds_test = torch.argmax(logits_test, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix, f1_score\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach().numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    ts_f1_full = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=None)\n",
    "    # full_f1_init\n",
    "    print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "    print(f\"time={time.time()-ts}\")\n",
    "\n",
    "    final_correctness = torch.tensor(final_correctness)\n",
    "    init_correctness = torch.tensor(init_correctness)\n",
    "    init_scores = torch.tensor(init_scores)\n",
    "    final_scores = torch.tensor(final_scores)\n",
    "    final_steps = torch.tensor(final_steps)\n",
    "    total_steps = torch.tensor(total_steps)\n",
    "    final_scores = F.sigmoid(torch.tensor(final_scores))\n",
    "    init_scores = F.sigmoid(torch.tensor(init_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_permutation_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_col_mask.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_permutation_i[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_cols=0 ts_micro_f1=1.0000, ts_macro_f1=1.0000\n",
    "# num_cols=2 ts_micro_f1=0.6364, ts_macro_f1=0.3241\n",
    "# num_cols=3 ts_micro_f1=0.5181, ts_macro_f1=0.1611\n",
    "# num_cols=4 ts_micro_f1=0.5909, ts_macro_f1=0.2328\n",
    "# num_cols=5 ts_micro_f1=0.5455, ts_macro_f1=0.2550\n",
    "# num_cols=6 ts_micro_f1=0.5733, ts_macro_f1=0.2734\n",
    "# num_cols=7 ts_micro_f1=0.5146, ts_macro_f1=0.2800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = torch.tensor(num_cols)\n",
    "for n_col in num_cols.unique().tolist():\n",
    "    mask = num_cols == n_col\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach()[mask].numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    \n",
    "    print(\"num_cols={} ts_micro_f1={:.4f}, ts_macro_f1={:.4f}, average_final_score={:.4f}\".format(n_col, ts_micro_f1, ts_macro_f1, final_scores[mask].mean().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_check_idx = []\n",
    "for i in (torch.tensor(final_correctness) == False).nonzero().reshape(-1).tolist():\n",
    "    if len(correct_scores[i])>0:\n",
    "        to_check_idx.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_check_idx[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_check_idx_init = []\n",
    "for i in (torch.tensor(final_correctness) == False).nonzero().reshape(-1).tolist():\n",
    "    if init_correctness[i] == True:\n",
    "        to_check_idx_init.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_check_idx_init[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[34, 52] in to_check_idx_init[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set([34, 52]).issubset(set(to_check_idx_init[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(to_check_idx_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_idx = 53\n",
    "print(final_scores[target_idx], final_correctness[target_idx], init_correctness[target_idx], init_scores[target_idx], num_cols[target_idx], \n",
    "      final_steps[target_idx], total_steps[target_idx], labels_test[target_idx], preds_test[target_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.sigmoid(torch.tensor(correct_scores[target_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(final_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(np.array(final_steps)/np.array(total_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(correct_scores), len(test_dataloader_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(torch.tensor(final_steps)[final_correctness==True]/torch.tensor(total_steps)[final_correctness==True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(torch.tensor(num_cols)[final_scores>0.999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = torch.tensor(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_col in num_cols.unique():\n",
    "    print(num_col, ((final_scores>0.999)&(num_cols==num_col)).sum()/(num_cols==num_col).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(torch.tensor(num_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(torch.tensor(num_cols)<8).sum()/len(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(torch.tensor(final_steps)[final_scores>0.999]/torch.tensor(total_steps)[final_scores>0.999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(final_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(F.sigmoid(final_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_f1_full - full_f1_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_init_mask = torch.tensor(init_correctness)\n",
    "correct_msp_mask = torch.tensor(final_correctness)\n",
    "init_scores = torch.tensor(init_scores)\n",
    "final_scores = torch.tensor(final_scores)\n",
    "for threshold in [0.9, 0.99, 0.999, 0.9999]:\n",
    "    uncertain_init_mask = init_scores < threshold\n",
    "    condition_mask = ~uncertain_init_mask\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    print(\"Init\")\n",
    "    # init prediction\n",
    "    print((condition_mask&correct_init_mask).sum().item(), \n",
    "        (condition_mask).sum().item(), \n",
    "        (condition_mask&correct_init_mask).sum().item()/(condition_mask).sum().item())\n",
    "    # init prediction\n",
    "    print((~condition_mask&correct_init_mask).sum().item(), \n",
    "        (~condition_mask).sum().item(), \n",
    "       (~condition_mask&correct_init_mask).sum().item()/(~condition_mask).sum().item())\n",
    "    print(\"MSP\")\n",
    "    # msp prediction\n",
    "    print((condition_mask&correct_msp_mask).sum().item(), \n",
    "        (condition_mask).sum().item(), \n",
    "        (condition_mask&correct_msp_mask).sum().item()/(condition_mask).sum().item())\n",
    "    # msp prediction\n",
    "    print((~condition_mask&correct_msp_mask).sum().item(), \n",
    "        (~condition_mask).sum().item(), \n",
    "        (~condition_mask&correct_msp_mask).sum().item()/(~condition_mask).sum().item())\n",
    "    print(\"MSP & Init\")\n",
    "    print(((condition_mask&correct_init_mask)&(condition_mask&correct_msp_mask)).sum().item())\n",
    "    # print(((~(init_target_mask&(~uncertain_init_mask & ~uncertain_target_mask))& correct_msp_mask)&(~(init_target_mask&(~uncertain_init_mask & ~uncertain_target_mask))& correct_init_mask)).sum().item())\n",
    "    print(((condition_mask&correct_init_mask)|(condition_mask&correct_msp_mask)).sum().item(),\n",
    "          (condition_mask).sum().item(), \n",
    "          ((condition_mask&correct_init_mask)|(condition_mask&correct_msp_mask)).sum().item()/(condition_mask).sum().item())\n",
    "    print(((~condition_mask&correct_init_mask)|(~condition_mask&correct_msp_mask)).sum().item(),\n",
    "          (~condition_mask).sum().item(), \n",
    "          ((~condition_mask&correct_init_mask)|(~condition_mask&correct_msp_mask)).sum().item()/(~condition_mask).sum().item())\n",
    "    # print(\"Permutation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((final_scores>0.999).sum(), (final_scores>0.999).sum()/len(final_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((final_scores>0.999).sum(), len(final_scores), (final_scores>0.999).sum()/len(final_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = None\n",
    "init_max_col_length = 8\n",
    "test_dataset_iter_extra = GittablesTablewiseIterateDataset(cv=cv,\n",
    "                            split=\"test\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only='all' not in task,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\",\n",
    "                            max_unlabeled=16,\n",
    "                            adaptive_max_length=False,)\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "# test_dataloader_iter_extra = DataLoader(test_dataset_iter_extra,\n",
    "#                                 batch_size=1,\n",
    "#                             #   collate_fn=collate_fn)\n",
    "#                             collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_iter_extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols_extra = []\n",
    "for i in range(len(test_dataset_iter_extra)):\n",
    "    init_permutation_i = get_permutation(test_dataset_iter_extra[i][\"target_col_mask\"].T)\n",
    "    num_cols_extra.append(len(init_permutation_i))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_permutation_i, init_permutation_i_extra = init_permutation_i[:8], init_permutation_i[8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(num_cols_extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "\n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "verifier.load_state_dict(veri_state_dict)\n",
    "verifier.eval()\n",
    "verifier = verifier.to(device)\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "init_scores = []\n",
    "init_correctness = []\n",
    "final_scores = []\n",
    "final_correctness = []\n",
    "num_cols = []\n",
    "total_steps = []\n",
    "final_steps = []\n",
    "correct_scores = defaultdict(list)\n",
    "correct_steps = defaultdict(list)\n",
    "init_max_col_length = 8\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in enumerate(test_dataset_iter_extra):\n",
    "        target_col_mask = batch[\"target_col_mask\"].T\n",
    "        embs = test_embs[batch_idx][0].reshape(1,-1).to(device)\n",
    "        logits = test_logits[batch_idx][0].reshape(-1).to(device)\n",
    "        scores_init = verifier(embs)\n",
    "        max_score = -float(\"inf\")\n",
    "\n",
    "        init_scores.append(scores_init.item())\n",
    "        init_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "        init_permutation_i = get_permutation(target_col_mask)\n",
    "        init_permutation_i, init_permutation_i_extra = init_permutation_i[:init_max_col_length], init_permutation_i[init_max_col_length:]\n",
    "        \n",
    "        col_idx_set = target_col_mask.unique().tolist()\n",
    "        early_stop = False\n",
    "        i = 0\n",
    "        final_step = 0\n",
    "        total_steps.append(len(init_permutation_i) - max(len(init_permutation_i)//2, len(init_permutation_i)-3) -1)\n",
    "        num_cols.append(len(init_permutation_i))\n",
    "        enough = False\n",
    "        for r in range(len(init_permutation_i),  max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "            for x in itertools.combinations(init_permutation_i, r):\n",
    "                if 0 not in x:\n",
    "                    continue\n",
    "                logits_temp = test_logits[batch_idx][i].reshape(-1).to(device)\n",
    "                embs_temp = test_embs[batch_idx][i].reshape(1,-1).to(device)\n",
    "                scores_temp = verifier(embs_temp).item()\n",
    "                predict_temp = logits_temp.argmax().item()\n",
    "                i += 1\n",
    "                if scores_temp > max_score:\n",
    "                    max_score = scores_temp\n",
    "                    logits = logits_temp.clone()\n",
    "                    final_step = len(init_permutation_i) - r\n",
    "                if logits_temp.argmax().item() == batch[\"label\"].item():\n",
    "                    correct_scores[batch_idx].append(scores_temp)\n",
    "                    correct_steps[batch_idx].append(len(init_permutation_i) - r)\n",
    "                if F.sigmoid(torch.tensor(max_score)).item() > 0.999:\n",
    "                    enough = True\n",
    "            if enough:\n",
    "                break  \n",
    "        if not enough and len(init_permutation_i_extra)>0:\n",
    "            for new_col_idx in init_permutation_i_extra:\n",
    "                init_permutation_i_new = init_permutation_i + [new_col_idx]\n",
    "                for r in range(len(init_permutation_i),  max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "                    for x in itertools.combinations(init_permutation_i_new, r):\n",
    "                        if 0 not in x or new_col_idx not in x:\n",
    "                            continue\n",
    "                        new_batch_data = []\n",
    "                        for col_i in x:\n",
    "                            if col_i == 0:\n",
    "                                if len(new_batch_data) == 0:\n",
    "                                    cls_indexes_value = 0\n",
    "                                else:\n",
    "                                    cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                            new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                        new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                        cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                        logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                        scores_temp = verifier(embs_temp.reshape(1,-1)).item()\n",
    "                        predict_temp = logits_temp.argmax().item()\n",
    "                        \n",
    "                        if scores_temp > max_score:\n",
    "                            max_score = scores_temp\n",
    "                            logits = logits_temp.clone()\n",
    "                            final_step = len(init_permutation_i) - r\n",
    "                        if logits_temp.argmax().item() == batch[\"label\"].item():\n",
    "                            correct_scores[batch_idx].append(scores_temp)\n",
    "                            correct_steps[batch_idx].append(len(init_permutation_i) - r)\n",
    "                        if F.sigmoid(torch.tensor(max_score)).item() > 0.999:\n",
    "                            enough = True\n",
    "                    if enough:\n",
    "                        break\n",
    "                if enough:\n",
    "                    break\n",
    "                \n",
    "                \n",
    "        final_scores.append(max_score)\n",
    "        final_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "        final_steps.append(final_step)\n",
    "        labels_test.append(batch[\"label\"].cpu())\n",
    "        logits_test.append(logits.detach().cpu())\n",
    "    labels_test = torch.cat(labels_test, dim=0)\n",
    "    logits_test = torch.stack(logits_test, dim=0)\n",
    "    preds_test = torch.argmax(logits_test, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "ts_f1_full = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=None)\n",
    "# full_f1_init\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "final_correctness = torch.tensor(final_correctness)\n",
    "init_correctness = torch.tensor(init_correctness)\n",
    "init_scores = torch.tensor(init_scores)\n",
    "final_scores = torch.tensor(final_scores)\n",
    "final_steps = torch.tensor(final_steps)\n",
    "total_steps = torch.tensor(total_steps)\n",
    "final_scores = F.sigmoid(torch.tensor(final_scores))\n",
    "init_scores = F.sigmoid(torch.tensor(init_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "\n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "verifier.load_state_dict(veri_state_dict)\n",
    "verifier.eval()\n",
    "verifier = verifier.to(device)\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "init_scores = []\n",
    "init_correctness = []\n",
    "final_scores = []\n",
    "final_correctness = []\n",
    "num_cols = []\n",
    "total_steps = []\n",
    "final_steps = []\n",
    "correct_scores = defaultdict(list)\n",
    "correct_steps = defaultdict(list)\n",
    "init_max_col_length = 8\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in enumerate(test_dataset_iter_extra):\n",
    "        target_col_mask = batch[\"target_col_mask\"].T\n",
    "        embs = test_embs[batch_idx][0].reshape(1,-1).to(device)\n",
    "        logits = test_logits[batch_idx][0].reshape(-1).to(device)\n",
    "        scores_init = verifier(embs)\n",
    "        max_score = -float(\"inf\")\n",
    "\n",
    "        init_scores.append(scores_init.item())\n",
    "        init_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "        init_permutation_i = get_permutation(target_col_mask)\n",
    "        init_permutation_i, init_permutation_i_extra = init_permutation_i[:init_max_col_length], init_permutation_i[init_max_col_length:]\n",
    "        \n",
    "        col_idx_set = target_col_mask.unique().tolist()\n",
    "        early_stop = False\n",
    "        i = 0\n",
    "        final_step = 0\n",
    "        total_steps.append(len(init_permutation_i) - max(len(init_permutation_i)//2, len(init_permutation_i)-3) -1)\n",
    "        num_cols.append(len(init_permutation_i))\n",
    "        enough = False\n",
    "        for r in range(len(init_permutation_i),  max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "            for x in itertools.combinations(init_permutation_i, r):\n",
    "                if 0 not in x:\n",
    "                    continue\n",
    "                logits_temp = test_logits[batch_idx][i].reshape(-1).to(device)\n",
    "                embs_temp = test_embs[batch_idx][i].reshape(1,-1).to(device)\n",
    "                scores_temp = verifier(embs_temp).item()\n",
    "                predict_temp = logits_temp.argmax().item()\n",
    "                i += 1\n",
    "                if scores_temp > max_score:\n",
    "                    max_score = scores_temp\n",
    "                    logits = logits_temp.clone()\n",
    "                    final_step = len(init_permutation_i) - r\n",
    "                if logits_temp.argmax().item() == batch[\"label\"].item():\n",
    "                    correct_scores[batch_idx].append(scores_temp)\n",
    "                    correct_steps[batch_idx].append(len(init_permutation_i) - r)\n",
    "\n",
    "        if len(init_permutation_i_extra)>0:\n",
    "            for new_col_idx in init_permutation_i_extra:\n",
    "                init_permutation_i_new = init_permutation_i + [new_col_idx]\n",
    "                for r in range(len(init_permutation_i),  max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "                    for x in itertools.combinations(init_permutation_i_new, r):\n",
    "                        if 0 not in x or new_col_idx not in x:\n",
    "                            continue\n",
    "                        new_batch_data = []\n",
    "                        for col_i in x:\n",
    "                            if col_i == 0:\n",
    "                                if len(new_batch_data) == 0:\n",
    "                                    cls_indexes_value = 0\n",
    "                                else:\n",
    "                                    cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                            new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                        new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                        cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                        logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                        scores_temp = verifier(embs_temp.reshape(1,-1)).item()\n",
    "                        predict_temp = logits_temp.argmax().item()\n",
    "                        \n",
    "                        if scores_temp > max_score:\n",
    "                            max_score = scores_temp\n",
    "                            logits = logits_temp.clone()\n",
    "                            final_step = len(init_permutation_i) - r\n",
    "                        if logits_temp.argmax().item() == batch[\"label\"].item():\n",
    "                            correct_scores[batch_idx].append(scores_temp)\n",
    "                            correct_steps[batch_idx].append(len(init_permutation_i) - r)\n",
    "\n",
    "                \n",
    "                \n",
    "        final_scores.append(max_score)\n",
    "        final_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "        final_steps.append(final_step)\n",
    "        labels_test.append(batch[\"label\"].cpu())\n",
    "        logits_test.append(logits.detach().cpu())\n",
    "    labels_test = torch.cat(labels_test, dim=0)\n",
    "    logits_test = torch.stack(logits_test, dim=0)\n",
    "    preds_test = torch.argmax(logits_test, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "ts_f1_full = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=None)\n",
    "# full_f1_init\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "final_correctness = torch.tensor(final_correctness)\n",
    "init_correctness = torch.tensor(init_correctness)\n",
    "init_scores = torch.tensor(init_scores)\n",
    "final_scores = torch.tensor(final_scores)\n",
    "final_steps = torch.tensor(final_steps)\n",
    "total_steps = torch.tensor(total_steps)\n",
    "final_scores = F.sigmoid(torch.tensor(final_scores))\n",
    "init_scores = F.sigmoid(torch.tensor(init_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "for max_unlabeled in [16, 32, 64, 128]:\n",
    "    print(f\"============================max_unlabeled={max_unlabeled}===============================\")\n",
    "    test_dataset_iter_extra = GittablesTablewiseIterateDataset(cv=cv,\n",
    "                                split=\"test\", src=src,\n",
    "                                tokenizer=tokenizer,\n",
    "                                max_length=max_length,\n",
    "                                gt_only='all' not in task,\n",
    "                                device=device,\n",
    "                                base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                                small_tag=\"semi1\",\n",
    "                                max_unlabeled=max_unlabeled,\n",
    "                                adaptive_max_length=False,)\n",
    "    model.load_state_dict(best_state_dict, strict=False)\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    verifier.load_state_dict(veri_state_dict)\n",
    "    verifier.eval()\n",
    "    verifier = verifier.to(device)\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    init_scores = []\n",
    "    init_correctness = []\n",
    "    final_scores = []\n",
    "    final_correctness = []\n",
    "    num_cols = []\n",
    "    total_steps = []\n",
    "    final_steps = []\n",
    "    correct_scores = defaultdict(list)\n",
    "    correct_steps = defaultdict(list)\n",
    "    init_max_col_length = 8\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(test_dataset_iter_extra):\n",
    "            target_col_mask = batch[\"target_col_mask\"].T\n",
    "            embs = test_embs[batch_idx][0].reshape(1,-1).to(device)\n",
    "            logits = test_logits[batch_idx][0].reshape(-1).to(device)\n",
    "            scores_init = verifier(embs)\n",
    "            max_score = -float(\"inf\")\n",
    "\n",
    "            init_scores.append(scores_init.item())\n",
    "            init_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            init_permutation_i, init_permutation_i_extra = init_permutation_i[:init_max_col_length], init_permutation_i[init_max_col_length:]\n",
    "            \n",
    "            if 0 not in init_permutation_i:\n",
    "                col_to_exclude = init_permutation_i[-1]\n",
    "                init_permutation_i = init_permutation_i[:-1] + [0]\n",
    "                init_permutation_i_extra.remove(0)\n",
    "                init_permutation_i_extra = [col_to_exclude] + init_permutation_i_extra\n",
    "                assert 0 in init_permutation_i and 0 not in init_permutation_i_extra\n",
    "            \n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            early_stop = False\n",
    "            i = 0\n",
    "            final_step = 0\n",
    "            total_steps.append(len(init_permutation_i) - max(len(init_permutation_i)//2, len(init_permutation_i)-3) -1)\n",
    "            num_cols.append(len(init_permutation_i))\n",
    "            enough = False\n",
    "            for r in range(len(init_permutation_i),  max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "                for x in itertools.combinations(init_permutation_i, r):\n",
    "                    if 0 not in x:\n",
    "                        continue\n",
    "                    logits_temp = test_logits[batch_idx][i].reshape(-1).to(device)\n",
    "                    embs_temp = test_embs[batch_idx][i].reshape(1,-1).to(device)\n",
    "                    scores_temp = verifier(embs_temp).item()\n",
    "                    predict_temp = logits_temp.argmax().item()\n",
    "                    i += 1\n",
    "                    if scores_temp > max_score:\n",
    "                        max_score = scores_temp\n",
    "                        logits = logits_temp.clone()\n",
    "                        final_step = len(init_permutation_i) - r\n",
    "                    if logits_temp.argmax().item() == batch[\"label\"].item():\n",
    "                        correct_scores[batch_idx].append(scores_temp)\n",
    "                        correct_steps[batch_idx].append(len(init_permutation_i) - r)\n",
    "                    if F.sigmoid(torch.tensor(max_score)).item() > 0.999:\n",
    "                        enough = True\n",
    "                if enough:\n",
    "                    break  \n",
    "            if not enough and len(init_permutation_i_extra)>0:\n",
    "                for new_col_idx in init_permutation_i_extra:\n",
    "                    init_permutation_i_new = init_permutation_i + [new_col_idx]\n",
    "                    for r in range(len(init_permutation_i),  max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "                        for x in itertools.combinations(init_permutation_i_new, r):\n",
    "                            if 0 not in x or new_col_idx not in x:\n",
    "                                continue\n",
    "                            new_batch_data = []\n",
    "                            for col_i in x:\n",
    "                                if col_i == 0:\n",
    "                                    if len(new_batch_data) == 0:\n",
    "                                        cls_indexes_value = 0\n",
    "                                    else:\n",
    "                                        cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                                new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                            new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                            cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                            logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                            scores_temp = verifier(embs_temp.reshape(1,-1)).item()\n",
    "                            predict_temp = logits_temp.argmax().item()\n",
    "                            \n",
    "                            if scores_temp > max_score:\n",
    "                                max_score = scores_temp\n",
    "                                logits = logits_temp.clone()\n",
    "                                final_step = len(init_permutation_i) - r\n",
    "                            if logits_temp.argmax().item() == batch[\"label\"].item():\n",
    "                                correct_scores[batch_idx].append(scores_temp)\n",
    "                                correct_steps[batch_idx].append(len(init_permutation_i) - r)\n",
    "                            if F.sigmoid(torch.tensor(max_score)).item() > 0.999:\n",
    "                                enough = True\n",
    "                        if enough:\n",
    "                            break\n",
    "                    if enough:\n",
    "                        break\n",
    "                    \n",
    "                    \n",
    "            final_scores.append(max_score)\n",
    "            final_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "            final_steps.append(final_step)\n",
    "            labels_test.append(batch[\"label\"].cpu())\n",
    "            logits_test.append(logits.detach().cpu())\n",
    "        labels_test = torch.cat(labels_test, dim=0)\n",
    "        logits_test = torch.stack(logits_test, dim=0)\n",
    "        preds_test = torch.argmax(logits_test, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix, f1_score\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach().numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    ts_f1_full = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=None)\n",
    "    # full_f1_init\n",
    "    print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "    final_correctness = torch.tensor(final_correctness)\n",
    "    init_correctness = torch.tensor(init_correctness)\n",
    "    init_scores = torch.tensor(init_scores)\n",
    "    final_scores = torch.tensor(final_scores)\n",
    "    final_steps = torch.tensor(final_steps)\n",
    "    total_steps = torch.tensor(total_steps)\n",
    "    final_scores = F.sigmoid(torch.tensor(final_scores))\n",
    "    init_scores = F.sigmoid(torch.tensor(init_scores))\n",
    "    print((final_scores>0.999).sum(), len(final_scores), (final_scores>0.999).sum()/len(final_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_micro_f1=0.5567, ts_macro_f1=0.2983"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "for max_unlabeled in [32, 64, 128]:\n",
    "    print(f\"============================max_unlabeled={max_unlabeled}===============================\")\n",
    "    test_dataset_iter_extra = GittablesTablewiseIterateDataset(cv=cv,\n",
    "                                split=\"test\", src=src,\n",
    "                                tokenizer=tokenizer,\n",
    "                                max_length=max_length,\n",
    "                                gt_only='all' not in task,\n",
    "                                device=device,\n",
    "                                base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                                small_tag=\"semi1\",\n",
    "                                max_unlabeled=max_unlabeled,\n",
    "                                adaptive_max_length=False,)\n",
    "    model.load_state_dict(best_state_dict, strict=False)\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    verifier.load_state_dict(veri_state_dict)\n",
    "    verifier.eval()\n",
    "    verifier = verifier.to(device)\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    init_scores = []\n",
    "    init_correctness = []\n",
    "    final_scores = []\n",
    "    final_correctness = []\n",
    "    num_cols = []\n",
    "    total_steps = []\n",
    "    final_steps = []\n",
    "    correct_scores = defaultdict(list)\n",
    "    correct_steps = defaultdict(list)\n",
    "    init_max_col_length = 8\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(test_dataset_iter_extra):\n",
    "            target_col_mask = batch[\"target_col_mask\"].T\n",
    "            embs = test_embs[batch_idx][0].reshape(1,-1).to(device)\n",
    "            logits = test_logits[batch_idx][0].reshape(-1).to(device)\n",
    "            scores_init = verifier(embs)\n",
    "            max_score = -float(\"inf\")\n",
    "\n",
    "            init_scores.append(scores_init.item())\n",
    "            init_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            init_permutation_i, init_permutation_i_extra = init_permutation_i[:init_max_col_length], init_permutation_i[init_max_col_length:]\n",
    "            \n",
    "            if 0 not in init_permutation_i:\n",
    "                col_to_exclude = init_permutation_i[-1]\n",
    "                init_permutation_i = init_permutation_i[:-1] + [0]\n",
    "                init_permutation_i_extra.remove(0)\n",
    "                init_permutation_i_extra = [col_to_exclude] + init_permutation_i_extra\n",
    "                assert 0 in init_permutation_i and 0 not in init_permutation_i_extra\n",
    "            \n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            early_stop = False\n",
    "            i = 0\n",
    "            final_step = 0\n",
    "            total_steps.append(len(init_permutation_i) - max(len(init_permutation_i)//2, len(init_permutation_i)-3) -1)\n",
    "            num_cols.append(len(init_permutation_i))\n",
    "            enough = False\n",
    "            for r in range(len(init_permutation_i),  max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "                for x in itertools.combinations(init_permutation_i, r):\n",
    "                    if 0 not in x:\n",
    "                        continue\n",
    "                    logits_temp = test_logits[batch_idx][i].reshape(-1).to(device)\n",
    "                    embs_temp = test_embs[batch_idx][i].reshape(1,-1).to(device)\n",
    "                    scores_temp = verifier(embs_temp).item()\n",
    "                    predict_temp = logits_temp.argmax().item()\n",
    "                    i += 1\n",
    "                    if scores_temp > max_score:\n",
    "                        max_score = scores_temp\n",
    "                        logits = logits_temp.clone()\n",
    "                        final_step = len(init_permutation_i) - r\n",
    "                    if logits_temp.argmax().item() == batch[\"label\"].item():\n",
    "                        correct_scores[batch_idx].append(scores_temp)\n",
    "                        correct_steps[batch_idx].append(len(init_permutation_i) - r)\n",
    "                    if F.sigmoid(torch.tensor(max_score)).item() > 0.999:\n",
    "                        enough = True\n",
    "                if enough:\n",
    "                    break  \n",
    "            if not enough and len(init_permutation_i_extra)>0:\n",
    "                for new_col_idx in init_permutation_i_extra:\n",
    "                    init_permutation_i_new = init_permutation_i + [new_col_idx]\n",
    "                    for r in range(len(init_permutation_i),  max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "                        for x in itertools.combinations(init_permutation_i_new, r):\n",
    "                            if 0 not in x or new_col_idx not in x:\n",
    "                                continue\n",
    "                            new_batch_data = []\n",
    "                            for col_i in x:\n",
    "                                if col_i == 0:\n",
    "                                    if len(new_batch_data) == 0:\n",
    "                                        cls_indexes_value = 0\n",
    "                                    else:\n",
    "                                        cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                                new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                            new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                            cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                            logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                            scores_temp = verifier(embs_temp.reshape(1,-1)).item()\n",
    "                            predict_temp = logits_temp.argmax().item()\n",
    "                            \n",
    "                            if scores_temp > max_score:\n",
    "                                max_score = scores_temp\n",
    "                                logits = logits_temp.clone()\n",
    "                                final_step = len(init_permutation_i) - r\n",
    "                            if logits_temp.argmax().item() == batch[\"label\"].item():\n",
    "                                correct_scores[batch_idx].append(scores_temp)\n",
    "                                correct_steps[batch_idx].append(len(init_permutation_i) - r)\n",
    "                            if F.sigmoid(torch.tensor(max_score)).item() > 0.999:\n",
    "                                enough = True\n",
    "                        if enough:\n",
    "                            break\n",
    "                    if enough:\n",
    "                        break\n",
    "                    \n",
    "                    \n",
    "            final_scores.append(max_score)\n",
    "            final_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "            final_steps.append(final_step)\n",
    "            labels_test.append(batch[\"label\"].cpu())\n",
    "            logits_test.append(logits.detach().cpu())\n",
    "        labels_test = torch.cat(labels_test, dim=0)\n",
    "        logits_test = torch.stack(logits_test, dim=0)\n",
    "        preds_test = torch.argmax(logits_test, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix, f1_score\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach().numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    ts_f1_full = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=None)\n",
    "    # full_f1_init\n",
    "    print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "    final_correctness = torch.tensor(final_correctness)\n",
    "    init_correctness = torch.tensor(init_correctness)\n",
    "    init_scores = torch.tensor(init_scores)\n",
    "    final_scores = torch.tensor(final_scores)\n",
    "    final_steps = torch.tensor(final_steps)\n",
    "    total_steps = torch.tensor(total_steps)\n",
    "    final_scores = F.sigmoid(torch.tensor(final_scores))\n",
    "    init_scores = F.sigmoid(torch.tensor(init_scores))\n",
    "    print((final_scores>0.999).sum(), len(final_scores), (final_scores>0.999).sum()/len(final_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "for max_unlabeled in [16]:\n",
    "    print(f\"============================max_unlabeled={max_unlabeled}===============================\")\n",
    "    test_dataset_iter_extra = GittablesTablewiseIterateDataset(cv=cv,\n",
    "                                split=\"test\", src=src,\n",
    "                                tokenizer=tokenizer,\n",
    "                                max_length=max_length,\n",
    "                                gt_only='all' not in task,\n",
    "                                device=device,\n",
    "                                base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                                small_tag=\"semi1\",\n",
    "                                max_unlabeled=max_unlabeled,\n",
    "                                adaptive_max_length=False,)\n",
    "    model.load_state_dict(best_state_dict, strict=False)\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    verifier.load_state_dict(veri_state_dict)\n",
    "    verifier.eval()\n",
    "    verifier = verifier.to(device)\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    init_scores = []\n",
    "    init_correctness = []\n",
    "    final_scores = []\n",
    "    final_correctness = []\n",
    "    num_cols = []\n",
    "    total_steps = []\n",
    "    final_steps = []\n",
    "    correct_scores = defaultdict(list)\n",
    "    correct_steps = defaultdict(list)\n",
    "    init_max_col_length = 8\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(test_dataset_iter_extra):\n",
    "            target_col_mask = batch[\"target_col_mask\"].T\n",
    "            embs = test_embs[batch_idx][0].reshape(1,-1).to(device)\n",
    "            logits = test_logits[batch_idx][0].reshape(-1).to(device)\n",
    "            scores_init = verifier(embs)\n",
    "            max_score = -float(\"inf\")\n",
    "\n",
    "            init_scores.append(scores_init.item())\n",
    "            init_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            init_permutation_i, init_permutation_i_extra = init_permutation_i[:init_max_col_length], init_permutation_i[init_max_col_length:]\n",
    "            \n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            early_stop = False\n",
    "            i = 0\n",
    "            final_step = 0\n",
    "            total_steps.append(len(init_permutation_i) - max(len(init_permutation_i)//2, len(init_permutation_i)-3) -1)\n",
    "            num_cols.append(len(init_permutation_i))\n",
    "            enough = False\n",
    "            for r in range(len(init_permutation_i),  max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "                for x in itertools.combinations(init_permutation_i, r):\n",
    "                    if 0 not in x:\n",
    "                        continue\n",
    "                    logits_temp = test_logits[batch_idx][i].reshape(-1).to(device)\n",
    "                    embs_temp = test_embs[batch_idx][i].reshape(1,-1).to(device)\n",
    "                    scores_temp = verifier(embs_temp).item()\n",
    "                    predict_temp = logits_temp.argmax().item()\n",
    "                    i += 1\n",
    "                    if scores_temp > max_score:\n",
    "                        max_score = scores_temp\n",
    "                        logits = logits_temp.clone()\n",
    "                        final_step = len(init_permutation_i) - r\n",
    "                    if logits_temp.argmax().item() == batch[\"label\"].item():\n",
    "                        correct_scores[batch_idx].append(scores_temp)\n",
    "                        correct_steps[batch_idx].append(len(init_permutation_i) - r)\n",
    "                    if F.sigmoid(torch.tensor(max_score)).item() > 0.999:\n",
    "                        enough = True\n",
    "                if enough:\n",
    "                    break  \n",
    "                \n",
    "            if not enough and len(init_permutation_i_extra)>0:\n",
    "                for z in range(1, len(init_permutation_i_extra)+1):\n",
    "                    for new_col_idx in itertools.combinations(init_permutation_i_extra, z):\n",
    "                        init_permutation_i_new = init_permutation_i + list(new_col_idx)\n",
    "                        for r in range(len(init_permutation_i),  max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1):\n",
    "                            for x in itertools.combinations(init_permutation_i_new, r):\n",
    "                                if not set(list(new_col_idx)+[0]).issubset(set(x)):\n",
    "                                    continue\n",
    "                                new_batch_data = []\n",
    "                                for col_i in x:\n",
    "                                    if col_i == 0:\n",
    "                                        if len(new_batch_data) == 0:\n",
    "                                            cls_indexes_value = 0\n",
    "                                        else:\n",
    "                                            cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                                    new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                                new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                                cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                                logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                                scores_temp = verifier(embs_temp.reshape(1,-1)).item()\n",
    "                                predict_temp = logits_temp.argmax().item()\n",
    "                                \n",
    "                                if scores_temp > max_score:\n",
    "                                    max_score = scores_temp\n",
    "                                    logits = logits_temp.clone()\n",
    "                                    final_step = len(init_permutation_i) - r\n",
    "                                if logits_temp.argmax().item() == batch[\"label\"].item():\n",
    "                                    correct_scores[batch_idx].append(scores_temp)\n",
    "                                    correct_steps[batch_idx].append(len(init_permutation_i) - r)\n",
    "                                if F.sigmoid(torch.tensor(max_score)).item() > 0.999:\n",
    "                                    enough = True\n",
    "                            if enough:\n",
    "                                break\n",
    "                        if enough:\n",
    "                            break\n",
    "                        \n",
    "                    \n",
    "            final_scores.append(max_score)\n",
    "            final_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "            final_steps.append(final_step)\n",
    "            labels_test.append(batch[\"label\"].cpu())\n",
    "            logits_test.append(logits.detach().cpu())\n",
    "        labels_test = torch.cat(labels_test, dim=0)\n",
    "        logits_test = torch.stack(logits_test, dim=0)\n",
    "        preds_test = torch.argmax(logits_test, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix, f1_score\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach().numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    ts_f1_full = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=None)\n",
    "    # full_f1_init\n",
    "    print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "    final_correctness = torch.tensor(final_correctness)\n",
    "    init_correctness = torch.tensor(init_correctness)\n",
    "    init_scores = torch.tensor(init_scores)\n",
    "    final_scores = torch.tensor(final_scores)\n",
    "    final_steps = torch.tensor(final_steps)\n",
    "    total_steps = torch.tensor(total_steps)\n",
    "    final_scores = F.sigmoid(torch.tensor(final_scores))\n",
    "    init_scores = F.sigmoid(torch.tensor(init_scores))\n",
    "    print((final_scores>0.999).sum(), len(final_scores), (final_scores>0.999).sum()/len(final_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "        for batch_idx, batch in enumerate(test_dataset_iter_extra):\n",
    "            target_col_mask = batch[\"target_col_mask\"].T\n",
    "            embs = test_embs[batch_idx][0].reshape(1,-1).to(device)\n",
    "            logits = test_logits[batch_idx][0].reshape(-1).to(device)\n",
    "            scores_init = verifier(embs)\n",
    "            max_score = -float(\"inf\")\n",
    "\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            init_permutation_i, init_permutation_i_extra = init_permutation_i[:init_max_col_length], init_permutation_i[init_max_col_length:]\n",
    "            \n",
    "            if 0 not in init_permutation_i:\n",
    "                col_to_exclude = init_permutation_i[-1]\n",
    "                init_permutation_i = init_permutation_i[:-1] + [0]\n",
    "                init_permutation_i_extra.remove(0)\n",
    "                init_permutation_i_extra = [col_to_exclude] + init_permutation_i_extra\n",
    "                assert 0 in init_permutation_i and 0 not in init_permutation_i_extra\n",
    "            if len(init_permutation_i_extra) == 2:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_permutation_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_permutation_i_extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_permutation_i_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(new_col_idx)+[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for z in range(1, len(init_permutation_i_extra)+1):\n",
    "    for new_col_idx in itertools.combinations(init_permutation_i_extra, z):\n",
    "        init_permutation_i_new = init_permutation_i + list(new_col_idx)\n",
    "        for r in range(len(init_permutation_i),  max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1):\n",
    "            for x in itertools.combinations(init_permutation_i_new, r):\n",
    "                if not set(list(new_col_idx)+[0]).issubset(set(x)):\n",
    "                    continue\n",
    "                if 0 not in x:\n",
    "                    break\n",
    "                print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_permutation_i_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(list(new_col_idx)+[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_permutation_i_extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(test_dataset_iter_extra):\n",
    "        target_col_mask = batch[\"target_col_mask\"].T\n",
    "        init_permutation_i = get_permutation(target_col_mask)\n",
    "        num_cols.append(len(init_permutation_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# table search STARMIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list_1 = [\n",
    "    \"Name: Philip Duffy; Jeremy Oppenheim; Mark Sedwill;\",\n",
    "    \"Mode of Travel: Air; Taxi; Air;\",\n",
    "    \"Purpose: Regional Meeting; Exchange Visit; Evening Meal;\",\n",
    "    \"Destination: London; Ottawa; Bristol;\",\n",
    "    \"Day: 10; 30; 02;\",\n",
    "    \"Month: April; July; September;\",\n",
    "    \"Year: 2019; 2019; 2019;\",\n",
    "    \"Expense: 189.06; 8.08; 50.00;\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cur_maxlen = min(max_length, 512 // len(column_list_1) - 1)\n",
    "\n",
    "# print(tokenizer.cls_token)\n",
    "# print(group_df[\"data\"])\n",
    "token_ids_list = [tokenizer.encode(\n",
    "                tokenizer.cls_token + \" \" + str(x), add_special_tokens=False, max_length=cur_maxlen, truncation=True) for x in column_list_1]\n",
    "token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                    token_ids_list)).to(device)\n",
    "cls_index_list = [0] + np.cumsum(\n",
    "    np.array([len(x) for x in token_ids_list])).tolist()[:-1]\n",
    "cls_indexes = torch.LongTensor(cls_index_list).to(device).reshape(-1, 1)\n",
    "cls_indexes = torch.hstack([torch.zeros_like(cls_indexes), cls_indexes])\n",
    "logits, embs_1 = model(token_ids.reshape(1, -1), cls_indexes=cls_indexes, get_enc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "cur_maxlen = min(max_length, 512 // len(column_list_1) - 1)\n",
    "\n",
    "# print(tokenizer.cls_token)\n",
    "# print(group_df[\"data\"])\n",
    "token_ids_list = [tokenizer.encode(\n",
    "                tokenizer.cls_token + \" \" + str(x), add_special_tokens=False, max_length=cur_maxlen, truncation=True) for x in column_list_1]\n",
    "token_ids = nn.utils.rnn.pad_sequence(\n",
    "      [torch.tensor(x) for x in token_ids_list], padding_value=tokenizer.pad_token_id).to(device)\n",
    "cls_indexes = torch.nonzero(\n",
    "                token_ids == tokenizer.cls_token_id)\n",
    "logits, embs_1_seperate = model(token_ids, cls_indexes=cls_indexes, get_enc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list_2 = [\n",
    "    \"Name: Clark; Gyimah; Harrington;\",\n",
    "    \"Date: 23/07; 03/09; 05/08;\",\n",
    "    \"Destination: France; Belgium; China;\",\n",
    "    \"Purpose: Discuss EU; Build Relations; Discuss Productivity;\",\n",
    "]\n",
    "cur_maxlen = min(max_length, 512 // len(column_list_2) - 1)\n",
    "\n",
    "# print(tokenizer.cls_token)\n",
    "# print(group_df[\"data\"])\n",
    "token_ids_list = [tokenizer.encode(\n",
    "                tokenizer.cls_token + \" \" + str(x), add_special_tokens=False, max_length=cur_maxlen, truncation=True) \n",
    "                  for x in column_list_2]\n",
    "token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                    token_ids_list)).to(device)\n",
    "cls_index_list = [0] + np.cumsum(\n",
    "    np.array([len(x) for x in token_ids_list])).tolist()[:-1]\n",
    "cls_indexes = torch.LongTensor(cls_index_list).to(device).reshape(-1, 1)\n",
    "cls_indexes = torch.hstack([torch.zeros_like(cls_indexes), cls_indexes])\n",
    "logits, embs_2 = model(token_ids.reshape(1, -1), cls_indexes=cls_indexes, get_enc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids = token_ids.reshape(1, -1)\n",
    "attention_mask = token_ids != 0\n",
    "res = model.bert(token_ids, attention_mask=attention_mask, return_dict=True, output_attentions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(res['attentions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res['attentions'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res['attentions'][0].squeeze().mean(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res['attentions'][0].squeeze().mean(0)[cls_mask][:, cls_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_mask = (token_ids==tokenizer.cls_token_id).reshape(-1)\n",
    "acc_attention = []\n",
    "for i in range(len(res['attentions'])):\n",
    "    attn_i = res['attentions'][i].squeeze().mean(0)[cls_mask][:, cls_mask].mean(0)\n",
    "    acc_attention.append(attn_i)\n",
    "    print(attn_i)\n",
    "acc_attention = torch.stack(acc_attention, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_mask = (token_ids==tokenizer.cls_token_id).reshape(-1)\n",
    "acc_attention = torch.ones_like(res['attentions'][0].squeeze().mean(0)[cls_mask][:, cls_mask].mean(0))\n",
    "for i in range(len(res['attentions'])-1, -1, -1):\n",
    "    attn_i = res['attentions'][i].squeeze().mean(0)[cls_mask][:, cls_mask].mean(0)\n",
    "    acc_attention = acc_attention * attn_i\n",
    "    print(acc_attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res['attentions'][0].squeeze().mean(0)[cls_mask][:, cls_mask].fill_diagonal_(0).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "cur_maxlen = min(max_length, 512 // len(column_list_2) - 1)\n",
    "\n",
    "# print(tokenizer.cls_token)\n",
    "# print(group_df[\"data\"])\n",
    "token_ids_list = [tokenizer.encode(\n",
    "                tokenizer.cls_token + \" \" + str(x), add_special_tokens=False, max_length=cur_maxlen, truncation=True) \n",
    "                  for x in column_list_2]\n",
    "token_ids = nn.utils.rnn.pad_sequence(\n",
    "      [torch.tensor(x) for x in token_ids_list], padding_value=tokenizer.pad_token_id).to(device)\n",
    "cls_indexes = torch.nonzero(\n",
    "                token_ids == tokenizer.cls_token_id)\n",
    "logits, embs_2_seperate = model(token_ids, cls_indexes=cls_indexes, get_enc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list_3 = [\n",
    "    'Bird Name: Pine Siskin; American Robin; Northern Flicker;',\n",
    "    'Scientific Name: Carduelis Pinus; Turdus migratorius; Colaptes auratus;',\n",
    "    'Date: 2019; 2019; 2019;',\n",
    "    'Location: Ottawa; Ottawa; London;'\n",
    "]\n",
    "\n",
    "cur_maxlen = min(max_length, 512 // len(column_list_3) - 1)\n",
    "\n",
    "# print(tokenizer.cls_token)\n",
    "# print(group_df[\"data\"])\n",
    "token_ids_list = [tokenizer.encode(\n",
    "                tokenizer.cls_token + \" \" + str(x), add_special_tokens=False, max_length=cur_maxlen, truncation=True) \n",
    "                  for x in column_list_3]\n",
    "token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                    token_ids_list)).to(device)\n",
    "cls_index_list = [0] + np.cumsum(\n",
    "    np.array([len(x) for x in token_ids_list])).tolist()[:-1]\n",
    "cls_indexes = torch.LongTensor(cls_index_list).to(device).reshape(-1, 1)\n",
    "cls_indexes = torch.hstack([torch.zeros_like(cls_indexes), cls_indexes])\n",
    "logits, embs_3 = model(token_ids.reshape(1, -1), cls_indexes=cls_indexes, get_enc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "cur_maxlen = min(max_length, 512 // len(column_list_3) - 1)\n",
    "\n",
    "# print(tokenizer.cls_token)\n",
    "# print(group_df[\"data\"])\n",
    "token_ids_list = [tokenizer.encode(\n",
    "                tokenizer.cls_token + \" \" + str(x), add_special_tokens=False, max_length=cur_maxlen, truncation=True) \n",
    "                  for x in column_list_3]\n",
    "token_ids = nn.utils.rnn.pad_sequence(\n",
    "      [torch.tensor(x) for x in token_ids_list], padding_value=tokenizer.pad_token_id).to(device)\n",
    "cls_indexes = torch.nonzero(\n",
    "                token_ids == tokenizer.cls_token_id)\n",
    "logits, embs_3_seperate = model(token_ids, cls_indexes=cls_indexes, get_enc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_similarity(embs_1.detach().cpu().numpy(), embs_2.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cosine_similarity(embs_1.detach().cpu().numpy(), embs_2.detach().cpu().numpy()).max(0))\n",
    "cosine_similarity(embs_1.detach().cpu().numpy(), embs_2.detach().cpu().numpy()).max(0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cosine_similarity(embs_1_seperate.detach().cpu().numpy(), embs_2_seperate.detach().cpu().numpy()).max(0))\n",
    "cosine_similarity(embs_1_seperate.detach().cpu().numpy(), embs_2_seperate.detach().cpu().numpy()).max(0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((final_scores>0.999).sum(), len(final_scores), (final_scores>0.999).sum()/len(final_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "    if len(group_df) > 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_embs = sb_model.encode(group_df[\"data\"].to_list())\n",
    "# use cosine similarity to find the closest column\n",
    "closest_col = []\n",
    "for i in range(8):\n",
    "    sim = F.cosine_similarity(col_embs, centers[i].reshape(1, -1))\n",
    "    closest_col.append(sim.argmax().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kmeans cluster the columns and find the column closest to the center\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=8, random_state=0).fit(col_embs)\n",
    "centers = torch.tensor(kmeans.cluster_centers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the closest column to the center\n",
    "closest_col = []\n",
    "col_embs = torch.tensor(col_embs)\n",
    "for i in range(8):\n",
    "    dist = torch.norm(col_embs - centers[i], dim=1)\n",
    "    closest_col.append(dist.argmin().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in closest_col:\n",
    "    print(group_df.iloc[i][\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(group_df[\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
