{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/zhihao/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/zhihao/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "from time import time\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from collections import defaultdict\n",
    "\n",
    "# import pytrec_eval\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss, BCEWithLogitsLoss\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, BertConfig, AutoTokenizer\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from accelerate import Accelerator\n",
    "from copy import deepcopy\n",
    "\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "from watchog.dataset import (\n",
    "    # collate_fn,\n",
    "    TURLColTypeTablewiseDataset,\n",
    "    TURLRelExtTablewiseDataset,\n",
    "    SatoCVTablewiseDataset,\n",
    "    ColPoplTablewiseDataset\n",
    ")\n",
    "\n",
    "from watchog.dataset import TableDataset, SupCLTableDataset, SemtableCVTablewiseDataset, GittablesColwiseDataset, GittablesTablewiseDataset\n",
    "from watchog.model import BertMultiPairPooler, BertForMultiOutputClassification, BertForMultiOutputClassificationColPopl, Verifier\n",
    "from watchog.model import SupCLforTable, UnsupCLforTable, lm_mp\n",
    "from watchog.utils import load_checkpoint, f1_score_multilabel, collate_fn, get_col_pred, ColPoplEvaluator\n",
    "from watchog.utils import task_num_class_dict\n",
    "from accelerate import DistributedDataParallelKwargs\n",
    "import wandb\n",
    "\n",
    "from argparse import Namespace\n",
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import re\n",
    "import transformers\n",
    "from torch.utils import data\n",
    "from torch.nn.utils import rnn\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from typing import List\n",
    "from functools import reduce\n",
    "import operator\n",
    "\n",
    "from itertools import chain\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args={\"wandb\": false, \"model\": \"Watchog\", \"unlabeled_train_only\": false, \"context_encoding_type\": \"v0\", \"pool_version\": \"v0.2\", \"random_sample\": false, \"comment\": \"debug\", \"shortcut_name\": \"bert-base-uncased\", \"max_length\": 64, \"adaptive_max_length\": false, \"max_num_col\": 8, \"batch_size\": 3, \"epoch\": 1, \"random_seed\": 4649, \"train_n_seed_cols\": -1, \"num_classes\": 101, \"multi_gpu\": false, \"fp16\": false, \"warmup\": 0.0, \"lr\": 5e-05, \"task\": \"gt-semtab22-dbpedia-all0\", \"colpair\": false, \"metadata\": false, \"from_scratch\": false, \"cl_tag\": \"wikitables/simclr/bert_100000_10_32_256_5e-05_sample_row4,sample_row4_tfidf_entity_column_0.05_0_last.pt\", \"dropout_prob\": 0.5, \"eval_test\": true, \"small_tag\": \"semi1\", \"data_path\": \"/data/zhihao/TU/\", \"pretrained_ckpt_path\": \"/data/zhihao/TU/Watchog/model/\"}\n",
      "gt-semtab22-dbpedia-all0/wikitables-simclr-bert_100000_10_32_256_5e-05_sample_row4,sample_row4_tfidf_entity_column_0.05_0_last.pt_bert-base-uncased-poolsemi1-max_colsv0.2-rand8-bsFalse-ml3-ne64-do10.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1276939/3989646571.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(ckpt_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(augment_op='sample_row4,sample_row4', batch_size=32, data_path='/data/zhihao/TU/TURL/', fp16=True, gpus='0', lm='bert', logdir='/data/zhihao/TU/Watchog/model/', lr=5e-05, max_len=256, mode='simclr', model='Watchog', n_epochs=10, pretrain_data='wikitables', pretrained_model_path='', projector=768, run_id=0, sample_meth='tfidf_entity', save_model=10, single_column=False, size=100000, table_order='column', temperature=0.05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "    device = torch.device(2)\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--wandb\", type=bool, default=False)\n",
    "    parser.add_argument(\"--model\", type=str, default=\"Watchog\")\n",
    "    parser.add_argument(\"--unlabeled_train_only\", type=bool, default=False)\n",
    "    parser.add_argument(\"--context_encoding_type\", type=str, default=\"v0\")\n",
    "    parser.add_argument(\"--pool_version\", type=str, default=\"v0.2\")\n",
    "    parser.add_argument(\"--random_sample\", type=bool, default=False)\n",
    "    parser.add_argument(\"--comment\", type=str, default=\"debug\", help=\"to distinguish the runs\")\n",
    "    parser.add_argument(\n",
    "        \"--shortcut_name\",\n",
    "        default=\"bert-base-uncased\",\n",
    "        type=str,\n",
    "        help=\"Huggingface model shortcut name \",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--max_length\",\n",
    "        default=64,\n",
    "        type=int,\n",
    "        help=\n",
    "        \"The maximum total input sequence length after tokenization. Sequences longer \"\n",
    "        \"than this will be truncated, sequences shorter will be padded.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--adaptive_max_length\",\n",
    "        default=False,\n",
    "        type=bool,\n",
    "    )    \n",
    "    parser.add_argument(\n",
    "        \"--max_num_col\",\n",
    "        default=8,\n",
    "        type=int,\n",
    "    )   \n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--batch_size\",\n",
    "        default=3,\n",
    "        type=int,\n",
    "        help=\"Batch size\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--epoch\",\n",
    "        default=1,\n",
    "        type=int,\n",
    "        help=\"Number of epochs for training\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--random_seed\",\n",
    "        default=4649,\n",
    "        type=int,\n",
    "        help=\"Random seed\",\n",
    "    )\n",
    "    \n",
    "    parser.add_argument(\n",
    "        \"--train_n_seed_cols\",\n",
    "        default=-1,\n",
    "        type=int,\n",
    "        help=\"number of seeding columns in training\",\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--num_classes\",\n",
    "        default=78,\n",
    "        type=int,\n",
    "        help=\"Number of classes\",\n",
    "    )\n",
    "    parser.add_argument(\"--multi_gpu\",\n",
    "                        action=\"store_true\",\n",
    "                        default=False,\n",
    "                        help=\"Use multiple GPU\")\n",
    "    parser.add_argument(\"--fp16\",\n",
    "                        action=\"store_true\",\n",
    "                        default=False,\n",
    "                        help=\"Use FP16\")\n",
    "    parser.add_argument(\"--warmup\",\n",
    "                        type=float,\n",
    "                        default=0.,\n",
    "                        help=\"Warmup ratio\")\n",
    "    parser.add_argument(\"--lr\", type=float, default=5e-5, help=\"Learning rate\")\n",
    "    parser.add_argument(\"--task\",\n",
    "                        type=str,\n",
    "                        default='gt-semtab22-dbpedia-all0',\n",
    "                        choices=[\n",
    "                            \"sato0\", \"sato1\", \"sato2\", \"sato3\", \"sato4\",\n",
    "                            \"msato0\", \"msato1\", \"msato2\", \"msato3\", \"msato4\",\n",
    "                            \"gt-dbpedia0\", \"gt-dbpedia1\", \"gt-dbpedia2\", \"gt-dbpedia3\", \"gt-dbpedia4\",\n",
    "                            \"gt-dbpedia-all0\", \"gt-dbpedia-all1\", \"gt-dbpedia-all2\", \"gt-dbpedia-all3\", \"gt-dbpedia-all4\",\n",
    "                            \"gt-schema-all0\", \"gt-schema-all1\", \"gt-schema-all2\", \"gt-schema-all3\", \"gt-schema-all4\",\n",
    "                            \"gt-semtab22-dbpedia\", \"gt-semtab22-dbpedia0\", \"gt-semtab22-dbpedia1\", \"gt-semtab22-dbpedia2\", \"gt-semtab22-dbpedia3\", \"gt-semtab22-dbpedia4\",\n",
    "                            \"gt-semtab22-dbpedia-all\", \"gt-semtab22-dbpedia-all0\", \"gt-semtab22-dbpedia-all1\", \"gt-semtab22-dbpedia-all2\", \"gt-semtab22-dbpedia-all3\", \"gt-semtab22-dbpedia-all4\",\n",
    "                            \"gt-semtab22-schema-class-all\", \"gt-semtab22-schema-property-all\",\n",
    "                            \"turl\", \"turl-re\", \"col-popl-1\", \"col-popl-2\", \"col-popl-3\", \"row-popl\",\n",
    "                            \"col-popl-turl-0\", \"col-popl-turl-1\", \"col-popl-turl-2\",\n",
    "                            \"col-popl-turl-mdonly-0\", \"col-popl-turl-mdonly-1\", \"col-popl-turl-mdonly-2\"\n",
    "                        ],\n",
    "                        help=\"Task names}\")\n",
    "    parser.add_argument(\"--colpair\",\n",
    "                        action=\"store_true\",\n",
    "                        help=\"Use column pair embedding\")\n",
    "    parser.add_argument(\"--metadata\",\n",
    "                        action=\"store_true\",\n",
    "                        help=\"Use column header metadata\")\n",
    "    parser.add_argument(\"--from_scratch\",\n",
    "                        action=\"store_true\",\n",
    "                        help=\"Training from scratch\")\n",
    "    parser.add_argument(\"--cl_tag\",\n",
    "                        type=str,\n",
    "                        default=\"wikitables/simclr/bert_100000_10_32_256_5e-05_sample_row4,sample_row4_tfidf_entity_column_0.05_0_last.pt\",\n",
    "                        help=\"path to the pre-trained file\")\n",
    "    parser.add_argument(\"--dropout_prob\",\n",
    "                        type=float,\n",
    "                        default=0.5)\n",
    "    parser.add_argument(\"--eval_test\",\n",
    "                        action=\"store_true\",\n",
    "                        help=\"evaluate on testset and do not save the model file\")\n",
    "    parser.add_argument(\"--small_tag\",\n",
    "                        type=str,\n",
    "                        default=\"semi1\",\n",
    "                        help=\"e.g., by_table_t5_v1\")\n",
    "    parser.add_argument(\"--data_path\",\n",
    "                        type=str,\n",
    "                        default=\"/data/zhihao/TU/\")\n",
    "    parser.add_argument(\"--pretrained_ckpt_path\",\n",
    "                        type=str,\n",
    "                        default=\"/data/zhihao/TU/Watchog/model/\")    \n",
    "\n",
    "    args = parser.parse_args([])\n",
    "    task = args.task\n",
    "    if args.small_tag != \"\":\n",
    "        args.eval_test = True\n",
    "    \n",
    "    args.num_classes = task_num_class_dict[task]\n",
    "    if args.colpair:\n",
    "        assert \"turl-re\" == task, \"colpair can be only used for Relation Extraction\"\n",
    "    if args.metadata:\n",
    "        assert \"turl-re\" == task or \"turl\" == task, \"metadata can be only used for TURL datasets\"\n",
    "    if \"col-popl\":\n",
    "        # metrics = {\n",
    "        #     \"accuracy\": CategoricalAccuracy(tie_break=True),\n",
    "        # }\n",
    "        if args.train_n_seed_cols != -1:\n",
    "            if \"col-popl\" in task:\n",
    "                assert args.train_n_seed_cols == int(task[-1]),  \"# of seed columns must match\"\n",
    "\n",
    "    print(\"args={}\".format(json.dumps(vars(args))))\n",
    "\n",
    "    max_length = args.max_length\n",
    "    batch_size = args.batch_size\n",
    "    num_train_epochs = args.epoch\n",
    "\n",
    "    shortcut_name = args.shortcut_name\n",
    "\n",
    "    if args.colpair and args.metadata:\n",
    "        taskname = \"{}-colpair-metadata\".format(task)\n",
    "    elif args.colpair:\n",
    "        taskname = \"{}-colpair\".format(task)\n",
    "    elif args.metadata:\n",
    "        taskname = \"{}-metadata\".format(task)\n",
    "    elif args.train_n_seed_cols == -1 and 'popl' in task:\n",
    "        taskname = \"{}-mix\".format(task)\n",
    "    else:\n",
    "        taskname = \"\".join(task)\n",
    "    cv = int(task[-1])\n",
    "\n",
    "    if args.from_scratch:\n",
    "        if \"gt\" in task:\n",
    "            tag_name = \"{}/{}-{}-{}-pool{}-max_cols{}-rand{}-bs{}-ml{}-ne{}-do{}{}\".format(\n",
    "                taskname,  \"{}-fromscratch\".format(shortcut_name), args.small_tag, args.comment, args.pool_version, args.max_num_col, args.random_sample,\n",
    "                batch_size, max_length, num_train_epochs, args.dropout_prob, \n",
    "                '-rs{}'.format(args.random_seed) if args.random_seed != 4649 else '')\n",
    "        else:\n",
    "            tag_name = \"{}/{}-{}-{}-bs{}-ml{}-ne{}-do{}{}\".format(\n",
    "                taskname,  \"{}-fromscratch\".format(shortcut_name), args.small_tag, args.comment, \n",
    "                batch_size, max_length, num_train_epochs, args.dropout_prob, \n",
    "                '-rs{}'.format(args.random_seed) if args.random_seed != 4649 else '')\n",
    "        \n",
    "    else:\n",
    "        if \"gt\" in task:\n",
    "            tag_name = \"{}/{}_{}-pool{}-max_cols{}-rand{}-bs{}-ml{}-ne{}-do{}{}\".format(\n",
    "                taskname, args.cl_tag.replace('/', '-'),  shortcut_name, args.small_tag, args.pool_version, args.max_num_col, args.random_sample,\n",
    "                batch_size, max_length, num_train_epochs, args.dropout_prob,\n",
    "                '-rs{}'.format(args.random_seed) if args.random_seed != 4649 else '')\n",
    "        else:\n",
    "            tag_name = \"{}/{}_{}-{}-bs{}-ml{}-ne{}-do{}{}\".format(\n",
    "                taskname, args.cl_tag.replace('/', '-'),  shortcut_name, args.small_tag,\n",
    "                batch_size, max_length, num_train_epochs, args.dropout_prob,\n",
    "                '-rs{}'.format(args.random_seed) if args.random_seed != 4649 else '')\n",
    "\n",
    "    # if args.eval_test:\n",
    "    #     if args.small_tag != '':\n",
    "    #         tag_name = tag_name.replace('outputs', 'small_outputs')\n",
    "    #         tag_name += '-' + args.small_tag\n",
    "    print(tag_name)\n",
    "    file_path = os.path.join(args.data_path, \"Watchog\", \"outputs\", tag_name)\n",
    "\n",
    "    dirpath = os.path.dirname(file_path)\n",
    "    if not os.path.exists(dirpath):\n",
    "        print(\"{} not exists. Created\".format(dirpath))\n",
    "        os.makedirs(dirpath)\n",
    "    \n",
    "    if args.fp16:\n",
    "        torch.backends.cuda.matmul.allow_fp16_reduced_precision_reduction = True\n",
    "        \n",
    "      \n",
    "        \n",
    "    # accelerator = Accelerator(mixed_precision=\"no\" if not args.fp16 else \"fp16\")   \n",
    "    ddp_kwargs = DistributedDataParallelKwargs(find_unused_parameters=True)\n",
    "    accelerator = Accelerator(mixed_precision=\"no\" if not args.fp16 else \"fp16\", kwargs_handlers=[ddp_kwargs])\n",
    "\n",
    "    device = torch.device(0)\n",
    "    ckpt_path = os.path.join(args.pretrained_ckpt_path, args.cl_tag)\n",
    "    # ckpt_path = '/efs/checkpoints/{}.pt'.format(args.cl_tag)\n",
    "    ckpt = torch.load(ckpt_path, map_location=device)\n",
    "    ckpt_hp = ckpt['hp']\n",
    "    print(ckpt_hp)\n",
    " \n",
    "    setattr(ckpt_hp, 'batch_size', args.batch_size)\n",
    "    setattr(ckpt_hp, 'hidden_dropout_prob', args.dropout_prob)\n",
    "    setattr(ckpt_hp, 'shortcut_name', args.shortcut_name)\n",
    "    setattr(ckpt_hp, 'num_labels', args.num_classes)\n",
    "    \n",
    "    \n",
    "    \n",
    "    tokenizer = BertTokenizer.from_pretrained(shortcut_name)\n",
    "    padder = collate_fn(tokenizer.pad_token_id)\n",
    "    if task == \"turl-re\" and args.colpair:\n",
    "        model = BertForMultiOutputClassification(ckpt_hp, device=device, lm=ckpt['hp'].lm, col_pair='Pair')\n",
    "    elif \"col-popl\" in task:\n",
    "        model = BertForMultiOutputClassificationColPopl(ckpt_hp, device=device, lm=ckpt['hp'].lm, n_seed_cols=int(task[i][-1]), cls_for_md=\"md\" in task)\n",
    "    else:\n",
    "        model = BertForMultiOutputClassification(ckpt_hp, device=device, lm=ckpt['hp'].lm, version=\"v0\", use_attention_mask=True)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1276939/307592194.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_state_dict = torch.load(\"/data/zhihao/TU/Watchog/outputs/gt-semtab22-dbpedia-all0/bert-base-uncased-fromscratch-semi1-Repeat@5-AttnMask-UnlabelValid-max-unlabeled@8-poolv0-unlabeled8-randFalse-bs16-ml128-ne50-do0.1_best_f1_macro.pt\", map_location=device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best_state_dict = torch.load(\"/data/zhihao/TU/Watchog/outputs/gt-semtab22-dbpedia-all0/bert-base-uncased-fromscratch-semi1-AttnMask-max-unlabeled@8-poolv0-unlabeled8-randFalse-bs16-ml128-ne50-do0.1_best_f1_micro.pt\", map_location=device)\n",
    "best_state_dict = torch.load(\"/data/zhihao/TU/Watchog/outputs/gt-semtab22-dbpedia-all0/bert-base-uncased-fromscratch-semi1-Repeat@5-AttnMask-UnlabelValid-max-unlabeled@8-poolv0-unlabeled8-randFalse-bs16-ml128-ne50-do0.1_best_f1_macro.pt\", map_location=device)\n",
    "model.load_state_dict(best_state_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GittablesTablewiseIterateDataset(data.Dataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            cv: int,\n",
    "            split: str,\n",
    "            src: str,  # train or test\n",
    "            tokenizer: AutoTokenizer,\n",
    "            max_length: int = 256,\n",
    "            gt_only: bool = False,\n",
    "            device: torch.device = None,\n",
    "            base_dirpath: str = \"/data/zhihao/TU/GitTables/semtab_gittables/2022\",\n",
    "            base_tag: str = '', # blank, comma\n",
    "            small_tag: str = \"\",\n",
    "            train_ratio: float = 1.0,\n",
    "            max_unlabeled=8,\n",
    "            adaptive_max_length=True,\n",
    "            random_sample=False, # TODO\n",
    "            train_only=False): # TODO\n",
    "        if device is None:\n",
    "            device = torch.device('cpu')\n",
    "        basename = small_tag+ \"_cv_{}.csv\"\n",
    "    \n",
    "        if split in [\"train\", \"valid\"]:\n",
    "            df_list = []\n",
    "            for i in range(5):\n",
    "                if i == cv:\n",
    "                    continue\n",
    "                filepath = os.path.join(base_dirpath, basename.format(i))\n",
    "                df_list.append(pd.read_csv(filepath))\n",
    "                print(split, i)\n",
    "            df = pd.concat(df_list, axis=0)\n",
    "        else:\n",
    "            # test\n",
    "            filepath = os.path.join(base_dirpath, basename.format(cv))\n",
    "            df = pd.read_csv(filepath)\n",
    "            print(split)\n",
    "\n",
    "\n",
    "        if gt_only:\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "        if train_only and split != \"train\":\n",
    "            df = df[df[\"class_id\"] > -1]\n",
    "\n",
    "        \n",
    "        data_list = []\n",
    "        \n",
    "        df['class_id'] = df['class_id'].astype(int)\n",
    "        df.drop(df[(df['data'].isna()) & (df['class_id'] == -1)].index, inplace=True)\n",
    "        df['col_idx'] = df['col_idx'].astype(int)\n",
    "        df['data'] = df['data'].astype(str)\n",
    "        \n",
    "        num_tables = len(df.groupby(\"table_id\"))\n",
    "        valid_index = int(num_tables * 0.8)\n",
    "        num_train = int(train_ratio * num_tables * 0.8)        \n",
    "        \n",
    "        # df.drop(df[(df['data'] == '') & (df['class_id'] == -1)].index, inplace=True)\n",
    "        total_num_cols = 0\n",
    "        for i, (index, group_df) in enumerate(df.groupby(\"table_id\")):\n",
    "            if (split == \"train\") and ((i >= num_train) or (i >= valid_index)):\n",
    "                break\n",
    "            if split == \"valid\" and i < valid_index:\n",
    "                continue\n",
    "            #     break\n",
    "            labeled_columns = group_df[group_df['class_id'] > -1]\n",
    "            unlabeled_columns = group_df[group_df['class_id'] == -1]\n",
    "            num_unlabeled = min(max(max_unlabeled-len(labeled_columns), 0), len(unlabeled_columns)) if max_unlabeled > 0 else len(unlabeled_columns)\n",
    "            unlabeled_columns = unlabeled_columns.sample(num_unlabeled) if random_sample else unlabeled_columns[0:num_unlabeled]\n",
    "            # group_df = pd.concat([group_df[group_df['class_id'] > -1], unlabeled_columns.sample(min(10-len(labeled_columns), len(unlabeled_columns)))])\n",
    "            # group_df = pd.concat([group_df[group_df['class_id'] > -1], unlabeled_columns[0:min(max(10-len(labeled_columns), 0), len(unlabeled_columns))]])\n",
    "            group_df = pd.concat([group_df[group_df['class_id'] > -1], unlabeled_columns]) # TODO\n",
    "            group_df.sort_values(by=['col_idx'], inplace=True)\n",
    "\n",
    "            if max_length <= 128 and adaptive_max_length:\n",
    "                cur_maxlen = min(max_length, 512 // len(list(group_df[\"class_id\"].values)) - 1)\n",
    "            else:\n",
    "                cur_maxlen = max_length\n",
    "                \n",
    "            token_ids_list = group_df[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "                tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=cur_maxlen, truncation=True)).tolist(\n",
    "                )\n",
    "            token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                                token_ids_list)).to(device)\n",
    "            for col_i in range(len(token_ids_list)):\n",
    "                if group_df[\"class_id\"].values[col_i] == -1:\n",
    "                    continue\n",
    "                target_col_mask = []\n",
    "                cls_index_value = 0\n",
    "                context_id = 1\n",
    "                for col_j in range(len(token_ids_list)):\n",
    "                    if col_j == col_i:\n",
    "                        target_col_mask += [0] * len(token_ids_list[col_j])\n",
    "                    else:\n",
    "                        target_col_mask += [context_id] * len(token_ids_list[col_j])\n",
    "                        context_id += 1\n",
    "                    if col_j < col_i:\n",
    "                        cls_index_value += len(token_ids_list[col_j])\n",
    "                cls_index_list = [cls_index_value] \n",
    "                for cls_index in cls_index_list:\n",
    "                    assert token_ids[\n",
    "                        cls_index] == tokenizer.cls_token_id, \"cls_indexes validation\"\n",
    "                cls_indexes = torch.LongTensor(cls_index_list).to(device)\n",
    "                class_ids = torch.LongTensor(\n",
    "                    [group_df[\"class_id\"].values[col_i]]).to(device)\n",
    "                target_col_mask = torch.LongTensor(target_col_mask).to(device)\n",
    "                data_list.append(\n",
    "                    [index,\n",
    "                    len(group_df), token_ids, class_ids, cls_indexes, target_col_mask])                \n",
    "        print(split, len(data_list))\n",
    "        self.table_df = pd.DataFrame(data_list,\n",
    "                                     columns=[\n",
    "                                         \"table_id\", \"num_col\", \"data_tensor\",\n",
    "                                         \"label_tensor\", \"cls_indexes\", \"target_col_mask\"\n",
    "                                     ])\n",
    "        \"\"\"\n",
    "        # NOTE: msato contains a small portion of single-col tables. keep it to be consistent.  \n",
    "        if multicol_only:\n",
    "            # Check\n",
    "            num_all_tables = len(self.table_df)\n",
    "            self.table_df = self.table_df[self.table_df[\"num_col\"] > 1]\n",
    "            assert len(self.table_df) == num_all_tables\n",
    "        \"\"\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.table_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"data\": self.table_df.iloc[idx][\"data_tensor\"],\n",
    "            \"label\": self.table_df.iloc[idx][\"label_tensor\"],\n",
    "            \"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"],\n",
    "            \"target_col_mask\": self.table_df.iloc[idx][\"target_col_mask\"],\n",
    "        }\n",
    "        #\"idx\": torch.LongTensor([idx])}\n",
    "        #\"cls_indexes\": self.table_df.iloc[idx][\"cls_indexes\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(pad_token_id, data_only=True):\n",
    "    '''padder for input batch'''\n",
    "\n",
    "    def padder(samples):    \n",
    "        data = torch.nn.utils.rnn.pad_sequence(\n",
    "            [sample[\"data\"] for sample in samples], padding_value=pad_token_id)\n",
    "        if not data_only:\n",
    "            label = torch.nn.utils.rnn.pad_sequence(\n",
    "                [sample[\"label\"] for sample in samples], padding_value=-1)\n",
    "        else:\n",
    "            label = torch.cat([sample[\"label\"] for sample in samples])\n",
    "        batch = {\"data\": data, \"label\": label}\n",
    "        if \"idx\" in samples[0]:\n",
    "            batch[\"idx\"] = [sample[\"idx\"] for sample in samples]\n",
    "        if \"cls_indexes\" in samples[0]:\n",
    "            cls_indexes = torch.nn.utils.rnn.pad_sequence(\n",
    "                [sample[\"cls_indexes\"] for sample in samples], padding_value=0)\n",
    "            batch[\"cls_indexes\"] = cls_indexes\n",
    "        if \"target_col_mask\" in samples[0]:\n",
    "            target_col_mask = torch.nn.utils.rnn.pad_sequence(\n",
    "                [sample[\"target_col_mask\"] for sample in samples], padding_value=-1)\n",
    "            batch[\"target_col_mask\"] = target_col_mask\n",
    "        if \"table_embedding\" in samples[0]:\n",
    "            table_embeddings = [sample[\"table_embedding\"] for sample in samples]\n",
    "            batch[\"table_embedding\"] = torch.stack(table_embeddings, dim=0)\n",
    "        return batch\n",
    "        \n",
    "    return padder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "test 1085\n"
     ]
    }
   ],
   "source": [
    "src = None\n",
    "test_dataset_iter = GittablesTablewiseIterateDataset(cv=cv,\n",
    "                            split=\"test\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only='all' not in task,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\")\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "test_dataloader_iter = DataLoader(test_dataset_iter,\n",
    "                                batch_size=1,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 1\n",
      "train 2\n",
      "train 3\n",
      "train 4\n",
      "train 3463\n"
     ]
    }
   ],
   "source": [
    "train_dataset_iter = GittablesTablewiseIterateDataset(cv=cv,\n",
    "                            split=\"train\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only='all' not in task,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\")\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "train_dataloader_iter = DataLoader(train_dataset_iter,\n",
    "                                batch_size=1,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(train_dataloader_iter):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    num_cols.append(batch[\"target_col_mask\"].max().item()+1)\n",
    "num_cols = torch.tensor(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(num_cols.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid 1\n",
      "valid 2\n",
      "valid 3\n",
      "valid 4\n",
      "valid 885\n"
     ]
    }
   ],
   "source": [
    "src = None\n",
    "valid_dataset_iter = GittablesTablewiseIterateDataset(cv=cv,\n",
    "                            split=\"valid\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only='all' not in task,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\")\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "valid_dataloader_iter = DataLoader(valid_dataset_iter,\n",
    "                                batch_size=1,\n",
    "                            #   collate_fn=collate_fn)\n",
    "                            collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_micro_f1=0.5355, ts_macro_f1=0.2745\n",
      "ts_micro_f1=0.5351, ts_macro_f1=0.2745\n",
      "ts_micro_f1=1.0000, ts_macro_f1=1.0000\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    labels_test.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "    num_cols.append(batch[\"target_col_mask\"].max().item())\n",
    "    ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "labels_test = torch.cat(labels_test, dim=0)\n",
    "logits_test = torch.stack(logits_test, dim=0)\n",
    "preds_test = torch.argmax(logits_test, dim=1)\n",
    "num_cols = torch.tensor(num_cols)\n",
    "ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "mask = num_cols > 0\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "full_f1_init = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=None)\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach()[mask].numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach()[~mask].numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_cols=0 ts_micro_f1=1.0000, ts_macro_f1=1.0000\n",
      "num_cols=2 ts_micro_f1=0.6364, ts_macro_f1=0.3241\n",
      "num_cols=3 ts_micro_f1=0.5181, ts_macro_f1=0.1611\n",
      "num_cols=4 ts_micro_f1=0.5909, ts_macro_f1=0.2328\n",
      "num_cols=5 ts_micro_f1=0.5455, ts_macro_f1=0.2550\n",
      "num_cols=6 ts_micro_f1=0.5733, ts_macro_f1=0.2734\n",
      "num_cols=7 ts_micro_f1=0.5146, ts_macro_f1=0.2800\n"
     ]
    }
   ],
   "source": [
    "for n_col in num_cols.unique().tolist():\n",
    "    mask = num_cols == n_col\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach()[mask].numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    print(\"num_cols={} ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(n_col, ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_embedding = nn.Embedding(2, 768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 768])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_embedding(torch.ones(32).long()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.82129278, 0.7003367 , 0.49019608, 0.41463415, 0.5       ,\n",
       "       0.57777778, 0.54545455, 0.5       , 0.31578947, 0.81081081,\n",
       "       0.21621622, 0.20689655, 0.84848485, 0.1875    , 0.64285714,\n",
       "       0.86666667, 0.10526316, 0.5       , 0.21428571, 0.92307692,\n",
       "       0.46153846, 0.56      , 0.28571429, 0.42105263, 0.31578947,\n",
       "       0.33333333, 0.26666667, 0.        , 0.14285714, 0.5       ,\n",
       "       0.36363636, 0.        , 0.        , 0.35294118, 0.44444444,\n",
       "       0.42857143, 0.26666667, 0.2       , 0.25      , 0.2       ,\n",
       "       0.        , 0.28571429, 0.30769231, 0.22222222, 0.        ,\n",
       "       0.        , 0.33333333, 0.        , 0.33333333, 0.33333333,\n",
       "       0.28571429, 0.        , 0.5       , 0.25      , 0.66666667,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 1.        , 0.        , 0.66666667, 0.        ,\n",
       "       0.        , 0.        , 0.5       , 0.33333333, 0.33333333,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.28571429, 0.33333333, 0.66666667, 0.28571429, 0.        ,\n",
       "       0.        , 0.        , 0.4       , 0.        , 0.22222222,\n",
       "       0.5       , 0.        , 0.5       , 1.        , 0.        ,\n",
       "       0.        , 0.33333333, 0.        , 0.        , 0.66666667,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_f1_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_micro_f1=0.5503, ts_macro_f1=0.3178\n",
      "ts_micro_f1=0.5493, ts_macro_f1=0.3178\n",
      "ts_micro_f1=1.0000, ts_macro_f1=1.0000\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(valid_dataloader_iter):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    labels_test.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "    num_cols.append(batch[\"target_col_mask\"].max().item())\n",
    "    ft_embs_test.append(embs.detach().cpu().reshape(1, -1))\n",
    "labels_test = torch.cat(labels_test, dim=0)\n",
    "logits_test = torch.stack(logits_test, dim=0)\n",
    "preds_test = torch.argmax(logits_test, dim=1)\n",
    "num_cols = torch.tensor(num_cols)\n",
    "ft_embs_test = torch.cat(ft_embs_test, dim=0)\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "mask = num_cols > 0\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach()[mask].numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach()[~mask].numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_freq = torch.zeros(args.num_classes)\n",
    "for batch_idx, batch in enumerate(train_dataloader_iter):\n",
    "    class_freq[batch[\"label\"].item()] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def reweight_logits(logits, class_weights):\n",
    "#     # Reweight the logits by multiplying with class weights\n",
    "#     reweighted_logits = logits * torch.sqrt(class_weights)\n",
    "    \n",
    "#     # Apply softmax to the reweighted logits\n",
    "#     reweighted_probs = F.softmax(reweighted_logits, dim=-1)\n",
    "    \n",
    "#     return reweighted_probs\n",
    "def reweight_logits(logits, class_weights):\n",
    "    # Step 1: Apply exp(logits)\n",
    "    exp_logits = torch.exp(logits)\n",
    "    \n",
    "    # Step 2: Multiply by class weights\n",
    "    # reweighted_exp = exp_logits * torch.sqrt(class_weights)\n",
    "    reweighted_exp = exp_logits * class_weights\n",
    "    # Step 3: Normalize to get valid probabilities (like softmax)\n",
    "    reweighted_probs = reweighted_exp / reweighted_exp.sum(dim=-1, keepdim=True)\n",
    "    \n",
    "    return reweighted_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Threshold: 0.9****************************\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# brute force perumate, find uncertain init prediction, weighted msp\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "idx_list = []\n",
    "uncertain_init_mask = []\n",
    "uncertain_target_mask = []\n",
    "correct_init_mask = []\n",
    "correct_target_mask = []\n",
    "correct_permutation_mask = []\n",
    "correct_permutation_confident_mask = []\n",
    "correct_permutation_confident_scores = []\n",
    "correct_msp_mask = []\n",
    "init_target_mask = []\n",
    "ood_score_init_list = []\n",
    "ood_score_target_list = []\n",
    "ood_score_final_list = []\n",
    "msp_predicts = []\n",
    "max_col_length = 3\n",
    "\n",
    "alpha = 0\n",
    "# class_weights = (1.0 / class_freq) ** alpha\n",
    "# debias_threshold = 1.0\n",
    "# # Normalize the weights\n",
    "# class_weights /= class_weights.sum()\n",
    "for threshold in [0.9]:\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    log = defaultdict(list)\n",
    "    num_cols = []\n",
    "    corrected = 0\n",
    "    total_mistakes = 0\n",
    "\n",
    "    for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "        target_col_mask = batch[\"target_col_mask\"].T\n",
    "        if 1 in target_col_mask:\n",
    "            idx_list.append(batch_idx)\n",
    "\n",
    "            cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "            logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "            # logits = reweight_logits(logits.detach().cpu(), class_weights)\n",
    "            logits = F.softmax(logits, dim=-1)\n",
    "            num_cols.append(batch[\"target_col_mask\"].max().item())         \n",
    "            ood_score_init = logits.max().item()\n",
    "            ood_score_init_list.append(ood_score_init)\n",
    "            uncertain_init_mask.append(ood_score_init < threshold)\n",
    "            predict_init = logits.argmax().item()\n",
    "            correct_init_mask.append(predict_init == batch[\"label\"].item())\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            \n",
    "            correct_permutation = False\n",
    "            correct_permutation_ood_score = 0.0\n",
    "            correct_permutation_confident = False\n",
    "            ood_score_max = max_msp = 0\n",
    "            max_msp_debiased = 0\n",
    "            debias_class = []\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            assert -1 not in col_idx_set\n",
    "            for r in range(len(col_idx_set)-1, len(col_idx_set)//2, -1):\n",
    "                for subset in itertools.combinations(col_idx_set, r):\n",
    "                    if 0 not in subset and r != 1:\n",
    "                        continue\n",
    "                    for x in itertools.permutations(subset):\n",
    "                        if not is_sublist(x, init_permutation_i):\n",
    "                            continue\n",
    "                        new_batch_data = []\n",
    "                        for col_i in x:\n",
    "                            if col_i == 0:\n",
    "                                if len(new_batch_data) == 0:\n",
    "                                    cls_indexes_value = 0\n",
    "                                else:\n",
    "                                    cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                            new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                        if 0 not in x:\n",
    "                            cls_indexes_value = 0\n",
    "                        new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                        cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                        logits_temp = model(new_batch_data, cls_indexes=cls_indexes,)\n",
    "                        logits_temp = F.softmax(logits_temp, dim=-1)\n",
    "                        # logits_temp = reweight_logits(logits_temp.detach().cpu(), class_weights)\n",
    "                        msp_temp = logits_temp.max().item()\n",
    "                        predict_temp = logits_temp.argmax().item()\n",
    "                        # if 0 not in x and msp_temp > debias_threshold and (predict_temp!=predict_target or predict_temp!=predict_init):\n",
    "                        #     debias_class.append(predict_temp)\n",
    "                        #     continue\n",
    "                        # print(x, msp_temp, predict_temp)\n",
    "                        # if msp_temp > max_msp and 0 in x and predict_temp not in debias_class:\n",
    "                        if msp_temp > max_msp and 0 in x:\n",
    "                            max_msp = msp_temp\n",
    "                            msp_predict = predict_temp\n",
    "                        if predict_temp == batch[\"label\"].item():\n",
    "                            correct_permutation = True\n",
    "                            if msp_temp > correct_permutation_ood_score:\n",
    "                                correct_permutation_ood_score = msp_temp\n",
    "            msp_predicts.append(msp_predict)\n",
    "            ood_score_final_list.append(max_msp)\n",
    "            correct_permutation_mask.append(correct_permutation)\n",
    "            correct_permutation_confident_scores.append(correct_permutation_ood_score)\n",
    "            correct_msp_mask.append(msp_predict == batch[\"label\"].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3888413/4104837288.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  idx_list = torch.tensor(idx_list).reshape(-1)\n",
      "/tmp/ipykernel_3888413/4104837288.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  uncertain_init_mask = torch.tensor(uncertain_init_mask).reshape(-1)\n",
      "/tmp/ipykernel_3888413/4104837288.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  uncertain_target_mask = torch.tensor(uncertain_target_mask).reshape(-1)\n",
      "/tmp/ipykernel_3888413/4104837288.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  correct_init_mask = torch.tensor(correct_init_mask).reshape(-1)\n",
      "/tmp/ipykernel_3888413/4104837288.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  correct_target_mask = torch.tensor(correct_target_mask).reshape(-1)\n",
      "/tmp/ipykernel_3888413/4104837288.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  correct_permutation_mask = torch.tensor(correct_permutation_mask).reshape(-1)\n",
      "/tmp/ipykernel_3888413/4104837288.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  correct_permutation_confident_scores = torch.tensor(correct_permutation_confident_scores).reshape(-1)\n",
      "/tmp/ipykernel_3888413/4104837288.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  correct_msp_mask = torch.tensor(correct_msp_mask).reshape(-1)\n",
      "/tmp/ipykernel_3888413/4104837288.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  init_target_mask = torch.tensor(init_target_mask).reshape(-1)\n",
      "/tmp/ipykernel_3888413/4104837288.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ood_score_init_list = torch.tensor(ood_score_init_list).reshape(-1)\n",
      "/tmp/ipykernel_3888413/4104837288.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ood_score_target_list = torch.tensor(ood_score_target_list).reshape(-1)\n",
      "/tmp/ipykernel_3888413/4104837288.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ood_score_final_list = torch.tensor(ood_score_final_list).reshape(-1)\n",
      "/tmp/ipykernel_3888413/4104837288.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  msp_predicts = torch.tensor(msp_predicts).reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1084 0 1084 0 1084\n"
     ]
    }
   ],
   "source": [
    "\n",
    "idx_list = torch.tensor(idx_list).reshape(-1)\n",
    "uncertain_init_mask = torch.tensor(uncertain_init_mask).reshape(-1)\n",
    "uncertain_target_mask = torch.tensor(uncertain_target_mask).reshape(-1)\n",
    "correct_init_mask = torch.tensor(correct_init_mask).reshape(-1)\n",
    "correct_target_mask = torch.tensor(correct_target_mask).reshape(-1)\n",
    "correct_permutation_mask = torch.tensor(correct_permutation_mask).reshape(-1)\n",
    "correct_permutation_confident_scores = torch.tensor(correct_permutation_confident_scores).reshape(-1)\n",
    "correct_msp_mask = torch.tensor(correct_msp_mask).reshape(-1)\n",
    "init_target_mask = torch.tensor(init_target_mask).reshape(-1)\n",
    "ood_score_init_list = torch.tensor(ood_score_init_list).reshape(-1)\n",
    "ood_score_target_list = torch.tensor(ood_score_target_list).reshape(-1)\n",
    "ood_score_final_list = torch.tensor(ood_score_final_list).reshape(-1)\n",
    "msp_predicts = torch.tensor(msp_predicts).reshape(-1)\n",
    "print(len(idx_list), len(init_target_mask), len(correct_init_mask), len(correct_target_mask), len(correct_permutation_mask))\n",
    "torch.save({\"idx_list\": idx_list, \"uncertain_init_mask\": uncertain_init_mask, \"uncertain_target_mask\": uncertain_target_mask, \"correct_init_mask\": correct_init_mask, \"correct_target_mask\": correct_target_mask, \"correct_permutation_mask\": correct_permutation_mask, \"correct_msp_mask\": correct_msp_mask, \"init_target_mask\": init_target_mask, \"ood_score_init_list\": ood_score_init_list, \"ood_score_target_list\": ood_score_target_list, \"ood_score_final_list\": ood_score_final_list}, f\"./results/brute_force_permutation_alpha@{alpha}_drop.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Threshold: 0.9****************************\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# brute force perumate, find uncertain init prediction, weighted msp\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "idx_list = []\n",
    "uncertain_init_mask = []\n",
    "uncertain_target_mask = []\n",
    "correct_init_mask = []\n",
    "correct_target_mask = []\n",
    "correct_permutation_mask = []\n",
    "correct_permutation_confident_mask = []\n",
    "correct_permutation_confident_scores = []\n",
    "correct_msp_mask = []\n",
    "init_target_mask = []\n",
    "ood_score_init_list = []\n",
    "ood_score_target_list = []\n",
    "ood_score_final_list = []\n",
    "msp_predicts = []\n",
    "max_col_length = 3\n",
    "\n",
    "alpha = 0.25\n",
    "class_weights = (1.0 / class_freq) ** alpha\n",
    "debias_threshold = 1.0\n",
    "# Normalize the weights\n",
    "class_weights /= class_weights.sum()\n",
    "for threshold in [0.9]:\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    log = defaultdict(list)\n",
    "    num_cols = []\n",
    "    corrected = 0\n",
    "    total_mistakes = 0\n",
    "\n",
    "    for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "        target_col_mask = batch[\"target_col_mask\"].T\n",
    "        if 1 in target_col_mask:\n",
    "            idx_list.append(batch_idx)\n",
    "\n",
    "            cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "            logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "            logits = reweight_logits(logits.detach().cpu(), class_weights)\n",
    "            num_cols.append(batch[\"target_col_mask\"].max().item())         \n",
    "            ood_score_init = logits.max().item()\n",
    "            ood_score_init_list.append(ood_score_init)\n",
    "            uncertain_init_mask.append(ood_score_init < threshold)\n",
    "            predict_init = logits.argmax().item()\n",
    "            correct_init_mask.append(predict_init == batch[\"label\"].item())\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            \n",
    "            correct_permutation = False\n",
    "            correct_permutation_ood_score = 0.0\n",
    "            correct_permutation_confident = False\n",
    "            ood_score_max = max_msp = 0\n",
    "            max_msp_debiased = 0\n",
    "            debias_class = []\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            assert -1 not in col_idx_set\n",
    "            for r in range(len(col_idx_set)-1, len(col_idx_set)//2, -1):\n",
    "                for subset in itertools.combinations(col_idx_set, r):\n",
    "                    if 0 not in subset and r != 1:\n",
    "                        continue\n",
    "                    for x in itertools.permutations(subset):\n",
    "                        if not is_sublist(x, init_permutation_i):\n",
    "                            continue\n",
    "                        new_batch_data = []\n",
    "                        for col_i in x:\n",
    "                            if col_i == 0:\n",
    "                                if len(new_batch_data) == 0:\n",
    "                                    cls_indexes_value = 0\n",
    "                                else:\n",
    "                                    cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                            new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                        if 0 not in x:\n",
    "                            cls_indexes_value = 0\n",
    "                        new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                        cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                        logits_temp = model(new_batch_data, cls_indexes=cls_indexes,)\n",
    "                        logits_temp = reweight_logits(logits_temp.detach().cpu(), class_weights)\n",
    "                        msp_temp = logits_temp.max().item()\n",
    "                        predict_temp = logits_temp.argmax().item()\n",
    "                        # if 0 not in x and msp_temp > debias_threshold and (predict_temp!=predict_target or predict_temp!=predict_init):\n",
    "                        #     debias_class.append(predict_temp)\n",
    "                        #     continue\n",
    "                        # print(x, msp_temp, predict_temp)\n",
    "                        # if msp_temp > max_msp and 0 in x and predict_temp not in debias_class:\n",
    "                        if msp_temp > max_msp and 0 in x:\n",
    "                            max_msp = msp_temp\n",
    "                            msp_predict = predict_temp\n",
    "                        if predict_temp == batch[\"label\"].item():\n",
    "                            correct_permutation = True\n",
    "                            if msp_temp > correct_permutation_ood_score:\n",
    "                                correct_permutation_ood_score = msp_temp\n",
    "            msp_predicts.append(msp_predict)\n",
    "            ood_score_final_list.append(max_msp)\n",
    "            correct_permutation_mask.append(correct_permutation)\n",
    "            correct_permutation_confident_scores.append(correct_permutation_ood_score)\n",
    "            correct_msp_mask.append(msp_predict == batch[\"label\"].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1084 0 1084 0 1084\n"
     ]
    }
   ],
   "source": [
    "\n",
    "idx_list = torch.tensor(idx_list).reshape(-1)\n",
    "uncertain_init_mask = torch.tensor(uncertain_init_mask).reshape(-1)\n",
    "uncertain_target_mask = torch.tensor(uncertain_target_mask).reshape(-1)\n",
    "correct_init_mask = torch.tensor(correct_init_mask).reshape(-1)\n",
    "correct_target_mask = torch.tensor(correct_target_mask).reshape(-1)\n",
    "correct_permutation_mask = torch.tensor(correct_permutation_mask).reshape(-1)\n",
    "correct_permutation_confident_scores = torch.tensor(correct_permutation_confident_scores).reshape(-1)\n",
    "correct_msp_mask = torch.tensor(correct_msp_mask).reshape(-1)\n",
    "init_target_mask = torch.tensor(init_target_mask).reshape(-1)\n",
    "ood_score_init_list = torch.tensor(ood_score_init_list).reshape(-1)\n",
    "ood_score_target_list = torch.tensor(ood_score_target_list).reshape(-1)\n",
    "ood_score_final_list = torch.tensor(ood_score_final_list).reshape(-1)\n",
    "msp_predicts = torch.tensor(msp_predicts).reshape(-1)\n",
    "print(len(idx_list), len(init_target_mask), len(correct_init_mask), len(correct_target_mask), len(correct_permutation_mask))\n",
    "torch.save({\"idx_list\": idx_list, \"uncertain_init_mask\": uncertain_init_mask, \"uncertain_target_mask\": uncertain_target_mask, \"correct_init_mask\": correct_init_mask, \"correct_target_mask\": correct_target_mask, \"correct_permutation_mask\": correct_permutation_mask, \"correct_msp_mask\": correct_msp_mask, \"init_target_mask\": init_target_mask, \"ood_score_init_list\": ood_score_init_list, \"ood_score_target_list\": ood_score_target_list, \"ood_score_final_list\": ood_score_final_list}, f\"./results/brute_force_permutation_alpha@{alpha}_drop.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Threshold: 0.8****************************\n",
      "Init\n",
      "528 758 0.6965699208443272\n",
      "48 326 0.147239263803681\n",
      "MSP\n",
      "503 758 0.6635883905013192\n",
      "59 326 0.18098159509202455\n",
      "MSP & Init\n",
      "482\n",
      "549 758 0.7242744063324539\n",
      "85 326 0.2607361963190184\n",
      "Permutation\n",
      "609 758 0.8034300791556728\n",
      "141 326 0.4325153374233129\n",
      "Permutation Confident\n",
      "567 758 0.7480211081794196\n",
      "81 326 0.24846625766871167\n",
      "*********************Threshold: 0.9****************************\n",
      "Init\n",
      "505 688 0.7340116279069767\n",
      "71 396 0.17929292929292928\n",
      "MSP\n",
      "482 688 0.7005813953488372\n",
      "80 396 0.20202020202020202\n",
      "MSP & Init\n",
      "466\n",
      "521 688 0.7572674418604651\n",
      "113 396 0.28535353535353536\n",
      "Permutation\n",
      "564 688 0.8197674418604651\n",
      "186 396 0.4696969696969697\n",
      "Permutation Confident\n",
      "531 688 0.7718023255813954\n",
      "100 396 0.25252525252525254\n",
      "*********************Threshold: 0.99****************************\n",
      "Init\n",
      "431 515 0.8368932038834952\n",
      "145 569 0.2548330404217926\n",
      "MSP\n",
      "413 515 0.8019417475728156\n",
      "149 569 0.2618629173989455\n",
      "MSP & Init\n",
      "410\n",
      "434 515 0.8427184466019417\n",
      "200 569 0.351493848857645\n",
      "Permutation\n",
      "446 515 0.8660194174757282\n",
      "304 569 0.5342706502636204\n",
      "Permutation Confident\n",
      "433 515 0.8407766990291262\n",
      "104 569 0.1827768014059754\n"
     ]
    }
   ],
   "source": [
    "# weighted, only uncertain init\n",
    "\n",
    "for threshold in [0.8, 0.9, 0.99]:\n",
    "    correct_permutation_confident_mask = correct_permutation_confident_scores>threshold\n",
    "    uncertain_init_mask = ood_score_init_list < threshold\n",
    "    uncertain_target_mask = ood_score_target_list < threshold\n",
    "    condition_mask = ~uncertain_init_mask\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    print(\"Init\")\n",
    "    # init prediction\n",
    "    print((condition_mask&correct_init_mask).sum().item(), \n",
    "        (condition_mask).sum().item(), \n",
    "        (condition_mask&correct_init_mask).sum().item()/(condition_mask).sum().item())\n",
    "    # init prediction\n",
    "    print((~condition_mask&correct_init_mask).sum().item(), \n",
    "        (~condition_mask).sum().item(), \n",
    "       (~condition_mask&correct_init_mask).sum().item()/(~condition_mask).sum().item())\n",
    "    print(\"MSP\")\n",
    "    # msp prediction\n",
    "    print((condition_mask&correct_msp_mask).sum().item(), \n",
    "        (condition_mask).sum().item(), \n",
    "        (condition_mask&correct_msp_mask).sum().item()/(condition_mask).sum().item())\n",
    "    # msp prediction\n",
    "    print((~condition_mask&correct_msp_mask).sum().item(), \n",
    "        (~condition_mask).sum().item(), \n",
    "        (~condition_mask&correct_msp_mask).sum().item()/(~condition_mask).sum().item())\n",
    "    print(\"MSP & Init\")\n",
    "    print(((condition_mask&correct_init_mask)&(condition_mask&correct_msp_mask)).sum().item())\n",
    "    # print(((~(init_target_mask&(~uncertain_init_mask & ~uncertain_target_mask))& correct_msp_mask)&(~(init_target_mask&(~uncertain_init_mask & ~uncertain_target_mask))& correct_init_mask)).sum().item())\n",
    "    print(((condition_mask&correct_init_mask)|(condition_mask&correct_msp_mask)).sum().item(),\n",
    "          (condition_mask).sum().item(), \n",
    "          ((condition_mask&correct_init_mask)|(condition_mask&correct_msp_mask)).sum().item()/(condition_mask).sum().item())\n",
    "    print(((~condition_mask&correct_init_mask)|(~condition_mask&correct_msp_mask)).sum().item(),\n",
    "          (~condition_mask).sum().item(), \n",
    "          ((~condition_mask&correct_init_mask)|(~condition_mask&correct_msp_mask)).sum().item()/(~condition_mask).sum().item())\n",
    "    print(\"Permutation\")\n",
    "    print((condition_mask&correct_permutation_mask).sum().item(), \n",
    "        (condition_mask).sum().item(), \n",
    "        (condition_mask&correct_permutation_mask).sum().item()/(condition_mask).sum().item())\n",
    "    print((~condition_mask&correct_permutation_mask).sum().item(), \n",
    "         (~condition_mask).sum().item(), \n",
    "        (~condition_mask&correct_permutation_mask).sum().item()/(~condition_mask).sum().item())\n",
    "    print(\"Permutation Confident\")\n",
    "    print((condition_mask&correct_permutation_confident_mask).sum().item(), \n",
    "        (condition_mask).sum().item(), \n",
    "        (condition_mask&correct_permutation_confident_mask).sum().item()/(condition_mask).sum().item())\n",
    "    print((~condition_mask&correct_permutation_confident_mask).sum().item(),\n",
    "            (~condition_mask).sum().item(), \n",
    "            (~condition_mask&correct_permutation_confident_mask).sum().item()/(~condition_mask).sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Threshold: 0.82****************************\n",
      "Init\n",
      "524 742 0.706199460916442\n",
      "52 342 0.15204678362573099\n",
      "MSP\n",
      "497 742 0.6698113207547169\n",
      "65 342 0.19005847953216373\n",
      "MSP & Init\n",
      "479\n",
      "542 742 0.7304582210242587\n",
      "92 342 0.26900584795321636\n",
      "Permutation\n",
      "599 742 0.807277628032345\n",
      "151 342 0.4415204678362573\n",
      "Permutation Confident\n",
      "558 742 0.7520215633423181\n",
      "88 342 0.2573099415204678\n"
     ]
    }
   ],
   "source": [
    "# weighted, only uncertain init\n",
    "\n",
    "for threshold in [0.82]:\n",
    "    correct_permutation_confident_mask = correct_permutation_confident_scores>threshold\n",
    "    uncertain_init_mask = ood_score_init_list < threshold\n",
    "    uncertain_target_mask = ood_score_target_list < threshold\n",
    "    condition_mask = ~uncertain_init_mask\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    print(\"Init\")\n",
    "    # init prediction\n",
    "    print((condition_mask&correct_init_mask).sum().item(), \n",
    "        (condition_mask).sum().item(), \n",
    "        (condition_mask&correct_init_mask).sum().item()/(condition_mask).sum().item())\n",
    "    # init prediction\n",
    "    print((~condition_mask&correct_init_mask).sum().item(), \n",
    "        (~condition_mask).sum().item(), \n",
    "       (~condition_mask&correct_init_mask).sum().item()/(~condition_mask).sum().item())\n",
    "    print(\"MSP\")\n",
    "    # msp prediction\n",
    "    print((condition_mask&correct_msp_mask).sum().item(), \n",
    "        (condition_mask).sum().item(), \n",
    "        (condition_mask&correct_msp_mask).sum().item()/(condition_mask).sum().item())\n",
    "    # msp prediction\n",
    "    print((~condition_mask&correct_msp_mask).sum().item(), \n",
    "        (~condition_mask).sum().item(), \n",
    "        (~condition_mask&correct_msp_mask).sum().item()/(~condition_mask).sum().item())\n",
    "    print(\"MSP & Init\")\n",
    "    print(((condition_mask&correct_init_mask)&(condition_mask&correct_msp_mask)).sum().item())\n",
    "    # print(((~(init_target_mask&(~uncertain_init_mask & ~uncertain_target_mask))& correct_msp_mask)&(~(init_target_mask&(~uncertain_init_mask & ~uncertain_target_mask))& correct_init_mask)).sum().item())\n",
    "    print(((condition_mask&correct_init_mask)|(condition_mask&correct_msp_mask)).sum().item(),\n",
    "          (condition_mask).sum().item(), \n",
    "          ((condition_mask&correct_init_mask)|(condition_mask&correct_msp_mask)).sum().item()/(condition_mask).sum().item())\n",
    "    print(((~condition_mask&correct_init_mask)|(~condition_mask&correct_msp_mask)).sum().item(),\n",
    "          (~condition_mask).sum().item(), \n",
    "          ((~condition_mask&correct_init_mask)|(~condition_mask&correct_msp_mask)).sum().item()/(~condition_mask).sum().item())\n",
    "    print(\"Permutation\")\n",
    "    print((condition_mask&correct_permutation_mask).sum().item(), \n",
    "        (condition_mask).sum().item(), \n",
    "        (condition_mask&correct_permutation_mask).sum().item()/(condition_mask).sum().item())\n",
    "    print((~condition_mask&correct_permutation_mask).sum().item(), \n",
    "         (~condition_mask).sum().item(), \n",
    "        (~condition_mask&correct_permutation_mask).sum().item()/(~condition_mask).sum().item())\n",
    "    print(\"Permutation Confident\")\n",
    "    print((condition_mask&correct_permutation_confident_mask).sum().item(), \n",
    "        (condition_mask).sum().item(), \n",
    "        (condition_mask&correct_permutation_confident_mask).sum().item()/(condition_mask).sum().item())\n",
    "    print((~condition_mask&correct_permutation_confident_mask).sum().item(),\n",
    "            (~condition_mask).sum().item(), \n",
    "            (~condition_mask&correct_permutation_confident_mask).sum().item()/(~condition_mask).sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both correct tensor(25) tensor(0.6187) tensor(0.9433)\n",
      "MSP correct  tensor(40) tensor(0.5216) tensor(0.9643)\n",
      "Init correct tensor(27) tensor(0.5349) tensor(0.9423)\n",
      "Permutation correct tensor(13) tensor(0.5649) tensor(0.9761)\n"
     ]
    }
   ],
   "source": [
    "# MSP is wrong, but init is correct\n",
    "target_col_idx_msp_init = idx_list[~condition_mask&correct_msp_mask&correct_init_mask]\n",
    "target_col_idx_msp =  idx_list[~condition_mask&correct_msp_mask&~correct_init_mask]\n",
    "target_col_idx_init =  idx_list[~condition_mask&~correct_msp_mask&correct_init_mask]\n",
    "target_col_idx_permutation = idx_list[~condition_mask&correct_permutation_confident_mask&~correct_msp_mask&~correct_init_mask]\n",
    "target_col_idx_permutation_msp =  idx_list[~condition_mask&correct_permutation_confident_mask&~correct_msp_mask]\n",
    "target_col_idx_permutation_init =  idx_list[~condition_mask&correct_permutation_confident_mask&~correct_init_mask]\n",
    "\n",
    "print(\"Both correct\", (~condition_mask&correct_msp_mask&correct_init_mask).sum(), \n",
    "      ood_score_init_list[~condition_mask&correct_msp_mask&correct_init_mask].mean(), \n",
    "      # ood_score_target_list[~condition_mask&correct_msp_mask&correct_init_mask].mean(),\n",
    "      ood_score_final_list[~condition_mask&correct_msp_mask&correct_init_mask].mean())\n",
    "print(\"MSP correct \", (~condition_mask&correct_msp_mask&~correct_init_mask).sum(), \n",
    "      ood_score_init_list[~condition_mask&correct_msp_mask&~correct_init_mask].mean(),\n",
    "      #   ood_score_target_list[~condition_mask&correct_msp_mask&~correct_init_mask].mean(),\n",
    "        ood_score_final_list[~condition_mask&correct_msp_mask&~correct_init_mask].mean())\n",
    "print(\"Init correct\", (~condition_mask&~correct_msp_mask&correct_init_mask).sum(), \n",
    "      ood_score_init_list[~condition_mask&~correct_msp_mask&correct_init_mask].mean(),\n",
    "      #   ood_score_target_list[~condition_mask&~correct_msp_mask&correct_init_mask].mean(),\n",
    "        ood_score_final_list[~condition_mask&~correct_msp_mask&correct_init_mask].mean())\n",
    "print(\"Permutation correct\",(~condition_mask&correct_permutation_confident_mask&~correct_msp_mask&~correct_init_mask).sum(), \n",
    "      ood_score_init_list[~condition_mask&correct_permutation_confident_mask&~correct_msp_mask&~correct_init_mask].mean(),\n",
    "      #   ood_score_target_list[~condition_mask&correct_permutation_confident_mask&~correct_msp_mask&~correct_init_mask].mean(),\n",
    "        ood_score_final_list[~condition_mask&correct_permutation_confident_mask&~correct_msp_mask&~correct_init_mask].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  21,   52,   59,  118,  138,  154,  246,  265,  273,  275,  286,  287,\n",
       "         296,  325,  372,  419,  433,  568,  610,  643,  743,  808,  894,  929,\n",
       "         989, 1042, 1075])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_col_idx_permutation_msp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "7 [1, 2, 3, 4, 5, 6, 7, 0]\n",
      "********************************************************\n",
      "(1, 2, 3, 4, 5, 6, 0) tensor(0.6651) tensor(23)\n",
      "(1, 2, 3, 4, 5, 7, 0) tensor(0.3092) tensor(23)\n",
      "(1, 2, 3, 4, 6, 7, 0) tensor(0.4810) tensor(23)\n",
      "(1, 2, 3, 5, 6, 7, 0) tensor(0.2688) tensor(23)\n",
      "(1, 2, 4, 5, 6, 7, 0) tensor(0.2278) tensor(37)\n",
      "(1, 3, 4, 5, 6, 7, 0) tensor(0.1427) tensor(0)\n",
      "(2, 3, 4, 5, 6, 7, 0) tensor(0.3503) tensor(23)\n",
      "(1, 2, 3, 4, 5, 0) tensor(0.5194) tensor(23)\n",
      "(1, 2, 3, 4, 6, 0) tensor(0.7849) tensor(23)\n",
      "(1, 2, 3, 4, 7, 0) tensor(0.8610) tensor(23)\n",
      "(1, 2, 3, 5, 6, 0) tensor(0.4876) tensor(23)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3888413/152469504.py:38: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3697.)\n",
      "  target_col_mask = batch[\"target_col_mask\"].T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 3, 5, 7, 0) tensor(0.5947) tensor(23)\n",
      "(1, 2, 3, 6, 7, 0) tensor(0.8060) tensor(23)\n",
      "(1, 2, 4, 5, 6, 0) tensor(0.5498) tensor(34)\n",
      "(1, 2, 4, 5, 7, 0) tensor(0.8120) tensor(34)\n",
      "(1, 2, 4, 6, 7, 0) tensor(0.7552) tensor(34)\n",
      "(1, 2, 5, 6, 7, 0) tensor(0.3124) tensor(23)\n",
      "(1, 3, 4, 5, 6, 0) tensor(0.2555) tensor(23)\n",
      "(1, 3, 4, 5, 7, 0) tensor(0.3216) tensor(0)\n",
      "(1, 3, 4, 6, 7, 0) tensor(0.5315) tensor(0)\n",
      "(1, 3, 5, 6, 7, 0) tensor(0.4935) tensor(0)\n",
      "(1, 4, 5, 6, 7, 0) tensor(0.9806) tensor(0)\n",
      "(2, 3, 4, 5, 6, 0) tensor(0.2808) tensor(58)\n",
      "(2, 3, 4, 5, 7, 0) tensor(0.5887) tensor(23)\n",
      "(2, 3, 4, 6, 7, 0) tensor(0.7600) tensor(23)\n",
      "(2, 3, 5, 6, 7, 0) tensor(0.4811) tensor(23)\n",
      "(2, 4, 5, 6, 7, 0) tensor(0.4818) tensor(34)\n",
      "(3, 4, 5, 6, 7, 0) tensor(0.4339) tensor(43)\n",
      "(1, 2, 3, 4, 0) tensor(0.4082) tensor(23)\n",
      "(1, 2, 3, 5, 0) tensor(0.3759) tensor(58)\n",
      "(1, 2, 3, 6, 0) tensor(0.3691) tensor(23)\n",
      "(1, 2, 3, 7, 0) tensor(0.4590) tensor(23)\n",
      "(1, 2, 4, 5, 0) tensor(0.5800) tensor(34)\n",
      "(1, 2, 4, 6, 0) tensor(0.6279) tensor(34)\n",
      "(1, 2, 4, 7, 0) tensor(0.9516) tensor(34)\n",
      "(1, 2, 5, 6, 0) tensor(0.1263) tensor(34)\n",
      "(1, 2, 5, 7, 0) tensor(0.8446) tensor(34)\n",
      "(1, 2, 6, 7, 0) tensor(0.8761) tensor(34)\n",
      "(1, 3, 4, 5, 0) tensor(0.1679) tensor(23)\n",
      "(1, 3, 4, 6, 0) tensor(0.2394) tensor(0)\n",
      "(1, 3, 4, 7, 0) tensor(0.2182) tensor(43)\n",
      "(1, 3, 5, 6, 0) tensor(0.2751) tensor(0)\n",
      "(1, 3, 5, 7, 0) tensor(0.1049) tensor(23)\n",
      "(1, 3, 6, 7, 0) tensor(0.2515) tensor(43)\n",
      "(1, 4, 5, 6, 0) tensor(0.9962) tensor(0)\n",
      "(1, 4, 5, 7, 0) tensor(0.2923) tensor(0)\n",
      "(1, 4, 6, 7, 0) tensor(0.6230) tensor(0)\n",
      "(1, 5, 6, 7, 0) tensor(0.9986) tensor(0)\n",
      "(2, 3, 4, 5, 0) tensor(0.3924) tensor(23)\n",
      "(2, 3, 4, 6, 0) tensor(0.6938) tensor(23)\n",
      "(2, 3, 4, 7, 0) tensor(0.5539) tensor(23)\n",
      "(2, 3, 5, 6, 0) tensor(0.2649) tensor(27)\n",
      "(2, 3, 5, 7, 0) tensor(0.3043) tensor(23)\n",
      "(2, 3, 6, 7, 0) tensor(0.4006) tensor(23)\n",
      "(2, 4, 5, 6, 0) tensor(0.8024) tensor(34)\n",
      "(2, 4, 5, 7, 0) tensor(0.1661) tensor(34)\n",
      "(2, 4, 6, 7, 0) tensor(0.2791) tensor(34)\n",
      "(2, 5, 6, 7, 0) tensor(0.2626) tensor(3)\n",
      "(3, 4, 5, 6, 0) tensor(0.5505) tensor(0)\n",
      "(3, 4, 5, 7, 0) tensor(0.5359) tensor(0)\n",
      "(3, 4, 6, 7, 0) tensor(0.4521) tensor(0)\n",
      "(3, 5, 6, 7, 0) tensor(0.5652) tensor(0)\n",
      "(4, 5, 6, 7, 0) tensor(0.9993) tensor(0)\n",
      "********************************************************\n",
      "(4, 5, 6, 7, 0) tensor(0.9993) tensor(0)\n"
     ]
    }
   ],
   "source": [
    "# use target as head, the MSP context\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "ft_embs_test = []\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "log = defaultdict(list)\n",
    "num_cols = []\n",
    "threshold = 0.8\n",
    "corrected = 0\n",
    "total_mistakes = 0\n",
    "init_permutation = defaultdict(list)\n",
    "corrected_permutation = defaultdict(list)\n",
    "init_logits = defaultdict(list)\n",
    "corrected_logits = defaultdict(list)\n",
    "max_col_length = 3\n",
    "msp_threshold = 0.9\n",
    "\n",
    "\n",
    "alpha = 0.25\n",
    "\n",
    "class_weights = (1.0 / class_freq) ** alpha\n",
    "\n",
    "# Normalize the weights\n",
    "class_weights /= class_weights.sum()\n",
    "\n",
    "for batch_idx, batch in enumerate(test_dataset_iter):\n",
    "    if batch_idx == 19:\n",
    "        break\n",
    "cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "target_col_mask = batch[\"target_col_mask\"].T\n",
    "col_idx_set = target_col_mask.unique().tolist()\n",
    "init_permutation_i = get_permutation(target_col_mask)\n",
    "successs = False\n",
    "# logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,).detach().cpu()\n",
    "# logits = reweight_logits(logits, class_weights)\n",
    "# logits_init = logits.clone()\n",
    "# num_cols.append(batch[\"target_col_mask\"].max().item())\n",
    "\n",
    "\n",
    "# col_idx_set = target_col_mask.unique().tolist()\n",
    "# successs = False\n",
    "# init_permutation_i = get_permutation(target_col_mask)\n",
    "# init_permutation[batch_idx].append(get_permutation(target_col_mask))\n",
    "# init_logits[batch_idx].append(logits_init.detach().cpu())     \n",
    "# init_msp = logits_init.max().item()\n",
    "# print(batch[\"label\"].item())\n",
    "# print(get_permutation(target_col_mask), init_msp, init_logits[batch_idx][0].argmax().item()) \n",
    "print(batch[\"label\"].item())  \n",
    "print(batch[\"target_col_mask\"].max().item(), get_permutation(target_col_mask))\n",
    "print(\"********************************************************\")\n",
    "assert -1 not in col_idx_set\n",
    "max_msp = 0 \n",
    "# for r in range(1, min(len(col_idx_set), max_col_length) + 1):\n",
    "enough = False\n",
    "# for r in range(len(col_idx_set)-1, 0, -1):\n",
    "for r in range(len(col_idx_set)-1, len(col_idx_set)//2, -1):\n",
    "    for subset in itertools.combinations(col_idx_set, r):\n",
    "        if 0 not in subset and r != 1:\n",
    "            continue\n",
    "        for x in itertools.permutations(subset):\n",
    "            if not is_sublist(x, init_permutation_i):\n",
    "                continue\n",
    "            new_batch_data = []\n",
    "            for col_i in x:\n",
    "                if col_i == 0:\n",
    "                    if len(new_batch_data) == 0:\n",
    "                        cls_indexes_value = 0\n",
    "                    else:\n",
    "                        cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "            if 0 not in x:\n",
    "                cls_indexes_value = 0\n",
    "            new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "            cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "            logits_temp = model(new_batch_data, cls_indexes=cls_indexes,).detach().cpu()\n",
    "            logits_temp = reweight_logits(logits_temp, class_weights)\n",
    "            msp_temp = logits_temp.max()\n",
    "            predict_temp = logits_temp.argmax()\n",
    "            # msp_temp = F.softmax(logits_temp).max().item()\n",
    "            # predict_temp = F.softmax(logits_temp).argmax().item()\n",
    "\n",
    "            print(x, msp_temp,predict_temp)\n",
    "            if msp_temp > max_msp and 0 in x:\n",
    "                max_msp = msp_temp\n",
    "                best_msp_perm = x\n",
    "                msp_predict = predict_temp\n",
    "        \n",
    "print(\"********************************************************\")\n",
    "print(best_msp_perm, max_msp, msp_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************alpha: 0.25; uncertain: 0.8; debias: 1.0; msp: 0.8****************************\n",
      "ts_micro_f1=0.5419, ts_macro_f1=0.2608\n",
      "ts_micro_f1=0.5415, ts_macro_f1=0.2608\n",
      "ts_micro_f1=1.0000, ts_macro_f1=1.0000\n",
      "*********************alpha: 0.25; uncertain: 0.8; debias: 1.0; msp: 0.9****************************\n",
      "ts_micro_f1=0.5419, ts_macro_f1=0.2621\n",
      "ts_micro_f1=0.5415, ts_macro_f1=0.2621\n",
      "ts_micro_f1=1.0000, ts_macro_f1=1.0000\n",
      "*********************alpha: 0.25; uncertain: 0.8; debias: 1.0; msp: 0.99****************************\n",
      "ts_micro_f1=0.5382, ts_macro_f1=0.2664\n",
      "ts_micro_f1=0.5378, ts_macro_f1=0.2664\n",
      "ts_micro_f1=1.0000, ts_macro_f1=1.0000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# brute force perumate, early stop\n",
    "import itertools\n",
    "\n",
    "\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "\n",
    "max_col_length = 3\n",
    "for alpha in [0.25]:\n",
    "    class_weights = (1.0 / class_freq) ** alpha\n",
    "    # Normalize the weights\n",
    "    class_weights /= class_weights.sum()\n",
    "    for uncertainty_threshold in [ 0.8]:\n",
    "        for msp_threshold in [ 0.8, 0.9, 0.99]:\n",
    "            for debias_threshold in [1.0]:\n",
    "                print(f\"*********************alpha: {alpha}; uncertain: {uncertainty_threshold}; debias: {debias_threshold}; msp: {msp_threshold}****************************\")\n",
    "                ft_embs_test = []\n",
    "                labels_test = []\n",
    "                logits_test = []\n",
    "                log = defaultdict(list)\n",
    "                num_cols = []\n",
    "                corrected = 0\n",
    "                total_mistakes = 0\n",
    "\n",
    "                for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "                    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "                    target_col_mask = batch[\"target_col_mask\"].T\n",
    "                    logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "                    logits = reweight_logits(logits.detach().cpu(), class_weights) # Here !!!!!!!!!!\n",
    "                    msp_init = logits.max().item()\n",
    "                    num_cols.append(batch[\"target_col_mask\"].max().item())\n",
    "                    predict_init = logits.argmax().item()\n",
    "                    max_msp = 0\n",
    "                    \n",
    "                    if 1 in target_col_mask and msp_init < uncertainty_threshold:\n",
    "                        init_permutation_i = get_permutation(target_col_mask)\n",
    "                        col_idx_set = target_col_mask.unique().tolist()\n",
    "                        debias_classes = []\n",
    "                        early_stop = False\n",
    "                        assert -1 not in col_idx_set\n",
    "                        for r in range(len(col_idx_set)-1, len(col_idx_set)//2, -1):\n",
    "                            round_classes = set()\n",
    "                            for subset in itertools.combinations(col_idx_set, r):\n",
    "                                if 0 not in subset and r != 1:\n",
    "                                    continue\n",
    "                                for x in itertools.permutations(subset):\n",
    "                                    if not is_sublist(x, init_permutation_i):\n",
    "                                        continue\n",
    "                                    new_batch_data = []\n",
    "                                    for col_i in x:\n",
    "                                        if col_i == 0:\n",
    "                                            if len(new_batch_data) == 0:\n",
    "                                                cls_indexes_value = 0\n",
    "                                            else:\n",
    "                                                cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                                        new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                                    if 0 not in x:\n",
    "                                        cls_indexes_value = 0\n",
    "                                    new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                                    cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                                    logits_temp = model(new_batch_data, cls_indexes=cls_indexes,)\n",
    "                                    logits_temp = reweight_logits(logits_temp.detach().cpu(), class_weights)\n",
    "                                    msp_temp = logits_temp.max().item()\n",
    "                                    predict_temp = logits_temp.argmax().item()\n",
    "                                    round_classes.add(predict_temp)\n",
    "                                    # if len(x) == 1 and 0 in x:\n",
    "                                    #     predict_target = predict_temp\n",
    "                                    #     msp_target = msp_temp\n",
    "                                    # # print(x, msp_temp, predict_temp)\n",
    "                                    # if 0 not in x and msp_temp > debias_threshold and (predict_temp != predict_target):\n",
    "                                    #     debias_classes.append(predict_temp)\n",
    "                                    #     continue\n",
    "                                    if msp_temp > max_msp and 0 in x and predict_temp not in debias_classes:\n",
    "                                        max_msp = msp_temp\n",
    "                                        best_msp_perm = x\n",
    "                                        msp_predict = predict_temp\n",
    "                                        logits_msp = logits_temp.clone()\n",
    "                                        if max_msp > msp_threshold and 0 in x and len(round_classes) > 1: # make sure the classes in one round is not homogenous \n",
    "                                            early_stop = True\n",
    "                            if early_stop:\n",
    "                                break\n",
    "                    if max_msp > msp_threshold:\n",
    "                        logits = logits_msp.clone()\n",
    "                    labels_test.append(batch[\"label\"].cpu())\n",
    "                    logits_test.append(logits.detach().cpu())\n",
    "                labels_test = torch.cat(labels_test, dim=0)\n",
    "                logits_test = torch.stack(logits_test, dim=0)\n",
    "                preds_test = torch.argmax(logits_test, dim=1)\n",
    "                num_cols = torch.tensor(num_cols)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                from sklearn.metrics import confusion_matrix, f1_score\n",
    "                mask = num_cols > 0\n",
    "                ts_pred_list = logits_test.argmax(\n",
    "                                            1).cpu().detach().numpy().tolist()\n",
    "                ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"micro\")\n",
    "                ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"macro\")\n",
    "                print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "                ts_pred_list = logits_test.argmax(\n",
    "                                            1).cpu().detach()[mask].numpy().tolist()\n",
    "                ts_micro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"micro\")\n",
    "                ts_macro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"macro\")\n",
    "                print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "                ts_pred_list = logits_test.argmax(\n",
    "                                            1).cpu().detach()[~mask].numpy().tolist()\n",
    "                ts_micro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"micro\")\n",
    "                ts_macro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"macro\")\n",
    "                print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************alpha: 0.25; uncertain: 0.8; debias: 1.0; msp: 0.0****************************\n",
      "ts_micro_f1=0.5373, ts_macro_f1=0.2554\n",
      "ts_micro_f1=0.5369, ts_macro_f1=0.2554\n",
      "ts_micro_f1=1.0000, ts_macro_f1=1.0000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# brute force perumate, early stop\n",
    "import itertools\n",
    "\n",
    "\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "\n",
    "max_col_length = 3\n",
    "for alpha in [0.25]:\n",
    "    class_weights = (1.0 / class_freq) ** alpha\n",
    "    # Normalize the weights\n",
    "    class_weights /= class_weights.sum()\n",
    "    for uncertainty_threshold in [ 0.8]:\n",
    "        for msp_threshold in [0.0]:\n",
    "            for debias_threshold in [1.0]:\n",
    "                print(f\"*********************alpha: {alpha}; uncertain: {uncertainty_threshold}; debias: {debias_threshold}; msp: {msp_threshold}****************************\")\n",
    "                ft_embs_test = []\n",
    "                labels_test = []\n",
    "                logits_test = []\n",
    "                log = defaultdict(list)\n",
    "                num_cols = []\n",
    "                corrected = 0\n",
    "                total_mistakes = 0\n",
    "\n",
    "                for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "                    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "                    target_col_mask = batch[\"target_col_mask\"].T\n",
    "                    logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "                    logits = reweight_logits(logits.detach().cpu(), class_weights) # Here !!!!!!!!!!\n",
    "                    msp_init = logits.max().item()\n",
    "                    num_cols.append(batch[\"target_col_mask\"].max().item())\n",
    "                    predict_init = logits.argmax().item()\n",
    "                    max_msp = 0\n",
    "                    \n",
    "                    if 1 in target_col_mask and msp_init < uncertainty_threshold:\n",
    "                        init_permutation_i = get_permutation(target_col_mask)\n",
    "                        col_idx_set = target_col_mask.unique().tolist()\n",
    "                        debias_classes = []\n",
    "                        early_stop = False\n",
    "                        assert -1 not in col_idx_set\n",
    "                        for r in range(len(col_idx_set)-1, len(col_idx_set)//2, -1):\n",
    "                            round_classes = set()\n",
    "                            for subset in itertools.combinations(col_idx_set, r):\n",
    "                                if 0 not in subset and r != 1:\n",
    "                                    continue\n",
    "                                for x in itertools.permutations(subset):\n",
    "                                    if not is_sublist(x, init_permutation_i):\n",
    "                                        continue\n",
    "                                    new_batch_data = []\n",
    "                                    for col_i in x:\n",
    "                                        if col_i == 0:\n",
    "                                            if len(new_batch_data) == 0:\n",
    "                                                cls_indexes_value = 0\n",
    "                                            else:\n",
    "                                                cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                                        new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                                    if 0 not in x:\n",
    "                                        cls_indexes_value = 0\n",
    "                                    new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                                    cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                                    logits_temp = model(new_batch_data, cls_indexes=cls_indexes,)\n",
    "                                    logits_temp = reweight_logits(logits_temp.detach().cpu(), class_weights)\n",
    "                                    msp_temp = logits_temp.max().item()\n",
    "                                    predict_temp = logits_temp.argmax().item()\n",
    "                                    round_classes.add(predict_temp)\n",
    "                                    # if len(x) == 1 and 0 in x:\n",
    "                                    #     predict_target = predict_temp\n",
    "                                    #     msp_target = msp_temp\n",
    "                                    # # print(x, msp_temp, predict_temp)\n",
    "                                    # if 0 not in x and msp_temp > debias_threshold and (predict_temp != predict_target):\n",
    "                                    #     debias_classes.append(predict_temp)\n",
    "                                    #     continue\n",
    "                                    if msp_temp > max_msp and 0 in x and predict_temp not in debias_classes:\n",
    "                                        max_msp = msp_temp\n",
    "                                        best_msp_perm = x\n",
    "                                        msp_predict = predict_temp\n",
    "                                        logits_msp = logits_temp.clone()\n",
    "                                        if max_msp > msp_threshold and 0 in x and len(round_classes) > 1: # make sure the classes in one round is not homogenous \n",
    "                                            early_stop = True\n",
    "                            if early_stop:\n",
    "                                break\n",
    "                    if max_msp > msp_threshold:\n",
    "                        logits = logits_msp.clone()\n",
    "                    labels_test.append(batch[\"label\"].cpu())\n",
    "                    logits_test.append(logits.detach().cpu())\n",
    "                labels_test = torch.cat(labels_test, dim=0)\n",
    "                logits_test = torch.stack(logits_test, dim=0)\n",
    "                preds_test = torch.argmax(logits_test, dim=1)\n",
    "                num_cols = torch.tensor(num_cols)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                from sklearn.metrics import confusion_matrix, f1_score\n",
    "                mask = num_cols > 0\n",
    "                ts_pred_list = logits_test.argmax(\n",
    "                                            1).cpu().detach().numpy().tolist()\n",
    "                ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"micro\")\n",
    "                ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"macro\")\n",
    "                print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "                ts_pred_list = logits_test.argmax(\n",
    "                                            1).cpu().detach()[mask].numpy().tolist()\n",
    "                ts_micro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"micro\")\n",
    "                ts_macro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"macro\")\n",
    "                print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "                ts_pred_list = logits_test.argmax(\n",
    "                                            1).cpu().detach()[~mask].numpy().tolist()\n",
    "                ts_micro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"micro\")\n",
    "                ts_macro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"macro\")\n",
    "                print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************alpha: 0.25; uncertain: 0.85; debias: 1.0; msp: 0.9****************************\n",
      "ts_micro_f1=0.5447, ts_macro_f1=0.2636\n",
      "ts_micro_f1=0.5443, ts_macro_f1=0.2636\n",
      "ts_micro_f1=1.0000, ts_macro_f1=1.0000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# brute force perumate, early stop\n",
    "import itertools\n",
    "\n",
    "\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "\n",
    "max_col_length = 3\n",
    "for alpha in [0.25]:\n",
    "    class_weights = (1.0 / class_freq) ** alpha\n",
    "    # Normalize the weights\n",
    "    class_weights /= class_weights.sum()\n",
    "    for uncertainty_threshold in [ 0.85]:\n",
    "        for msp_threshold in [0.9]:\n",
    "            for debias_threshold in [1.0]:\n",
    "                print(f\"*********************alpha: {alpha}; uncertain: {uncertainty_threshold}; debias: {debias_threshold}; msp: {msp_threshold}****************************\")\n",
    "                ft_embs_test = []\n",
    "                labels_test = []\n",
    "                logits_test = []\n",
    "                log = defaultdict(list)\n",
    "                num_cols = []\n",
    "                corrected = 0\n",
    "                total_mistakes = 0\n",
    "\n",
    "                for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "                    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "                    target_col_mask = batch[\"target_col_mask\"].T\n",
    "                    logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "                    logits = reweight_logits(logits.detach().cpu(), class_weights) # Here !!!!!!!!!!\n",
    "                    msp_init = logits.max().item()\n",
    "                    num_cols.append(batch[\"target_col_mask\"].max().item())\n",
    "                    predict_init = logits.argmax().item()\n",
    "                    max_msp = 0\n",
    "                    \n",
    "                    if 1 in target_col_mask and msp_init < uncertainty_threshold:\n",
    "                        init_permutation_i = get_permutation(target_col_mask)\n",
    "                        col_idx_set = target_col_mask.unique().tolist()\n",
    "                        debias_classes = []\n",
    "                        early_stop = False\n",
    "                        assert -1 not in col_idx_set\n",
    "                        for r in range(len(col_idx_set)-1, len(col_idx_set)//2, -1):\n",
    "                            round_classes = set()\n",
    "                            for subset in itertools.combinations(col_idx_set, r):\n",
    "                                if 0 not in subset and r != 1:\n",
    "                                    continue\n",
    "                                for x in itertools.permutations(subset):\n",
    "                                    if not is_sublist(x, init_permutation_i):\n",
    "                                        continue\n",
    "                                    new_batch_data = []\n",
    "                                    for col_i in x:\n",
    "                                        if col_i == 0:\n",
    "                                            if len(new_batch_data) == 0:\n",
    "                                                cls_indexes_value = 0\n",
    "                                            else:\n",
    "                                                cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                                        new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                                    if 0 not in x:\n",
    "                                        cls_indexes_value = 0\n",
    "                                    new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                                    cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                                    logits_temp = model(new_batch_data, cls_indexes=cls_indexes,)\n",
    "                                    logits_temp = reweight_logits(logits_temp.detach().cpu(), class_weights)\n",
    "                                    msp_temp = logits_temp.max().item()\n",
    "                                    predict_temp = logits_temp.argmax().item()\n",
    "                                    round_classes.add(predict_temp)\n",
    "                                    # if len(x) == 1 and 0 in x:\n",
    "                                    #     predict_target = predict_temp\n",
    "                                    #     msp_target = msp_temp\n",
    "                                    # # print(x, msp_temp, predict_temp)\n",
    "                                    # if 0 not in x and msp_temp > debias_threshold and (predict_temp != predict_target):\n",
    "                                    #     debias_classes.append(predict_temp)\n",
    "                                    #     continue\n",
    "                                    if msp_temp > max_msp and 0 in x and predict_temp not in debias_classes:\n",
    "                                        max_msp = msp_temp\n",
    "                                        best_msp_perm = x\n",
    "                                        msp_predict = predict_temp\n",
    "                                        logits_msp = logits_temp.clone()\n",
    "                                        if max_msp > msp_threshold and 0 in x and len(round_classes) > 1: # make sure the classes in one round is not homogenous \n",
    "                                            early_stop = True\n",
    "                            if early_stop:\n",
    "                                break\n",
    "                    if max_msp > msp_threshold:\n",
    "                        logits = logits_msp.clone()\n",
    "                    labels_test.append(batch[\"label\"].cpu())\n",
    "                    logits_test.append(logits.detach().cpu())\n",
    "                labels_test = torch.cat(labels_test, dim=0)\n",
    "                logits_test = torch.stack(logits_test, dim=0)\n",
    "                preds_test = torch.argmax(logits_test, dim=1)\n",
    "                num_cols = torch.tensor(num_cols)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                from sklearn.metrics import confusion_matrix, f1_score\n",
    "                mask = num_cols > 0\n",
    "                ts_pred_list = logits_test.argmax(\n",
    "                                            1).cpu().detach().numpy().tolist()\n",
    "                ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"micro\")\n",
    "                ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"macro\")\n",
    "                print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "                ts_pred_list = logits_test.argmax(\n",
    "                                            1).cpu().detach()[mask].numpy().tolist()\n",
    "                ts_micro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"micro\")\n",
    "                ts_macro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"macro\")\n",
    "                print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "                ts_pred_list = logits_test.argmax(\n",
    "                                            1).cpu().detach()[~mask].numpy().tolist()\n",
    "                ts_micro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"micro\")\n",
    "                ts_macro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"macro\")\n",
    "                print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************alpha: 0.25; uncertain: 0.85; debias: 1.0; msp: 0.0****************************\n",
      "ts_micro_f1=0.5392, ts_macro_f1=0.2552\n",
      "ts_micro_f1=0.5387, ts_macro_f1=0.2552\n",
      "ts_micro_f1=1.0000, ts_macro_f1=1.0000\n",
      "*********************alpha: 0.25; uncertain: 0.85; debias: 1.0; msp: 0.8****************************\n",
      "ts_micro_f1=0.5456, ts_macro_f1=0.2609\n",
      "ts_micro_f1=0.5452, ts_macro_f1=0.2609\n",
      "ts_micro_f1=1.0000, ts_macro_f1=1.0000\n",
      "*********************alpha: 0.25; uncertain: 0.85; debias: 1.0; msp: 0.85****************************\n",
      "ts_micro_f1=0.5456, ts_macro_f1=0.2607\n",
      "ts_micro_f1=0.5452, ts_macro_f1=0.2607\n",
      "ts_micro_f1=1.0000, ts_macro_f1=1.0000\n",
      "*********************alpha: 0.25; uncertain: 0.85; debias: 1.0; msp: 0.9****************************\n",
      "ts_micro_f1=0.5456, ts_macro_f1=0.2627\n",
      "ts_micro_f1=0.5452, ts_macro_f1=0.2626\n",
      "ts_micro_f1=1.0000, ts_macro_f1=1.0000\n",
      "*********************alpha: 0.25; uncertain: 0.8; debias: 1.0; msp: 0.0****************************\n",
      "ts_micro_f1=0.5373, ts_macro_f1=0.2553\n",
      "ts_micro_f1=0.5369, ts_macro_f1=0.2553\n",
      "ts_micro_f1=1.0000, ts_macro_f1=1.0000\n",
      "*********************alpha: 0.25; uncertain: 0.8; debias: 1.0; msp: 0.8****************************\n",
      "ts_micro_f1=0.5438, ts_macro_f1=0.2610\n",
      "ts_micro_f1=0.5434, ts_macro_f1=0.2610\n",
      "ts_micro_f1=1.0000, ts_macro_f1=1.0000\n",
      "*********************alpha: 0.25; uncertain: 0.8; debias: 1.0; msp: 0.85****************************\n",
      "ts_micro_f1=0.5429, ts_macro_f1=0.2596\n",
      "ts_micro_f1=0.5424, ts_macro_f1=0.2596\n",
      "ts_micro_f1=1.0000, ts_macro_f1=1.0000\n",
      "*********************alpha: 0.25; uncertain: 0.8; debias: 1.0; msp: 0.9****************************\n",
      "ts_micro_f1=0.5429, ts_macro_f1=0.2612\n",
      "ts_micro_f1=0.5424, ts_macro_f1=0.2612\n",
      "ts_micro_f1=1.0000, ts_macro_f1=1.0000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# brute force perumate, early stop\n",
    "import itertools\n",
    "\n",
    "\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "\n",
    "max_col_length = 3\n",
    "for alpha in [0.25]:\n",
    "    class_weights = (1.0 / class_freq) ** alpha\n",
    "    # Normalize the weights\n",
    "    class_weights /= class_weights.sum()\n",
    "    for uncertainty_threshold in [ 0.85, 0.8]:\n",
    "        for msp_threshold in [0.0, 0.8, 0.85, 0.9]:\n",
    "            for debias_threshold in [1.0]:\n",
    "                print(f\"*********************alpha: {alpha}; uncertain: {uncertainty_threshold}; debias: {debias_threshold}; msp: {msp_threshold}****************************\")\n",
    "                ft_embs_test = []\n",
    "                labels_test = []\n",
    "                logits_test = []\n",
    "                log = defaultdict(list)\n",
    "                num_cols = []\n",
    "                corrected = 0\n",
    "                total_mistakes = 0\n",
    "\n",
    "                for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "                    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "                    target_col_mask = batch[\"target_col_mask\"].T\n",
    "                    logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "                    logits = reweight_logits(logits.detach().cpu(), class_weights) # Here !!!!!!!!!!\n",
    "                    msp_init = logits.max().item()\n",
    "                    num_cols.append(batch[\"target_col_mask\"].max().item())\n",
    "                    predict_init = logits.argmax().item()\n",
    "                    max_msp = 0\n",
    "                    \n",
    "                    if 1 in target_col_mask and msp_init < uncertainty_threshold:\n",
    "                        init_permutation_i = get_permutation(target_col_mask)\n",
    "                        col_idx_set = target_col_mask.unique().tolist()\n",
    "                        debias_classes = []\n",
    "                        early_stop = False\n",
    "                        assert -1 not in col_idx_set\n",
    "                        for r in range(len(col_idx_set)-1, len(col_idx_set)//2, -1):\n",
    "                            round_classes = set()\n",
    "                            for subset in itertools.combinations(col_idx_set, r):\n",
    "                                if 0 not in subset and r != 1:\n",
    "                                    continue\n",
    "                                for x in itertools.permutations(subset):\n",
    "                                    if not is_sublist(x, init_permutation_i):\n",
    "                                        continue\n",
    "                                    new_batch_data = []\n",
    "                                    for col_i in x:\n",
    "                                        if col_i == 0:\n",
    "                                            if len(new_batch_data) == 0:\n",
    "                                                cls_indexes_value = 0\n",
    "                                            else:\n",
    "                                                cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                                        new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                                    if 0 not in x:\n",
    "                                        cls_indexes_value = 0\n",
    "                                    new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                                    cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                                    logits_temp = model(new_batch_data, cls_indexes=cls_indexes,)\n",
    "                                    logits_temp = reweight_logits(logits_temp.detach().cpu(), class_weights)\n",
    "                                    msp_temp = logits_temp.max().item()\n",
    "                                    predict_temp = logits_temp.argmax().item()\n",
    "                                    round_classes.add(predict_temp)\n",
    "                                    # if len(x) == 1 and 0 in x:\n",
    "                                    #     predict_target = predict_temp\n",
    "                                    #     msp_target = msp_temp\n",
    "                                    # # print(x, msp_temp, predict_temp)\n",
    "                                    # if 0 not in x and msp_temp > debias_threshold and (predict_temp != predict_target):\n",
    "                                    #     debias_classes.append(predict_temp)\n",
    "                                    #     continue\n",
    "                                    if msp_temp > max_msp and 0 in x and predict_temp not in debias_classes:\n",
    "                                        max_msp = msp_temp\n",
    "                                        best_msp_perm = x\n",
    "                                        msp_predict = predict_temp\n",
    "                                        logits_msp = logits_temp.clone()\n",
    "                                        if max_msp > msp_threshold and 0 in x: # make sure the classes in one round is not homogenous \n",
    "                                            early_stop = True\n",
    "                            if early_stop:\n",
    "                                break\n",
    "                    if max_msp > msp_threshold:\n",
    "                        logits = logits_msp.clone()\n",
    "                    labels_test.append(batch[\"label\"].cpu())\n",
    "                    logits_test.append(logits.detach().cpu())\n",
    "                labels_test = torch.cat(labels_test, dim=0)\n",
    "                logits_test = torch.stack(logits_test, dim=0)\n",
    "                preds_test = torch.argmax(logits_test, dim=1)\n",
    "                num_cols = torch.tensor(num_cols)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                from sklearn.metrics import confusion_matrix, f1_score\n",
    "                mask = num_cols > 0\n",
    "                ts_pred_list = logits_test.argmax(\n",
    "                                            1).cpu().detach().numpy().tolist()\n",
    "                ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"micro\")\n",
    "                ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"macro\")\n",
    "                print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "                ts_pred_list = logits_test.argmax(\n",
    "                                            1).cpu().detach()[mask].numpy().tolist()\n",
    "                ts_micro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"micro\")\n",
    "                ts_macro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"macro\")\n",
    "                print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "                ts_pred_list = logits_test.argmax(\n",
    "                                            1).cpu().detach()[~mask].numpy().tolist()\n",
    "                ts_micro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"micro\")\n",
    "                ts_macro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"macro\")\n",
    "                print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *********************alpha: 0.25; uncertain: 0.85; debias: 1.0; msp: 0.9****************************\n",
    "# ts_micro_f1=0.5456, ts_macro_f1=0.2627\n",
    "# ts_micro_f1=0.5452, ts_macro_f1=0.2626\n",
    "# ts_micro_f1=1.0000, ts_macro_f1=1.0000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************alpha: 0.0; uncertain: 0.85; debias: 1.0; msp: 0.0****************************\n",
      "ts_micro_f1=0.5429, ts_macro_f1=0.2582\n",
      "ts_micro_f1=0.5424, ts_macro_f1=0.2582\n",
      "ts_micro_f1=1.0000, ts_macro_f1=1.0000\n",
      "*********************alpha: 0.0; uncertain: 0.85; debias: 1.0; msp: 0.8****************************\n",
      "ts_micro_f1=0.5484, ts_macro_f1=0.2633\n",
      "ts_micro_f1=0.5480, ts_macro_f1=0.2633\n",
      "ts_micro_f1=1.0000, ts_macro_f1=1.0000\n",
      "*********************alpha: 0.0; uncertain: 0.85; debias: 1.0; msp: 0.85****************************\n",
      "ts_micro_f1=0.5475, ts_macro_f1=0.2644\n",
      "ts_micro_f1=0.5470, ts_macro_f1=0.2644\n",
      "ts_micro_f1=1.0000, ts_macro_f1=1.0000\n",
      "*********************alpha: 0.0; uncertain: 0.85; debias: 1.0; msp: 0.9****************************\n",
      "ts_micro_f1=0.5456, ts_macro_f1=0.2667\n",
      "ts_micro_f1=0.5452, ts_macro_f1=0.2667\n",
      "ts_micro_f1=1.0000, ts_macro_f1=1.0000\n",
      "*********************alpha: 0.0; uncertain: 0.8; debias: 1.0; msp: 0.0****************************\n",
      "ts_micro_f1=0.5419, ts_macro_f1=0.2561\n",
      "ts_micro_f1=0.5415, ts_macro_f1=0.2561\n",
      "ts_micro_f1=1.0000, ts_macro_f1=1.0000\n",
      "*********************alpha: 0.0; uncertain: 0.8; debias: 1.0; msp: 0.8****************************\n",
      "ts_micro_f1=0.5475, ts_macro_f1=0.2611\n",
      "ts_micro_f1=0.5470, ts_macro_f1=0.2611\n",
      "ts_micro_f1=1.0000, ts_macro_f1=1.0000\n",
      "*********************alpha: 0.0; uncertain: 0.8; debias: 1.0; msp: 0.85****************************\n",
      "ts_micro_f1=0.5465, ts_macro_f1=0.2624\n",
      "ts_micro_f1=0.5461, ts_macro_f1=0.2624\n",
      "ts_micro_f1=1.0000, ts_macro_f1=1.0000\n",
      "*********************alpha: 0.0; uncertain: 0.8; debias: 1.0; msp: 0.9****************************\n",
      "ts_micro_f1=0.5447, ts_macro_f1=0.2642\n",
      "ts_micro_f1=0.5443, ts_macro_f1=0.2642\n",
      "ts_micro_f1=1.0000, ts_macro_f1=1.0000\n",
      "*********************alpha: 0.0; uncertain: 0.9; debias: 1.0; msp: 0.0****************************\n",
      "ts_micro_f1=0.5429, ts_macro_f1=0.2577\n",
      "ts_micro_f1=0.5424, ts_macro_f1=0.2577\n",
      "ts_micro_f1=1.0000, ts_macro_f1=1.0000\n",
      "*********************alpha: 0.0; uncertain: 0.9; debias: 1.0; msp: 0.8****************************\n",
      "ts_micro_f1=0.5493, ts_macro_f1=0.2627\n",
      "ts_micro_f1=0.5489, ts_macro_f1=0.2627\n",
      "ts_micro_f1=1.0000, ts_macro_f1=1.0000\n",
      "*********************alpha: 0.0; uncertain: 0.9; debias: 1.0; msp: 0.85****************************\n",
      "ts_micro_f1=0.5484, ts_macro_f1=0.2637\n",
      "ts_micro_f1=0.5480, ts_macro_f1=0.2637\n",
      "ts_micro_f1=1.0000, ts_macro_f1=1.0000\n",
      "*********************alpha: 0.0; uncertain: 0.9; debias: 1.0; msp: 0.9****************************\n",
      "ts_micro_f1=0.5465, ts_macro_f1=0.2657\n",
      "ts_micro_f1=0.5461, ts_macro_f1=0.2657\n",
      "ts_micro_f1=1.0000, ts_macro_f1=1.0000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# brute force perumate, early stop\n",
    "import itertools\n",
    "\n",
    "\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "\n",
    "max_col_length = 3\n",
    "for alpha in [0.0]:\n",
    "    # class_weights = (1.0 / class_freq) ** alpha\n",
    "    # # Normalize the weights\n",
    "    # class_weights /= class_weights.sum()\n",
    "    for uncertainty_threshold in [ 0.85, 0.8, 0.9]:\n",
    "        for msp_threshold in [0.0, 0.8, 0.85, 0.9]:\n",
    "            for debias_threshold in [1.0]:\n",
    "                print(f\"*********************alpha: {alpha}; uncertain: {uncertainty_threshold}; debias: {debias_threshold}; msp: {msp_threshold}****************************\")\n",
    "                ft_embs_test = []\n",
    "                labels_test = []\n",
    "                logits_test = []\n",
    "                log = defaultdict(list)\n",
    "                num_cols = []\n",
    "                corrected = 0\n",
    "                total_mistakes = 0\n",
    "\n",
    "                for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "                    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "                    target_col_mask = batch[\"target_col_mask\"].T\n",
    "                    logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "                    # logits = reweight_logits(logits.detach().cpu(), class_weights) # Here !!!!!!!!!!\n",
    "                    logits = F.softmax(logits, dim=-1)\n",
    "                    msp_init = logits.max().item()\n",
    "                    num_cols.append(batch[\"target_col_mask\"].max().item())\n",
    "                    predict_init = logits.argmax().item()\n",
    "                    max_msp = 0\n",
    "                    \n",
    "                    if 1 in target_col_mask and msp_init < uncertainty_threshold:\n",
    "                        init_permutation_i = get_permutation(target_col_mask)\n",
    "                        col_idx_set = target_col_mask.unique().tolist()\n",
    "                        debias_classes = []\n",
    "                        early_stop = False\n",
    "                        assert -1 not in col_idx_set\n",
    "                        for r in range(len(col_idx_set)-1, len(col_idx_set)//2, -1):\n",
    "                            round_classes = set()\n",
    "                            for subset in itertools.combinations(col_idx_set, r):\n",
    "                                if 0 not in subset and r != 1:\n",
    "                                    continue\n",
    "                                for x in itertools.permutations(subset):\n",
    "                                    if not is_sublist(x, init_permutation_i):\n",
    "                                        continue\n",
    "                                    new_batch_data = []\n",
    "                                    for col_i in x:\n",
    "                                        if col_i == 0:\n",
    "                                            if len(new_batch_data) == 0:\n",
    "                                                cls_indexes_value = 0\n",
    "                                            else:\n",
    "                                                cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                                        new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                                    if 0 not in x:\n",
    "                                        cls_indexes_value = 0\n",
    "                                    new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                                    cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                                    logits_temp = model(new_batch_data, cls_indexes=cls_indexes,)\n",
    "                                    # logits_temp = reweight_logits(logits_temp.detach().cpu(), class_weights)\n",
    "                                    logits_temp = F.softmax(logits_temp, dim=-1)\n",
    "                                    msp_temp = logits_temp.max().item()\n",
    "                                    predict_temp = logits_temp.argmax().item()\n",
    "                                    round_classes.add(predict_temp)\n",
    "                                    # if len(x) == 1 and 0 in x:\n",
    "                                    #     predict_target = predict_temp\n",
    "                                    #     msp_target = msp_temp\n",
    "                                    # # print(x, msp_temp, predict_temp)\n",
    "                                    # if 0 not in x and msp_temp > debias_threshold and (predict_temp != predict_target):\n",
    "                                    #     debias_classes.append(predict_temp)\n",
    "                                    #     continue\n",
    "                                    if msp_temp > max_msp and 0 in x and predict_temp not in debias_classes:\n",
    "                                        max_msp = msp_temp\n",
    "                                        best_msp_perm = x\n",
    "                                        msp_predict = predict_temp\n",
    "                                        logits_msp = logits_temp.clone()\n",
    "                                        if max_msp > msp_threshold and 0 in x: # make sure the classes in one round is not homogenous \n",
    "                                            early_stop = True\n",
    "                            if early_stop:\n",
    "                                break\n",
    "                    if max_msp > msp_threshold:\n",
    "                        logits = logits_msp.clone()\n",
    "                    labels_test.append(batch[\"label\"].cpu())\n",
    "                    logits_test.append(logits.detach().cpu())\n",
    "                labels_test = torch.cat(labels_test, dim=0)\n",
    "                logits_test = torch.stack(logits_test, dim=0)\n",
    "                preds_test = torch.argmax(logits_test, dim=1)\n",
    "                num_cols = torch.tensor(num_cols)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                from sklearn.metrics import confusion_matrix, f1_score\n",
    "                mask = num_cols > 0\n",
    "                ts_pred_list = logits_test.argmax(\n",
    "                                            1).cpu().detach().numpy().tolist()\n",
    "                ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"micro\")\n",
    "                ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"macro\")\n",
    "                print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "                ts_pred_list = logits_test.argmax(\n",
    "                                            1).cpu().detach()[mask].numpy().tolist()\n",
    "                ts_micro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"micro\")\n",
    "                ts_macro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"macro\")\n",
    "                print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "                ts_pred_list = logits_test.argmax(\n",
    "                                            1).cpu().detach()[~mask].numpy().tolist()\n",
    "                ts_micro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"micro\")\n",
    "                ts_macro_f1 = f1_score(labels_test.reshape(-1)[~mask].numpy().tolist(),\n",
    "                                    ts_pred_list,\n",
    "                                    average=\"macro\")\n",
    "                print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f5e60d93e20>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Threshold: 1.5****************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3888413/2143681938.py:31: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
      "/tmp/ipykernel_3888413/2143681938.py:61: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n"
     ]
    }
   ],
   "source": [
    "# brute force perumate in training TODO: restrict mamimus length of permutation\n",
    "import itertools\n",
    "import torch.nn.functional as F\n",
    "\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "for threshold in [1.5]:\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    log = defaultdict(list)\n",
    "    num_cols = []\n",
    "    corrected = 0\n",
    "    total_mistakes = 0\n",
    "    num_permutations = {}\n",
    "    init_permutation = {}\n",
    "    init_correctness = {}\n",
    "    score_init = {}\n",
    "    score_permutation = defaultdict(list)\n",
    "    permutation_correctness = defaultdict(list)\n",
    "    for batch_idx, batch in enumerate(train_dataloader_iter):\n",
    "        cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "        target_col_mask = batch[\"target_col_mask\"].T\n",
    "        logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "        score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
    "        label_i = batch[\"label\"].item()\n",
    "        predict_init = logits.argmax().item()\n",
    "        init_permutation_i = get_permutation(target_col_mask)\n",
    "        init_permutation[batch_idx] = init_permutation_i\n",
    "        if predict_init == label_i:\n",
    "            init_correctness[batch_idx] = True\n",
    "        else:\n",
    "            init_correctness[batch_idx] = False\n",
    "        num_permutations[batch_idx] = 0\n",
    "        if 1 in target_col_mask:\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            assert -1 not in col_idx_set\n",
    "            for r in range(len(init_permutation_i)-1, len(init_permutation_i)//2, -1): # not \n",
    "                for x in itertools.combinations(init_permutation_i, r):\n",
    "                    if 0 not in x:\n",
    "                        continue\n",
    "\n",
    "                    num_permutations[batch_idx] += 1\n",
    "                    new_batch_data = []\n",
    "                    for col_i in x:\n",
    "                        if col_i == 0:\n",
    "                            if len(new_batch_data) == 0:\n",
    "                                cls_indexes_value = 0\n",
    "                            else:\n",
    "                                cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                        new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                    new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                    cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                    logits_temp = model(new_batch_data, cls_indexes=cls_indexes,)\n",
    "                    ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n",
    "                    score_permutation[batch_idx].append(ood_score_temp)\n",
    "                    predict_temp = logits_temp.argmax().item()\n",
    "                    permutation_correctness[batch_idx].append(predict_temp == label_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhihao/jupyterprojects/jupyter/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/zhihao/jupyterprojects/jupyter/lib/python3.8/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "permutation_correctness_ratio = []\n",
    "score_permutation_avg = []\n",
    "for i in score_init:\n",
    "    permutation_correctness_ratio.append(np.mean(permutation_correctness[i]))\n",
    "    score_permutation_avg.append(np.mean(score_permutation[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(score_permutation_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8814620980217899 0.6078544614496102\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(permutation_correctness_ratio)\n",
    "permutation_correctness_ratio = np.array(permutation_correctness_ratio)\n",
    "print(np.mean(permutation_correctness_ratio[~np.isnan(permutation_correctness_ratio)]), sum(permutation_correctness_ratio==1)/len(permutation_correctness_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permutation_correctness[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.873015873015873"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(permutation_correctness[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9998397827148438 True 15 [0, 1, 2, 3, 4, 5]\n",
      "0.9998408555984497 True\n",
      "0.9998300075531006 True\n",
      "0.9998401403427124 True\n",
      "0.9998437166213989 True\n",
      "0.9998289346694946 True\n",
      "0.9998310804367065 True\n",
      "0.9998443126678467 True\n",
      "0.9998371601104736 True\n",
      "0.999847412109375 True\n",
      "0.9998385906219482 True\n",
      "0.9998388290405273 True\n",
      "0.9998251795768738 True\n",
      "0.9998200535774231 True\n",
      "0.9998272061347961 True\n",
      "0.9998300075531006 True\n"
     ]
    }
   ],
   "source": [
    "for i in score_init:\n",
    "    print(score_init[i], init_correctness[i], num_permutations[i], init_permutation[i])\n",
    "    for score, correct in zip(score_permutation[i], permutation_correctness[i], ):\n",
    "        print(score, correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.9998397827148438 True 15 [0, 1, 2, 3, 4, 5]\n",
      "0.9998348991076151 1.0\n",
      "1 0.9995976090431213 True 15 [1, 0, 2, 3, 4, 5]\n",
      "0.9996114333470663 1.0\n",
      "2 0.999115526676178 True 2 [1, 0, 2]\n",
      "0.9991608262062073 1.0\n",
      "3 0.9965730905532837 True 63 [1, 2, 3, 4, 5, 6, 7, 0]\n",
      "0.9962718657084874 1.0\n",
      "4 0.9998373985290527 True 63 [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "0.9998213913705614 1.0\n",
      "5 0.9994794726371765 True 63 [1, 2, 0, 3, 4, 5, 6, 7]\n",
      "0.9994508624076843 1.0\n",
      "6 0.9974454641342163 True 63 [1, 2, 3, 4, 5, 0, 6, 7]\n",
      "0.9942260819768148 1.0\n",
      "7 0.9841338396072388 True 63 [1, 2, 3, 4, 5, 6, 0, 7]\n",
      "0.9567946072608705 1.0\n",
      "8 0.43239864706993103 False 3 [1, 2, 3, 0]\n",
      "0.5922626058260599 1.0\n",
      "9 0.9992141723632812 True 15 [1, 0, 2, 3, 4, 5]\n",
      "0.9992281198501587 1.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(i, score_init[i], init_correctness[i], num_permutations[i], init_permutation[i])\n",
    "    print(np.mean(score_permutation[i]), np.mean(permutation_correctness[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True, True]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permutation_correctness[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_valid = []\n",
    "for batch_idx, batch in enumerate(valid_dataloader_iter):\n",
    "    labels_valid.append(batch[\"label\"].cpu())\n",
    "labels_valid = torch.tensor(labels_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(labels_valid.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, batch in enumerate(valid_dataloader_iter):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 439])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"target_col_mask\"].T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " batch[\"cls_indexes\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brute force perumate in validation TODO: restrict mamimus length of permutation\n",
    "import itertools\n",
    "import torch.nn.functional as F\n",
    "\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "for threshold in [1.5]:\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    log = defaultdict(list)\n",
    "    num_cols = []\n",
    "    corrected = 0\n",
    "    total_mistakes = 0\n",
    "    num_permutations = {}\n",
    "    init_permutation = {}\n",
    "    init_correctness = {}\n",
    "    score_init = {}\n",
    "    score_permutation = defaultdict(list)\n",
    "    permutation_correctness = defaultdict(list)\n",
    "    for batch_idx, batch in enumerate(valid_dataloader_iter):\n",
    "        cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "        target_col_mask = batch[\"target_col_mask\"].T\n",
    "        logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "        score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
    "        label_i = batch[\"label\"].item()\n",
    "        predict_init = logits.argmax().item()\n",
    "        init_permutation_i = get_permutation(target_col_mask)\n",
    "        init_permutation[batch_idx] = init_permutation_i\n",
    "        if predict_init == label_i:\n",
    "            init_correctness[batch_idx] = True\n",
    "        else:\n",
    "            init_correctness[batch_idx] = False\n",
    "        num_permutations[batch_idx] = 0\n",
    "        if 1 in target_col_mask:\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            assert -1 not in col_idx_set\n",
    "            for r in range(len(init_permutation_i), max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "                for subset in itertools.combinations(init_permutation_i, r):\n",
    "                    if 0 not in subset and r != 1:\n",
    "                        continue\n",
    "                    for x in itertools.permutations(subset):\n",
    "                    num_permutations[batch_idx] += 1\n",
    "                    new_batch_data = []\n",
    "                    for col_i in x:\n",
    "                        if col_i == 0:\n",
    "                            if len(new_batch_data) == 0:\n",
    "                                cls_indexes_value = 0\n",
    "                            else:\n",
    "                                cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                        new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                    new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                    cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                    logits_temp = model(new_batch_data, cls_indexes=cls_indexes,)\n",
    "                    ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n",
    "                    score_permutation[batch_idx].append(ood_score_temp)\n",
    "                    predict_temp = logits_temp.argmax().item()\n",
    "                    permutation_correctness[batch_idx].append(predict_temp == label_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Threshold: 1.5****************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3888413/3589274539.py:31: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
      "/tmp/ipykernel_3888413/3589274539.py:61: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n"
     ]
    }
   ],
   "source": [
    "# brute force perumate in validation TODO: restrict mamimus length of permutation\n",
    "import itertools\n",
    "import torch.nn.functional as F\n",
    "\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "for threshold in [1.5]:\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    log = defaultdict(list)\n",
    "    num_cols = []\n",
    "    corrected = 0\n",
    "    total_mistakes = 0\n",
    "    num_permutations = {}\n",
    "    init_permutation = {}\n",
    "    init_correctness = {}\n",
    "    score_init = {}\n",
    "    score_permutation = defaultdict(list)\n",
    "    permutation_correctness = defaultdict(list)\n",
    "    for batch_idx, batch in enumerate(valid_dataloader_iter):\n",
    "        cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "        target_col_mask = batch[\"target_col_mask\"].T\n",
    "        logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "        score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
    "        label_i = batch[\"label\"].item()\n",
    "        predict_init = logits.argmax().item()\n",
    "        init_permutation_i = get_permutation(target_col_mask)\n",
    "        init_permutation[batch_idx] = init_permutation_i\n",
    "        if predict_init == label_i:\n",
    "            init_correctness[batch_idx] = True\n",
    "        else:\n",
    "            init_correctness[batch_idx] = False\n",
    "        num_permutations[batch_idx] = 0\n",
    "        if 1 in target_col_mask:\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            assert -1 not in col_idx_set\n",
    "            for r in range(len(init_permutation_i), max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "                for x in itertools.combinations(init_permutation_i, r):\n",
    "                    if 0 not in x:\n",
    "                        continue\n",
    "\n",
    "                    num_permutations[batch_idx] += 1\n",
    "                    new_batch_data = []\n",
    "                    for col_i in x:\n",
    "                        if col_i == 0:\n",
    "                            if len(new_batch_data) == 0:\n",
    "                                cls_indexes_value = 0\n",
    "                            else:\n",
    "                                cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                        new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                    new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                    cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                    logits_temp = model(new_batch_data, cls_indexes=cls_indexes,)\n",
    "                    ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n",
    "                    score_permutation[batch_idx].append(ood_score_temp)\n",
    "                    predict_temp = logits_temp.argmax().item()\n",
    "                    permutation_correctness[batch_idx].append(predict_temp == label_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhihao/jupyterprojects/jupyter/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/zhihao/jupyterprojects/jupyter/lib/python3.8/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "permutation_correctness_ratio = []\n",
    "score_permutation_avg = []\n",
    "for i in score_init:\n",
    "    permutation_correctness_ratio.append(np.mean(permutation_correctness[i]))\n",
    "    score_permutation_avg.append(np.mean(score_permutation[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5218385215200051 0.35141242937853107 0.3107344632768362 0.6621468926553672\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(permutation_correctness_ratio)\n",
    "permutation_correctness_ratio = np.array(permutation_correctness_ratio)\n",
    "print(np.mean(permutation_correctness_ratio[~np.isnan(permutation_correctness_ratio)]), sum(permutation_correctness_ratio==1)/len(permutation_correctness_ratio), sum(permutation_correctness_ratio==0)/len(permutation_correctness_ratio), (sum(permutation_correctness_ratio==0)+sum(permutation_correctness_ratio==1))/len(permutation_correctness_ratio))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(labels_valid[permutation_correctness_ratio==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(labels_valid[permutation_correctness_ratio==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAD4CAYAAAAD6PrjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAAR4UlEQVR4nO3dfbBcd13H8feHthQENC29ZkqSmgLxoaCkeK2FOk5tfSiIpsxgKYMQmWIYLQqKOgX/QGfsDM4gVXyoBFpJHaTUUmzUDlhKB2SU6k1h+ghDhNYkpM0VSkEZwZSvf+zJrzvpTXLTe8/uze77NbOz5/zOw35PT+Z+en7nt2dTVUiSBPCEcRcgSVo5DAVJUmMoSJIaQ0GS1BgKkqTm+HEXsBSnnHJKrV+/ftxlSNIxZceOHf9VVTMLLTumQ2H9+vXMzc2NuwxJOqYkuf9Qy+w+kiQ1hoIkqTEUJEmNoSBJagwFSVJjKEiSGkNBktQYCpKkxlCQJDVTGwpr1p1GkiW91qw7bdyHIUnLqrfHXCR5EvAJ4MTuc66vqrcmOR24Fng6sAN4VVV9K8mJwDXADwNfBl5eVff1Vd+Xdu/i5e/6lyXt4wOve+EyVSNJK0OfVwrfBM6rqucBG4ELkpwN/CFwRVU9G3gIuKRb/xLgoa79im49SdII9RYKNfDf3ewJ3auA84Dru/ZtwIXd9KZunm75+UnSV32SpMfq9Z5CkuOSfAbYB9wM/Afw1ara362yG1jTTa8BdgF0yx9m0MV08D63JJlLMjc/P99n+ZI0dXoNhap6pKo2AmuBs4DvX4Z9bq2q2aqanZlZ8HHgkqTHaSSjj6rqq8CtwAuAVUkO3OBeC+zppvcA6wC65d/F4IazJGlEeguFJDNJVnXTTwZ+CriXQTi8rFttM3BjN729m6db/rGqqr7qkyQ9Vp+/vHYqsC3JcQzC57qq+ock9wDXJvkD4NPAVd36VwF/nWQn8BXg4h5rkyQtoLdQqKo7gDMXaP8Cg/sLB7f/L/ALfdUjSTqyqf1GsyTpsQwFSVJjKEiSGkNBktQYCpKkxlCQJDWGgiSpMRQkSY2hIElqDAVJUmMoSJIaQ0GS1BgKkqTGUJAkNYaCJKkxFCRJjaEgSWoMBUlSYyhIkhpDQZLUGAqSpMZQkCQ1hoIkqTEUJEmNoSBJanoLhSTrktya5J4kdyd5Q9f+e0n2JPlM93rx0DZvTrIzyeeS/ExftUmSFnZ8j/veD7ypqm5P8jRgR5Kbu2VXVNXbh1dOcgZwMfAc4BnAR5N8b1U90mONkqQhvV0pVNXeqrq9m/46cC+w5jCbbAKurapvVtUXgZ3AWX3VJ0l6rJHcU0iyHjgTuK1ren2SO5JcneSkrm0NsGtos90sECJJtiSZSzI3Pz/fZ9mSNHV6D4UkTwU+CLyxqr4GXAk8C9gI7AX+6Gj2V1Vbq2q2qmZnZmaWu1xJmmq9hkKSExgEwvuq6gaAqnqwqh6pqm8D7+bRLqI9wLqhzdd2bZKkEelz9FGAq4B7q+odQ+2nDq32UuCubno7cHGSE5OcDmwA/q2v+iRJj9Xn6KNzgFcBdyb5TNf2FuAVSTYCBdwHvA6gqu5Och1wD4ORS5c68kiSRqu3UKiqTwJZYNFNh9nmcuDyvmqSJB2e32iWJDWGgiSpMRQkSY2hIElqDAVJUmMoSJIaQ0GS1BgKkqTGUJAkNYaCJKkxFCRJjaEgSWoMBUlSYyhIkhpDQZLUGAqSpMZQkCQ1hoIkqTEUJEmNoSBJagwFSVJjKEiSGkNBktQYCpKkxlCQJDW9hUKSdUluTXJPkruTvKFrPznJzUk+372f1LUnyTuT7ExyR5Ln91WbJGlhfV4p7AfeVFVnAGcDlyY5A7gMuKWqNgC3dPMALwI2dK8twJU91iZJWkBvoVBVe6vq9m7668C9wBpgE7CtW20bcGE3vQm4pgY+BaxKcmpf9UmSHmsk9xSSrAfOBG4DVlfV3m7RA8DqbnoNsGtos91d28H72pJkLsnc/Px8f0VL0hTqPRSSPBX4IPDGqvra8LKqKqCOZn9VtbWqZqtqdmZmZhkrlST1GgpJTmAQCO+rqhu65gcPdAt17/u69j3AuqHN13ZtkqQR6XP0UYCrgHur6h1Di7YDm7vpzcCNQ+2v7kYhnQ08PNTNJEkageN73Pc5wKuAO5N8pmt7C/A24LoklwD3Axd1y24CXgzsBL4BvKbH2iRJC+gtFKrqk0AOsfj8BdYv4NK+6pEkHZnfaJYkNYaCJKkxFCRJjaEgSWoMBUlSYyhIkhpDQZLUGAqSpGZRoZDknMW0SZKObYu9UvjTRbZJko5hh33MRZIXAC8EZpL85tCi7wSO67MwSdLoHenZR08Entqt97Sh9q8BL+urKEnSeBw2FKrq48DHk7y3qu4fUU2SpDFZ7FNST0yyFVg/vE1VnddHUZKk8VhsKPwt8JfAe4BH+itHkjROiw2F/VV1Za+VSJLGbrFDUv8+ya8mOTXJyQdevVYmSRq5xV4pHPhN5d8eaivgmctbjiRpnBYVClV1et+FSJLGb1GhkOTVC7VX1TXLW44kaZwW2330I0PTTwLOB24HDAVJmiCL7T76teH5JKuAa/soSJI0Po/30dn/A3ifQZImzGLvKfw9g9FGMHgQ3g8A1/VVlCRpPBZ7T+HtQ9P7gfuravfhNkhyNfASYF9VPbdr+z3gl4H5brW3VNVN3bI3A5cw+Mb0r1fVRxZ7EJKk5bGo7qPuwXifZfCk1JOAby1is/cCFyzQfkVVbexeBwLhDOBi4DndNn+RxEdzS9KILfaX1y4C/g34BeAi4LYkh310dlV9AvjKIuvYBFxbVd+sqi8CO4GzFrmtJGmZLLb76HeBH6mqfQBJZoCPAtc/js98ffe9hzngTVX1ELAG+NTQOru7NknSCC129NETDgRC58tHse2wK4FnARuBvcAfHe0OkmxJMpdkbn5+/sgbSJIWbbF/2D+c5CNJfinJLwH/CNx0tB9WVQ9W1SNV9W3g3TzaRbQHWDe06tqubaF9bK2q2aqanZmZOdoSJEmHcdhQSPLsJOdU1W8D7wJ+qHv9K7D1aD8syalDsy8F7uqmtwMXJzkxyenABgb3MCRJI3Skewp/DLwZoKpuAG4ASPKD3bKfO9SGSd4PnAuckmQ38Fbg3CQbGXzn4T7gdd2+705yHXAPgyGvl1aVP+YjSSN2pFBYXVV3HtxYVXcmWX+4DavqFQs0X3WY9S8HLj9CPZKkHh3pnsKqwyx78jLWIUlaAY4UCnNJfvngxiSvBXb0U5IkaVyO1H30RuBDSV7JoyEwCzyRwY1iSdIEOWwoVNWDwAuT/ATw3K75H6vqY71XJkkaucX+nsKtwK091yJJGrPH+3sKkqQJZChIkhpDQZLUGAqSpMZQkCQ1hoIkqTEUJEmNoSBJagwFSVJjKEiSGkNBktQYCpKkxlCQJDWGgiSpMRQkSY2hIElqDAVJUmMoSJIaQ0GS1BgKkqSmt1BIcnWSfUnuGmo7OcnNST7fvZ/UtSfJO5PsTHJHkuf3VZck6dD6vFJ4L3DBQW2XAbdU1Qbglm4e4EXAhu61Bbiyx7okSYfQWyhU1SeArxzUvAnY1k1vAy4car+mBj4FrEpyal+1SZIWNup7Cquram83/QCwupteA+waWm931/YYSbYkmUsyNz8/31+lkjSFxnajuaoKqMex3daqmq2q2ZmZmR4qk6TpNepQePBAt1D3vq9r3wOsG1pvbdcmSRqhUYfCdmBzN70ZuHGo/dXdKKSzgYeHupkkSSNyfF87TvJ+4FzglCS7gbcCbwOuS3IJcD9wUbf6TcCLgZ3AN4DX9FWXJOnQeguFqnrFIRadv8C6BVzaVy2SpMXxG82SpMZQkCQ1hoIkqTEUJEmNoSBJagwFSVJjKEiSGkNBktQYCpKkxlCQJDWGgiSpMRQkSY2hIElqDAVJUmMoSJIaQ0GS1BgKkqTGUJAkNYaCJKkxFCRJjaEgSWoMBUlSYyhIkhpDYczWrDuNJEt6rVl32rgPQ9KEOH7cBUy7L+3excvf9S9L2scHXvfCZapG0rQbSygkuQ/4OvAIsL+qZpOcDHwAWA/cB1xUVQ+Noz5Jmlbj7D76iaraWFWz3fxlwC1VtQG4pZuXJI3QSrqnsAnY1k1vAy4cXymSNJ3GFQoF/FOSHUm2dG2rq2pvN/0AsHqhDZNsSTKXZG5+fn4UtUrS1BjXjeYfq6o9Sb4buDnJZ4cXVlUlqYU2rKqtwFaA2dnZBdeRJD0+Y7lSqKo93fs+4EPAWcCDSU4F6N73jaM2SZpmIw+FJE9J8rQD08BPA3cB24HN3WqbgRtHXZskTbtxdB+tBj6U5MDn/01VfTjJvwPXJbkEuB+4aAy1SdJUG3koVNUXgOct0P5l4PxR1yNJetRKGpIqSRozQ0GS1BgKkqTGUJAkNT4ldSmecDzdKCpJmgiGwlJ8e7+PvZY0Uew+kiQ1hoIkqTEUBPizoJIGvKcgwJ8FlTTglYIkqfFKYRI4NFbSMjEUJoFDYyUtE7uPJEmNoSBJagwFSVJjKEgr2FK/P+J3R3S0vNEsrWBL/f6IAwh0tAwFLZ9lGBp73Akn8sj/fXPs+3jG2nXs2fWfS9qHdCwyFLR8lmlo7ErZhzSNDAVpISvkqkcaNUNBWsgKuupZkmUIN7vSpouhIE2yFfJt9zXrTuNLu3ctaR+G02gYCpJ6tyxP4f2VH/eqZwQMBUmHt1IeuLgcVz3LECyTPkJuxYVCkguAPwGOA95TVW8bc0nSdFshXVDLYgXdK1qp/01X1DeakxwH/DnwIuAM4BVJzhhvVZI0PVZUKABnATur6gtV9S3gWmDTmGuSpKmRqhp3DU2SlwEXVNVru/lXAT9aVa8fWmcLsKWb/T7gc4/z404B/msJ5R6rpvG4p/GYYTqPexqPGY7+uL+nqmYWWrDi7ikcSVVtBbYudT9J5qpqdhlKOqZM43FP4zHDdB73NB4zLO9xr7Tuoz3AuqH5tV2bJGkEVloo/DuwIcnpSZ4IXAxsH3NNkjQ1VlT3UVXtT/J64CMMhqReXVV39/RxS+6COkZN43FP4zHDdB73NB4zLONxr6gbzZKk8Vpp3UeSpDEyFCRJzVSGQpILknwuyc4kl427nj4kWZfk1iT3JLk7yRu69pOT3Jzk8937SeOutQ9Jjkvy6ST/0M2fnuS27px/oBvIMDGSrEpyfZLPJrk3yQum4Vwn+Y3u3/ddSd6f5EmTeK6TXJ1kX5K7htoWPL8ZeGd3/Hckef7RfNbUhcIUPUpjP/CmqjoDOBu4tDvOy4BbqmoDcEs3P4neANw7NP+HwBVV9WzgIeCSsVTVnz8BPlxV3w88j8GxT/S5TrIG+HVgtqqey2BwysVM5rl+L3DBQW2HOr8vAjZ0ry3AlUfzQVMXCkzJozSqam9V3d5Nf53BH4k1DI51W7faNuDCsRTYoyRrgZ8F3tPNBzgPuL5bZaKOO8l3AT8OXAVQVd+qqq8yBeeawQjKJyc5HvgOYC8TeK6r6hPAVw5qPtT53QRcUwOfAlYlOXWxnzWNobAGGP61j91d28RKsh44E7gNWF1Ve7tFDwCrx1VXj/4Y+B3g293804GvVtX+bn7SzvnpwDzwV12X2XuSPIUJP9dVtQd4O/CfDMLgYWAHk32uhx3q/C7pb9w0hsJUSfJU4IPAG6vqa8PLajAeeaLGJCd5CbCvqnaMu5YROh54PnBlVZ0J/A8HdRVN6Lk+icH/FZ8OPAN4Co/tYpkKy3l+pzEUpuZRGklOYBAI76uqG7rmBw9cSnbv+8ZVX0/OAX4+yX0MugbPY9DfvqrrYoDJO+e7gd1VdVs3fz2DkJj0c/2TwBerar6q/g+4gcH5n+RzPexQ53dJf+OmMRSm4lEaXT/6VcC9VfWOoUXbgc3d9GbgxlHX1qeqenNVra2q9QzO7ceq6pXArcDLutUm6rir6gFgV5Lv65rOB+5hws81g26js5N8R/fv/cBxT+y5Psihzu924NXdKKSzgYeHupmOaCq/0ZzkxQz6nQ88SuPy8Va0/JL8GPDPwJ082rf+Fgb3Fa4DTgPuBy6qqoNvYE2EJOcCv1VVL0nyTAZXDicDnwZ+saqW9nuIK0iSjQxurD8R+ALwGgb/0zfR5zrJ7wMvZzDa7tPAaxn0n0/UuU7yfuBcBo/IfhB4K/B3LHB+u4D8MwZdad8AXlNVc4v+rGkMBUnSwqax+0iSdAiGgiSpMRQkSY2hIElqDAVJUmMoSJIaQ0GS1Pw/w7BGN5i1SyMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(labels_valid[(permutation_correctness_ratio==1)|(permutation_correctness_ratio==0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(885,)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permutation_correctness_ratio.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8309)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_init = torch.tensor(list(score_init.values()))\n",
    "score_init.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9881)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3888413/2131006282.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  permutation_correctness_ratio = torch.tensor(permutation_correctness_ratio)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permutation_correctness_ratio = torch.tensor(permutation_correctness_ratio)\n",
    "print(score_init[permutation_correctness_ratio==1].mean())\n",
    "False in torch.tensor(list(init_correctness.values()))[permutation_correctness_ratio==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7196)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(score_init[permutation_correctness_ratio==0].mean())\n",
    "True in torch.tensor(list(init_correctness.values()))[permutation_correctness_ratio==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_permutations_all = num_permutations.values()\n",
    "sns.histplot(num_permutations_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_permutations.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 8\n",
      "64 8\n",
      "64 8\n",
      "64 8\n",
      "4 4\n",
      "11 5\n",
      "3 3\n",
      "64 8\n",
      "64 8\n",
      "64 8\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(num_permutations[i], len(init_permutation[i]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_correct_permutations = [sum(permutation_correctness[i]) for i in permutation_correctness]\n",
    "num_wrong_permutations = [len(permutation_correctness[i])-sum(permutation_correctness[i]) for i in permutation_correctness]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.0\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 31, 32, 34, 35, 37, 38, 39,\n",
      "        40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58,\n",
      "        59, 60, 61, 62, 63, 64])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAD4CAYAAAAD6PrjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAAUGElEQVR4nO3df7DddX3n8efL8ENXXQNyNxOTsKE1W5d21+BcEcHZQRhbZLtFdxBxHMk6dMPO4o6OrpW0s9s6s8zUmVa0nV3WVCi44wqIuqQsq6UB23Gs4AUjApE1VWgSArlVQK1TuoH3/nE++XIIN8kl5HvOPbnPx8x37vf7/n6+57wvHHjd78+TqkKSJIAXjbsBSdLCYShIkjqGgiSpYyhIkjqGgiSpc9S4G3ghTjjhhFq9evW425CkiXLXXXf9TVVNzbVuokNh9erVzMzMjLsNSZooSR7a3zoPH0mSOoaCJKljKEiSOoaCJKnTeygkWZLkW0lubssnJbkjybYk1yc5ptWPbcvb2vrVffcmSXq2UewpvB/YOrT8MeCKqno18BhwcatfDDzW6le0cZKkEeo1FJKsBP4l8Om2HOAs4MY25FrgbW3+vLZMW392Gy9JGpG+9xQ+AfwG8HRbfiXweFXtacs7gBVtfgWwHaCtf6KNf5Yk65PMJJmZnZ3tsXVJWnx6C4Ukvwrsrqq7DufrVtXGqpququmpqTlvyJMkHaI+9xTOAH4tyYPAdQwOG30SWJpk753UK4GdbX4nsAqgrX8F8MO+mlux6kSSjGxaserEvn4VSTpsenvMRVVtADYAJDkT+I9V9e4knwfOZxAU64Cb2iab2vJftvW3VY9fC/fwju2881Nf7+vln+P6S04f2XtJ0qEax30KHwE+mGQbg3MGV7X6VcArW/2DwGVj6E2SFrWRPBCvqr4KfLXNfx84dY4xfwe8YxT9SJLm5h3NkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqROb6GQ5MVJ7kzy7ST3Jfloq1+T5AdJtrRpbasnyR8k2ZbkniSv66s3SdLc+vw6zieBs6rqp0mOBr6W5P+0dR+uqhv3Gf9WYE2b3gBc2X5Kkkaktz2FGvhpWzy6TXWATc4DPtO2+wawNMnyvvqTJD1Xr+cUkixJsgXYDdxaVXe0VZe3Q0RXJDm21VYA24c239Fq+77m+iQzSWZmZ2f7bF+SFp1eQ6GqnqqqtcBK4NQkvwRsAF4DvB44HvjI83zNjVU1XVXTU1NTh7tlSVrURnL1UVU9DtwOnFNVu9ohoieBPwZObcN2AquGNlvZapKkEenz6qOpJEvb/EuAtwDf3XueIEmAtwH3tk02ARe1q5BOA56oql199SdJeq4+rz5aDlybZAmD8Lmhqm5OcluSKSDAFuDftfG3AOcC24CfAe/tsTdJ0hx6C4Wqugc4ZY76WfsZX8ClffUjSTo472iWJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHX6/I7mFye5M8m3k9yX5KOtflKSO5JsS3J9kmNa/di2vK2tX91Xb5KkufW5p/AkcFZVvRZYC5yT5DTgY8AVVfVq4DHg4jb+YuCxVr+ijZMkjVBvoVADP22LR7epgLOAG1v9WuBtbf68tkxbf3aS9NWfJOm5ej2nkGRJki3AbuBW4K+Ax6tqTxuyA1jR5lcA2wHa+ieAV87xmuuTzCSZmZ2d7bN9SVp0eg2FqnqqqtYCK4FTgdcchtfcWFXTVTU9NTX1Ql9OkjRkJFcfVdXjwO3AG4GlSY5qq1YCO9v8TmAVQFv/CuCHo+hPkjTQ59VHU0mWtvmXAG8BtjIIh/PbsHXATW1+U1umrb+tqqqv/iRJz3XUwYccsuXAtUmWMAifG6rq5iT3A9cl+S/At4Cr2virgP+RZBvwI+DCHnuTJM2ht1CoqnuAU+aof5/B+YV9638HvKOvfiRJB+cdzZKkjqEgSeoYCpKkjqEgSeoYCpKkjqEgSeoYCpKkjqEgSeoYCpKkjqEgSeoYCpKkjqEgSeoYCpKkjqEgSeoYCpKkjqEgSeoYCpKkTp/f0bwqye1J7k9yX5L3t/rvJNmZZEubzh3aZkOSbUkeSPIrffUmSZpbn9/RvAf4UFXdneTlwF1Jbm3rrqiq3xsenORkBt/L/IvAq4A/S/JPquqpHnuUJA3pbU+hqnZV1d1t/ifAVmDFATY5D7iuqp6sqh8A25jju5wlSf0ZyTmFJKuBU4A7Wul9Se5JcnWS41ptBbB9aLMdzBEiSdYnmUkyMzs722fbkrTo9B4KSV4GfAH4QFX9GLgS+HlgLbAL+P3n83pVtbGqpqtqempq6nC3K0mLWq+hkORoBoHw2ar6IkBVPVpVT1XV08Af8cwhop3AqqHNV7aaJGlE+rz6KMBVwNaq+vhQffnQsLcD97b5TcCFSY5NchKwBrizr/4kSc/V59VHZwDvAb6TZEur/SbwriRrgQIeBC4BqKr7ktwA3M/gyqVLvfJIkkart1Coqq8BmWPVLQfY5nLg8r56kiQdmHc0S5I6hoIkqWMoSJI6hoIkqTOvUEhyxnxqkqTJNt89hT+cZ02SNMEOeElqkjcCpwNTST44tOofAkv6bEySJsmKVSfy8I7tBx94mLxq5Sp2bv/rw/66B7tP4RjgZW3cy4fqPwbOP+zdSNKEenjHdt75qa+P7P2uv+T0Xl73gKFQVX8O/HmSa6rqoV46kCQtGPO9o/nYJBuB1cPbVNVZfTQlSRqP+YbC54H/Dnwa8HlEknSEmm8o7KmqK3vtRJI0dvO9JPVPkvz7JMuTHL936rUzSdLIzXdPYV37+eGhWgE/d3jbkSSN07xCoapO6rsRSdL4zSsUklw0V72qPnN425EkjdN8Dx+9fmj+xcDZwN2AoSBJR5D5Hj76D8PLSZYC1x1omySrGITGMgbnHzZW1SfbCerrGdzz8CBwQVU91r7T+ZPAucDPgH9TVXc/n19GkvTCHOqjs/8WONh5hj3Ah6rqZOA04NIkJwOXAZurag2wuS0DvBVY06b1gJfAStKIzfecwp8w+GsfBg/C+6fADQfapqp2Abva/E+SbAVWAOcBZ7Zh1wJfBT7S6p+pqgK+kWRpkuXtdSRJIzDfcwq/NzS/B3ioqnbM902SrAZOAe4Alg39j/4RBoeXYBAYw48Y3NFqzwqFJOsZ7Elw4oknzrcFSdI8zOvwUXsw3ncZPCn1OODv5/sGSV4GfAH4QFX9eJ/XLZ7ZA5mXqtpYVdNVNT01NfV8NpUkHcR8v3ntAuBO4B3ABcAdSQ766OwkRzMIhM9W1Rdb+dEky9v65cDuVt8JrBrafGWrSZJGZL4nmn8LeH1Vrauqi4BTgf90oA3a1URXAVur6uNDqzbxzB3S64CbhuoXZeA04AnPJ0jSaM33nMKLqmr30PIPOXignAG8B/hOki2t9pvA7wI3JLkYeIjBngfALQwuR93G4JLU986zN0nSYTLfUPhykq8An2vL72TwP/H9qqqvAdnP6rPnGF/ApfPsR5LUg4N9R/OrGVwt9OEk/xp4U1v1l8Bn+25OkjRaB9tT+ASwAaCdKP4iQJJ/1tb9qx57kySN2MHOCyyrqu/sW2y11b10JEkam4OFwtIDrHvJYexDkrQAHCwUZpL8232LSX4duKufliRJ43KwcwofAL6U5N08EwLTwDHA23vsS5I0BgcMhap6FDg9yZuBX2rl/11Vt/XemSRp5Ob7fQq3A7f33IskacwO9fsUJElHIENBktQxFCRJHUNBktQxFCRJHUNBktQxFCRJHUNBktQxFCRJnd5CIcnVSXYnuXeo9jtJdibZ0qZzh9ZtSLItyQNJfqWvviRJ+9fnnsI1wDlz1K+oqrVtugUgycnAhcAvtm3+W5IlPfYmSZpDb6FQVX8B/Giew88DrquqJ6vqB8A24NS+epMkzW0c5xTel+SednjpuFZbAWwfGrOj1SRJIzTqULgS+HlgLbAL+P3n+wJJ1ieZSTIzOzt7mNuTpMVtpKFQVY9W1VNV9TTwRzxziGgnsGpo6MpWm+s1NlbVdFVNT01N9duwJC0yIw2FJMuHFt8O7L0yaRNwYZJjk5wErAHuHGVvkqR5fsnOoUjyOeBM4IQkO4DfBs5MshYo4EHgEoCqui/JDcD9wB7g0qp6qq/eJElz6y0Uqupdc5SvOsD4y4HL++pHknRw3tEsSeoYCpKkjqEgSeoYCpKkjqEgSeoYCpKkjqEgSeoYCpKkjqEgSeoYCpKkjqEgSeoYCpKkjqEgSeoYCpKkjqEgSeoYCpKkjqEgSer0FgpJrk6yO8m9Q7Xjk9ya5Hvt53GtniR/kGRbknuSvK6vviRJ+9fnnsI1wDn71C4DNlfVGmBzWwZ4K7CmTeuBK3vsS5K0H72FQlX9BfCjfcrnAde2+WuBtw3VP1MD3wCWJlneV2+SpLmN+pzCsqra1eYfAZa1+RXA9qFxO1pNkjRCYzvRXFUF1PPdLsn6JDNJZmZnZ3voTJIWr1GHwqN7Dwu1n7tbfSewamjcylZ7jqraWFXTVTU9NTXVa7OStNiMOhQ2Aeva/DrgpqH6Re0qpNOAJ4YOM0mSRuSovl44yeeAM4ETkuwAfhv4XeCGJBcDDwEXtOG3AOcC24CfAe/tqy9J0v71FgpV9a79rDp7jrEFXNpXL5Kk+fGOZklSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1AYlRcdRZKRTStWnTju31jSBOrtgXjax9N7eOenvj6yt7v+ktNH9l6SjhzuKUiSOoaCJKljKEiSOoaCJKljKEiSOmO5+ijJg8BPgKeAPVU1neR44HpgNfAgcEFVPTaO/iRpsRrnnsKbq2ptVU235cuAzVW1BtjclnWoRnhfhPdESEeOhXSfwnnAmW3+WuCrwEfG1czEG+F9Ed4TIR05xrWnUMCfJrkryfpWW1ZVu9r8I8CyuTZMsj7JTJKZ2dnZUfQqSYvGuPYU3lRVO5P8I+DWJN8dXllVlaTm2rCqNgIbAaanp+ccI0k6NGPZU6iqne3nbuBLwKnAo0mWA7Sfu8fRmyQtZiMPhSQvTfLyvfPALwP3ApuAdW3YOuCmUfcmSYvdOA4fLQO+lGTv+//Pqvpykm8CNyS5GHgIuGAMvUnSojbyUKiq7wOvnaP+Q+DsUfcjSXqGdzRLkjqGgrSIrVh1ol/+pGdZSDevSRqxh3ds98uf9CzuKUiSOoaCJKljKEiSOoaCJKljKOiFG+Fjur2CReqXVx/phRvhY7rBK1g0PytWncjDO7aPu42JYyho8rQ9k1F51cpV7Nz+1yN7Px0eXm57aAwFTR73TKTeeE5BWkBGfYextC/3FKQF5Ig/5DHiQ396/gwFSaPjd4cveB4+kiR1DAVJUsdQkCR1FlwoJDknyQNJtiW5bNz9SKO8Y1satwV1ojnJEuC/Am8BdgDfTLKpqu4fb2da1Dw5qkVkoe0pnApsq6rvV9XfA9cB5425J0laNFJV4+6hk+R84Jyq+vW2/B7gDVX1vqEx64H1bfEXgAcO8e1OAP7mBbQ7bvY/PpPcO0x2/5PcOyyc/v9xVU3NtWJBHT6aj6raCGx8oa+TZKaqpg9DS2Nh/+Mzyb3DZPc/yb3DZPS/0A4f7QRWDS2vbDVJ0ggstFD4JrAmyUlJjgEuBDaNuSdJWjQW1OGjqtqT5H3AV4AlwNVVdV9Pb/eCD0GNmf2PzyT3DpPd/yT3DhPQ/4I60SxJGq+FdvhIkjRGhoIkqbMoQ2HSHqWR5Ooku5PcO1Q7PsmtSb7Xfh43zh73J8mqJLcnuT/JfUne3+qT0v+Lk9yZ5Nut/4+2+klJ7mifoevbhRELUpIlSb6V5Oa2PEm9P5jkO0m2JJlptUn57CxNcmOS7ybZmuSNk9D7oguFoUdpvBU4GXhXkpPH29VBXQOcs0/tMmBzVa0BNrflhWgP8KGqOhk4Dbi0/fOelP6fBM6qqtcCa4FzkpwGfAy4oqpeDTwGXDy+Fg/q/cDWoeVJ6h3gzVW1duj6/kn57HwS+HJVvQZ4LYN/Bwu/96paVBPwRuArQ8sbgA3j7msefa8G7h1afgBY3uaXAw+Mu8d5/h43MXi21cT1D/wD4G7gDQzuSj1qrs/UQpoY3OuzGTgLuBnIpPTe+nsQOGGf2oL/7ACvAH5Au5hnknpfdHsKwApg+9DyjlabNMuqalebfwRYNs5m5iPJauAU4A4mqP92+GULsBu4Ffgr4PGq2tOGLOTP0CeA3wCebsuvZHJ6ByjgT5Pc1R5xA5Px2TkJmAX+uB26+3SSlzIBvS/GUDji1ODPjgV9bXGSlwFfAD5QVT8eXrfQ+6+qp6pqLYO/uk8FXjPejuYnya8Cu6vqrnH38gK8qapex+Bw76VJ/sXwygX82TkKeB1wZVWdAvwt+xwqWqi9L8ZQOFIepfFokuUA7efuMfezX0mOZhAIn62qL7byxPS/V1U9DtzO4JDL0iR7b/5cqJ+hM4BfS/IggycOn8XgOPck9A5AVe1sP3cDX2IQypPw2dkB7KiqO9ryjQxCYsH3vhhD4Uh5lMYmYF2bX8fgWP2Ck8E3x1wFbK2qjw+tmpT+p5IsbfMvYXA+ZCuDcDi/DVuQ/VfVhqpaWVWrGXzOb6uqdzMBvQMkeWmSl++dB34ZuJcJ+OxU1SPA9iS/0EpnA/czAb2P/aTGOCbgXOD/Mjg2/Fvj7mce/X4O2AX8PwZ/gVzM4NjwZuB7wJ8Bx4+7z/30/iYGu8j3AFvadO4E9f/PgW+1/u8F/nOr/xxwJ7AN+Dxw7Lh7PcjvcSZw8yT13vr8dpvu2/vf6gR9dtYCM+2z87+A4yahdx9zIUnqLMbDR5Kk/TAUJEkdQ0GS1DEUJEkdQ0GS1DEUJEkdQ0GS1Pn/9ACra1H1/YAAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(np.median(num_correct_permutations))\n",
    "print(torch.tensor(num_correct_permutations).unique())\n",
    "sns.histplot(num_correct_permutations )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAD4CAYAAAAD6PrjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAAPt0lEQVR4nO3df8ydZX3H8fdHKuD8VX48IV1bVgxER5YJpCI/jFGICzIjbEHRGCWmrmbDBYPRwUy2mOwPTRZRl8XZgBMXIyDqQGZ0WNBlcZY9CCJQGdXJ2gq0KuCmUVf97o9z9dpDaXkOLedXn/crOTn3dd33Oed74G4+z3Xd97nvVBWSJAE8Y9IFSJKmh6EgSeoMBUlSZyhIkjpDQZLULZt0AQfi6KOPrjVr1ky6DEmaKbfffvsPq2pub+tmOhTWrFnD/Pz8pMuQpJmS5IF9rXP6SJLUGQqSpM5QkCR1hoIkqTMUJEmdoSBJ6gwFSVJnKEiSOkNBktQt2VBYufpYkoztsXL1sZP+ypK0qJm+zMWB+MG2rVz4sa+P7fOuffsZY/ssSdpfS3akIEl6IkNBktQZCpKkzlCQJHWGgiSpMxQkSZ2hIEnqDAVJUmcoSJI6Q0GS1BkKkqTOUJAkdSMPhSSHJLkjyU2tfVySTUm2JLk2yaGt/7DW3tLWrxl1bZKkxxvHSOESYPOC9geAK6rqeOARYF3rXwc80vqvaNtJksZopKGQZBXw+8CVrR3gLOD6tsnVwPlt+bzWpq0/u20vSRqTUY8UPgS8B/h1ax8FPFpVu1p7G7CyLa8EtgK09Y+17R8nyfok80nmd+7cOcLSJWnpGVkoJHkNsKOqbn8637eqNlTV2qpaOzc393S+tSQteaO889qZwGuTnAscDjwP+DCwPMmyNhpYBWxv228HVgPbkiwDng/8aIT1SZL2MLKRQlVdXlWrqmoN8Abglqp6E3ArcEHb7CLghrZ8Y2vT1t9SVTWq+iRJTzSJ3yn8GXBpki0Mjhlc1fqvAo5q/ZcCl02gNkla0kY5fdRV1VeBr7bl7wGn7mWbnwOvG0c9kqS98xfNkqTOUJAkdYaCJKkzFCRJnaEgSeoMBUlSZyhIkjpDQZLUGQqSpM5QkCR1hoIkqTMUJEmdoSBJ6gwFSVJnKEiSOkNBktQZCpKkzlCQJHWGgiSpMxQkSZ2hIEnqDAVJUmcoSJI6Q0GS1BkKkqTOUJAkdYaCJKkzFCRJnaEgSeoMBUlSZyhIkjpDQZLUGQqSpM5QkCR1hoIkqTMUJEmdoSBJ6gwFSVI3slBIcniS25J8K8k9Sd7X+o9LsinJliTXJjm09R/W2lva+jWjqk2StHejHCn8Ajirql4MnASck+Q04APAFVV1PPAIsK5tvw54pPVf0baTJI3RyEKhBv6nNZ/ZHgWcBVzf+q8Gzm/L57U2bf3ZSTKq+iRJTzTSYwpJDklyJ7ADuBn4LvBoVe1qm2wDVrbllcBWgLb+MeCoUdYnSXq8kYZCVf2qqk4CVgGnAi860PdMsj7JfJL5nTt3HujbSZIWGMvZR1X1KHArcDqwPMmytmoVsL0tbwdWA7T1zwd+tJf32lBVa6tq7dzc3KhLl6QlZZRnH80lWd6WnwW8CtjMIBwuaJtdBNzQlm9sbdr6W6qqRlWfJOmJli2+yX5bAVyd5BAG4XNdVd2U5F7gmiR/BdwBXNW2vwr4hyRbgB8DbxhhbZKkvRhZKFTVXcDJe+n/HoPjC3v2/xx43ajqkSQtzl80S5I6Q0GS1BkKkqTOUJAkdYaCJKkzFCRJnaEgSeoMBUlSZyhIkjpDQZLUGQqSpM5QkCR1hoIkqTMUJEmdoSBJ6gwFSVI3VCgkOXOYPknSbBt2pPA3Q/ZJkmbYk96OM8npwBnAXJJLF6x6HnDIKAuTJI3fYvdoPhR4TtvuuQv6fwJcMKqiJEmT8aShUFVfA76W5BNV9cCYapIkTchiI4XdDkuyAViz8DVVddYoipIkTcawofAZ4O+AK4Ffja4cSdIkDRsKu6rqoyOtRJI0ccOekvqFJH+SZEWSI3c/RlqZJGnshh0pXNSe372gr4AXPL3lSJImaahQqKrjRl2IJGnyhgqFJG/ZW39VffLpLUeSNEnDTh+9ZMHy4cDZwDcBQ0GSDiLDTh/96cJ2kuXANaMoSJI0Oft76eyfAh5nkKSDzLDHFL7A4GwjGFwI77eB60ZVlCRpMoY9pvDXC5Z3AQ9U1bYR1CNJmqChpo/ahfG+w+BKqUcAvxxlUZKkyRj2zmuvB24DXge8HtiUxEtnS9JBZtjpo/cCL6mqHQBJ5oCvANePqjBJ0vgNe/bRM3YHQvOjp/BaSdKMGHak8KUkXwY+3doXAl8cTUmSpElZ7B7NxwPHVNW7k/wh8LK26t+AT426OEnSeC02BfQhBvdjpqo+V1WXVtWlwOfbun1KsjrJrUnuTXJPkkta/5FJbk5yf3s+ovUnyUeSbElyV5JTDvTLSZKemsVC4Ziq+vaena1vzSKv3QW8q6pOBE4DLk5yInAZsLGqTgA2tjbAq4ET2mM94E19JGnMFguF5U+y7llP9sKqerCqvtmW/xvYDKwEzgOubptdDZzfls8DPlkD3wCWJ1mxSH2SpKfRYqEwn+SP9uxM8jbg9mE/JMka4GRgE4PRx4Nt1UPAMW15JbB1wcu2tb4932t9kvkk8zt37hy2BEnSEBY7++idwOeTvIn/D4G1wKHAHwzzAUmeA3wWeGdV/SRJX1dVlaT2+eK9qKoNwAaAtWvXPqXXSpKe3JOGQlU9DJyR5JXA77Tuf6qqW4Z58yTPZBAIn6qqz7Xuh5OsqKoH2/TQ7t8/bAdWL3j5qtYnSRqTYe+ncCtw61N54wyGBFcBm6vqgwtW3cjgns/vb883LOh/R5JrgJcCjy2YZpIkjcGwP17bH2cCbwa+neTO1vfnDMLguiTrgAcYXEsJBj+GOxfYAvwMeOsIa5Mk7cXIQqGq/hXIPlafvZftC7h4VPVIkhbn9Ysk6WmwcvWxJBnbY+XqY0fyPUY5fSRJS8YPtm3lwo99fWyfd+3bzxjJ+zpSkCR1hoIkqTMUJEmdoSBJ6gwFSVJnKEiSOkNBktQZCpKkzlCQJHWGgiSpMxQkSZ2hIEnqDAVJUmcoSJI6Q0GS1BkKkqTOUJAkdYaCJKkzFCRJnaEgSeoMBUlSZyhIkjpDQZLUGQqSpM5QkCR1hoIkqTMUJEmdoSBJ6gwFSVJnKEiSOkNBktQZCpKkzlCQJHWGgiSpMxQkSZ2hIEnqRhYKST6eZEeSuxf0HZnk5iT3t+cjWn+SfCTJliR3JTllVHVJkvZtlCOFTwDn7NF3GbCxqk4ANrY2wKuBE9pjPfDREdYlSdqHkYVCVf0L8OM9us8Drm7LVwPnL+j/ZA18A1ieZMWoapMk7d24jykcU1UPtuWHgGPa8kpg64LttrW+J0iyPsl8kvmdO3eOrlJJWoImdqC5qgqo/XjdhqpaW1Vr5+bmRlCZJC1d4w6Fh3dPC7XnHa1/O7B6wXarWp8kaYzGHQo3Ahe15YuAGxb0v6WdhXQa8NiCaSZJ0pgsG9UbJ/k08Arg6CTbgL8E3g9cl2Qd8ADw+rb5F4FzgS3Az4C3jqouSdK+jSwUquqN+1h19l62LeDiUdUiSRqOv2iWJHWGgiSpMxQkSZ2hIEnqDAVJUmcoSJI6Q0GS1BkKkqTOUJAkdYaCJKkzFCRJnaEgSeoMBUlSZyhIkjpDYVyesYwkY3usXH3spL+xpBk0svspaA+/3sWFH/v62D7u2refMbbPknTwcKQgSeoMBUlSZygcrMZ4DMPjF9LBw2MKB6sxHsPw+IV08HCkIC1hK1cf61lxehxHCtIS9oNtWz0rTo/jSEGS1BkKkqTOUJAkdYaCJKkzFCRJnaEgSeoMBUlSZyhIOiiN+4d5Bwt/vCbpoOQP8/aPIwVpivjXrSbNkYI0RfzrVpPmSEEHzluNSgcNRwo6cOO+1egfv3ysUx+/uWo127f+19g+T5okQ0Gzx/tdz642qtT0MhQkjY83f5p6HlOQJHWOFKTFOOWhJWSqQiHJOcCHgUOAK6vq/RMuSXLKQ0vK1EwfJTkE+Fvg1cCJwBuTnDjZqiRpaZmaUABOBbZU1feq6pfANcB5E65JkpaUVNWkawAgyQXAOVX1ttZ+M/DSqnrHHtutB9a35guB+/bzI48Gfrifr50Gs1z/LNcO1j9Js1w7TE/9v1VVc3tbMVXHFIZRVRuADQf6Pknmq2rt01DSRMxy/bNcO1j/JM1y7TAb9U/T9NF2YPWC9qrWJ0kak2kKhX8HTkhyXJJDgTcAN064JklaUqZm+qiqdiV5B/BlBqekfryq7hnhRx7wFNSEzXL9s1w7WP8kzXLtMAP1T82BZknS5E3T9JEkacIMBUlStyRDIck5Se5LsiXJZZOuZzFJPp5kR5K7F/QdmeTmJPe35yMmWeO+JFmd5NYk9ya5J8klrX/q609yeJLbknyr1f6+1n9ckk1t/7m2nRgxtZIckuSOJDe19szUn+T7Sb6d5M4k861v6vcdgCTLk1yf5DtJNic5fRZqX3KhMKOX0/gEcM4efZcBG6vqBGBja0+jXcC7qupE4DTg4vbfexbq/wVwVlW9GDgJOCfJacAHgCuq6njgEWDd5EocyiXA5gXtWav/lVV10oLz+2dh34HBddy+VFUvAl7M4P/B9NdeVUvqAZwOfHlB+3Lg8knXNUTda4C7F7TvA1a05RXAfZOuccjvcQPwqlmrH/gN4JvASxn8InXZ3vanaXsw+L3PRuAs4CYgM1b/94Gj9+ib+n0HeD7wn7STeWap9iU3UgBWAlsXtLe1vllzTFU92JYfAo6ZZDHDSLIGOBnYxIzU36Ze7gR2ADcD3wUerapdbZNp338+BLwH+HVrH8Vs1V/APye5vV3iBmZj3zkO2An8fZu6uzLJs5mB2pdiKBx0avBnx1SfW5zkOcBngXdW1U8Wrpvm+qvqV1V1EoO/uE8FXjTZioaX5DXAjqq6fdK1HICXVdUpDKZ7L07y8oUrp3jfWQacAny0qk4GfsoeU0XTWvtSDIWD5XIaDydZAdCed0y4nn1K8kwGgfCpqvpc656Z+gGq6lHgVgbTLcuT7P7h5zTvP2cCr03yfQZXHT6LwTz3rNRPVW1vzzuAzzMI5lnYd7YB26pqU2tfzyAkpr72pRgKB8vlNG4ELmrLFzGYq586Gdyy7Cpgc1V9cMGqqa8/yVyS5W35WQyOhWxmEA4XtM2msnaAqrq8qlZV1RoG+/ktVfUmZqT+JM9O8tzdy8DvAXczA/tOVT0EbE3ywtZ1NnAvM1D7xA9qTOIBnAv8B4P54fdOup4h6v008CDwvwz+AlnHYG54I3A/8BXgyEnXuY/aX8ZgiHwXcGd7nDsL9QO/C9zRar8b+IvW/wLgNmAL8BngsEnXOsR3eQVw0yzV3+r8Vnvcs/vf6izsO63Ok4D5tv/8I3DELNTuZS4kSd1SnD6SJO2DoSBJ6gwFSVJnKEiSOkNBktQZCpKkzlCQJHX/B93X8eMmh3UgAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(np.median(num_wrong_permutations))\n",
    "sns.histplot(num_wrong_permutations )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 21, 22, 23, 24, 25, 26, 27, 29, 30, 32, 33, 34, 35, 37, 38, 39,\n",
       "        40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57,\n",
       "        58, 59, 60, 61, 62, 63, 64])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(num_wrong_permutations).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, batch in enumerate(valid_dataloader_iter):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "            veri_data[batch_idx].append(new_batch_data.cpu())\n",
    "            veri_label[batch_idx].append(torch.tensor(predict_temp == label_i).long())\n",
    "            veri_cls_indexes[batch_idx].append(cls_indexes_value)\n",
    "            veri_embs[batch_idx].append(embs_temp.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([-8.5623e-01,  7.9049e-02,  3.8569e-01, -6.6407e-01, -1.1610e-01,\n",
       "          1.2273e-02,  4.6107e-02, -1.1365e-01, -8.2460e-01, -2.5970e-01,\n",
       "          9.7081e-01,  8.7536e-01,  6.9931e-01, -3.7064e-01,  1.5717e-01,\n",
       "         -9.5941e-01, -3.9030e-01, -3.4365e-01, -5.4322e-01, -7.6414e-01,\n",
       "         -3.5498e-01,  5.3573e-01, -7.5528e-03,  8.9907e-01,  9.6517e-01,\n",
       "          7.3408e-01, -4.5198e-01,  8.5908e-01, -4.4580e-01,  2.2950e-01,\n",
       "          2.9253e-01, -8.5116e-01, -7.7495e-01, -1.1472e-01,  8.1374e-01,\n",
       "          7.2535e-01,  9.1710e-01,  1.3555e-02,  4.6910e-01,  4.4896e-01,\n",
       "          3.5230e-01,  8.2012e-02,  5.3267e-01,  3.2740e-01, -7.5726e-01,\n",
       "          7.6358e-01, -8.2322e-01, -1.7131e-01, -6.4406e-02,  6.8759e-01,\n",
       "         -1.0792e-01,  3.8933e-01, -7.8018e-01,  3.1049e-02, -7.4943e-01,\n",
       "         -7.5538e-01, -5.2140e-01, -4.5425e-01, -8.4437e-01, -7.2915e-01,\n",
       "         -9.2840e-01, -2.2128e-01,  9.5900e-03,  1.9464e-01,  5.9089e-01,\n",
       "         -3.3018e-01,  6.4489e-01,  4.9774e-02, -9.2997e-01,  4.3776e-01,\n",
       "          1.0284e-01,  1.6019e-01,  8.6100e-01,  4.6374e-02, -8.3401e-01,\n",
       "          8.8687e-01, -4.6522e-01, -9.9633e-02,  1.3309e-01, -6.3779e-01,\n",
       "          4.5469e-01, -6.3094e-01, -8.3818e-01,  7.7902e-01, -4.8522e-01,\n",
       "         -5.8834e-01,  3.0443e-01, -4.5932e-01, -4.8500e-01,  7.3405e-01,\n",
       "         -2.2945e-01, -6.5467e-01,  1.5972e-01, -7.8529e-01,  4.7632e-01,\n",
       "         -1.6704e-01,  6.2478e-01,  5.7767e-01,  1.8077e-01,  2.3625e-01,\n",
       "         -6.9748e-02,  7.2845e-01, -7.7958e-01, -5.9337e-01, -4.0002e-01,\n",
       "         -4.5135e-01,  7.5507e-01, -6.4107e-02,  4.7773e-01, -7.1739e-01,\n",
       "         -2.4171e-01, -4.6856e-01,  7.4073e-01,  8.1377e-01, -5.9937e-01,\n",
       "         -3.3553e-01, -5.7118e-01, -3.3919e-01, -1.8406e-01, -7.1625e-02,\n",
       "         -4.5884e-01, -1.0034e-01,  3.1261e-01, -2.0556e-01, -6.2962e-01,\n",
       "         -3.8913e-01, -1.4897e-01,  6.8997e-01, -9.3466e-01,  3.4187e-01,\n",
       "         -8.5936e-01, -6.0764e-01,  6.8325e-01, -8.2343e-01,  1.8576e-01,\n",
       "          5.0281e-01, -7.9032e-01, -7.4007e-01, -5.4861e-01, -1.7795e-01,\n",
       "          5.1216e-01,  7.3116e-01, -6.7707e-01, -1.4837e-01, -4.9129e-01,\n",
       "         -8.8045e-01,  3.3217e-01,  8.3993e-01,  3.6906e-01,  3.8254e-01,\n",
       "         -7.8751e-01,  3.7775e-01,  6.9343e-01,  8.9910e-02,  7.2131e-01,\n",
       "         -7.5399e-01, -2.7933e-01, -8.9220e-01,  2.6742e-02,  5.3237e-01,\n",
       "          6.4245e-03, -6.2414e-01,  8.5267e-01,  7.8956e-02, -9.1288e-02,\n",
       "          4.6367e-01,  3.6438e-01,  9.2669e-01, -4.1000e-01,  3.7184e-02,\n",
       "         -4.1953e-01, -2.3199e-01,  8.8206e-01,  2.6604e-01, -8.0095e-01,\n",
       "         -1.3355e-01,  2.3650e-01, -9.0282e-01, -7.3664e-01, -4.6503e-01,\n",
       "         -4.6129e-01,  7.0448e-01,  6.4684e-01,  7.2586e-01,  7.1911e-01,\n",
       "         -7.5786e-01,  2.2211e-02, -5.4806e-01, -4.3014e-01, -2.6077e-01,\n",
       "         -7.7279e-01, -4.6252e-01,  2.8167e-01,  7.2826e-01,  8.0485e-01,\n",
       "          8.6818e-01,  8.0037e-01,  2.3917e-02,  8.4762e-01,  2.6322e-01,\n",
       "         -3.8312e-01,  2.6779e-01,  2.7457e-01, -3.9080e-01,  6.5700e-01,\n",
       "          5.1854e-01,  4.1975e-01, -7.6554e-01, -7.5955e-01,  1.5819e-01,\n",
       "          7.4251e-01,  2.4341e-01,  2.8724e-01,  5.4345e-01,  8.2266e-01,\n",
       "         -2.0837e-01, -2.3573e-01,  1.6640e-01,  9.1155e-01,  2.0538e-01,\n",
       "          4.6584e-02, -5.4318e-01,  6.5159e-01, -4.4423e-01, -9.3825e-01,\n",
       "         -7.3861e-01,  2.0642e-01,  8.8241e-01,  8.5494e-01, -7.7170e-01,\n",
       "         -3.1426e-01, -9.4032e-01,  6.9622e-01, -9.9020e-02,  7.0305e-01,\n",
       "         -3.0909e-01,  4.2899e-01, -1.7392e-01, -4.0277e-01, -3.4227e-01,\n",
       "         -1.5637e-01, -4.5876e-01, -8.6723e-01, -4.4867e-01,  8.8071e-02,\n",
       "          1.6605e-01,  8.9950e-01,  1.7277e-01, -7.1548e-01, -9.7539e-02,\n",
       "         -1.3491e-01, -8.1651e-01,  6.7140e-01,  7.9758e-03,  2.6559e-01,\n",
       "         -6.4143e-01, -7.9564e-01, -2.2990e-01,  5.4632e-01,  9.1918e-01,\n",
       "         -9.4052e-01, -9.4658e-02,  3.1082e-01,  5.9198e-01, -5.8959e-01,\n",
       "         -7.5396e-01,  8.3938e-01, -8.8946e-01, -7.6854e-01, -7.9186e-01,\n",
       "          1.1314e-03, -6.3325e-01, -5.2427e-02, -8.1466e-01,  8.5430e-01,\n",
       "          3.9427e-01,  6.7478e-01,  2.3743e-01,  1.3130e-01, -5.7686e-01,\n",
       "          3.1649e-01,  5.8030e-01,  8.2057e-01, -9.1157e-01,  4.6872e-01,\n",
       "         -7.6012e-01, -8.4340e-01,  7.5792e-01,  8.4570e-01, -7.5303e-01,\n",
       "         -1.3999e-01,  7.7277e-01, -8.7166e-02,  7.0124e-01,  6.2984e-01,\n",
       "         -6.1046e-01, -3.6200e-01,  5.2416e-01, -8.9426e-01,  6.2043e-01,\n",
       "          2.7637e-02,  5.7253e-02, -4.5128e-01, -1.3188e-01, -4.3407e-01,\n",
       "          8.5860e-01, -2.6904e-01, -3.6082e-01, -3.6363e-01, -7.2381e-01,\n",
       "          6.9098e-01,  9.6876e-01,  8.5293e-01,  8.2201e-01,  5.7408e-01,\n",
       "         -8.9780e-01, -5.0414e-01,  6.2350e-01,  9.3174e-01, -3.5183e-01,\n",
       "          2.0676e-01, -3.8118e-01,  6.4834e-01,  8.4267e-01,  6.7675e-01,\n",
       "         -7.6749e-01,  2.2539e-01, -1.5995e-01, -6.2669e-01, -4.9293e-01,\n",
       "         -4.5727e-01, -7.3388e-01, -9.4609e-01, -1.0049e-01, -8.1275e-01,\n",
       "         -2.5594e-02,  3.4680e-01,  5.9887e-01,  6.5187e-01, -5.2278e-01,\n",
       "          7.7710e-01,  5.1189e-01, -7.0711e-01,  6.2841e-01, -7.2155e-01,\n",
       "         -2.7197e-02, -1.4755e-01,  3.3333e-01,  8.3686e-01,  8.0758e-03,\n",
       "          6.7653e-01, -6.6353e-01,  4.9868e-01, -1.2802e-01,  8.7592e-01,\n",
       "         -8.8727e-01, -7.8112e-01, -3.6341e-01, -2.6201e-02,  2.0956e-01,\n",
       "         -5.3734e-01, -8.5271e-01, -6.2272e-04,  5.1855e-01,  8.3033e-01,\n",
       "         -7.3489e-02,  8.0470e-01,  2.9269e-01,  7.9522e-01, -3.5807e-01,\n",
       "          7.2736e-02,  5.4007e-01,  4.0153e-01,  4.0626e-01,  3.2091e-01,\n",
       "          2.3945e-01, -1.4316e-01,  1.9871e-01,  7.1775e-01,  3.5864e-01,\n",
       "          5.8229e-01,  1.7104e-01, -3.6728e-01,  5.3679e-01,  3.1920e-03,\n",
       "         -7.0399e-01,  2.6032e-01, -9.0367e-01,  5.5331e-01,  1.8254e-01,\n",
       "         -6.8203e-01, -1.0755e-01, -5.1410e-01,  5.9838e-01,  7.7786e-01,\n",
       "         -8.8186e-01,  2.0714e-01, -9.0683e-01, -3.9055e-02, -6.0657e-01,\n",
       "         -5.6444e-01,  5.5286e-01,  7.5931e-01,  8.0558e-02,  7.3440e-01,\n",
       "         -4.5892e-01, -1.7047e-01, -1.9265e-01,  7.8241e-01,  8.2253e-01,\n",
       "          3.9744e-01, -6.8564e-01,  1.2127e-01,  9.2830e-01, -4.6815e-02,\n",
       "         -7.8807e-01,  8.8890e-01, -1.8047e-01, -8.0649e-01, -5.2637e-01,\n",
       "         -1.1280e-01, -1.4870e-01, -1.1930e-01,  8.3277e-01, -1.9009e-01,\n",
       "         -4.0286e-01,  5.0935e-01, -7.0209e-01, -6.7545e-01,  7.9817e-02,\n",
       "         -4.5328e-01, -7.6676e-01,  8.6277e-01,  4.0053e-01,  5.6281e-01,\n",
       "         -1.8276e-01,  3.9914e-01, -1.3258e-01, -8.1331e-01,  2.4526e-01,\n",
       "         -2.5562e-01,  4.7813e-01,  6.7300e-01,  1.3557e-01,  4.7740e-01,\n",
       "          5.1496e-01, -2.2047e-01,  1.7860e-01, -2.2343e-01, -5.2841e-01,\n",
       "          5.6990e-01,  3.8978e-01,  7.9770e-01, -6.7654e-01, -4.1109e-01,\n",
       "          2.7147e-01,  7.2863e-01,  7.0913e-01,  2.2197e-01,  5.1826e-01,\n",
       "          1.8768e-01,  5.1330e-01, -3.1289e-01,  5.4118e-01, -7.8997e-01,\n",
       "         -3.9946e-01, -8.6512e-01,  7.2357e-02, -2.4427e-01, -5.6578e-02,\n",
       "         -1.9551e-01, -3.5268e-01,  7.7386e-01, -7.8452e-01, -5.0103e-01,\n",
       "          6.0461e-01, -4.8676e-01, -1.9048e-01,  4.6340e-01, -1.6974e-01,\n",
       "          7.6498e-01, -6.7232e-01,  6.8587e-01, -8.7978e-01,  3.1598e-01,\n",
       "          7.2324e-02,  8.5847e-01, -6.3676e-01, -8.1595e-01,  6.8995e-01,\n",
       "          6.2565e-02,  6.2503e-01, -3.0401e-01,  3.8160e-01, -7.8338e-01,\n",
       "          7.1922e-01, -1.6708e-01,  6.6168e-01, -7.1425e-01, -9.2502e-01,\n",
       "         -2.6198e-02,  8.3896e-01,  7.5586e-01, -7.1259e-01, -7.5276e-01,\n",
       "          1.7419e-01, -5.0424e-01, -5.7191e-01,  1.1109e-01, -7.5829e-01,\n",
       "         -2.3279e-02, -6.0213e-02,  5.2972e-01, -7.0459e-01,  6.5937e-01,\n",
       "          7.7165e-01, -7.9421e-01,  2.6666e-01,  6.1308e-01,  1.1468e-01,\n",
       "         -8.0884e-01,  8.0407e-01,  5.4657e-01, -4.4781e-01, -2.0665e-01,\n",
       "          9.2080e-02,  4.6106e-01, -3.6852e-01,  3.2393e-01, -4.3468e-01,\n",
       "          5.7383e-01, -3.5863e-01,  3.5774e-01,  6.4757e-01,  8.4722e-01,\n",
       "         -3.2973e-01,  2.3245e-01, -3.8674e-01, -8.4149e-01, -3.1728e-01,\n",
       "         -3.9402e-02, -8.8654e-01,  1.5996e-02, -1.2009e-01,  8.9415e-01,\n",
       "          4.2419e-01,  5.7183e-01,  4.0045e-01, -6.6391e-01, -8.8426e-01,\n",
       "         -8.4343e-01, -3.7317e-01,  4.4247e-01,  8.5271e-01,  1.8046e-01,\n",
       "          5.7091e-01,  1.6058e-01,  4.8580e-01,  6.8642e-01,  6.7851e-01,\n",
       "         -6.9921e-01, -1.8731e-01,  1.2670e-01, -5.8069e-01,  2.3768e-01,\n",
       "          7.8594e-01,  3.9692e-01, -8.2854e-01,  6.5875e-01, -6.8777e-01,\n",
       "         -7.9663e-01,  4.3537e-01, -1.4040e-01, -6.6973e-02,  6.5267e-01,\n",
       "         -4.7372e-01,  4.3913e-01, -9.2917e-01,  6.2594e-01,  5.6787e-01,\n",
       "         -3.7278e-01, -5.6726e-02,  5.3190e-01, -5.7507e-01, -5.6386e-01,\n",
       "         -7.6401e-01,  6.5321e-01,  3.2644e-01,  6.9360e-01, -9.3016e-01,\n",
       "         -6.0963e-01, -2.1018e-01,  6.4928e-02,  2.9490e-02,  8.0170e-01,\n",
       "         -1.9368e-01,  7.1989e-01, -4.0945e-01, -6.9319e-01,  3.6349e-01,\n",
       "         -6.1711e-01, -4.0219e-01,  3.7298e-01,  8.5711e-01,  3.5791e-01,\n",
       "          6.1758e-01,  8.8118e-01,  6.9896e-01, -6.8463e-01, -8.2357e-01,\n",
       "          3.5237e-01,  8.2533e-01,  1.4300e-01,  5.3443e-01,  9.7982e-01,\n",
       "         -3.7924e-01, -8.0272e-01,  2.3019e-01, -9.5634e-01, -8.2990e-01,\n",
       "          1.2114e-01,  3.0614e-01, -1.4537e-01,  2.0661e-03,  7.4615e-01,\n",
       "          5.4242e-01,  1.2082e-02, -7.6953e-01,  2.2758e-01, -3.6681e-01,\n",
       "         -7.9441e-01,  4.6509e-01,  6.8412e-01,  4.9506e-01,  3.0209e-02,\n",
       "          4.9102e-01, -5.1945e-01,  6.4441e-01, -3.9129e-01,  1.3802e-01,\n",
       "         -7.4199e-01, -6.5160e-01,  9.0517e-01, -9.4869e-02,  4.7882e-01,\n",
       "          8.2833e-01, -3.1057e-01,  4.1580e-01, -6.5806e-01,  1.0839e-01,\n",
       "         -1.8233e-01,  8.5714e-01,  2.2412e-01, -7.9914e-01, -9.0287e-01,\n",
       "          3.9833e-01,  3.5188e-01,  3.8416e-01,  4.0814e-01,  6.5777e-01,\n",
       "          6.9596e-01, -5.0950e-01,  6.9615e-01,  7.2930e-01, -6.2079e-02,\n",
       "          2.7933e-01, -1.9087e-01,  1.5604e-01, -1.3225e-01, -6.8051e-01,\n",
       "          8.1466e-01, -6.5116e-01,  6.2242e-01, -8.8151e-01,  9.3323e-01,\n",
       "         -4.0729e-01,  5.4545e-01,  2.6862e-01, -8.8152e-01,  2.4044e-01,\n",
       "         -7.3386e-01, -1.2100e-01,  6.2302e-01, -5.7593e-01,  3.3305e-01,\n",
       "          1.0188e-01, -3.9346e-01, -9.6263e-01,  6.6759e-02, -4.1548e-02,\n",
       "         -8.3101e-01, -8.3877e-01, -1.7018e-01, -7.3835e-03,  1.0559e-01,\n",
       "          9.0343e-01, -8.4546e-01, -1.4125e-01, -8.0406e-01, -7.2022e-02,\n",
       "          9.0003e-01, -9.0830e-01, -5.5746e-01,  2.0790e-01, -8.6113e-01,\n",
       "         -5.9245e-01, -6.4533e-01,  6.4104e-01, -8.0210e-01,  2.9760e-01,\n",
       "          9.5748e-01,  6.6036e-01,  9.5483e-01,  8.0541e-01, -8.6956e-01,\n",
       "          6.1659e-02,  7.2008e-01, -8.0043e-01, -2.3715e-01,  3.2704e-01,\n",
       "          8.5116e-01,  8.1305e-01, -3.8354e-01,  5.8711e-01, -4.0044e-01,\n",
       "         -6.1141e-01,  8.5653e-01, -1.1388e-01, -4.2611e-01, -8.2079e-01,\n",
       "          7.8589e-01, -1.3588e-01,  7.7631e-01, -8.3279e-01, -7.1647e-01,\n",
       "          6.1920e-01, -8.5016e-01,  5.3284e-01,  3.7885e-01,  2.0164e-01,\n",
       "          5.8651e-01,  6.5473e-02, -4.3460e-01,  1.2571e-02, -6.6851e-01,\n",
       "         -1.1913e-01,  4.7744e-01,  2.6077e-01,  4.7925e-01,  7.2491e-01,\n",
       "          6.6953e-01, -5.8609e-01, -3.1541e-01,  1.4357e-01, -7.3044e-01,\n",
       "          5.0364e-01, -3.7064e-01, -8.2445e-01, -1.5979e-01,  1.4650e-01,\n",
       "          7.3500e-01, -5.0992e-01,  9.7544e-02,  7.7241e-01,  6.7351e-01,\n",
       "          2.4681e-01, -3.6575e-01, -2.5452e-02], grad_fn=<ToCopyBackward0>)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "veri_embs[batch_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1072582/2035222989.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n"
     ]
    }
   ],
   "source": [
    "if 1 in target_col_mask:\n",
    "    col_idx_set = target_col_mask.unique().tolist()\n",
    "    assert -1 not in col_idx_set\n",
    "    for r in range(len(init_permutation_i), max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "        for x in itertools.combinations(init_permutation_i, r):\n",
    "            if 0 not in x:\n",
    "                continue\n",
    "\n",
    "            num_permutations[batch_idx] += 1\n",
    "            new_batch_data = []\n",
    "            for col_i in x:\n",
    "                if col_i == 0:\n",
    "                    if len(new_batch_data) == 0:\n",
    "                        cls_indexes_value = 0\n",
    "                    else:\n",
    "                        cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "            new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "            cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "            logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "            logits_temp = logits_temp.detach().cpu()\n",
    "            ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n",
    "            score_permutation[batch_idx].append(ood_score_temp)\n",
    "            predict_temp = logits_temp.argmax().item()\n",
    "            permutation_correctness[batch_idx].append(predict_temp == label_i)\n",
    "            \n",
    "            # veri_data[batch_idx].append(new_batch_data.cpu())\n",
    "            # veri_label[batch_idx].append(torch.tensor(predict_temp == label_i).long())\n",
    "            # veri_cls_indexes[batch_idx].append(cls_indexes_value)\n",
    "            # veri_embs[batch_idx].append(embs_temp.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Threshold: 1.5****************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4044608/3578846304.py:54: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
      "/tmp/ipykernel_4044608/3578846304.py:109: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n"
     ]
    }
   ],
   "source": [
    "# brute force perumate in validation TODO: restrict mamimus length of permutation\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "import torch.nn.functional as F\n",
    "train_data = defaultdict(list)\n",
    "train_logits = defaultdict(list)\n",
    "train_cls_indexes = defaultdict(list)\n",
    "train_target_col_mask = defaultdict(list)\n",
    "train_embs = defaultdict(list)\n",
    "train_col_num = defaultdict(list)\n",
    "train_label = defaultdict(list)\n",
    "train_class = defaultdict(list)\n",
    "train_target_embs = defaultdict(list)\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "for threshold in [1.5]:\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    log = defaultdict(list)\n",
    "    num_cols = []\n",
    "    corrected = 0\n",
    "    total_mistakes = 0\n",
    "    num_permutations = {}\n",
    "    init_permutation = {}\n",
    "    init_correctness = {}\n",
    "    score_init = {}\n",
    "    score_permutation = defaultdict(list)\n",
    "    permutation_correctness = defaultdict(list)\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(train_dataloader_iter):\n",
    "            cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "            target_col_mask = batch[\"target_col_mask\"].T\n",
    "            logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "            score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
    "            label_i = batch[\"label\"].item()\n",
    "            predict_init = logits.argmax().item()\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            init_permutation[batch_idx] = init_permutation_i\n",
    "            if predict_init == label_i:\n",
    "                init_correctness[batch_idx] = True\n",
    "            else:\n",
    "                init_correctness[batch_idx] = False\n",
    "            num_permutations[batch_idx] = 0\n",
    "\n",
    "            train_data[batch_idx].append(batch[\"data\"].T.cpu())\n",
    "            train_logits[batch_idx].append(logits.detach().cpu())\n",
    "            train_cls_indexes[batch_idx].append(batch[\"cls_indexes\"].cpu().item())\n",
    "            train_embs[batch_idx].append(embs.cpu())\n",
    "            train_col_num[batch_idx].append(len(init_permutation_i))\n",
    "            train_label[batch_idx].append(torch.tensor(predict_init == label_i).long()) # indicate whether the permutation is correct or not\n",
    "            train_class[batch_idx].append(label_i)\n",
    "\n",
    "\n",
    "            x = [0]\n",
    "            new_batch_data = []\n",
    "            for col_i in x:\n",
    "                if col_i == 0:\n",
    "                    if len(new_batch_data) == 0:\n",
    "                        cls_indexes_value = 0\n",
    "                    else:\n",
    "                        cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "            new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "            cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "            logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "            train_target_embs[batch_idx].append(embs_temp.cpu())\n",
    "\n",
    "            num_cols.append(len(init_permutation_i))\n",
    "            labels_test.append(batch[\"label\"].cpu().item())\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            assert -1 not in col_idx_set\n",
    "            for r in range(len(init_permutation_i)-1, 0, -1): # not \n",
    "                for x in itertools.combinations(init_permutation_i, r):\n",
    "                    if 0 not in x:\n",
    "                        continue\n",
    "\n",
    "                    num_permutations[batch_idx] += 1\n",
    "                    new_batch_data = []\n",
    "                    for col_i in x:\n",
    "                        if col_i == 0:\n",
    "                            if len(new_batch_data) == 0:\n",
    "                                cls_indexes_value = 0\n",
    "                            else:\n",
    "                                cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                        new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                    new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                    cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                    logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                    ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n",
    "                    score_permutation[batch_idx].append(ood_score_temp)\n",
    "                    predict_temp = logits_temp.argmax().item()\n",
    "                    permutation_correctness[batch_idx].append(predict_temp == label_i)\n",
    "                    if predict_temp == label_i:\n",
    "                        continue\n",
    "                    \n",
    "                    \n",
    "                    train_data[batch_idx].append(new_batch_data.cpu())\n",
    "                    train_logits[batch_idx].append(logits_temp.detach().cpu())\n",
    "                    train_cls_indexes[batch_idx].append(cls_indexes_value)\n",
    "                    train_embs[batch_idx].append(embs_temp.cpu())\n",
    "                    train_col_num[batch_idx].append(len(x))\n",
    "                    train_label[batch_idx].append(torch.tensor(predict_temp == label_i).long()) # indicate whether the permutation is correct or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Threshold: 1.5****************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4044608/1394525027.py:55: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
      "/tmp/ipykernel_4044608/1394525027.py:110: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n"
     ]
    }
   ],
   "source": [
    "# brute force perumate in validation TODO: restrict mamimus length of permutation\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "import torch.nn.functional as F\n",
    "train_data = defaultdict(list)\n",
    "train_logits = defaultdict(list)\n",
    "train_cls_indexes = defaultdict(list)\n",
    "train_target_col_mask = defaultdict(list)\n",
    "train_embs = defaultdict(list)\n",
    "train_col_num = defaultdict(list)\n",
    "train_label = defaultdict(list)\n",
    "train_class = defaultdict(list)\n",
    "train_target_embs = defaultdict(list)\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "max_col_length = 3\n",
    "for threshold in [1.5]:\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    log = defaultdict(list)\n",
    "    num_cols = []\n",
    "    corrected = 0\n",
    "    total_mistakes = 0\n",
    "    num_permutations = {}\n",
    "    init_permutation = {}\n",
    "    init_correctness = {}\n",
    "    score_init = {}\n",
    "    score_permutation = defaultdict(list)\n",
    "    permutation_correctness = defaultdict(list)\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(train_dataloader_iter):\n",
    "            cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "            target_col_mask = batch[\"target_col_mask\"].T\n",
    "            logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "            score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
    "            label_i = batch[\"label\"].item()\n",
    "            predict_init = logits.argmax().item()\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            init_permutation[batch_idx] = init_permutation_i\n",
    "            if predict_init == label_i:\n",
    "                init_correctness[batch_idx] = True\n",
    "            else:\n",
    "                init_correctness[batch_idx] = False\n",
    "            num_permutations[batch_idx] = 0\n",
    "\n",
    "            train_data[batch_idx].append(batch[\"data\"].T.cpu())\n",
    "            train_logits[batch_idx].append(logits.detach().cpu())\n",
    "            train_cls_indexes[batch_idx].append(batch[\"cls_indexes\"].cpu().item())\n",
    "            train_embs[batch_idx].append(embs.cpu())\n",
    "            train_col_num[batch_idx].append(len(init_permutation_i))\n",
    "            train_label[batch_idx].append(torch.tensor(predict_init == label_i).long()) # indicate whether the permutation is correct or not\n",
    "            train_class[batch_idx].append(label_i)\n",
    "\n",
    "\n",
    "            x = [0]\n",
    "            new_batch_data = []\n",
    "            for col_i in x:\n",
    "                if col_i == 0:\n",
    "                    if len(new_batch_data) == 0:\n",
    "                        cls_indexes_value = 0\n",
    "                    else:\n",
    "                        cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "            new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "            cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "            logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "            train_target_embs[batch_idx].append(embs_temp.cpu())\n",
    "\n",
    "            num_cols.append(len(init_permutation_i))\n",
    "            labels_test.append(batch[\"label\"].cpu().item())\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            assert -1 not in col_idx_set\n",
    "            for r in range(1, min(len(col_idx_set), max_col_length) + 1):\n",
    "                for subset in itertools.combinations(col_idx_set, r):\n",
    "                    if 0 not in subset:\n",
    "                        continue\n",
    "                    for x in itertools.permutations(subset):\n",
    "                        num_permutations[batch_idx] += 1\n",
    "                        new_batch_data = []\n",
    "                        for col_i in x:\n",
    "                            if col_i == 0:\n",
    "                                if len(new_batch_data) == 0:\n",
    "                                    cls_indexes_value = 0\n",
    "                                else:\n",
    "                                    cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                            new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                        new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                        cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                        logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                        ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n",
    "                        score_permutation[batch_idx].append(ood_score_temp)\n",
    "                        predict_temp = logits_temp.argmax().item()\n",
    "                        permutation_correctness[batch_idx].append(predict_temp == label_i)\n",
    "                        if predict_temp == label_i:\n",
    "                            continue\n",
    "                        \n",
    "                        \n",
    "                        train_data[batch_idx].append(new_batch_data.cpu())\n",
    "                        train_logits[batch_idx].append(logits_temp.detach().cpu())\n",
    "                        train_cls_indexes[batch_idx].append(cls_indexes_value)\n",
    "                        train_embs[batch_idx].append(embs_temp.cpu())\n",
    "                        train_col_num[batch_idx].append(len(x))\n",
    "                        train_label[batch_idx].append(torch.tensor(predict_temp == label_i).long()) # indicate whether the permutation is correct or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"/data/zhihao/TU/Watchog/trainfication\", exist_ok=True)\n",
    "torch.save({\"data\": train_data, \"label\": train_label, \"logits\": train_logits, \"cls_indexes\": train_cls_indexes, \"embs\": train_embs, \"target_embs\":train_target_embs , \"col_num\": train_col_num}, f\"/data/zhihao/TU/Watchog/trainfication/{args.task}_train_data_7.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Threshold: 1.5****************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4044608/759810728.py:55: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
      "/tmp/ipykernel_4044608/759810728.py:110: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n"
     ]
    }
   ],
   "source": [
    "# brute force perumate in validation TODO: restrict mamimus length of permutation\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "import torch.nn.functional as F\n",
    "train_data = defaultdict(list)\n",
    "train_logits = defaultdict(list)\n",
    "train_cls_indexes = defaultdict(list)\n",
    "train_target_col_mask = defaultdict(list)\n",
    "train_embs = defaultdict(list)\n",
    "train_col_num = defaultdict(list)\n",
    "train_label = defaultdict(list)\n",
    "train_class = defaultdict(list)\n",
    "train_target_embs = defaultdict(list)\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "max_col_length = 3\n",
    "for threshold in [1.5]:\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    log = defaultdict(list)\n",
    "    num_cols = []\n",
    "    corrected = 0\n",
    "    total_mistakes = 0\n",
    "    num_permutations = {}\n",
    "    init_permutation = {}\n",
    "    init_correctness = {}\n",
    "    score_init = {}\n",
    "    score_permutation = defaultdict(list)\n",
    "    permutation_correctness = defaultdict(list)\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(train_dataloader_iter):\n",
    "            cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "            target_col_mask = batch[\"target_col_mask\"].T\n",
    "            logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "            score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
    "            label_i = batch[\"label\"].item()\n",
    "            predict_init = logits.argmax().item()\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            init_permutation[batch_idx] = init_permutation_i\n",
    "            if predict_init == label_i:\n",
    "                init_correctness[batch_idx] = True\n",
    "            else:\n",
    "                init_correctness[batch_idx] = False\n",
    "            num_permutations[batch_idx] = 0\n",
    "\n",
    "            train_data[batch_idx].append(batch[\"data\"].T.cpu())\n",
    "            train_logits[batch_idx].append(logits.detach().cpu())\n",
    "            train_cls_indexes[batch_idx].append(batch[\"cls_indexes\"].cpu().item())\n",
    "            train_embs[batch_idx].append(embs.cpu())\n",
    "            train_col_num[batch_idx].append(len(init_permutation_i))\n",
    "            train_label[batch_idx].append(torch.tensor(predict_init == label_i).long()) # indicate whether the permutation is correct or not\n",
    "            train_class[batch_idx].append(label_i)\n",
    "\n",
    "\n",
    "            x = [0]\n",
    "            new_batch_data = []\n",
    "            for col_i in x:\n",
    "                if col_i == 0:\n",
    "                    if len(new_batch_data) == 0:\n",
    "                        cls_indexes_value = 0\n",
    "                    else:\n",
    "                        cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "            new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "            cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "            logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "            train_target_embs[batch_idx].append(embs_temp.cpu())\n",
    "\n",
    "            num_cols.append(len(init_permutation_i))\n",
    "            labels_test.append(batch[\"label\"].cpu().item())\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            assert -1 not in col_idx_set\n",
    "            for r in range(1, min(len(col_idx_set), max_col_length) + 1):\n",
    "                for subset in itertools.combinations(col_idx_set, r):\n",
    "                    if 0 not in subset:\n",
    "                        continue\n",
    "                    for x in itertools.permutations(subset):\n",
    "                        num_permutations[batch_idx] += 1\n",
    "                        new_batch_data = []\n",
    "                        for col_i in x:\n",
    "                            if col_i == 0:\n",
    "                                if len(new_batch_data) == 0:\n",
    "                                    cls_indexes_value = 0\n",
    "                                else:\n",
    "                                    cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                            new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                        new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                        cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                        logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                        ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n",
    "                        score_permutation[batch_idx].append(ood_score_temp)\n",
    "                        predict_temp = logits_temp.argmax().item()\n",
    "                        permutation_correctness[batch_idx].append(predict_temp == label_i)\n",
    "\n",
    "                        \n",
    "                        \n",
    "                        train_data[batch_idx].append(new_batch_data.cpu())\n",
    "                        train_logits[batch_idx].append(logits_temp.detach().cpu())\n",
    "                        train_cls_indexes[batch_idx].append(cls_indexes_value)\n",
    "                        train_embs[batch_idx].append(embs_temp.cpu())\n",
    "                        train_col_num[batch_idx].append(len(x))\n",
    "                        train_label[batch_idx].append(torch.tensor(predict_temp == label_i).long()) # indicate whether the permutation is correct or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"/data/zhihao/TU/Watchog/trainfication\", exist_ok=True)\n",
    "torch.save({\"data\": train_data, \"label\": train_label, \"logits\": train_logits, \"cls_indexes\": train_cls_indexes, \"embs\": train_embs, \"target_embs\":train_target_embs , \"col_num\": train_col_num}, f\"/data/zhihao/TU/Watchog/trainfication/{args.task}_train_data_8.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54164\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.0629)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_all = torch.cat([torch.tensor(train_label[i]) for i in train_label], dim=0)\n",
    "print(len(train_labels_all))\n",
    "train_labels_all.sum()/len(train_labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103517\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.1367)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# V6\n",
    "train_labels_all = torch.cat([torch.tensor(train_label[i]) for i in train_label], dim=0)\n",
    "print(len(train_labels_all))\n",
    "train_labels_all.sum()/len(train_labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "383924\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.6839)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# V8\n",
    "train_labels_all = torch.cat([torch.tensor(train_label[i]) for i in train_label], dim=0)\n",
    "print(len(train_labels_all))\n",
    "train_labels_all.sum()/len(train_labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122702\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.5972)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# V4\n",
    "train_labels_all = torch.cat([torch.tensor(train_label[i]) for i in train_label], dim=0)\n",
    "print(len(train_labels_all))\n",
    "train_labels_all.sum()/len(train_labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4044608/102346206.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  veri_results = torch.load( f\"/data/zhihao/TU/Watchog/verification/{args.task}_veri_data_3.pth\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.makedirs(\"/data/zhihao/TU/Watchog/verification\", exist_ok=True)\n",
    "# {args.task}_veri_data: min length: max(len(init_permutation_i)//2, len(init_permutation_i)-3)\n",
    "# {args.task}_veri_data_1: min length: for those without correct permutation, \n",
    "veri_results = torch.load( f\"/data/zhihao/TU/Watchog/verification/{args.task}_veri_data_3.pth\")\n",
    "veri_data = veri_results[\"data\"]\n",
    "veri_label = veri_results[\"label\"]\n",
    "veri_logits = veri_results[\"logits\"]\n",
    "veri_cls_indexes = veri_results[\"cls_indexes\"]\n",
    "veri_embs = veri_results[\"embs\"]\n",
    "veri_target_embs = veri_results[\"target_embs\"]\n",
    "veri_col_num = veri_results[\"col_num\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = len(train_data)\n",
    "for i in veri_data:\n",
    "    train_data[num_train+i] = veri_data[i]\n",
    "    train_label[num_train+i] = veri_label[i]\n",
    "    train_logits[num_train+i] = veri_logits[i]\n",
    "    train_cls_indexes[num_train+i] = veri_cls_indexes[i]\n",
    "    train_embs[num_train+i] = veri_embs[i]\n",
    "    train_target_embs[num_train+i] = veri_target_embs[i]\n",
    "    train_col_num[num_train+i] = veri_col_num[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172055\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.4884)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# veri V5\n",
    "train_labels_all = torch.cat([torch.tensor(train_label[i]) for i in train_label], dim=0)\n",
    "print(len(train_labels_all))\n",
    "train_labels_all.sum()/len(train_labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_init_mask = []\n",
    "for i in train_label:\n",
    "    k = 0\n",
    "    for j in train_label[i]:\n",
    "        if k == 0:\n",
    "            train_init_mask.append(True)\n",
    "        else:\n",
    "            train_init_mask.append(False)\n",
    "        k += 1\n",
    "train_init_mask = torch.tensor(train_init_mask)\n",
    "train_labels_all[train_init_mask] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_init_idx = train_init_mask.nonzero().reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4346) tensor(0.0253)\n",
      "tensor(80141) tensor(0.4658)\n",
      "tensor(87568) tensor(0.5090)\n"
     ]
    }
   ],
   "source": [
    "print((train_labels_all==2).sum(), (train_labels_all==2).sum()/len(train_labels_all))\n",
    "print((train_labels_all==1).sum(), (train_labels_all==1).sum()/len(train_labels_all))\n",
    "print((train_labels_all==0).sum(), (train_labels_all==0).sum()/len(train_labels_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([172055, 768])\n"
     ]
    }
   ],
   "source": [
    "# veri V5\n",
    "train_embs_all = torch.cat([torch.stack(train_embs[i], dim=0) for i in train_embs], dim=0)\n",
    "print(train_embs_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4346, 768])\n"
     ]
    }
   ],
   "source": [
    "# veri V5 init\n",
    "\n",
    "train_embs_all_init = torch.stack([train_embs[i][0] for i in train_embs], dim=0)\n",
    "print(train_embs_all_init.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f55f775b8b0>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAABDQklEQVR4nO3dd3iT5frA8e+T0TZt2XtvEURFhoODR1BRQFFQ3BNUVFy4xYWKP4/oUdwiAm7xKAqiKFOUIShT9t67rO42TXL//nhCB7R0Nx3357pyNXnnnRCeO++zXiMiKKWUqngcoQ5AKaVUaGgCUEqpCkoTgFJKVVCaAJRSqoLSBKCUUhWUK9QBZKdmzZrStGnTUIehlFJlxpIlSw6KSK387FMqE0DTpk1ZvHhxqMNQSqkywxizPb/7aBWQUkpVUJoAlFKqgtIEoJRSFZQmAKWUqqA0ASilVAWlCUAppSooTQBKqQJJTIRvv4U1ayAmBnRi4bKnVI4DUEqVbiLQrJkt+EEwBpo2NcyZAw0bhjo6lVd6BaCUyrONG+HOVn+w3n0a/425GfACIGLYus1P5wt3hTZAlS+aAJQqYZs2wYsvQs+eUKWKfV5WDB0KQzcN5FT/GpqzBXADBhAQYV/fM0lOSw5xlCqvNAEoVUJ27IC5c6FLF3jhBZg2DeLi7PPwcBgyxFat7NgBXi+kpkJSUoiDBti3j8Cv05g/aiVvzm5PU7bhw0EEmQt6Azghvh4bdsSGKlKVT9oGoFQRiouDL76A9u3hX10Ejh6FqlVZt97QqZPdJjmbH8heL7zzDqxfD7NmQY0a9lh+P/z4I1x6aUm+i0wOH4a2bUlLSOOMNIgmAQP4cLKVJkQ6DpIUqAUIEKD+khvZt6kuZ7YIUbwqX/QKQKkiMHQoOJ22Suf+++GCrj4OtTwHqVWLhU2uo39/CARsz5kqVbI7ggDC1KlCWhrs2+8jKUlITYV+/aBbN3j99RD0tNm6FVJTCU9LIIpEAhgE8ONkKK/jC1TGRRoGoTJxPLgolgs8f5dwkKqgTGm8KXynTp1EZwNVZcW82WkkXng5F/AHw3mWV3iW1qxjheMswgIpCBBOKp7KYQAYA7HH1ZIYAggOIGAXhCXAKT/CqluybHfmGQGW/7gDGjcGRzH/fluyBPr3h9hYfN4Abzgfp1IVQ/zeRJb72nIrX7KMMxnPDaymHYKTcFLY8NQ4Gv9ncPHGpk5gjFkiIp3ytZOIlLpHx44dRamy4puHF0o8USIgKYQJiLhJlaQW7cTnDJMjVJF4ouTKJsvE4RDbWnrc4y4+FAgI1dcJzgQBn1Bj7Qnb3cKnEgCRKlVEEhJsACtXikycKJKamreA4+Nl6aTtcuqpAenWTeTw4Ry2O+OMjBNfdVX64rPOEtlACwmApOKSu3lXqhMj4SRLNPFyZPm2wnycqoCAxZLPslargJQqpG6DTiEZDwlEMY+uAAx/NQzPumU43nuHqLA0oklk+vZTCATgWHVPZpPpAxhIqQbGAY4A7pQGOJ32isES3uVBDNhLiNGjYdkyOPtsuOkm+/eRRyAmhpUr4Ykn4I8/gIMHM1qTDxyAZs14pN9W1q0z/PknfPJJDm/M48l4vmVL+tPfpyTSzLEDA7jxcQPfsJSOvMaTLJxyiKpnNincB6pKTn4zRkk89ApAlTXJuw/JNQ3mi5tUcTpFhg4Nrti8WQLR0fIRd0l1YsRDotQgRlqzIv3HdSQJ8q3jWjlMFbmXd9KXDxwo8scfIpGRIh6PSMOGAfFWqZnxq9zpFOnQwW4AIsaIuFzib9FKqphYgYBEuNNkn6OeiMslgS+/kuvO3y1O0qQtKySKBImMFPn11xze1Lp1IlWrioSHi8yYkbH8ssskAOmP5H/3EJk2TWT37uL+mNVJUIArgJAX9tk9NAGosmjHDpGLLhLp00fk0CG7LPDIo5LkjJSXeFpe5xFZTHs5SmXZQIv0cvwxRog/WJj6MXIJvwoE5Icf7DHWrBH5+muR+HgR8XpFnnsua71Qt24iNWrYgtrplDScEkGSgEiESZYdNBQB2WkaSZjLb3MHafLlReNk/vxc3lQgYB+ZtW6dfu6Ayy0vXrZABgwQSUoq6k9U5YcmAKVKk3XrbH19sGC/mU8lEY+k4ZIXnS9IVJTIzJki90SMS98uALKDBjJ9fEz2x1yzRuTddzMKf5dLZO1aEZ9PZPhwkdtvF6lTR34L7ymXu3+VL7u8l75tKi5pEb1PIomX01gp/oF3inzxhUjduiLXXiuSlpa397Vggcgpp4jUry/vn/qObbvA5iBNAqGjCUCp0mT27CwFexOzXea8s1RkyRLZuFEkJljGr1oZkFldnxNfWIQt0J95Jutxli0TufNOkS+/FImKsvVB9euLXHyxyAcfnHjesWNt9VDNmnbfmjXlYwaKy/ikVd04meHuKcnhVUQmTxapXNkWA1FRIr//nu+32K1b1ouRkSPzfQhVRDQBKFWaeL0SaN1aAiD7I5vI9n9y6m6TjW3bbKF/8822bv9YnX9EhH0eFnZi1cwxHTtmbDNypEggII0bBdLL+a/fPmCPLyJy/vl2YXS0yM6dJxzq8NyV8vhNu+SNNwLi8514ql27bD46drrPP8/7W1RFqyAJQEcCK1Vc3G7M/v0A1DYHYf9ioEfu+x06BM2bE+wylMHvh4EDYc4cGDYsc/egrG64AVavtuMEuncHY7jiShg71i46t08tONZRZ+pUmD4dzjjjhGk8d559FfUX/Ug3LuHa/02iWrVwBgzIeqoGDWy4H31kRy/ffHPub0+VHjoQTKni1Lu3LbCdTlso52Wu5Fmz4OKLsz/WlCl5O++WLVC5MtSsCdgKmlWroF699EUnNXt6Gt0uDcMASXj4l/mTe0e1Z9CgvJ1elbyCDATLdRyAMWacMeaAMWZVpmUvGGN2G2OWBx+9c9i3pzFmvTFmkzHmqfwEplS5MGmSncxnzZq8T5R/3nlZRvnuozb1ww4yY8hxhf+8eVC7NrRuDbuOm4a5efMsJb0xcPrpeSv8AbbucvM3Z5NIJIepRt+eKSf8+ldlX14Ggn0K9Mxm+UgRaR98/HL8SmOME3gf6AW0BW4wxrQtTLBKlTlhYXDRRbauJK8iI+2UoF26cKh6K25xfcNebw2GDDluu2HD7B1ZtmyBzz8vyqi58UZ4t/Zw7uUDDlGdYZcvxe0u0lOoUiDXBCAic4DDBTj22cAmEdkiIl7gG+DKAhxHqQpl2jSo3KYBzffO5+8vNzDf3Z2oKHthkO6112DpUnC77ePcc4s0hogIeDrmYSbTh04s5quHdYK38qgwU0Hcb4xZEawiqpbN+gbAzkyvdwWXZcsYM8gYs9gYszjG3mdOqYpl2DCoVIkXbtpIfDzs2u5j9eOfsqTzPUyo/yAf3bfCbrdjBzz5pJ1qOi0Nvv8eLrywyMP5PxlKLNXwEc4t3rGkpBT5KVSIFTQBfAi0ANoDe4E3ChuIiIwWkU4i0qlWrVqFPZxSZUtaGgwfDgkJ9Dn6BR6XF1fAy/lrPqLNvI/pufFdnA8EZ9iMiMi6b/36xRJStYs7pj8XHCc0M6iyr0AJQET2i4hfRALAx9jqnuPtBhplet0wuEwpdTyXy7bSRkfzdI2PWHDfV6wLb8857qW2QTgyEk45xW5buzZ8+CG0bAnPPgtnnlksIb09tQ2tGqUAQrfzAzRvXiynUSFUoHEAxph6IrI3+LIfsCqbzRYBrYwxzbAF//XAjQWKUqnyzhhYsMA+2rfnzKpV8bXxs2V9CjXPbUnllANw/fUZ299zj30UI6cTNuw4NiOos1jPpUIj1wRgjBkPdANqGmN2AcOAbsaY9tg5bbcBdwe3rQ+MEZHeIuIzxtwPTMN+e8aJyOrieBNKlQuRkbbHUFDP7+5k4UKI+Bw2bIDqYSGMTZVLOhBMqVIqPNzeKzgqCmbOLPKOPqqcKZaBYEqp0Hj+eZsEunSBjh1z316p/NIEoFQp9cwzkJJip+rRQViqOGgCUKo0CgSIv/kedka34c1/TyIxMdQBqfJIE4BSpdGcObi++ZJGieu4de4djL7gq1BHpMohTQBKlUaNGuEgQArhxFOJekt+tFN6KlWENAEoVRq1aMHB50biIo1G7KAvPyJvvW3vCaBUEdEEoFQptXVHGD6cuBDC8cIjD0O/fqEOS5UjmgCUKqXavXozR6ie/tqAHSl8EiK219CiRcUbmyofNAEoVUpVreUmYtwokrHTMQjYwQEnMWwYXHUVXHBB3m8epiouTQBKlWLVBvTFI0mYw4cxU6fC7befdPu//oLERDuC+NZb7ejhAwdKJlZV9mgCUKq08/ttSX711fbm7V5vjpu++iq0aGGnjzh8GJYsgTFjSjBWVaZoAlCqtIuLY9+mBK5J/IQB24eRsP1QjpuedRZs2gQPPGCTQFhYDrNFP/ssRESw/5w+nNnOzyOPaC/Tikgng1OqDLip5ULGbz4bwdCuyk7+Odw4833jTyBiby1ZrRqcc042K10uCARIw8UrPMXrkS8xY6bJettJVaboZHBKlVPhLRsjGMCwKrYRjzpHcnRnfI7bGwM9e2ZT+AP89hv+eg3w48CFjwF8wqCkN9A7sVY8mgCUyotDh2DkSPjtt5Cc/u03/USQjO0LZNhAK+ZeaHsEzZ8PN9xgbw2cq7VroU8fzJ49+HAQwNCY3bzCs9x95d7cOhmpckYTgFJ5cfnl8NRT9u+yZSV++kpNqjPO3EkYqUSSSFfm4nOE4/fDpZfCN9/AzTeT+317Y2PBGBzix0sEPtyk4cSHi2Q8DB8ekrenQkQTgFK5ESF2xTbwehFjQtKvcuL0KG53fkml8DQeq/UZLU+LpMu0YRhDlraALO0Cv/0GnTrBo49mtPCecw48/TRp53fntqo/8gcX8Cu9OJ85xFIVEDp0CDBjRgm+ORU6IlLqHh07dhSlSouHGn4rB6guSYTLt/QTX7K3xGPo1EkERMLCRN58M+u6JUtE7r1XZOrU4IKnnxapWlXE47E7RUWJzJ5t1y1bJlK5svgiIuWiiHliM4NfIBB8bh8Xnp9Sgu9OFQVgseSzrNUrAKVy8eSuB6nJYSJIpTIJTJuUXOIxXHstRETYzjvdumVd16EDfPCBrQoiPh5GjICjRyE52V4SpKVB3bp24w8+gLg4nClJjDMDcTiE96s8zV2MwrYv2CuF9Zv1BsQVQa43hVeqoousHgGH7fMwUoluUbnEY3j8cejbF6pUgcOHhadePMw1V0bRsX1E1g2joqBJE9i/H0lM5J3AfWzyteaZ+CjqArRsmb5pY+9mfLgwsQEAWrKZp3gVcNKtuympt6ZCKbdLBGAccABYlWnZ68A6YAUwEaiaw77bgJXAcvJxeaJVQKo4BAIiV1zhl+hK8XLBraNl/Mrx4g/47YoffhD56isRn+/EHXfvFu9FPWXVOQPkt5n+kg88k5QUEXdkguBIFRMeLztjjpy40dGjIlOmyISImySSeHGSJheel2jXHTkiUreurUuqVk2y1Pt06SJ//CHy5Zciqakl+a5UUchPGXvskZcE8G+gw3EJ4BLAFXw+AhiRw77bgJr5DUoTgCoO770nwbrugK33vugJufyORyVwy60ikZH28dxzoQ7zpOLiRHCk2jLbmSKTlszLcdtv/2+DRDqTxeHwS7dumVakpIhs3y7Sr19G4R8VZRsTVJlVkASQaxWQiMwxxjQ9btn0TC8XAv3zd92hVMnzeDK/csDKm5jqGMeOWXNpQopdvHlzKELLs0qVoPfjE/jly+bU7zaFHqcPzXHbq59qxVaXnRpi2LBMK8LDoXFj+PjjjG5Do0dD9erZHkeVX3maCiKYAH4WkXbZrPsJ+J+IfJnNuq3AEWzL0kciMvok5xgEDAJo3Lhxx+3bt+f1PSiVJyJwVpt1/LP+FCAA57xNxMr+/JlyFWc1OgRNm8Jnn9k69FIuOS2ZCFcExmhdvbIKMhVEoRqBjTHPAD4gpztWdxWR3caY2sAMY8w6EZmT3YbB5DAa7FxAhYlLqewYA8vXncqypcIbbzhxBwbTz7zFWQ2bw6jpUKNGqEPMM4/bk/tGSuWiwAnAGHM7cDlwkeRwGSEiu4N/DxhjJgJnA9kmAKVKylkdDF9+BeABhsK6dXb464UXctIZ1pQqZwr0bTfG9ASeAK4QkaQctokyxlQ69hzbcLyqoIEqVSwWL7Yd6fv2hcGDQx1NidD7yqtjck0AxpjxwAKgtTFmlzHmDuA9oBK2Wme5MWZUcNv6xphfgrvWAeYZY/4B/gamiMjUYnkXShXU8uX2b2KinVWtHAsEoHdvO5gslxuLqQpC7wegKrbYWOjVC7Zuhc8/hx49Qh1RsdmyBdq2hdRUW9MVGwvR0aGOShWVEm8EVqrMq1IF/vwz1FGUiPXrbcHvctlar6ioUEekQk1bvJSqIK65xk4P5HTa+wRrD1KlCUCpCqJyZVv4OxxQtWqoo1GlgSYApTLbvNnOvPbzzyes+vkn4RIzgw5mKUOGlHxohTVvHrzwAkyfDo0ahToaVRpoI7BSmTVrBtu327mXFy+Gtm1JPRjPdy2fol/sp0SSRAphXMlPTJdLQh2tUun0pvDAxIlw332wYkWoI1FlUnIyiCAYnh9ZjfPOg1UXPcT1saOIJAkDhJPG2a7Sfd/EI8lHmL55OnGpcaEORZVi5aYXUGqKEOGxN8wG+PJLw9Gj2tCl8idpwi9MfXQGrx+4lYVj6gGw2ZXKGcH1AuykEY+uGhCyGHOT6kul3YftiEuNo05UHdbfvx6nwxnqsFQpVG4SQKQngL2gsSV+SkpIw1FlzNixMHIkeL0d2LWrA8mZbvr1VrO3aV3Vw/IVDpZ1vpv/m9qxVHehjEmK4WDSQbx+L8lpySSmJVI5vORvYqNKv3KTAALphb9t0xg92uivf5UnQzvPYMTi7kj6d8h+ccLCoF49+GFOTerWHcOZwG2hDDSPGlRqwID2Axi/ajx3d7xbC3+Vo3LTBvD8EykcK/y7dkritrLwP1WFXGB/DNNWhGFvjeEAfFSvDn362PaktWszbqdb2gXsnR0xxjDq8lHEPhXLaz1eC21QqlQrNwngxREeRAwihrmLSvH1uSpVJCyc81wzwZEKCKbxQmJiYPJkO2+OpwzMuhwIwOWX2xG+d90V6mhUWVJuEoBSBeGsVpn+L/alX+uX6HzbU2xYVq/MzAg9b14Mr53/DcM7T2TGDEHEtmUkZTs/r1InKjdtAEoVVPfHOtK97X749FNYshV6tAx1SLl68d21vPDgqcB1ABgEj8fQrl3ZuGpRpYMOBFPq6FGoWdNOlO92w5EjpX6mtPDwJLxeD8carEEYdt9Bnn6zFmFhoYxMhYoOBFOqINavz7hLSlpamRg8EpDw4DP7A86BnybjRxB27x3g9YYusHwSf4DUWfNg27ZQh1IhaQJQqlYtAg4nAiQZD0mBiFBHlKvhL9mBXTWIoQYxdOMPrjk8Cr75Br77LsTR5c2+vcLnYXfw6cWfs7nZRchKvWFgSdMEoFRsLP6AYACPJGPq14VSWDWa2VNPwaFDhp2JtTj4yKvMiu5LtDPFXsHExIQ6vFwlJ8Mz9T9mQGAs9/AR7VnO8k9K9/Qa5ZEmAKWqV8cRrEoxQER8DPuX7w1tTLn56iuqX3YentdehFGjICHBVmP5/fD007BpU6gjPKn7rjnAt1yHBAfeJRDNgXOvCHVYFY4mAKWaNEH++wbHfvP7cXBph308/4wvpGHlKD4eBg6EhQvhlVfsMo/HTvQfCNg2jNjYjO137rT7lBKBAHw9pTJJRHNs9H69ailcem2VUIdW4eQpARhjxhljDhhjVmVaVt0YM8MYszH4t1oO+94W3GajMUbH56pSyfXIEHZGtiYRD7toxHpa88cr81g9/2ioQztRWJidrtrlgvBw+P13eOcdO3S5WzeSHnueRn074vHA0gsfg+bNoWFDe9/jUuDAHh/n8ieCwUkaVTnC7kPadzUkRCTXB/BvoAOwKtOy14Cngs+fAkZks191YEvwb7Xg82q5na9jx46iVElL2Bcv5zFfIomX8VwrCUTKEWd1kf37Qx3aidauFRkxQmTlyhNWDRwoAgEBkY00F7EtGiLjxoUg0BMFxn8jiSZSXuNhucc1WlJTQx1R+QAsljyU55kfeboCEJE5wOHjFl8JfBZ8/hnQN5tdLwVmiMhhETkCzAB65uWcSpW0qDrRTN19Bhe2O0AvphJFEu6AF/75J9ShnejUU+GJJ6BduxNWnXbasWfCt1wDgB9Y9NNH+Bs1sFcKIWTq1sHjgcfCP+CDiyfquIUQKsxI4DoicqylbB9QJ5ttGgA7M73eFVymVKlUuX40k1dEM+fypzn/l6cxbVrDv/4V6rDy5eGHwfXnXDzff8adjGN3NJw+GLyuv7jUDd8PHgz9+oUuwG7dMN99Bxs3woDSe1+FiqBIpoIQETHGFKrfnDFmEDAIoHHjxkURllIFYgxcMOVJkCeILAODwo5nDDw44d/Q6CbYBf/UhVSnISlM+L0ZEH9WqEO0M+2pkCtML6D9xph6AMG/B7LZZjeQ+fbTDYPLTiAio0Wkk4h0qlWrViHCUqqIlMHCPxCAZ5+FNm1gQrd3CWA4e1sE7GuPSYvgpeaD4IcfQh0mLFsGt91mB66pkCnMFcBk7P0xXg3+/TGbbaYBr2TqIXQJMLQQ51RKncTgwfDRR/Z51XXvIhg8PgcNP/mawzVPZfABMqYPCqUePeDQITtquUMHOOWUUEdUIeW1G+h4YAHQ2hizyxhzB7bg72GM2QhcHHyNMaaTMWYMgIgcBoYDi4KPl4LLlFLFYP58+7c6h+jObJwE8JDEsPpj+fPPUnRRk3nO7VITVMWjs4EqVY7MmAE33gg9+JWIgzv5nYt5hSe5/tBHUL16qMPLsGIFvPsu9OwJV18d6mjKhYLMBqoJQKly6O5H/+aLN9uRTCThjgRS/NElev61MWsZOHkg9aLr8Xm/z4kOK9nzF8j27bB8OfTqRVnsm6rTQSulANi0sj3JeADBXbn4qlh274Y33oBXX7VV+sfc98t9LNy1kF82/sK4ZeNO3HHiRHjuOdizp9hiy5e//4amTaFvXzuQYvp0+OuvUEdV7PSOYEqVQw8MDmPu7/bqfsI3xXNzG6/XjkdLSLCvhw6FzZvtzBMtq7fkr50L8Xt9eMf+A+1T7Uyld99tJ6pbscK+/vVXKA1X+y+/nPF80ya49NJgf9oH4a23QhZWcdMqIKXKqYMH7XRBVasWw8HT0jgaa6hWK+tvyMsvh59+glSfl0b/+pCYw6dgNl3CDwOn0Pe0TXamUq/XNgL7/dCypR0Qlhuvt3irZV55BZ55Jvt1DgdMmBDawXN5oFVASql0NVN2UfXhAfbXbSBQJMdMTYWfr/0cf2Q0VZtWZUjXrD/U7j34EjRvjv/1D4n5+0HY1AvBwZwtDWy1is9nC/IOHaBPH/j++5Oezzf/L76IvoezwlfxbvVhxXe3s/vvz3ldIAD33pvx/OjR4okhFPI7eVBJPHQyOKVyFwjkskG3biIOh0hkpMj48UVyzoEXbpGZdM+YYK5PH9m2TeTtt0U+fnG3BMLCREACLpdc3OmIQEAi3V459OpokfBwu0/duiIpKbmfbP9+8YV5JA2HxFBDIokXefbZInkfsn27yKefiuzZk7Fs6FCRYPwnPJo0EUlMFDn1VAlgZK+rgUx+5cSJ+EKJ4poMTilVfHwBH0sW/UjsqiV52n7yZPsj2umEDz88yYZud0Z/e7c7203iYoX/PbeC7X9sy9O5Ezbvoy2rMxYcPUqTJraq/M7HqmKioiAyElOjBtP/jObQIUNCqpvqLavzW+q/qEEMp+2byb6Zebj9Y1ISDgK4CBBNAueyEFavzn2/PByX9u3tqLn27e1VCdhqoNhY/orsTgrh+HDazy0sDMaMgWXLkC1bMQh1fLu57OnT8V/ZL+N+0mVRfjNGSTz0CkBVFAu/2iQvXlpTrroGmdsISe7WVcTrPek+mX+kRkefZMM9e0Q6dRJp2VJk4sSs6xYvFvnxRxnB41KfXeLCK1d13pZrvPFdLxUfRgIgAYdD5Kefsm6wfbvIZ59l/WUtIhIIyLksEBAJI0Xe7PFLrucSEZFRoySlel1ZxhmSQph9w8OHZ6w/cEDk1ltFHnxQJCkpb8fcsyfjQ3S5ROLi0lcdOiQS4UqTOxktDzrekSP7UjIuteLjxV+7rn3vwX+AAIh4PCJ+/4nn8ftFhg0T6d1bZNWqvMVWCBTgCiDkhX12D00AqiKYO2adJBMmaTjED+IH8TkdIp9/ftL9KlXKSACnnnqSDb/+WsTtths6HCKPPSZy1VW2vsbjkThPbXmThyScZAGxVSw5WLxYpG1bkRn1brHVPB6PyAcf5Ov9Ptv0C4kkQTwkyvxX55y4gdcr0rOnLeTfftsu27BB5MUXRT76SCQiwr4XY0TS0uz6G2+0hXh4uMhrr+U9mOHDRZo1E3nrrSyLk37/SyoTK25SpXJEiiQnH7dfaqoc6XltegJITwJjxpx4jsmTbWzHtn3oobzHVwCaAJQqQ55z/Z+4SZUaxMgmmonXgQQiwkWmTz/pfkuXijRvLnLmmfYHcLbS0kSef94WlscKIKfT/nW7RSIiJADyLvdKD36V3zlfxnNtjlcfXbrYXWuEx8v8Pv8RGTs2D40QWQWOxsqfg7+QDW/+JBIIyL59Nkdt3x7cYM4ckagoe6LISJG//xapWtUmL49HpHp1mxzatcs46F132V/zBUhI2Xr5ZVnraCv/5RFZ1/nm7Lc5eFD21W2XfiUQAPF+OEZ8vuO2mz1bTmhL2Lmz8DHmQBOAUmVIBIm2PCZVXuZpkZEjT6xSKagBA2xh6nbbQvOUUzJ+QUdH2wbi5s3l1UGb5BJ+FTep0o4VkvrKf7M93N1328N5PCIzZuRy7rg4kYsvtllqTja/9EXk/vuzlot9Gy2SOFPZxhsZaQv+zBtERNiEMG2aSEJCxoESEkSeeEKkTRuRSy8V2bu3gB9Y0OrVGVdNt9+e42YzZ4qMdDwsPoxM5WKJcKRKeLhI945HZWn//xP57TdZvVrkkehRMo0eGe9j0qTCxXcSmgCUKkOO3bYRAlI5+vifj4XUtq397+3xZNwKctYsW1f+/vsif/4pIiJbL707vWzykCirmvfJ9nBpaSLffScyf34ezv3xx/a8YC9TMktJkYP3PisGf5by3YFPHmKkLXyHDTvxl/PgwTmf7/77bVWL0ylyzz15CPAkMl+FeDx22f/+Z5PMrl1ZNt36ylfiC4+U3mZK+r8jiDRimwTCI6RmDb9AQDwmWTbTVK5lvLRmjbw5POeqtsIoSALQXkBKhUiTJsemaDC0au0s/AG//BIGDoSVK+1N4hs0gHPOgf797frOneHHH22f9+7dYdIk6s/8jKuZgIs0WrOeVmdGZntol8sepkuXPMTRtq39GxVl+/tn9s47RI9+Aw/JgKQ/nPgJc/qhUSPb88aVaYCZMciYMQR+/hkOH4YDx916JDzcbh8eDk2a5CHAk2jTxh4nKgouuMBOrzpggJ3v4oorsmza9KkbcI56nxuv9REWZgfUGvwkE0Hz1NUcOWyXBNxh/OPuzPV8wwrOpMdz55I2fTbMnGnzRijlN2OUxEOvAFRFsHevSK9/HZW+XQ9IfGF/FK5YkfGru359u2zjRttD5ptv7Otx42x9+rFf1fffn96jZz815XBEXSmyO7QvWWJ7Hh1rrPV6bWPuWWeJOJ2yi7pyHvPkFFbL7bV/khfcwyXJU12ka1f7Czw8XOTOO9OvZLwGeeV8h2yqZuvct1z5kD3uZ5/Z9x0WZhtZs+uNk18HD4osWGBjnj7dVknl0uK+a5dtuz/71KNZruwc+KR7lcVy6Oup6Z97CmHpjci+2wfKkQkzi+RzR6uAlCpDJk2yhVdkpMjo0fnfPxCwdeCBQNYE0KCBbRDNXIUyb57IokW2Lt0YkZo1Rf7+W7yOcAmA+HDIlpmbiv49ioj8809GbMfiO+MMW23Tt29GfX90tEi1ahnVLz//LPLww7I3CvmnNtL4IeS1LvYYiXjk54/32F5Ax457771FH3sgIDJihEj//rZ9IBdREb5gOLb6x+CTy/lRUqvVls1NuosXlyRiB8QFQFJxSTxRsqzmxfLLL/luV89CE4BSZclDD2X00unfP+/7ffCB/ZV8rD9oz54igYCkfva1zG09UL5pOTRLN0UBW1CKiKxcaQvWYJcV/y9TZfcNj8j+2bkXbgX25JNZY7nggqzrP/5YpEoVkR49RF56yX4mDod9n4cOyTvXNZXwZ41EPu+SJXWDvW5wSXJEVZHffhOpVUukXr08FdDFKRAXL03ZLBCQ+3lLevOTXMJU2UYjiSdKUsKi5fyIv+R2xogfI7uoJ0/wf9KdmTKQj8VNsoyOeMC2MBeAJgClypING0QaN7ZTIyxZkuvmq1eLtG8vEueqmrVABZE9e+Tt5w/KSzwnP9FT/Jis6+vVyz2emTNFGjUSueiirD1tCmvuXPuL3uUSueyyk/fUee65jKR4ySXpi7ce2SoHEw/Kptk7JA3btz4QGZmnz62k/N+ziRJJghj8MpnLJBWXJBApiYTLdhqKgFTjkIBIHdemYFVRIL2qCAJyPr/bwXsFoAlAqXKs1wUJAgH5yVwuvuML+G3b5Ivoe+QavpEo4qU3P8kOGtpf0hERIuedZ38t5yAlRcTXsrUcq5rwtzu9aOrTj4mJEdm9O/ft1q+31VMeT86/hN96y44JuOGGoo0xD9auFXnvvUxjFzLp10/SC/TqxMgrPCkv8qzUcBySsZ0/kBs9EzIV+r5MbQWS/rwFG0Uef7xAsWkCUKq82rpVnnC/IVHES2UTJ9taXphR+DdrJpKcLAGXW87mTwG/OEmTp+6LFTl82K53uWyhunbtCYfessVWvc+ie5YpDr6vcVfhKqULKhAovvPGx4v88UeW6R/y6uhR20wRHm5rnY4f+LVwYUZh3oyN0pMp8s5Lh2XaNLv9sX+us1kgAxkj3RttlHOZL6ezTMIcaWIIyGt3rS/we9cEoFRpt22brbbI73/yqVPFF1VZvqefzKrc15Y+X3xhR+QeK4m+/lrWtLlK2tQ5KJ07B39wb96cMe9NZKQtpY7zwQf2IuEU1oo/2CvoWBKYelE+plco7dLSJNCipfg8UZLaoJnEH/Zm+WfYuFFk0bgV4l++Iut+gYDIq6/KjvOulXC3Hb/gcskJ00R4vbagv5KJ8j19pb7ZnT6mLPMv/e00lAQ8soc6cjYLpR3/yMw7x+d5KqOclGgCAFoDyzM94oAhx23TDYjNtM3zeTm2JgBVLi1aZAc6ORwigwblb9/UVJE+fURq1xb56qu87fPXXxmjWo0RufrqbBPP5s22I05YmEh/z88Zk72BzGl8Y/7iLM1iYsTncEkApDMLBQJSKTJNDr77tcz7bJPc5vhMEvFIqtMjW17+UgY0mSWx7uria9g4fSrr1x1PyOmRm+Sz17Jvx9i7MkbSXHbbWuzPOtjNIdLasV4OUV16ME2qcVAMPjH4pffp2dQp5VPIrgAAJ7APaHLc8m7Az/k9niYAVZbFHEmSc3tulWtv35+1muChhzJKg7Cw4g+kT5+M87lcJ52GICnJdn+PixMZeuoPsp2GstbRRg4u2FD8cZag72reIxtpEeymaX+R12S/vMlDMo7b0iflm1LrVpnPuelXQic0up9xRvYnOHIkvcvrrY5PsowJgIA48coT4W9JJAlZlkdGBgpSK5VFQRJAUY0EvgjYLCLbi+h4SpVJ25ce4j/V3uGfqbX54dOqXHz50YyVvXrZ+8wC1KlT/MH06AEejx0lO2TICSNZM/N4oEYNqFQJXlnbj8ayk1P9a6hxbqvij7MEVfn6QzpU2oS9GaIAcIjq3MjXTKUn+6iHl3A2dr6R392XkEJ4xs7OTKO1169n1iw491x7b3sRkOQUfltUiUkvTuHdLi5WtdyV6cyCHSfs4rXUB0kiCjh2lzZDUpLhueeK9a1nL78ZI7sHMA64P5vl3YBDwD/Ar8BpJznGIGAxsLhx48aFS4VKhcjYpi/K4/xHvuEa+Yg7pG2dzVk3mDBB5NFHRbZuFRE7Tfzu3WLnqM/LXbLya/FikTVriv64ZdzSpSIP3eeVaf9+SSAgvflZ5tBVkgkTiYgQ3y/T5Nv/BWTFe7+LnH66BJwu2Xbrs7axxO0W6dFDqlTJqF1bOGisrDKnyVVMkCocFqpsEsJibdUPaTKM58VNavovfpfxyeWOn+Q0lqcvGziwcO+JUFQBAWHAQaBONusqA9HB572BjXk5plYBqTJpzRpZWL+vHCVa0nBKCmGy7aacu/S9/HJwILArVRa7zrFTOBw6VIIBKxF7Z8imTUW+6vGJHVsAdnbRoMmT7b9TY88BSQ6vbKvvevSQ3u5pYoLdObdFtZVa7BUIiJsU+Zg75GFeE4fTL6c2TxUvdvqL8/lNIkmQETwqPhxyiCpyITOke8T8PPWSPZmCJICiqALqBSwVkf3ZXF3EiUhC8PkvgNsYU7MIzqlU6ZKcDB07cvaeSUSTiEEIcwVo8q9mOe4yaZLdzecT5vrOhbg4+OuvkotZAXDbbbB1K9z46hl2dEVUlK3b8fngmmu44Ib69Ev+mguSfyE8Nc7emH7WLG5gPB5SiCSJr1o8x0FqA5CGmzas4RWe45za23mw1wbqRcbRiN3M598kEcULvMgKzmAvDRjEaH4742Hq1y/5914UCeAGYHx2K4wxdY2xlZ7GmLOD5ztUBOdUqnRJTYXUVAzgRHASsIXJrbfmuMuwYXbiyVrRyVzjnGgr4c87r+RiVll16ABLlsCECfDxx/DHH/Drr1RO3MsHjvuoU9ULJlhkVq3KzRHfMzuiNzPaDuEH9/UIGbO7vsd9GAL49+7n/vdP5VCSB8FBINj2IMG/n3A7I9zPwQ8/hOQtFyoBGGOigB7AD5mW3WOMuSf4sj+wyhjzD/AOcH3wUkWp8iU5maS6zdlGE9K/4JGROd6MHWxZYwzEUpW4+Sth82aoWtX+8ty1K/RTBVdEbdpAz562wbdVK/sPFBVFlfPP5PXNV2PatrH/rg88AI0acfa/I+hy12mc6VgRPIABDN9yPVczgY4sIYADQwAQangSac4m3KTSh5941/kI1z/T0k7dHQr5rTMqiYe2AagyZc0a+ZNzxEOiuPDKYN613S7//vukuzVtlSQgEh7ul1GjggtTU0VOP902NPbqVfSxbtxo7zoWF2enZ1Ant2mTndb6uFFa3lr1REDScMofrm4STuIJXT7BL5HBu76FO1Ll8Ud9kpYmkhibJmPG2F65m4pwAlb0hjBKlbwF7y7iUn4lgAMfbr7gVtv18rTTctxnX8I+LvXehQsvNby76XNu8CYnW7bAxo2Qlga//mqrlorKd99B69bQr5+tbqpfH4YPL7rjl0ctWkDfvrafbCaHY/x4cRPAwZe+a0nN1F3UEOByfqQL8zBRkXg84AgP44abnLhcEFnZxR13wJVX2sOHkiYApQrp4z2X0ZPp1GMPDvzcYz6CKVNsVUEOErwJvHLgK1LwsNbVmLq7/rYrWraE00+3VRBXX20bCQri77/ht9/sD9J334X27e3dwgIBW8WUlmYfo0cX7Pjl3cSJ8NJLGXcfCwRg7Fho3JiYyCbspBFhpCEYKpEEGGpzACdpAPxGD57gdb79NImRI2HGDDjrrNC9nRzl95KhJB5aBaTKkvXrRXrwq8QRJQepKmldu+Vpv7mDLxe/QeJaNs46OZnfb7uDFnRCtIkTbb/FqCiRoUMz5gIKjmoNgPg8wRvGv/xywc5Rns2da+dNcrlEunSxy0aMSJ9WoyOLpDMLZAMtZC7/kurESJf6WyUJj9zIF3I6yyWKeJlEH7m5XxFOq50LtApIqZJ3yinwS+ol+J4fTo0XH8b160/w+ONQvTo89liO+3V9/yccaT4qbdxuh+Ae43DYfY+NGj5GhFH3jqJppQ1c1GY3+/blcOAlS2xXxcREWLYs/SpiIZ15gLdpy2oikg8x/4f98MwzhXz35VBsrP3sfT44csQu27zZXjEB+6jDIs7lFDZwr3ssr7+YwrTJqYQ70/iCW1lMZz7jVnbQiDZRpXxyhPxmjJJ46BWAKtNiYtLvvRsA8fa/vkhG+X7y0DOC8aY3MN7faYFIy5YizzyTdcPdu+29d1u0EFm+XOSuu0ScTrmab+QB3pIwUsSJV1o3K4aRx+WB329vTNO7t72Dmoj9TINXAGs5RfZSS/aHNRCfO1wCER6ROXNEOndOv9ISsJPq3Xd/iYWNXgEoVQpUqQLh4fgxGCB5whTubTQ5526ds2fD4MG5DgL7c81hMAEI9jdvtvg72LQJ3ngDNm0iMdH+6Kd+fVi61K4780z7i1aEp/kPddiPEz8ufJx+pv73z5bDYev/p0yBdu3ssvr14a23ADiVDdQlhlre3TjTUpGUZJb9d6ZtT6lXL/3KzWnA3HN3iN5E3ug3QKmi5nbDf/+Ll3DiieJPuvBRzNVsWpvGiBEweXKmbQ8fRnr3hg8/xN/twpP2+hk+YiDVG0/C4dnHLa0+Y0iD79LHGvy+tg7Vq0O1arbtNwu/HwIBOkRvZkCbhfyHp3iy8ii+eGFLsbz9cmvwYJg/P/2lgfQxH39MS7EN7Xv2wPr18N//wsqVGQmktMrvJUNJPLQKSJUH8//zu3RjlrhJkUhXipx/vq1FiIy0N6USEZGYGPE6bCNtMuEy5PYj0r27yLRpeTjBvn0i48aJbNwoZ52Zll770LCh2Mnm1q+34woyVUv4u3YVvyfSTnHcokXxvfny7JFH0qv3fCApuOSr5s/kvl8xowBVQEZyuiwNoU6dOsnixYtDHYZShbZsGUyfDtf2TuC9y35l4s6OxEQ2ZeYDP3JOVzffHLiQ3nfUIYokAhiqcpQkoglz+7n/jd+4p9eFtGrpPOk5Fi2Cf53tJY0wmrGFVs7NTAu70q684Qb49FPbjRH7izWJSDwkY1q1xGzYULwfQHmVkAB//03sm2M4khpFvfFvEl6zUu77FSNjzBIR6ZSvfTQBKFX80s7oAOs3kOZ38GfnB+n+z1ukpQpL6ECXwLz06oQ67CMNN/PoSnO2cBejuPLb27nmmpyP3amT7fhzITP5iSsIx4sTf8bKNWsgKQkxhtnSjU+5lS4s5OaljxJ9Vvma778iK0gC0DYApYpZXBz4Vq7D7U2EQICLqy+D5GRcgVQ6B/7KUpf8FK/Sl0k0ZTseUnmJl3Idq9W2LUSGpdGDGXhItoV/WBhUrgwjR8Jrr0G3biBCd2YzkE+Z1ncUUe218K/oNAEoVcx27YKH3O+ziwaMl+vwv/0ey8PPYQHnsonm6YX/1pqdWEJnltIBwZBIJL/QmwMH7BxxY8dmf/wxY+DjT9z0+N8gTMOGduNZs2zvn65d4b77YPPm4DRl0I0/+OE7/wnDDFTFowlAqeIUCNCmYTzJ1w2gXZVd7Ht5LM5mjalXz9CFBWylOZvCT8P06EHNRdOo8cCNdLmnPQs+30Tg97k0+P5dtmyxZfkTT2R/irAwuPFG6HhtC9i50w5e6to160Z33JExsOzaazGuk7crqIpB2wCUKg4+H5svGsSqOYe4hOl47rkdPvzQrtu4ETn9dExqKoIhZe0WPPffaUeefvklNGxot3vpJdLGfsbQ/UMY5XqA7t3hp7e32KqdmgW4r9LOnXZSs4Lsq0q9grQBhLzLZ3YP7Qaqyrqtn8yWMFLEhVd68bPthvnqq3aUqdcr0q6dnaPnootEHnpIxOm0o4cHDLAH2LlTJDzcdjd0OuX3KQkS/8rbEh9ew/YjXbbMbhcIiMTHh+ptqlIEHQmsVOnwyWOr8BKGDzf38b5d+Nxz0LmzHSi0dKn9+9BDdmSY02mnkP7hB7jlFjuiy+OByEhMrVqEVYmg9tN3UTN1Fz+nXIR/5my6nutjmaMDUqkSNG0KSUkhfc+q7NEEoFQxOOvQLBz4ASGKRLswLc0W/P37w7PPQvPmcMUV9oa0InZ9bKytBvruO1i+HD74AJYt479vOknGQyoRvB+4h3HjhMS/VnAGK+zEENu359xKrFQONAEoVQyuvKUyH3IvjzCStmdXgl697C98h8PO/Pn661nnBjq27pjhw+Hrr+HNN2HCBK6/HmxnUeEypjBg7RN8z9X4McGlEPP+/0r0PaqyTxuBlSoOIhATY++85Qz2uPn+e/urfvBg6NEDVq+2y//9bztx2549WY9hjD2OwwHXXcee/Q7m/C5cF/jaTjJHOG58uIKDvnyOMFz+IryDWBGKj4fff7f3XQ/V7W/Lu4I0AruKKxilKjRjoHZtW63z7LO2cB8xwt7lC2DxYlv3X6sWrFgBQ4Zk3d/jsYW/12uncRg/nvrA9ZUrw7mXwIwZRPToRurGHTi2rsMgJNx8N1VL+G3m1fnn2xxnDMydC2fM+C/L3vod9523ccaLJxnmrIpXfluNj38A24CVwHKyaYXGjj15B9gErAA65HZM7QWkyo1Ro+zduZxOkcsuszdkX7MmY31cnEiPHumTiw3lZanOQXm8z1p7x/AOHbJM5pb+WLHC7p+SYnsEHTkSineXJ4GAffvHQo8I90tfvhODXyAgbVqlhjrEciG78je3R1G1AXQXkfaS/eVHL6BV8DEI+LCIzqlU6RcRYf86HPaX/vXX2/l5Vqywy6+/3t4wFjhMNV7ncQ5Tg7emtORApRZwxhnZH3fHDvs3PNxOQ1y1arG+jcIwxjZlHGviSEkVJnE1tvgxrN3o5ujRUEZYcZVEI/CVwOfBJLUQqGqMqVcC51Uq9G65xc7F89hjti0gMdgjaNUq+3fz5vRNKxFPHQ4QTTw1HEdsmR4WduKtITt0gJ49SyT8AklNhalTbc+koAcfhO/e2xdssnZCetO1FRlZ4lEqiiYBCDDdGLPEGDMom/UNgJ2ZXu8KLsvCGDPIGLPYGLM4JiamCMJSqhRwOBhb4zpqzO3A0LqvEqhXH847j5+cfenbdgNpmzMKSRc+5vEvPudWVv5nCmFh2OQxcKBtKP72W1uLsmRJRsNyaXTllbara7t2GVcqP//MVY825zSzmswFv2Vwu0s6SAVF0wjcVUR2G2NqAzOMMetEZE5+DyIio4HRYHsBFUFcSoXcA8M28p63I3RP5rVV/ZCLtvCf4eFc44EuqbtIxYEbIDISR58+NP3hB5q2WAf3fW0PUKWKne2tLPn7b3ulExVlB7s1bmyvCJKTmcWF/KfR+7y1sz/Hbm15xRUnXuSoklHoKwAR2R38ewCYCJx93Ca7gUaZXjcMLlOq3Htv5kRwecHpI1BnPSK7MAbq1oUFzq6M5wbScEFyMnzyif3FvHKl7QVUVr31lu3+2q0bXHCBXXbPPVCrFrWrpjFyQhMmTzbccQf88gv8+GMog63YCjUOwBgTBThEJD74fAbwkohMzbTNZcD9QG/gHOAdETk+SWSh4wBUeeGuuwbfwHPA6SVszqPET3uZsAgHe/bA9+/s5vwRl9Gef2yVzsGDpboxV5VuoRgHUAeYaOz1mwv4WkSmGmPuARCRUcAv2MJ/E5AEDCjkOZUqMxZPa8sdd24iyruBMR+1JSzCXnTXrw8PvNoAmg+GUaPggQe08FclTkcCK6VUOaC3hFRKKZVnmgCUUqqC0gSglFIVlCYApZSqoDQBKKVUBaUJQCmlKihNAEopVUFpAlBKqQpKE4BSSlVQmgCUUqqC0gSglFIVlCYApZSqoDQBKKVUBaUJQCmlKihNAEopVUFpAlBKqQpKE4BSSlVQmgCUUqqC0gSglFIVlCYApZSqoAqcAIwxjYwxs40xa4wxq40xD2WzTTdjTKwxZnnw8XzhwlVKKVVUXIXY1wc8KiJLjTGVgCXGmBkisua47eaKyOWFOI9SSqliUOArABHZKyJLg8/jgbVAg6IKTCmlVPEqkjYAY0xT4Czgr2xWn2eM+ccY86sx5rSTHGOQMWaxMWZxTExMUYSllFLqJAqdAIwx0cD3wBARiTtu9VKgiYicCbwLTMrpOCIyWkQ6iUinWrVqFTYspZRSuShUAjDGuLGF/1ci8sPx60UkTkQSgs9/AdzGmJqFOadSSqmiUZheQAYYC6wVkTdz2KZucDuMMWcHz3eooOdUSilVdArTC+hfwC3ASmPM8uCyp4HGACIyCugP3GuM8QHJwPUiIoU4p1JKqSJS4AQgIvMAk8s27wHvFfQcSimlio+OBFZKqQpKE4BSZYnPB9OmwebNWZfv2gUTJ0Lc8R3xlMpZYdoAlFIl7aabYMoUEIE5c4hfsRUnfiIfvtsmhyZNYPXqUEepyghNAEqVJQsWQGIiREYyvNMPPMpIAObSkfOZB+vWQSAADr24V7nTb4lSZclbb0HNmhAZSVWO4saLh2TiiSauVgsYOVILf5VnegWgVFly1VXgdiPXXc9a2rCYTlQigScZwXc/NqLyedVCHaEqQ/SnglJlTVgYaclpvM1DLOUszuNParOf1i39oY5MlTGaAJQqo5wEuINxHA2rw6yX/8bU0llWVP5oFZBSZc2YMbhJAyCeKtQ4uhM84SEOSpVFmgCUKkuWLIEJE9KH4NdqGA7h7pCGpMourQJSqiz56qusr/fsgb17QxOLKvM0AShVllxxRdbXLVtC3bqhiUWVeZoAlCor/vkHfvoJzjkHn3GzpMU17J2xivHfOpk7N9TBqbJI2wCUKgv8fujaFRISIDycCzol8M+aMNJa2YG/bjf8/DNceGGoA1VliV4BKFUWpKXZwh+Q1FRWL04hMRG8XjsFUHIyrF8f4hhVmaMJQKmyoE+fLC+ff+Awtzm/5CleoTKxwInNA0rlRquAlCrFYo8KK5peQdfYmRhgB40YyRDcExfwSfjdpCWl0ZnFjLvsBxo0CHW0qqzRBKBUKbbl5ufoGvszAAI0YQcAg/aNQ5xCmPFx1QVHuOrnEAapyixNAEqVVgcP0nDKKASDA8GLm0v4ld9dlzCv6S0ELl2JY+dWOwOoUgWgCUCpUmraFwfoy3aG8io9mcqjvMk69+ks+GQ9p/dsiKuGFvyqcArVCGyM6WmMWW+M2WSMeSqb9eHGmP8F1/9ljGlamPMpVZFMWnMKKUQxjOF04U/mcT5JaS6O3Hw/7kZ1Yd++Yj3/lv+Mp2nEXto1T8DnK9ZTqRApcAIwxjiB94FeQFvgBmNM2+M2uwM4IiItgZHAiIKeT6mK5s57XES7U4gkkdv5FEOAU9hAFxZASgpMngyzZ9uBAEVt0SLaPN2X7al1Wb01ihYtiv4UKvQKcwVwNrBJRLaIiBf4BrjyuG2uBD4LPp8AXGSMMSilctWxI8SmRBCXGkHN2/rQkN3MNhcRQQpUrgxDhtjuoffeW/QndzrxEpb+Miam6E+hQq8wCaABsDPT613BZdluIyI+IBaokd3BjDGDjDGLjTGLY/TbphRg7+7oDHPy6qd1WX6oEZWO7sJs22Ybfo2x9weeM4cVK2DMGDh8uIhO3KEDz1++PP3l998X0XFVqVJqBoKJyGgR6SQinWrVqhXqcJQqdapXB2flKGjSxN4asl07qFmTA0++wXnnwYMPQrduRXe+F3/qiIhBxNCrV9EdV5UehUkAu4FGmV43DC7LdhtjjAuoAhwqxDmVUgBVqsBff0FMDFtO7Y0x0CN5Eg+vvgNGjQp1dKqMKEwCWAS0MsY0M8aEAdcDk4/bZjJwW/B5f+A3EZFCnFMpdZxzzoEn+2/mf1zP7YFxtk3g7ruLp3FYlSsFTgDBOv37gWnAWuBbEVltjHnJGHNsVpKxQA1jzCbgEeCErqJKqcIxBp57JkAEqRjsiOHA6I9ZdPmwUIemSrlCDQQTkV+AX45b9nym5ynANYU5h1IqD1q1ggsvRH77DQOk4eK3X73s/iKOvrdUDnV0qpQqNY3ASqlCmjyZeCoRwHCY6oxkCPcN0fsFq5xpAlCqvIiKonJKDK87HucU1nOQWjRoHh7qqFQppnMBKVWehIfzpH8ELSbAqlUweHCoA1KlmSYApcqh/v3tQ6mT0SogpZSqoDQBKKVUBaUJQCmlKihNAEopVUFpAlBKqQpKE4BSSlVQmgCUUqqCMqVxck5jTAywPdRxFIOawMFQB1EK6eeSPf1csqefS/Zai0il/OxQKgeCiUi5vCOMMWaxiHQKdRyljX4u2dPPJXv6uWTPGLM4v/toFZBSSlVQmgCUUqqC0gRQskaHOoBSSj+X7Onnkj39XLKX78+lVDYCK6WUKn56BaCUUhWUJgCllKqgNAGUAGNMT2PMemPMJmPMU6GOpzQxxmwzxqw0xiwvSDe28sIYM84Yc8AYsyrTsurGmBnGmI3Bv9VCGWMo5PC5vGCM2R38ziw3xvQOZYyhYIxpZIyZbYxZY4xZbYx5KLg8X98ZTQDFzBjjBN4HegFtgRuMMW1DG1Wp011E2lfwvt2fAj2PW/YUMEtEWgGzgq8rmk858XMBGBn8zrQXkV9KOKbSwAc8KiJtgXOB+4LlSr6+M5oAit/ZwCYR2SIiXuAb4MoQx6RKGRGZAxw+bvGVwGfB558BfUsyptIgh8+lwhORvSKyNPg8HlgLNCCf3xlNAMWvAbAz0+tdwWXKEmC6MWaJMWZQqIMpZeqIyN7g831AnVAGU8rcb4xZEawiqnBVY5kZY5oCZwF/kc/vjCYAFWpdRaQDtorsPmPMv0MdUGkktr+29tm2PgRaAO2BvcAbIY0mhIwx0cD3wBARicu8Li/fGU0AxW830CjT64bBZQoQkd3BvweAidgqM2XtN8bUAwj+PRDieEoFEdkvIn4RCQAfU0G/M8YYN7bw/0pEfgguztd3RhNA8VsEtDLGNDPGhAHXA5NDHFOpYIyJMsZUOvYcuARYdfK9KpTJwG3B57cBP4YwllLjWAEX1I8K+J0xxhhgLLBWRN7MtCpf3xkdCVwCgt3U3gKcwDgR+b/QRlQ6GGOaY3/1g52Z9uuK+tkYY8YD3bBTHe8HhgGTgG+Bxtjp0a8VkQrVIJrD59INW/0jwDbg7kz13hWCMaYrMBdYCQSCi5/GtgPk+TujCUAppSoorQJSSqkKShOAUkpVUJoAlFKqgtIEoJRSFZQmAKWUqqA0ASilVAWlCUAppSqo/wevgGhvIxhihAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "chosen_idx = torch.randperm(len(train_embs_all))[:1000]\n",
    "chosen_embs = train_embs_all[chosen_idx]\n",
    "chosen_labels = train_labels_all[chosen_idx]\n",
    "# umap \n",
    "import umap\n",
    "reducer = umap.UMAP()\n",
    "embedding = reducer.fit_transform(chosen_embs)\n",
    "chosen_colors = []\n",
    "for label in chosen_labels:\n",
    "    if label == 0:\n",
    "        chosen_colors.append(\"red\")\n",
    "    elif label == 1:\n",
    "        chosen_colors.append(\"blue\")\n",
    "    else:\n",
    "        chosen_colors.append(\"green\")\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1], c=chosen_colors, s=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([     0,     16,     32,  ..., 171776, 171805, 171931])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_init_mask.nonzero().reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 112978 is out of bounds for dimension 0 with size 103517",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [177]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m chosen_idx \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([chosen_idx, train_init_idx[chosen_init_idx]])\n\u001b[1;32m      4\u001b[0m chosen_embs \u001b[38;5;241m=\u001b[39m train_embs_all[chosen_idx]\n\u001b[0;32m----> 5\u001b[0m chosen_labels \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_labels_all\u001b[49m\u001b[43m[\u001b[49m\u001b[43mchosen_idx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# umap \u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mumap\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 112978 is out of bounds for dimension 0 with size 103517"
     ]
    }
   ],
   "source": [
    "chosen_idx = torch.randperm(len(train_embs_all))[:1000]\n",
    "chosen_init_idx = torch.randperm(len(train_init_idx))[:500]\n",
    "chosen_idx = torch.cat([chosen_idx, train_init_idx[chosen_init_idx]])\n",
    "chosen_embs = train_embs_all[chosen_idx]\n",
    "chosen_labels = train_labels_all[chosen_idx]\n",
    "# umap \n",
    "import umap\n",
    "reducer = umap.UMAP()\n",
    "embedding = reducer.fit_transform(chosen_embs)\n",
    "chosen_colors = []\n",
    "for label in chosen_labels:\n",
    "    if label == 0:\n",
    "        chosen_colors.append(\"red\")\n",
    "    elif label == 1:\n",
    "        chosen_colors.append(\"blue\")\n",
    "    else:\n",
    "        chosen_colors.append(\"green\")\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1], c=chosen_colors, s=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4044608/3622939009.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  veri_results = torch.load( f\"/data/zhihao/TU/Watchog/verification/{args.task}_veri_data_4.pth\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.makedirs(\"/data/zhihao/TU/Watchog/trainfication\", exist_ok=True)\n",
    "veri_results = torch.load( f\"/data/zhihao/TU/Watchog/verification/{args.task}_veri_data_4.pth\")\n",
    "veri_embs_4 = veri_results[\"embs\"]\n",
    "veri_label_4 = veri_results[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128489\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.6493)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# veri V4\n",
    "veri_labels_all_4 = torch.cat([torch.tensor(veri_label_4[i]) for i in veri_label_4], dim=0)\n",
    "print(len(veri_labels_all_4))\n",
    "veri_labels_all_4.sum()/len(veri_labels_all_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128489, 768])\n"
     ]
    }
   ],
   "source": [
    "# veri V4\n",
    "veri_embs_all_4 = torch.cat([torch.stack(veri_embs_4[i], dim=0) for i in veri_embs_4], dim=0)\n",
    "print(veri_embs_all_4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f53b8d9b0a0>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "chosen_idx = torch.randperm(len(veri_embs_all_4))[:1000]\n",
    "chosen_embs = veri_embs_all_4[chosen_idx]\n",
    "chosen_labels = veri_labels_all_4[chosen_idx]\n",
    "# umap \n",
    "import umap\n",
    "reducer = umap.UMAP()\n",
    "embedding = reducer.fit_transform(chosen_embs)\n",
    "chosen_colors = ['red' if label == 0 else 'blue' for label in chosen_labels]\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1], c=chosen_colors, s=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"/data/zhihao/TU/Watchog/verification\", exist_ok=True)\n",
    "torch.save({\"data\": train_data, \"label\": train_label, \"logits\": train_logits, \"cls_indexes\": train_cls_indexes, \"embs\": train_embs, \"target_embs\":train_target_embs , \"col_num\": train_col_num}, f\"/data/zhihao/TU/Watchog/verification/{args.task}_veri_data_6.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79136"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randperm(len(train_labels_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9185)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Threshold: 1.5****************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4044608/3268456744.py:54: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
      "/tmp/ipykernel_4044608/3268456744.py:100: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n"
     ]
    }
   ],
   "source": [
    "# brute force perumate in validation TODO: restrict mamimus length of permutation\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "import torch.nn.functional as F\n",
    "veri_data = defaultdict(list)\n",
    "veri_logits = defaultdict(list)\n",
    "veri_cls_indexes = defaultdict(list)\n",
    "veri_target_col_mask = defaultdict(list)\n",
    "veri_embs = defaultdict(list)\n",
    "veri_col_num = defaultdict(list)\n",
    "veri_label = defaultdict(list)\n",
    "veri_class = defaultdict(list)\n",
    "veri_target_embs = defaultdict(list)\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "for threshold in [1.5]:\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    log = defaultdict(list)\n",
    "    num_cols = []\n",
    "    corrected = 0\n",
    "    total_mistakes = 0\n",
    "    num_permutations = {}\n",
    "    init_permutation = {}\n",
    "    init_correctness = {}\n",
    "    score_init = {}\n",
    "    score_permutation = defaultdict(list)\n",
    "    permutation_correctness = defaultdict(list)\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(valid_dataloader_iter):\n",
    "            cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "            target_col_mask = batch[\"target_col_mask\"].T\n",
    "            logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "            score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
    "            label_i = batch[\"label\"].item()\n",
    "            predict_init = logits.argmax().item()\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            init_permutation[batch_idx] = init_permutation_i\n",
    "            if predict_init == label_i:\n",
    "                init_correctness[batch_idx] = True\n",
    "            else:\n",
    "                init_correctness[batch_idx] = False\n",
    "            num_permutations[batch_idx] = 0\n",
    "\n",
    "            x = [0]\n",
    "            new_batch_data = []\n",
    "            for col_i in x:\n",
    "                if col_i == 0:\n",
    "                    if len(new_batch_data) == 0:\n",
    "                        cls_indexes_value = 0\n",
    "                    else:\n",
    "                        cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "            new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "            cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "            logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "            veri_target_embs[batch_idx].append(embs_temp.cpu())\n",
    "\n",
    "            num_cols.append(len(init_permutation_i))\n",
    "            labels_test.append(batch[\"label\"].cpu().item())\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            assert -1 not in col_idx_set\n",
    "            for r in range(len(init_permutation_i), max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "                for x in itertools.combinations(init_permutation_i, r):\n",
    "                    if 0 not in x:\n",
    "                        continue\n",
    "\n",
    "                    num_permutations[batch_idx] += 1\n",
    "                    new_batch_data = []\n",
    "                    for col_i in x:\n",
    "                        if col_i == 0:\n",
    "                            if len(new_batch_data) == 0:\n",
    "                                cls_indexes_value = 0\n",
    "                            else:\n",
    "                                cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                        new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                    new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                    cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                    logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                    ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n",
    "                    score_permutation[batch_idx].append(ood_score_temp)\n",
    "                    predict_temp = logits_temp.argmax().item()\n",
    "                    permutation_correctness[batch_idx].append(predict_temp == label_i)\n",
    "                    \n",
    "                    veri_data[batch_idx].append(new_batch_data.cpu())\n",
    "                    veri_logits[batch_idx].append(logits_temp.detach().cpu())\n",
    "                    veri_cls_indexes[batch_idx].append(cls_indexes_value)\n",
    "                    veri_embs[batch_idx].append(embs_temp.cpu())\n",
    "                    veri_col_num[batch_idx].append(len(x))\n",
    "                    veri_label[batch_idx].append(torch.tensor(predict_temp == label_i).long()) # indicate whether the permutation is correct or not\n",
    "                    veri_class[batch_idx].append(label_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Threshold: 1.5****************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4044608/162256889.py:54: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
      "/tmp/ipykernel_4044608/162256889.py:100: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n"
     ]
    }
   ],
   "source": [
    "# drop one column for column correlation\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "import torch.nn.functional as F\n",
    "veri_data = defaultdict(list)\n",
    "veri_logits = defaultdict(list)\n",
    "veri_cls_indexes = defaultdict(list)\n",
    "veri_target_col_mask = defaultdict(list)\n",
    "veri_embs = defaultdict(list)\n",
    "veri_col_num = defaultdict(list)\n",
    "veri_label = defaultdict(list)\n",
    "veri_class = defaultdict(list)\n",
    "veri_target_embs = defaultdict(list)\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "for threshold in [1.5]:\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    log = defaultdict(list)\n",
    "    num_cols = []\n",
    "    corrected = 0\n",
    "    total_mistakes = 0\n",
    "    num_permutations = {}\n",
    "    init_permutation = {}\n",
    "    init_correctness = {}\n",
    "    score_init = {}\n",
    "    score_permutation = defaultdict(list)\n",
    "    permutation_correctness = defaultdict(list)\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(valid_dataloader_iter):\n",
    "            cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "            target_col_mask = batch[\"target_col_mask\"].T\n",
    "            logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "            score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
    "            label_i = batch[\"label\"].item()\n",
    "            predict_init = logits.argmax().item()\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            init_permutation[batch_idx] = init_permutation_i\n",
    "            if predict_init == label_i:\n",
    "                init_correctness[batch_idx] = True\n",
    "            else:\n",
    "                init_correctness[batch_idx] = False\n",
    "            num_permutations[batch_idx] = 0\n",
    "\n",
    "            x = [0]\n",
    "            new_batch_data = []\n",
    "            for col_i in x:\n",
    "                if col_i == 0:\n",
    "                    if len(new_batch_data) == 0:\n",
    "                        cls_indexes_value = 0\n",
    "                    else:\n",
    "                        cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "            new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "            cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "            logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "            veri_target_embs[batch_idx].append(embs_temp.cpu())\n",
    "\n",
    "            num_cols.append(len(init_permutation_i))\n",
    "            labels_test.append(batch[\"label\"].cpu().item())\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            assert -1 not in col_idx_set\n",
    "            for r in range(len(init_permutation_i), len(init_permutation_i)-2, -1): # not \n",
    "                for x in itertools.combinations(init_permutation_i, r):\n",
    "                    if 0 not in x:\n",
    "                        continue\n",
    "\n",
    "                    num_permutations[batch_idx] += 1\n",
    "                    new_batch_data = []\n",
    "                    for col_i in x:\n",
    "                        if col_i == 0:\n",
    "                            if len(new_batch_data) == 0:\n",
    "                                cls_indexes_value = 0\n",
    "                            else:\n",
    "                                cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                        new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                    new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                    cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                    logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                    ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n",
    "                    score_permutation[batch_idx].append(ood_score_temp)\n",
    "                    predict_temp = logits_temp.argmax().item()\n",
    "                    permutation_correctness[batch_idx].append(predict_temp == label_i)\n",
    "                    \n",
    "                    veri_data[batch_idx].append(new_batch_data.cpu())\n",
    "                    veri_logits[batch_idx].append(logits_temp.detach().cpu())\n",
    "                    veri_cls_indexes[batch_idx].append(cls_indexes_value)\n",
    "                    veri_embs[batch_idx].append(embs_temp.cpu())\n",
    "                    veri_col_num[batch_idx].append(len(x))\n",
    "                    if predict_init != label_i and predict_temp == label_i:\n",
    "                        veri_label[batch_idx].append(torch.tensor(1).long())\n",
    "                    elif predict_init == label_i and predict_temp != label_i:\n",
    "                        veri_label[batch_idx].append(torch.tensor(0).long())\n",
    "                    elif predict_init == label_i and predict_temp == label_i:\n",
    "                        veri_label[batch_idx].append(torch.tensor(2).long())\n",
    "                    else:\n",
    "                        veri_label[batch_idx].append(torch.tensor(3).long())\n",
    "                    veri_class[batch_idx].append(label_i)\n",
    "            assert len(veri_label[batch_idx]) == len(init_permutation_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"/data/zhihao/TU/Watchog/verification\", exist_ok=True)\n",
    "torch.save({\"data\": veri_data, \"label\": veri_label, \"logits\": veri_logits, \"cls_indexes\": veri_cls_indexes, \"embs\": veri_embs, \"target_embs\":veri_target_embs , \"col_num\": veri_col_num}, f\"/data/zhihao/TU/Watchog/verification/{args.task}_veri_drop_data_0.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for veri_i in veri_label:\n",
    "    context_embs = veri_embs[veri_i][0].reshape(-1)\n",
    "    for veri_j in range(1, len(veri_label[veri_i])):\n",
    "        if label_version == 0:\n",
    "            if veri_label[veri_i][veri_j] != 0 or veri_label[veri_i][veri_j-1] != 1:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6155\n",
      "tensor(226) tensor(0.0367)\n",
      "tensor(132) tensor(0.0214)\n",
      "tensor(3148) tensor(0.5115)\n",
      "tensor(2649) tensor(0.4304)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "veri_labels_all = torch.cat([torch.tensor(veri_label[i]) for i in veri_label], dim=0)\n",
    "print(len(veri_labels_all))\n",
    "for i in range(4):\n",
    "    print((veri_labels_all==i).sum(), (veri_labels_all==i).sum()/len(veri_labels_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5270\n",
      "tensor(226) tensor(0.0429)\n",
      "tensor(132) tensor(0.0250)\n",
      "tensor(2661) tensor(0.5049)\n",
      "tensor(2251) tensor(0.4271)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "veri_labels_all = torch.cat([torch.tensor(veri_label[i])[1:] for i in veri_label], dim=0)\n",
    "print(len(veri_labels_all))\n",
    "for i in range(4):\n",
    "    print((veri_labels_all==i).sum(), (veri_labels_all==i).sum()/len(veri_labels_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "        self.pos_iter[anchor_idx] = iter(self.veri_pos_embs[anchor_idx])\n",
    "        self.neg_iter[anchor_idx] = iter(self.veri_neg_embs[anchor_idx])\n",
    "        # Shuffle for randomness\n",
    "        random.shuffle(self.pos_embeddings[anchor_idx])\n",
    "        random.shuffle(self.neg_embeddings[anchor_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"/data/zhihao/TU/Watchog/verification\", exist_ok=True)\n",
    "torch.save({\"data\": veri_data, \"label\": veri_label, \"logits\": veri_logits, \"cls_indexes\": veri_cls_indexes, \"embs\": veri_embs, \"target_embs\":veri_target_embs , \"col_num\": veri_col_num}, f\"/data/zhihao/TU/Watchog/verification/{args.task}_veri_data.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4044608/4079443277.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  res = torch.load(f\"/data/zhihao/TU/Watchog/verification/SOTAB_veri_data.pth\")\n"
     ]
    }
   ],
   "source": [
    "res = torch.load(f\"/data/zhihao/TU/Watchog/verification/SOTAB_veri_data.pth\")\n",
    "veri_label_sotab = res[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "veri_label_sotab_all = []\n",
    "for i in veri_label_sotab:\n",
    "    veri_label_sotab_all += veri_label_sotab[i]\n",
    "veri_label_sotab_all = torch.tensor(veri_label_sotab_all).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "503402"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(veri_label_sotab_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8646)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "veri_label_sotab_all.sum()/len(veri_label_sotab_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4044608/2986149398.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  res = torch.load(f\"/data/zhihao/TU/Watchog/verification/{args.task}_veri_data.pth\")\n"
     ]
    }
   ],
   "source": [
    "res = torch.load(f\"/data/zhihao/TU/Watchog/verification/{args.task}_veri_data.pth\")\n",
    "veri_label_old = res[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4044608/2111244162.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  res1 = torch.load(f\"/data/zhihao/TU/Watchog/verification/{args.task}_veri_data_1.pth\")\n"
     ]
    }
   ],
   "source": [
    "res1 = torch.load(f\"/data/zhihao/TU/Watchog/verification/{args.task}_veri_data_1.pth\")\n",
    "veri_label_1 = res1[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "veri_label_old_all = []\n",
    "for i in veri_label_old:\n",
    "    veri_label_old_all += veri_label_old[i]\n",
    "veri_label_old_all = torch.tensor(veri_label_old_all).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "veri_label_1_all = []\n",
    "for i in veri_label_1:\n",
    "    veri_label_1_all += veri_label_1[i]\n",
    "veri_label_1_all = torch.tensor(veri_label_1_all).reshape(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20130\n",
      "tensor(0.5288)\n"
     ]
    }
   ],
   "source": [
    "print(len(veri_label_old_all))\n",
    "print(veri_label_old_all.sum()/len(veri_label_old_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67813\n",
      "tensor(0.4861)\n"
     ]
    }
   ],
   "source": [
    "print(len(veri_label_1_all))\n",
    "print(veri_label_1_all.sum()/len(veri_label_1_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def veri_collate_fn(pad_token_id, binary=False):\n",
    "    '''padder for input batch'''\n",
    "    \n",
    "    def padder(samples):    \n",
    "        batch = {}\n",
    "        if \"embs\" in samples[0]:\n",
    "            embs = torch.stack([sample[\"embs\"] for sample in samples], dim=0)\n",
    "            batch[\"embs\"] = embs\n",
    "        \n",
    "        if \"data\" in samples[0]:\n",
    "            data = []\n",
    "            for sample in samples:\n",
    "                data.extend(sample[\"data\"])\n",
    "            data =torch.nn.utils.rnn.pad_sequence(\n",
    "                data, padding_value=pad_token_id)\n",
    "            batch[\"data\"] = data\n",
    "        if \"label\" in samples[0]:\n",
    "            label = torch.cat([sample[\"label\"] for sample in samples], dim=-1)\n",
    "            batch[\"label\"] = label\n",
    "        if \"cls_indexes\" in samples[0]:\n",
    "            i = 0\n",
    "            cls_indexes = []\n",
    "            for sample in samples:\n",
    "                for value in sample[\"cls_indexes\"]:\n",
    "                    cls_indexes.append(torch.tensor([i, value]))\n",
    "                    i += 1\n",
    "            cls_indexes = torch.stack(cls_indexes, dim=0).long()\n",
    "            batch[\"cls_indexes\"] = cls_indexes\n",
    "        return batch\n",
    "    \n",
    "    def padder_binary(samples):   \n",
    "\n",
    "        label = torch.cat([sample[\"label\"] for sample in samples], dim=-1)\n",
    "        batch = {\"label\": label}\n",
    "        if  \"data\" in samples[0]:\n",
    "            data = torch.nn.utils.rnn.pad_sequence(\n",
    "                [sample[\"data\"] for sample in samples], padding_value=pad_token_id)\n",
    "            batch[\"data\"] = data\n",
    "        if \"cls_indexes\" in samples[0]:\n",
    "            i = 0\n",
    "            cls_indexes = []\n",
    "            for sample in samples:\n",
    "                value =  sample[\"cls_indexes\"]\n",
    "                cls_indexes.append(torch.tensor([i, value]))\n",
    "                i += 1\n",
    "            cls_indexes = torch.stack(cls_indexes, dim=0).long()\n",
    "            batch[\"cls_indexes\"] = cls_indexes\n",
    "        if \"embs\" in samples[0]:\n",
    "            embs = torch.stack([sample[\"embs\"] for sample in samples], dim=0)\n",
    "            batch[\"embs\"] = embs\n",
    "        if \"logits\" in samples[0]:\n",
    "            logits = torch.stack([sample[\"logits\"] for sample in samples], dim=0)\n",
    "            batch[\"logits\"] = logits\n",
    "        return batch\n",
    "    if binary:\n",
    "        return padder_binary\n",
    "    else:\n",
    "        return padder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VerificationCompareDataset(data.Dataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            data_path: str = \"/data/zhihao/TU/Watchog/verification/gt-semtab22-dbpedia-all0_veri_data.pth\",\n",
    "            pos_ratio = None, # clone the negative samples\n",
    "            context = None,\n",
    "            ): \n",
    "        \n",
    "        self.num_neg = int((1-pos_ratio)/pos_ratio)\n",
    "        self.context = context\n",
    "        \n",
    "        data_raw = torch.load(data_path)\n",
    "        veri_label = data_raw[\"label\"]\n",
    "        veri_data = data_raw[\"data\"]\n",
    "        veri_cls_indexes = data_raw[\"cls_indexes\"]\n",
    "        veri_embs = data_raw[\"embs\"]\n",
    "        veri_target_embs = data_raw[\"target_embs\"]\n",
    "        veri_logits = data_raw[\"logits\"]\n",
    "        \n",
    "        \n",
    "        self.veri_pos_embs = defaultdict(list)\n",
    "        self.veri_neg_embs = defaultdict(list)\n",
    "        self.veri_anchor_embs = defaultdict(list)\n",
    "        \n",
    "        # self.veri_label = {}\n",
    "        # self.veri_logits = {}\n",
    "        # self.veri_cls_indexes = {}\n",
    "        # self.veri_logits = {}\n",
    "        i = 0\n",
    "        for veri_i in veri_label:\n",
    "            if 1 not in veri_label[veri_i] or 0 not in veri_label[veri_i]:\n",
    "                continue\n",
    "            # save anchor emb\n",
    "            if context is None or context == \"None\" or context == \"init\":\n",
    "                self.veri_anchor_embs[i].append(veri_embs[veri_i][0])\n",
    "            elif context == \"target\":\n",
    "                self.veri_anchor_embs[i].append(veri_target_embs[veri_i][0])        \n",
    "            else:\n",
    "                raise ValueError(\"context {} is not supported\".format(context))\n",
    "            # save pos and neg embs\n",
    "            for veri_j in range(len(veri_label[veri_i])):\n",
    "                if veri_label[veri_i][veri_j] == 1:\n",
    "                    self.veri_pos_embs[i].append(veri_embs[veri_i][veri_j])\n",
    "                else:\n",
    "                    self.veri_neg_embs[i].append(veri_embs[veri_i][veri_j])\n",
    "            i += 1\n",
    "\n",
    "        # Maintain the iteration state for each anchor\n",
    "        self.pos_iter = {anchor_idx: iter(pos_embs) for anchor_idx, pos_embs in self.veri_pos_embs.items()}\n",
    "        self.neg_iter = {anchor_idx: iter(neg_embs) for anchor_idx, neg_embs in self.veri_neg_embs.items()}\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.veri_anchor_embs)\n",
    "\n",
    "    def reset_iterators(self, anchor_idx, type=\"pos\"):\n",
    "        \"\"\"Reset the iterator for the given anchor when all positives or negatives are iterated through.\"\"\"\n",
    "        if type == \"pos\":\n",
    "            self.pos_iter[anchor_idx] = iter(self.veri_pos_embs[anchor_idx])\n",
    "            random.shuffle(self.veri_pos_embs[anchor_idx])\n",
    "        else:\n",
    "            self.neg_iter[anchor_idx] = iter(self.veri_neg_embs[anchor_idx])\n",
    "            random.shuffle(self.veri_neg_embs[anchor_idx])\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        anchor_emb = self.veri_anchor_embs[idx]\n",
    "\n",
    "        # Get one positive embedding\n",
    "        try:\n",
    "            pos_emb = next(self.pos_iter[idx])\n",
    "        except StopIteration:\n",
    "            # If we've exhausted all positives, reset and shuffle\n",
    "            self.reset_iterators(idx, type=\"pos\")\n",
    "            pos_emb = next(self.pos_iter[idx])\n",
    "\n",
    "        # Get N negative embeddings\n",
    "        neg_embs = []\n",
    "        for _ in range(self.num_neg):\n",
    "            try:\n",
    "                neg_emb = next(self.neg_iter[idx])\n",
    "                neg_embs.append(neg_emb)\n",
    "            except StopIteration:\n",
    "                # If we've exhausted all negatives, reset and shuffle\n",
    "                self.reset_iterators(idx, type=\"neg\")\n",
    "                neg_emb = next(self.neg_iter[idx])\n",
    "                neg_embs.append(neg_emb)\n",
    "        if self.context is None or self.context == \"None\":\n",
    "            embs = [pos_emb] + neg_embs\n",
    "        else:\n",
    "            embs = [anchor_emb, pos_emb] + neg_embs\n",
    "        embs = torch.stack(embs, dim=0)\n",
    "        \n",
    "        \n",
    "        \n",
    "        return {\n",
    "            # \"data\": self.veri_data[idx].reshape(-1),\n",
    "            \"embs\": embs,\n",
    "            # \"label\": self.veri_label[idx],\n",
    "            # \"logits\": self.veri_logits[idx],\n",
    "            # \"cls_indexes\": self.veri_cls_indexes[idx], \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4044608/4010096706.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data_raw = torch.load(data_path)\n"
     ]
    }
   ],
   "source": [
    "dataset_comp = VerificationCompareDataset(pos_ratio=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "veri_comp_padder = veri_collate_fn(0)\n",
    "veri_comp_dataloader = data.DataLoader(\n",
    "    dataset_comp, batch_size=5, shuffle=True, num_workers=4, collate_fn=veri_comp_padder\n",
    ")\n",
    "num = 0\n",
    "for batch_idx, batch in enumerate(veri_comp_dataloader):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2, 768])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"embs\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = nn.MultiheadAttention(embed_dim=128, num_heads=2, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = torch.randn(32, 2, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = torch.randn(32, 1, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = attention(q, embs, embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 128])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = ffn(batch[\"embs\"])\n",
    "pos_scores, neg_scores = scores[:, 0], scores[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "margin = 0.1\n",
    "loss = torch.clamp(pos_scores - neg_scores + margin, min=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'VerificationCompareDataset' object has no attribute 'anchor_embeddings'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [40]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdataset_comp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "Input \u001b[0;32mIn [38]\u001b[0m, in \u001b[0;36mVerificationCompareDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[0;32m---> 67\u001b[0m     anchor_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43manchor_embeddings\u001b[49m[idx]\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# Get one positive embedding\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'VerificationCompareDataset' object has no attribute 'anchor_embeddings'"
     ]
    }
   ],
   "source": [
    "dataset_comp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "labels_test = []\n",
    "for batch in veri_class:\n",
    "    labels_test.append(batch[0])\n",
    "sns.histplot(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, test_counts = np.unique(labels_test, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([207, 113,  42,  37,  33,  20,  12,  13,  12,  19,  11,  14,  19,\n",
       "        11,  15,  13,   9,   3,  12,  10,   8,   9,   9,   8,   9,   7,\n",
       "         5,   6,   9,   3,   4,   4,   2,   6,   5,   3,   7,   2,   5,\n",
       "         3,   4,   1,   6,   8,   8,   4,   5,   1,   5,   2,   4,   2,\n",
       "         5,   1,   2,   3,   4,   5,   1,   5,   2,   3,   2,   1,   4,\n",
       "         4,   2,   2,   1,   1,   2,   4,   3,   2,   3,   4,   4,   1,\n",
       "         3,   2,   1,   1,   1,   2,   1,   1,   1,   2,   1,   1,   1,\n",
       "         2,   3,   1,   1])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, veri_counts = np.unique(labels_all, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4340, 2331,  923,  818,  700,  425,  328,  306,  253,  519,  209,\n",
       "        295,  393,  287,  359,  334,  120,   61,  335,  272,  219,  254,\n",
       "        221,  207,  240,  183,  132,  174,  210,   87,   47,   96,   58,\n",
       "        174,  125,   56,  153,   58,  138,   69,  109,   29,  117,  188,\n",
       "        214,  116,  145,   16,  111,   40,   80,   32,  138,   16,   58,\n",
       "         44,   85,  138,   16,  145,   32,   87,   32,   29,   90,  116,\n",
       "         58,   20,   29,   29,   45,   91,   80,   58,   69,  116,  116,\n",
       "         22,   67,   58,   29,   29,   29,   58,   29,   29,   29,   58,\n",
       "         29,   29,   29,   32,   87,   22,   22])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(max(test_counts)/min(test_counts), )\n",
    "veri_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "labels_all = []\n",
    "for batch in veri_class:\n",
    "    for label in veri_class[batch]:\n",
    "        labels_all.append(label)\n",
    "sns.histplot(labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhihao/jupyterprojects/jupyter/lib/python3.8/site-packages/seaborn/_core.py:721: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  values = np.atleast_1d(np.asarray(data, dtype=object))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [98]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43msns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/jupyterprojects/jupyter/lib/python3.8/site-packages/seaborn/distributions.py:1462\u001b[0m, in \u001b[0;36mhistplot\u001b[0;34m(data, x, y, hue, weights, stat, bins, binwidth, binrange, discrete, cumulative, common_bins, common_norm, multiple, element, fill, shrink, kde, kde_kws, line_kws, thresh, pthresh, pmax, cbar, cbar_ax, cbar_kws, palette, hue_order, hue_norm, color, log_scale, legend, ax, **kwargs)\u001b[0m\n\u001b[1;32m   1451\u001b[0m estimate_kws \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m   1452\u001b[0m     stat\u001b[38;5;241m=\u001b[39mstat,\n\u001b[1;32m   1453\u001b[0m     bins\u001b[38;5;241m=\u001b[39mbins,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1457\u001b[0m     cumulative\u001b[38;5;241m=\u001b[39mcumulative,\n\u001b[1;32m   1458\u001b[0m )\n\u001b[1;32m   1460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39munivariate:\n\u001b[0;32m-> 1462\u001b[0m     \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_univariate_histogram\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmultiple\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmultiple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[43m        \u001b[49m\u001b[43melement\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43melement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1465\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1466\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshrink\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshrink\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1467\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcommon_norm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommon_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1468\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcommon_bins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommon_bins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkde\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkde\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1470\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkde_kws\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkde_kws\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1471\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1472\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlegend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlegend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1473\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimate_kws\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimate_kws\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1474\u001b[0m \u001b[43m        \u001b[49m\u001b[43mline_kws\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mline_kws\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1475\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1476\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1480\u001b[0m     p\u001b[38;5;241m.\u001b[39mplot_bivariate_histogram(\n\u001b[1;32m   1481\u001b[0m         common_bins\u001b[38;5;241m=\u001b[39mcommon_bins,\n\u001b[1;32m   1482\u001b[0m         common_norm\u001b[38;5;241m=\u001b[39mcommon_norm,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1492\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1493\u001b[0m     )\n",
      "File \u001b[0;32m~/jupyterprojects/jupyter/lib/python3.8/site-packages/seaborn/distributions.py:428\u001b[0m, in \u001b[0;36m_DistributionPlotter.plot_univariate_histogram\u001b[0;34m(self, multiple, element, fill, common_norm, common_bins, shrink, kde, kde_kws, color, legend, line_kws, estimate_kws, **plot_kws)\u001b[0m\n\u001b[1;32m    418\u001b[0m     densities \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_univariate_density(\n\u001b[1;32m    419\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_variable,\n\u001b[1;32m    420\u001b[0m         common_norm,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    424\u001b[0m         warn_singular\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    425\u001b[0m     )\n\u001b[1;32m    427\u001b[0m \u001b[38;5;66;03m# First pass through the data to compute the histograms\u001b[39;00m\n\u001b[0;32m--> 428\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sub_vars, sub_data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_data(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhue\u001b[39m\u001b[38;5;124m\"\u001b[39m, from_comp_data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    429\u001b[0m \n\u001b[1;32m    430\u001b[0m     \u001b[38;5;66;03m# Prepare the relevant data\u001b[39;00m\n\u001b[1;32m    431\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(sub_vars\u001b[38;5;241m.\u001b[39mitems())\n\u001b[1;32m    432\u001b[0m     sub_data \u001b[38;5;241m=\u001b[39m sub_data\u001b[38;5;241m.\u001b[39mdropna()\n",
      "File \u001b[0;32m~/jupyterprojects/jupyter/lib/python3.8/site-packages/seaborn/_core.py:997\u001b[0m, in \u001b[0;36mVectorPlotter.iter_data\u001b[0;34m(self, grouping_vars, reverse, from_comp_data)\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m grouping_vars:\n\u001b[1;32m    995\u001b[0m     grouping_keys\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvar_levels\u001b[38;5;241m.\u001b[39mget(var, []))\n\u001b[0;32m--> 997\u001b[0m iter_keys \u001b[38;5;241m=\u001b[39m \u001b[43mitertools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgrouping_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    998\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reverse:\n\u001b[1;32m    999\u001b[0m     iter_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mlist\u001b[39m(iter_keys))\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20130"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs_temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 378])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_batch_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_indexes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 504])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"data\"].T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in veri_data:\n",
    "    assert len(veri_data[i]) == len(veri_label[i]) == len(veri_cls_indexes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_drop_idx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [211]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtest_drop_idx\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_drop_idx' is not defined"
     ]
    }
   ],
   "source": [
    "test_drop_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Threshold: 1.5****************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4044608/1425838558.py:55: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
      "/tmp/ipykernel_4044608/1425838558.py:107: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n"
     ]
    }
   ],
   "source": [
    "# brute force perumate in validation TODO: restrict mamimus length of permutation\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "import torch.nn.functional as F\n",
    "test_data = defaultdict(list)\n",
    "test_logits = defaultdict(list)\n",
    "test_cls_indexes = defaultdict(list)\n",
    "test_target_col_mask = defaultdict(list)\n",
    "test_embs = defaultdict(list)\n",
    "test_col_num = defaultdict(list)\n",
    "test_label = defaultdict(list)\n",
    "test_class = defaultdict(list)\n",
    "test_target_embs = defaultdict(list)\n",
    "test_drop_idx = defaultdict(list)\n",
    "    \n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "change_log = []\n",
    "score_init = []\n",
    "score_best = [] \n",
    "for threshold in [1.5]:\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    ft_embs_test = []\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    log = defaultdict(list)\n",
    "    num_cols = []\n",
    "    corrected = 0\n",
    "    total_mistakes = 0\n",
    "    num_permutations = {}\n",
    "    init_permutation = {}\n",
    "    init_correctness = {}\n",
    "    score_init = {}\n",
    "    score_permutation = defaultdict(list)\n",
    "    permutation_correctness = defaultdict(list)\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "            cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "            target_col_mask = batch[\"target_col_mask\"].T\n",
    "            logits = model(batch[\"data\"].T, cls_indexes=cls_indexes,)\n",
    "            score_init[batch_idx] = F.softmax(logits.detach()).max().item()\n",
    "            label_i = batch[\"label\"].item()\n",
    "            predict_init = logits.argmax().item()\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            init_permutation[batch_idx] = init_permutation_i\n",
    "            if predict_init == label_i:\n",
    "                init_correctness[batch_idx] = True\n",
    "            else:\n",
    "                init_correctness[batch_idx] = False\n",
    "            num_permutations[batch_idx] = 0\n",
    "\n",
    "\n",
    "            x = [0]\n",
    "            new_batch_data = []\n",
    "            for col_i in x:\n",
    "                if col_i == 0:\n",
    "                    if len(new_batch_data) == 0:\n",
    "                        cls_indexes_value = 0\n",
    "                    else:\n",
    "                        cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "            new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "            cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "            logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "            test_target_embs[batch_idx].append(embs_temp.cpu())\n",
    "\n",
    "\n",
    "            num_cols.append(len(init_permutation_i))\n",
    "            labels_test.append(batch[\"label\"].cpu())\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            assert -1 not in col_idx_set\n",
    "            for r in range(len(init_permutation_i), len(init_permutation_i)-2, -1): # not \n",
    "                for x in itertools.combinations(init_permutation_i, r):\n",
    "                    if 0 not in x:\n",
    "                        continue\n",
    "\n",
    "                    num_permutations[batch_idx] += 1\n",
    "                    new_batch_data = []\n",
    "                    if len(x) != len(init_permutation_i):\n",
    "                        drop_idx = (set(init_permutation_i)-set(x)).pop()\n",
    "                    else:\n",
    "                        drop_idx = -1\n",
    "                    for col_i in x:\n",
    "                        if col_i == 0:\n",
    "                            if len(new_batch_data) == 0:\n",
    "                                cls_indexes_value = 0\n",
    "                            else:\n",
    "                                cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                        new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                    new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                    cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                    logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                    ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n",
    "                    score_permutation[batch_idx].append(ood_score_temp)\n",
    "                    predict_temp = logits_temp.argmax().item()\n",
    "                    permutation_correctness[batch_idx].append(predict_temp == label_i)\n",
    "                    \n",
    "                    test_data[batch_idx].append(new_batch_data.cpu())\n",
    "                    test_logits[batch_idx].append(logits_temp.detach().cpu())\n",
    "                    test_cls_indexes[batch_idx].append(cls_indexes_value)\n",
    "                    test_embs[batch_idx].append(embs_temp.cpu())\n",
    "                    test_col_num[batch_idx].append(len(x))\n",
    "                    test_label[batch_idx].append(torch.tensor(predict_temp == label_i).long()) # indicate whether the permutation is correct or not\n",
    "                    test_class[batch_idx].append(label_i)\n",
    "                    test_drop_idx[batch_idx].append(drop_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"/data/zhihao/TU/Watchog/verification\", exist_ok=True)\n",
    "torch.save({\"data\": test_data, \"logits\": test_logits, \"cls_indexes\": test_cls_indexes, \n",
    "            \"embs\": test_embs, \"target_embs\":test_target_embs, \"col_num\": test_col_num, \"label\": test_label, \"class\": test_class}, f\"/data/zhihao/TU/Watchog/verification/{args.task}_test_data_drop_0.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1276939/872819949.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  test_veri = torch.load(f\"/data/zhihao/TU/Watchog/verification/{args.task}_test_data.pth\")\n"
     ]
    }
   ],
   "source": [
    "test_veri = torch.load(f\"/data/zhihao/TU/Watchog/verification/{args.task}_test_data.pth\")\n",
    "test_data = test_veri[\"data\"]\n",
    "test_logits = test_veri[\"logits\"]\n",
    "test_cls_indexes = test_veri[\"cls_indexes\"]\n",
    "test_embs = test_veri[\"embs\"]\n",
    "test_col_num = test_veri[\"col_num\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_col_num[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test = []\n",
    "logits_test = []\n",
    "col_scores = defaultdict(list)\n",
    "verifier = Verifier(norm=\"batch_norm\").to(device)\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "        embs = test_embs[batch_idx][0].reshape(-1).to(device)\n",
    "        logits = test_logits[batch_idx][0].reshape(-1).to(device)\n",
    "        # scores_init = verifier(embs)\n",
    "        max_score = -float(\"inf\")\n",
    "        target_col_mask = batch[\"target_col_mask\"].T\n",
    "        init_permutation_i = get_permutation(target_col_mask)\n",
    "        num_cols_to_drop = min(2, len(init_permutation_i)//2)\n",
    "        if len(init_permutation_i) ==1:\n",
    "            labels_test.append(batch[\"label\"].cpu())\n",
    "            logits_test.append(logits.detach().cpu())\n",
    "            continue\n",
    "        \n",
    "        for i in range(1, len(test_embs[batch_idx])):\n",
    "            logits_temp = test_logits[batch_idx][i].reshape(-1).to(device)\n",
    "            embs_temp = test_embs[batch_idx][i].reshape(-1).to(device)\n",
    "\n",
    "            scores_temp = np.random.rand()\n",
    "            predict_temp = logits_temp.argmax().item()\n",
    "            col_scores[batch_idx].append(scores_temp)\n",
    "            \n",
    "            \n",
    "        cols_to_drop = torch.tensor(col_scores[batch_idx]).argsort()[:num_cols_to_drop]\n",
    "        x = deepcopy(init_permutation_i)\n",
    "        for col_i in cols_to_drop:\n",
    "            x.remove(col_i)\n",
    "        new_batch_data = []\n",
    "        if len(x) != len(init_permutation_i):\n",
    "            drop_idx = (set(init_permutation_i)-set(x)).pop()\n",
    "        else:\n",
    "            drop_idx = -1\n",
    "        for col_i in x:\n",
    "            if col_i == 0:\n",
    "                if len(new_batch_data) == 0:\n",
    "                    cls_indexes_value = 0\n",
    "                else:\n",
    "                    cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "            new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "        new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "        cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "        logits_topk, embs_topk = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "        if len(init_permutation_i) > 4: \n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 5, 6, 0, 7]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cols_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2])"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_permutation_i = torch.tensor(init_permutation_i)\n",
    "init_permutation_i[init_permutation_i!=0][:num_cols_to_drop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 5, 6, 1, 0, 2, 4])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(col_scores[batch_idx]).argsort(descending=True)[: ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(col_scores[batch_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(init_permutation_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_idx = (set(init_permutation_i)-set(x)).pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1085"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1085"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"/data/zhihao/TU/Watchog/verification\", exist_ok=True)\n",
    "torch.save({\"data\": test_data, \"logits\": test_logits, \"cls_indexes\": test_cls_indexes, \n",
    "            \"embs\": test_embs, \"target_embs\":test_target_embs, \"col_num\": test_col_num, \"label\": test_label, \"class\": test_class}, f\"/data/zhihao/TU/Watchog/verification/{args.task}_test_data_2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405\n"
     ]
    }
   ],
   "source": [
    "for i, r in enumerate(test_dataloader_iter):\n",
    "    try:\n",
    "        res = test_embs[i][0]\n",
    "    except:\n",
    "        print(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gt-semtab22-dbpedia-all0'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = torch.load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gt-semtab22-dbpedia-all0'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5288)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels = []\n",
    "for i in veri_label:\n",
    "    all_labels.extend(veri_label[i])\n",
    "all_labels = torch.tensor(all_labels).reshape(-1)\n",
    "all_labels.sum()/len(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veri_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VerificationDataset(data.Dataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            data_path: str = \"/data/zhihao/TU/Watchog/verification/veri_data.pth\",\n",
    "            max_list_length: int = 10,\n",
    "            pos_ratio : int = 0.5, # None: only control pos_ratio to be less than 0.5\n",
    "            label_padding_value: int = -1,\n",
    "            data_padding_value: int = 0,\n",
    "            ): \n",
    "        data_raw = torch.load(data_path)\n",
    "        veri_label = data_raw[\"label\"]\n",
    "        veri_data = data_raw[\"data\"]\n",
    "        veri_cls_indexes = data_raw[\"cls_indexes\"]\n",
    "        self.label_padding_value = label_padding_value\n",
    "        self.data_padding_value = data_padding_value\n",
    "        self.max_list_length = max_list_length\n",
    "        self.pos_ratio = pos_ratio\n",
    "        self.veri_label = {}\n",
    "        self.veri_data = {}\n",
    "        self.veri_cls_indexes = {}\n",
    "        i = 0\n",
    "        for veri_i in veri_label:\n",
    "            labels_i = torch.tensor(veri_label[veri_i]).reshape(-1)\n",
    "            \n",
    "            if 0 not in labels_i or 1 not in labels_i:\n",
    "                continue\n",
    "            self.veri_data[i] = veri_data[veri_i]\n",
    "            self.veri_label[i] = labels_i\n",
    "            self.veri_cls_indexes[i] = veri_cls_indexes[veri_i]\n",
    "            i += 1\n",
    "    def sample(self, labels):\n",
    "        labels = labels.tolist()  # Convert tensor to list for easier manipulation\n",
    "        positive_indices = [i for i, label in enumerate(labels) if label == 1]\n",
    "        negative_indices = [i for i, label in enumerate(labels) if label == 0]\n",
    "\n",
    "        # Determine how many positives we can sample, respecting the ratio requirement\n",
    "        max_num_positives = max_num_negatives = min(len(positive_indices), len(negative_indices), self.max_list_length // 2)\n",
    "        \n",
    "        # Randomly sample the positives and negatives\n",
    "        sampled_positives = random.sample(positive_indices, max_num_positives)\n",
    "        sampled_negatives = random.sample(negative_indices, max_num_negatives)\n",
    "\n",
    "        # Combine and shuffle the indices\n",
    "        sampled_indices = sampled_positives + sampled_negatives\n",
    "\n",
    "        return sampled_indices\n",
    "        # {\"data\": veri_data, \"label\": veri_label, \"cls_indexes\": veri_cls_indexes}\n",
    "    def __len__(self):\n",
    "        return len(self.veri_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        labels = self.veri_label[idx]\n",
    "        sampled_indices = self.sample(labels)\n",
    "        sampled_labels = torch.tensor([labels[i] for i in sampled_indices]).reshape(-1)\n",
    "        sampled_data = [self.veri_data[idx][i].reshape(-1) for i in sampled_indices]\n",
    "        sampled_cls_indexes = torch.tensor([self.veri_cls_indexes[idx][i] for i in sampled_indices], dtype=torch.long)\n",
    "        if len(sampled_indices) < self.max_list_length:\n",
    "            sampled_labels = torch.cat([sampled_labels, torch.ones(self.max_list_length - len(sampled_labels))*self.label_padding_value])\n",
    "            sampled_data.extend([torch.tensor([self.data_padding_value]) for _ in range(self.max_list_length - len(sampled_data))])\n",
    "            sampled_cls_indexes = torch.cat([sampled_cls_indexes, torch.zeros(self.max_list_length - len(sampled_cls_indexes))])\n",
    "        return {\n",
    "            \"data\": sampled_data,\n",
    "            \"label\": sampled_labels,\n",
    "            \"cls_indexes\": sampled_cls_indexes, \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VerificationBinaryDataset(data.Dataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            data_path: str = \"/data/zhihao/TU/Watchog/verification/veri_data.pth\",\n",
    "            pos_ratio = None, # clone the negative samples\n",
    "            ): \n",
    "        data_raw = torch.load(data_path)\n",
    "        veri_label = data_raw[\"label\"]\n",
    "        veri_data = data_raw[\"data\"]\n",
    "        veri_cls_indexes = data_raw[\"cls_indexes\"]\n",
    "        veri_embs = data_raw[\"embs\"]\n",
    "        veri_logits = data_raw[\"logits\"]\n",
    "        self.neg_expand = int(1/pos_ratio)-1 if pos_ratio is not None else 1\n",
    "        self.veri_label = {}\n",
    "        self.veri_data = {}\n",
    "        self.veri_embs = {}\n",
    "        self.veri_cls_indexes = {}\n",
    "        self.veri_logits = {}\n",
    "        i = 0\n",
    "        for veri_i in veri_label:\n",
    "            for veri_j in range(len(veri_label[veri_i])):\n",
    "                if veri_label[veri_i][veri_j] == 1:\n",
    "                    labels_i = torch.tensor([1]).reshape(-1)\n",
    "                    self.veri_data[i] = veri_data[veri_i][veri_j]\n",
    "                    self.veri_label[i] = labels_i\n",
    "                    self.veri_cls_indexes[i] = veri_cls_indexes[veri_i][veri_j]\n",
    "                    self.veri_embs[i] = veri_embs[veri_i][veri_j]\n",
    "                    self.veri_logits[i] = veri_logits[veri_i][veri_j]\n",
    "                    i += 1\n",
    "                else:\n",
    "                    for _ in range(self.neg_expand):\n",
    "                        labels_i = torch.tensor([0]).reshape(-1)\n",
    "                        self.veri_data[i] = veri_data[veri_i][veri_j]\n",
    "                        self.veri_label[i] = labels_i\n",
    "                        self.veri_cls_indexes[i] = veri_cls_indexes[veri_i][veri_j]\n",
    "                        self.veri_embs[i] = veri_embs[veri_i][veri_j]\n",
    "                        self.veri_logits[i] = veri_logits[veri_i][veri_j]\n",
    "                        i += 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.veri_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            # \"data\": self.veri_data[idx].reshape(-1),\n",
    "            \"embs\": self.veri_embs[idx].reshape(-1),\n",
    "            \"label\": self.veri_label[idx],\n",
    "            \"logits\": self.veri_logits[idx],\n",
    "            # \"cls_indexes\": self.veri_cls_indexes[idx], \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'veri_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mveri_dataset\u001b[49m), \u001b[38;5;28mlen\u001b[39m(veri_dataset\u001b[38;5;241m.\u001b[39mveri_data), \u001b[38;5;28mlen\u001b[39m(veri_dataset\u001b[38;5;241m.\u001b[39mveri_label), \u001b[38;5;28mlen\u001b[39m(veri_dataset\u001b[38;5;241m.\u001b[39mveri_cls_indexes))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'veri_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "print(len(veri_dataset), len(veri_dataset.veri_data), len(veri_dataset.veri_label), len(veri_dataset.veri_cls_indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1072582/3275163660.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data_raw = torch.load(data_path)\n"
     ]
    }
   ],
   "source": [
    "verit_binary_dataset = VerificationBinaryDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48583"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(verit_binary_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.nn.utils.rnn.pad_sequence(\n",
    "            [verit_binary_dataset[i][\"data\"] for i in range(10)], padding_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verit_binary_dataset[0][\"embs\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "verit_labels = []\n",
    "for i in range(len(verit_binary_dataset)):\n",
    "    verit_labels.append(verit_binary_dataset[i][\"label\"].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2191)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(verit_labels).sum()/len(verit_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(veri_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_345769/3192291341.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data_raw = torch.load(data_path)\n"
     ]
    }
   ],
   "source": [
    "veri_dataset = VerificationDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(veri_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = veri_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res[\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([352])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"data\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"label\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = []\n",
    "for i in range(len(veri_dataset)):\n",
    "    data_test.extend(veri_dataset[i][\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2500"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def veri_collate_fn(pad_token_id, binary=False):\n",
    "    '''padder for input batch'''\n",
    "    \n",
    "    def padder(samples):    \n",
    "        data = []\n",
    "        for sample in samples:\n",
    "            data.extend(sample[\"data\"])\n",
    "        data =torch.nn.utils.rnn.pad_sequence(\n",
    "            data, padding_value=pad_token_id)\n",
    "\n",
    "        label = torch.cat([sample[\"label\"] for sample in samples], dim=-1)\n",
    "        batch = {\"data\": data, \"label\": label}\n",
    "        if \"cls_indexes\" in samples[0]:\n",
    "            i = 0\n",
    "            cls_indexes = []\n",
    "            for sample in samples:\n",
    "                for value in sample[\"cls_indexes\"]:\n",
    "                    cls_indexes.append(torch.tensor([i, value]))\n",
    "                    i += 1\n",
    "            cls_indexes = torch.stack(cls_indexes, dim=0).long()\n",
    "            batch[\"cls_indexes\"] = cls_indexes\n",
    "        return batch\n",
    "    \n",
    "    def padder_binary(samples):   \n",
    "\n",
    "        label = torch.cat([sample[\"label\"] for sample in samples], dim=-1)\n",
    "        batch = {\"label\": label}\n",
    "        if  \"data\" in samples[0]:\n",
    "            data = torch.nn.utils.rnn.pad_sequence(\n",
    "                [sample[\"data\"] for sample in samples], padding_value=pad_token_id)\n",
    "            batch[\"data\"] = data\n",
    "        if \"cls_indexes\" in samples[0]:\n",
    "            i = 0\n",
    "            cls_indexes = []\n",
    "            for sample in samples:\n",
    "                value =  sample[\"cls_indexes\"]\n",
    "                cls_indexes.append(torch.tensor([i, value]))\n",
    "                i += 1\n",
    "            cls_indexes = torch.stack(cls_indexes, dim=0).long()\n",
    "            batch[\"cls_indexes\"] = cls_indexes\n",
    "        if \"embs\" in samples[0]:\n",
    "            embs = torch.stack([sample[\"embs\"] for sample in samples], dim=0)\n",
    "            batch[\"embs\"] = embs\n",
    "        if \"logits\" in samples[0]:\n",
    "            logits = torch.stack([sample[\"logits\"] for sample in samples], dim=0)\n",
    "            batch[\"logits\"] = logits\n",
    "        return batch\n",
    "    if binary:\n",
    "        return padder_binary\n",
    "    else:\n",
    "        return padder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'veri_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m veri_padder \u001b[38;5;241m=\u001b[39m veri_collate_fn(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      2\u001b[0m veri_dataloader \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mDataLoader(\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mveri_dataset\u001b[49m, batch_size\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, collate_fn\u001b[38;5;241m=\u001b[39mveri_padder\n\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m veri_dataloader:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'veri_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "veri_padder = veri_collate_fn(0)\n",
    "veri_dataloader = data.DataLoader(\n",
    "    veri_dataset, batch_size=args.batch_size, shuffle=True, num_workers=4, collate_fn=veri_padder\n",
    ")\n",
    "for batch in veri_dataloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "veri_binary_padder = veri_collate_fn(0, binary=True)\n",
    "veri_binary_dataloader = data.DataLoader(\n",
    "    verit_binary_dataset, batch_size=args.batch_size, shuffle=True, num_workers=4, collate_fn=veri_binary_padder\n",
    ")\n",
    "for batch_idx, batch in enumerate(veri_binary_dataloader):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 768])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"embs\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 101])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"logits\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"label\"].to(device).squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model = model.to(device)\n",
    "verifier.train()\n",
    "verifier = verifier.to(device)\n",
    "pos_ratio = 0.1\n",
    "pos_weight = torch.tensor([(1-pos_ratio)/pos_ratio]).to(device)\n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "for batch_idx, batch in enumerate(veri_binary_dataloader ):\n",
    "    cls_indexes = batch[\"cls_indexes\"].to(device)\n",
    "    input_data = batch[\"data\"].T.to(device)\n",
    "    logits, embs = model(input_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "    scores = verifier(embs).squeeze()\n",
    "    loss = loss_fn(scores, batch[\"label\"].to(device).squeeze().float())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " batch[\"label\"].to(device).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([378, 3])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"data\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([365, 30])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"data\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"label\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 2])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"cls_indexes\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "verifier = Verifier(norm=\"batch_norm\", num_layers=None).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1276939/1693025953.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  veri_state_dict = torch.load(\"/data/zhihao/TU/Watchog/outputs/gt-semtab22-dbpedia-all0/bert-base-uncased-fromscratch-semi1-mode@ffn-context@None-data@5-lr@5e-05-warmup@0.0-dp@0.0-norm@batch_norm-pos@0.1-poolv0-unlabeled8-randFalse-bs64-ml128-ne200-do0.0_verifier_binary_best_f1_micro.pt\")\n"
     ]
    }
   ],
   "source": [
    "# veri_state_dict = torch.load(\"/data/zhihao/TU/Watchog/outputs/gt-semtab22-dbpedia-all0/bert-base-uncased-fromscratch-semi1-mode@ffn-context@None-data@5-lr@5e-05-warmup@0.0-dp@0.0-norm@batch_norm-pos@0.1-poolv0-unlabeled8-randFalse-bs64-ml128-ne200-do0.0_verifier_binary_best_f1_macro.pt\")\n",
    "# veri_state_dict = torch.load(\"/data/zhihao/TU/Watchog/outputs/gt-semtab22-dbpedia-all0/bert-base-uncased-fromscratch-semi1-mode@ffn-context@None-data@5-lr@5e-05-warmup@0.0-dp@0.0-norm@batch_norm-pos@0.2-poolv0-unlabeled8-randFalse-bs64-ml128-ne200-do0.0_verifier_binary_best_f1_micro.pt\")\n",
    "veri_state_dict = torch.load(\"/data/zhihao/TU/Watchog/outputs/gt-semtab22-dbpedia-all0/bert-base-uncased-fromscratch-semi1-mode@ffn-context@None-data@5-lr@5e-05-warmup@0.0-dp@0.0-norm@batch_norm-pos@0.1-poolv0-unlabeled8-randFalse-bs64-ml128-ne200-do0.0_verifier_binary_best_f1_micro.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verifier.load_state_dict(veri_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Verifier(\n",
       "  (ffn): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (1): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): SiLU()\n",
       "    (3): Dropout(p=0.0, inplace=False)\n",
       "    (4): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (5): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): SiLU()\n",
       "    (7): Dropout(p=0.0, inplace=False)\n",
       "    (8): Linear(in_features=768, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verifier.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhihao/jupyterprojects/jupyter/lib/python3.8/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(verifier.parameters(), lr=args.lr, eps=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.to(device)\n",
    "verifier.train()\n",
    "tr_loss = 0.0\n",
    "for batch_idx, batch in enumerate(veri_dataloader):\n",
    "    cls_indexes = batch[\"cls_indexes\"].to(device)\n",
    "    input_data = batch[\"data\"].T.to(device)\n",
    "    logits, embs = model(input_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "    scores = verifier(embs)\n",
    "    loss = listMLE(scores.reshape(args.batch_size, -1), batch[\"label\"].to(device).reshape(args.batch_size, -1))\n",
    "\n",
    "    accelerator.backward(loss)\n",
    "    # loss.backward()\n",
    "    tr_loss += loss.cpu().detach().item()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def listMLE(y_pred, y_true, eps=1e-10, padded_value_indicator=-1):\n",
    "    \"\"\"\n",
    "    ListMLE loss introduced in \"Listwise Approach to Learning to Rank - Theory and Algorithm\".\n",
    "    :param y_pred: predictions from the model, shape [batch_size, slate_length]\n",
    "    :param y_true: ground truth labels, shape [batch_size, slate_length]\n",
    "    :param eps: epsilon value, used for numerical stability\n",
    "    :param padded_value_indicator: an indicator of the y_true index containing a padded item, e.g. -1\n",
    "    :return: loss value, a torch.Tensor\n",
    "    \"\"\"\n",
    "    # shuffle for randomised tie resolution\n",
    "    random_indices = torch.randperm(y_pred.shape[-1])\n",
    "    y_pred_shuffled = y_pred[:, random_indices]\n",
    "    y_true_shuffled = y_true[:, random_indices]\n",
    "\n",
    "    y_true_sorted, indices = y_true_shuffled.sort(descending=True, dim=-1)\n",
    "\n",
    "    mask = y_true_sorted == padded_value_indicator\n",
    "\n",
    "    preds_sorted_by_true = torch.gather(y_pred_shuffled, dim=1, index=indices)\n",
    "    preds_sorted_by_true[mask] = float(\"-inf\")\n",
    "\n",
    "    max_pred_values, _ = preds_sorted_by_true.max(dim=1, keepdim=True)\n",
    "\n",
    "    preds_sorted_by_true_minus_max = preds_sorted_by_true - max_pred_values\n",
    "\n",
    "    cumsums = torch.cumsum(preds_sorted_by_true_minus_max.exp().flip(dims=[1]), dim=1).flip(dims=[1])\n",
    "\n",
    "    observation_loss = torch.log(cumsums + eps) - preds_sorted_by_true_minus_max\n",
    "\n",
    "    observation_loss[mask] = 0.0\n",
    "\n",
    "    return torch.mean(torch.sum(observation_loss, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.9761, device='cuda:2', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "\n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "verifier.eval()\n",
    "verifier = verifier.to(device)\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "init_scores = []\n",
    "init_correctness = []\n",
    "final_scores = []\n",
    "final_correctness = []\n",
    "\n",
    "for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "    cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "    target_col_mask = batch[\"target_col_mask\"].T\n",
    "    logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "    scores_init = verifier(embs)\n",
    "    max_score = -float(\"inf\")\n",
    "    if 1 in target_col_mask:\n",
    "        init_scores.append(scores_init.item())\n",
    "        init_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "        init_permutation_i = get_permutation(target_col_mask)\n",
    "        col_idx_set = target_col_mask.unique().tolist()\n",
    "        early_stop = False\n",
    "        assert -1 not in col_idx_set\n",
    "        for r in range(len(init_permutation_i), max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "            for x in itertools.combinations(init_permutation_i, r):\n",
    "                if 0 not in x:\n",
    "                    continue\n",
    "                new_batch_data = []\n",
    "                for col_i in x:\n",
    "                    if col_i == 0:\n",
    "                        if len(new_batch_data) == 0:\n",
    "                            cls_indexes_value = 0\n",
    "                        else:\n",
    "                            cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                    new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                if 0 not in x:\n",
    "                    cls_indexes_value = 0\n",
    "                new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                logits_temp, embs = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                scores_temp = verifier(embs).item()\n",
    "                predict_temp = logits_temp.argmax().item()\n",
    "                    # if len(x) == 1 and 0 in x:\n",
    "                    #     predict_target = predict_temp\n",
    "                    #     msp_target = msp_temp\n",
    "                    # # print(x, msp_temp, predict_temp)\n",
    "                    # if 0 not in x and msp_temp > debias_threshold and (predict_temp != predict_target):\n",
    "                    #     debias_classes.append(predict_temp)\n",
    "                    #     continue\n",
    "                if scores_temp > max_score:\n",
    "                    max_score = scores_temp\n",
    "                    logits = logits_temp.clone()\n",
    "        final_scores.append(max_score)\n",
    "        final_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "    labels_test.append(batch[\"label\"].cpu())\n",
    "    logits_test.append(logits.detach().cpu())\n",
    "labels_test = torch.cat(labels_test, dim=0)\n",
    "logits_test = torch.stack(logits_test, dim=0)\n",
    "preds_test = torch.argmax(logits_test, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_correctness = torch.tensor(init_correctness)\n",
    "final_correctness = torch.tensor(final_correctness)\n",
    "init_scores = torch.tensor(init_scores)\n",
    "final_scores = torch.tensor(final_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(637)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(init_correctness | final_correctness).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAD4CAYAAAAD6PrjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAASwklEQVR4nO3df7DldV3H8ecrNvyR2Yrctju70KUkCwyVuRJGOeoaoZG7NUY4hWTYjoqk5UQgU/6jM1SOiv2w2YDEiZGQUCh/BKHpNBPYBRFEtBgM2Z2Le0tp16yYbd/9cb58vW73x7l37znfc+59Pmbu3HM+3+8557U7d/d1v5/vr1QVkiQBfEfXASRJo8NSkCS1LAVJUstSkCS1LAVJUmtT1wGOxLHHHltTU1Ndx5CksXLnnXf+W1VNLLRsrEthamqKmZmZrmNI0lhJ8tBiy5w+kiS1LAVJUstSkCS1LAVJUstSkCS1LAVJUstSkCS1LAVJUstSkCS1xvqMZqkrJ5/yHGZnZ5dcZ3JykvvuuXs4gaQ1YilIqzA7O8uZb//wkuvcctnOoWSR1pLTR5KklqUgSWpZCpKklvsUpMP0sxN5/4EDQ0ojDZelIB2mn53IH3zDi4cTRhoyp48kSa2BlUKSq5PsS/L5BZa9OUklObZ5niTvSfJAknuSnDqoXJKkxQ1yS+F9wFmHDyY5DjgT+Mq84ZcCJzZfu4D3DjCXJGkRAyuFqvo08LUFFr0LuBioeWM7gPdXz+3A5iSTg8omSVrYUPcpJNkB7K2qzx22aCvw8Lzne5qxhd5jV5KZJDNzc3MDSipJG9PQSiHJk4G3AL97JO9TVburarqqpicmJtYmnCQJGO4hqT8InAB8LgnANuCuJKcBe4Hj5q27rRmTJA3R0LYUqureqvreqpqqqil6U0SnVtUjwM3Aq5qjkE4H/qOqlj57SJK05gZ5SOoHgH8EnplkT5ILllj9o8CDwAPAnwGvH1QuSdLiBjZ9VFWvXGb51LzHBVw4qCySpP54RrMkqWUpSJJaloIkqWUpSJJaloIkqWUpSJJaloIkqWUpSJJaloIkqWUpSJJaloIkqWUpSJJaloIkqWUpSJJaloIkqWUpSJJaloIkqWUpSJJaloIkqTWwUkhydZJ9ST4/b+wPknwxyT1JPpRk87xllyZ5IMmXkvz0oHJJkhY3yC2F9wFnHTZ2K/CsqjoF+GfgUoAkJwHnAic3r/mTJEcNMJskaQEDK4Wq+jTwtcPGbqmqg83T24FtzeMdwHVV9T9V9WXgAeC0QWWTJC2sy30Kvwp8rHm8FXh43rI9zdj/k2RXkpkkM3NzcwOOKEkbSyelkOQy4CBw7UpfW1W7q2q6qqYnJibWPpwkbWCbhv2BSX4FOBvYXlXVDO8Fjpu32rZmTJI0REPdUkhyFnAx8PKq+ua8RTcD5yZ5QpITgBOBzwwzmyRpgFsKST4AvBA4Nske4K30jjZ6AnBrEoDbq+q1VXVfkuuBL9CbVrqwqv53UNkkSQsbWClU1SsXGL5qifXfDrx9UHkkScvzjGZJUstSkCS1LAVJUstSkCS1LAVJUstSkCS1LAVJUstSkCS1LAVJUstSkCS1LAVJUstSkCS1LAVJUstSkCS1LAVJUstSkCS1LAVJUstSkCS1LAVJUmtgpZDk6iT7knx+3tgxSW5N8i/N96c140nyniQPJLknyamDyiVJWtwgtxTeB5x12NglwG1VdSJwW/Mc4KXAic3XLuC9A8wlSVrEwEqhqj4NfO2w4R3ANc3ja4Cd88bfXz23A5uTTA4qmyRpYcPep7Clqmabx48AW5rHW4GH5623pxn7f5LsSjKTZGZubm5wSSVpA+psR3NVFVCreN3uqpququmJiYkBJJOkjWvYpfDVx6eFmu/7mvG9wHHz1tvWjEmShmjYpXAzcH7z+Hzgpnnjr2qOQjod+I9500ySpCHZNKg3TvIB4IXAsUn2AG8FLgeuT3IB8BBwTrP6R4GXAQ8A3wRePahckqTFDawUquqViyzavsC6BVw4qCySpP54RrMkqWUpSJJaloIkqWUpSJJaloIkqWUpSJJaloIkqWUpSJJaAzt5Tdro9h/4BsdMbFlyncnJSe675+7hBJL6YClIA1KHDnHm2z+85Dq3XLZzKFmkfjl9JElqWQqSpJalIElq9VUKSc7oZ0ySNN763VL4wz7HJEljbMmjj5I8H/hxYCLJb85b9FTgqEEGkyQN33KHpB4NPKVZ77vnje8HXjGoUJKkbixZClX1KeBTSd5XVQ8NKZMkqSP9nrz2hCS7gan5r6mqFw8ilCSpG/2WwgeBPwWuBP73SD80yW8ArwEKuBd4NTAJXAc8HbgTOK+qHjvSz5Ik9a/fo48OVtV7q+ozVXXn41+r+cAkW4FfB6ar6ln0dlifC/we8K6qegbwdeCC1by/JGn1+i2Fv07y+iSTSY55/OsIPncT8KQkm4AnA7PAi4EbmuXXADuP4P0lSavQ7/TR+c3335o3VsAPrPQDq2pvkncAXwH+C7iF3nTRo1V1sFltD7B1odcn2QXsAjj++ONX+vGSpCX0VQpVdcJafWCSpwE7gBOAR+ntrzir39dX1W5gN8D09HStVS5JUp+lkORVC41X1ftX8ZkvAb5cVXPNe98InAFsTrKp2VrYBuxdxXtLko5Av9NHz5v3+InAduAuYDWl8BXg9CRPpjd9tB2YAT5J74S46+hNV920iveWJB2BfqePLpr/PMlmev95r1hV3ZHkBnqlchD4LL3poI8A1yV5WzN21WreX5K0equ989p/0tsnsCpV9VbgrYcNPwicttr3lMaRt+zUqOl3n8Jf0zvaCHrnFfwIcP2gQkkbhbfs1Kjpd0vhHfMeHwQeqqo9A8gjSepQXyevNRfG+yK9K6U+DfDyE5K0DvV757VzgM8AvwCcA9yRxEtnS9I60+/00WXA86pqH0CSCeDv+NZlKaSxcPIpz2F2dnbJdfYfODCkNNLo6bcUvuPxQmj8O/1fN0kaGbOzs8vu2P3gG7wivDaufkvh40n+FvhA8/wXgY8OJpIkqSvL3aP5GcCWqvqtJD8P/ESz6B+BawcdTpI0XMttKbwbuBSgqm4EbgRI8qPNsp8dYDZJ0pAtt19gS1Xde/hgMzY1kESSpM4sVwqbl1j2pDXMIUkaAcuVwkySXzt8MMlr6N0YR5K0jiy3T+FNwIeS/BLfKoFp4Gjg5waYS5LUgSVLoaq+Cvx4khcBz2qGP1JVnxh4MknS0PV7P4VP0rsJjiRpHVvt/RSkkeMlLKQjZylo3fASFtKR8/pFkqSWpSBJanVSCkk2J7khyReT3J/k+UmOSXJrkn9pvj+ti2yStJF1taVwBfDxqvph4NnA/cAlwG1VdSJwW/NckjREQy+FJN8DvAC4CqCqHquqR4EdwDXNatcAO4edTZI2ui62FE4A5oA/T/LZJFcm+S56F997/HjCR4AtC704ya4kM0lm5ubmhhRZkjaGLkphE3Aq8N6qei7wnxw2VVRVBdRCL66q3VU1XVXTExMTAw8rSRtJF6WwB9hTVXc0z2+gVxJfTTIJ0Hzft8jrJUkDMvST16rqkSQPJ3lmVX0J2A58ofk6H7i8+X7TsLNJo2j/gW9wzMSCs6kATE5Oct89dw8vkNa1rs5ovgi4NsnRwIPAq+lttVyf5ALgIeCcjrJJI6UOHVryTO1bLts5tCxa/zophaq6m94luA+3fchRJEnzeEazJKllKUiSWpaCJKllKUiSWpaCJKnlTXY0FryrmjQcloLGgndVk4bD6SNJUstSkCS1LAVJUstSkCS1LAVJUstSkCS1LAVJUstSkCS1PHlNnfNsZWl0WArqnGcrS6PD6SNJUsstBWkD6GeKbnJykvvuuXs4gTSyOiuFJEcBM8Deqjo7yQnAdcDTgTuB86rqsa7ySetJP1N0t1y2cyhZNNq6nD56I3D/vOe/B7yrqp4BfB24oJNUkrSBdVIKSbYBPwNc2TwP8GLghmaVa4CdXWSTpI2sqy2FdwMXA4ea508HHq2qg83zPcDWhV6YZFeSmSQzc3NzAw8qSRvJ0EshydnAvqq6czWvr6rdVTVdVdMTExNrnE6SNrYudjSfAbw8ycuAJwJPBa4ANifZ1GwtbAP2dpBNkja0oW8pVNWlVbWtqqaAc4FPVNUvAZ8EXtGsdj5w07CzSdJGN0rnKfw2cF2StwGfBa7qOI80FvYf+AbHTGxZZh0vE6L+dFoKVfX3wN83jx8ETusyjzSO6tAhLxOiNeNlLiRJLUtBktSyFCRJLUtBktSyFCRJLUtBktSyFCRJLUtBktQapTOaJXWonzOjvTvb+mcpSAL6OzP6hl9/icWxzlkKkvrWT3F4W8/x5j4FSVLLUpAktSwFSVLLUpAktSwFSVLLUpAktSwFSVLL8xQ0UCef8hxmZ2eXXMf7B0ujY+ilkOQ44P3AFqCA3VV1RZJjgL8EpoB/Bc6pqq8PO5/W1uzsrPcPlsZIF9NHB4E3V9VJwOnAhUlOAi4BbquqE4HbmueSpCEaeilU1WxV3dU8PgDcD2wFdgDXNKtdA+wcdjZJ2ug63aeQZAp4LnAHsKWqHp98foTe9NJCr9kF7AI4/vjjh5BS0kp4tdXx1lkpJHkK8FfAm6pqf5J2WVVVklrodVW1G9gNMD09veA6krrjRfPGWyeHpCb5TnqFcG1V3dgMfzXJZLN8EtjXRTZJ2si6OPoowFXA/VX1znmLbgbOBy5vvt807GyShsMpptHVxfTRGcB5wL1J7m7G3kKvDK5PcgHwEHBOB9kkDYFTTKNr6KVQVf8AZJHF24eZZaPq54Qyf0uTNibPaN6A+jmhzN/SpI3JUtCCnPNV1/wZ7IaloAWt1U3cva6RVsv9Dt2wFLRq/fyj9bpG0nixFNYZr0oq6UhYCuuMVyWVRtuoH/1nKUjSEI360X/eeU2S1LIUJEktS0GS1LIUJEktdzQPwVodbeDhptK386zntWcpDMFaHW3g4abSt/Os57VnKUha19yaWBlLQdK65tbEylgKktSHUT8Tea1YCpI2vH6mmPYfOMAr3nPbkuushy0OS0HShucVf7/F8xQkSa2R21JIchZwBXAUcGVVXd5xpKHod/NV0uhaq3/HXR4xNVKlkOQo4I+BnwL2AP+U5Oaq+sJaf1Y/O42++V//zZOf9MQjXqefHwI3X6Xxt1b/jrs8YmqkSgE4DXigqh4ESHIdsANY81Lo90SwM9/58TVZR5LGQaqq6wytJK8Azqqq1zTPzwN+rKreMG+dXcCu5ukzgS8d9jbHAv82hLiDYPbujHP+cc4O451/XLN/f1VNLLRg1LYUllVVu4Hdiy1PMlNV00OMtGbM3p1xzj/O2WG8849z9sWM2tFHe4Hj5j3f1oxJkoZg1Erhn4ATk5yQ5GjgXODmjjNJ0oYxUtNHVXUwyRuAv6V3SOrVVXXfCt9m0amlMWD27oxz/nHODuOdf5yzL2ikdjRLkro1atNHkqQOWQqSpNa6LIUkFyX5YpL7kvx+13lWI8mbk1SSY7vO0q8kf9D8vd+T5ENJNnedaTlJzkrypSQPJLmk6zwrkeS4JJ9M8oXmZ/2NXWdaqSRHJflskr/pOstKJdmc5IbmZ/7+JM/vOtNaWHelkORF9M6CfnZVnQy8o+NIK5bkOOBM4CtdZ1mhW4FnVdUpwD8Dl3acZ0nzLqvyUuAk4JVJTuo21YocBN5cVScBpwMXjll+gDcC93cdYpWuAD5eVT8MPJvx/XN8m3VXCsDrgMur6n8Aqmpfx3lW413AxcBYHQVQVbdU1cHm6e30zjMZZe1lVarqMeDxy6qMhaqaraq7mscH6P2ntLXbVP1Lsg34GeDKrrOsVJLvAV4AXAVQVY9V1aOdhloj67EUfgj4ySR3JPlUkud1HWglkuwA9lbV57rOcoR+FfhY1yGWsRV4eN7zPYzRf6rzJZkCngvc0XGUlXg3vV9+DnWcYzVOAOaAP2+mv65M8l1dh1oLI3WeQr+S/B3wfQssuozen+kYepvTzwOuT/IDNULH3i6T/y30po5G0lLZq+qmZp3L6E1tXDvMbBtVkqcAfwW8qar2d52nH0nOBvZV1Z1JXthxnNXYBJwKXFRVdyS5ArgE+J1uYx25sSyFqnrJYsuSvA64sSmBzyQ5RO+iVXPDyrecxfIn+VF6v4F8Lgn0pl/uSnJaVT0yxIiLWurvHiDJrwBnA9tHqYgXMfaXVUnynfQK4dqqurHrPCtwBvDyJC8Dngg8NclfVNUvd5yrX3uAPVX1+JbZDfRKYeytx+mjDwMvAkjyQ8DRjMlVDKvq3qr63qqaqqopej94p45KISynuUHSxcDLq+qbXefpw1hfViW93xyuAu6vqnd2nWclqurSqtrW/JyfC3xijAqB5t/kw0me2QxtZwCX+O/CWG4pLONq4OoknwceA84fg99Y14s/Ap4A3Nps6dxeVa/tNtLi1uiyKl06AzgPuDfJ3c3YW6rqo91F2lAuAq5tfqF4EHh1x3nWhJe5kCS11uP0kSRplSwFSVLLUpAktSwFSVLLUpAktSwFSVLLUpAktf4PZiXoPXqm+yQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(init_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(F.sigmoid(init_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6686)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.sigmoid(init_scores)[init_correctness].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5715)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.sigmoid(init_scores)[~init_correctness].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7619)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.sigmoid(final_scores)[init_correctness].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7984)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.sigmoid(final_scores)[~init_correctness].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(final_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(F.sigmoid(final_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2509825123311368"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_macro_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Threshold: 0.9****************************\n",
      "Init\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for &: 'Tensor' and 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [314]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInit\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# init prediction\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28mprint\u001b[39m((\u001b[43mcondition_mask\u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43mcorrect_init_mask\u001b[49m)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem(), \n\u001b[1;32m     10\u001b[0m     (condition_mask)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem(), \n\u001b[1;32m     11\u001b[0m     (condition_mask\u001b[38;5;241m&\u001b[39mcorrect_init_mask)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;241m/\u001b[39m(condition_mask)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# init prediction\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m((\u001b[38;5;241m~\u001b[39mcondition_mask\u001b[38;5;241m&\u001b[39mcorrect_init_mask)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem(), \n\u001b[1;32m     14\u001b[0m     (\u001b[38;5;241m~\u001b[39mcondition_mask)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem(), \n\u001b[1;32m     15\u001b[0m    (\u001b[38;5;241m~\u001b[39mcondition_mask\u001b[38;5;241m&\u001b[39mcorrect_init_mask)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;241m/\u001b[39m(\u001b[38;5;241m~\u001b[39mcondition_mask)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem())\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for &: 'Tensor' and 'list'"
     ]
    }
   ],
   "source": [
    "correct_init_mask = init_correctness\n",
    "correct_msp_mask = final_correctness\n",
    "for threshold in [ 0.9, 0.99, 0.999]:\n",
    "    uncertain_init_mask = F.sigmoid(init_scores) < threshold\n",
    "    condition_mask = ~uncertain_init_mask\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    print(\"Init\")\n",
    "    # init prediction\n",
    "    print((condition_mask&correct_init_mask).sum().item(), \n",
    "        (condition_mask).sum().item(), \n",
    "        (condition_mask&correct_init_mask).sum().item()/(condition_mask).sum().item())\n",
    "    # init prediction\n",
    "    print((~condition_mask&correct_init_mask).sum().item(), \n",
    "        (~condition_mask).sum().item(), \n",
    "       (~condition_mask&correct_init_mask).sum().item()/(~condition_mask).sum().item())\n",
    "    print(\"MSP\")\n",
    "    # msp prediction\n",
    "    print((condition_mask&correct_msp_mask).sum().item(), \n",
    "        (condition_mask).sum().item(), \n",
    "        (condition_mask&correct_msp_mask).sum().item()/(condition_mask).sum().item())\n",
    "    # msp prediction\n",
    "    print((~condition_mask&correct_msp_mask).sum().item(), \n",
    "        (~condition_mask).sum().item(), \n",
    "        (~condition_mask&correct_msp_mask).sum().item()/(~condition_mask).sum().item())\n",
    "    print(\"MSP & Init\")\n",
    "    print(((condition_mask&correct_init_mask)&(condition_mask&correct_msp_mask)).sum().item())\n",
    "    # print(((~(init_target_mask&(~uncertain_init_mask & ~uncertain_target_mask))& correct_msp_mask)&(~(init_target_mask&(~uncertain_init_mask & ~uncertain_target_mask))& correct_init_mask)).sum().item())\n",
    "    print(((condition_mask&correct_init_mask)|(condition_mask&correct_msp_mask)).sum().item(),\n",
    "          (condition_mask).sum().item(), \n",
    "          ((condition_mask&correct_init_mask)|(condition_mask&correct_msp_mask)).sum().item()/(condition_mask).sum().item())\n",
    "    print(((~condition_mask&correct_init_mask)|(~condition_mask&correct_msp_mask)).sum().item(),\n",
    "          (~condition_mask).sum().item(), \n",
    "          ((~condition_mask&correct_init_mask)|(~condition_mask&correct_msp_mask)).sum().item()/(~condition_mask).sum().item())\n",
    "    # print(\"Permutation\")\n",
    "    # print((condition_mask&correct_permutation_mask).sum().item(), \n",
    "    #     (condition_mask).sum().item(), \n",
    "    #     (condition_mask&correct_permutation_mask).sum().item()/(condition_mask).sum().item())\n",
    "    # print((~condition_mask&correct_permutation_mask).sum().item(), \n",
    "    #      (~condition_mask).sum().item(), \n",
    "    #     (~condition_mask&correct_permutation_mask).sum().item()/(~condition_mask).sum().item())\n",
    "    # print(\"Permutation Confident\")\n",
    "    # print((condition_mask&correct_permutation_confident_mask).sum().item(), \n",
    "    #     (condition_mask).sum().item(), \n",
    "    #     (condition_mask&correct_permutation_confident_mask).sum().item()/(condition_mask).sum().item())\n",
    "    # print((~condition_mask&correct_permutation_confident_mask).sum().item(),\n",
    "    #         (~condition_mask).sum().item(), \n",
    "    #         (~condition_mask&correct_permutation_confident_mask).sum().item()/(~condition_mask).sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_micro_f1=0.5594, ts_macro_f1=0.2968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1276939/1055160861.py:102: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  final_scores = F.sigmoid(torch.tensor(final_scores))\n",
      "/tmp/ipykernel_1276939/1055160861.py:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  init_scores = F.sigmoid(torch.tensor(init_scores))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "\n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "verifier.load_state_dict(veri_state_dict)\n",
    "verifier.eval()\n",
    "verifier = verifier.to(device)\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "init_scores = []\n",
    "init_correctness = []\n",
    "final_scores = []\n",
    "final_correctness = []\n",
    "num_cols = []\n",
    "total_steps = []\n",
    "final_steps = []\n",
    "correct_scores = defaultdict(list)\n",
    "correct_steps = defaultdict(list)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "        target_col_mask = batch[\"target_col_mask\"].T\n",
    "        embs = test_embs[batch_idx][0].reshape(1,-1).to(device)\n",
    "        logits = test_logits[batch_idx][0].reshape(-1).to(device)\n",
    "        scores_init = verifier(embs)\n",
    "        max_score = -float(\"inf\")\n",
    "\n",
    "        init_scores.append(scores_init.item())\n",
    "        init_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "        init_permutation_i = get_permutation(target_col_mask)\n",
    "        col_idx_set = target_col_mask.unique().tolist()\n",
    "        early_stop = False\n",
    "        i = 0\n",
    "        final_step = 0\n",
    "        total_steps.append(len(init_permutation_i) - max(len(init_permutation_i)//2, len(init_permutation_i)-3) -1)\n",
    "        num_cols.append(len(init_permutation_i))\n",
    "        for r in range(len(init_permutation_i), max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "            for x in itertools.combinations(init_permutation_i, r):\n",
    "                if 0 not in x:\n",
    "                    continue\n",
    "                logits_temp = test_logits[batch_idx][i].reshape(-1).to(device)\n",
    "                embs_temp = test_embs[batch_idx][i].reshape(1,-1).to(device)\n",
    "                scores_temp = verifier(embs_temp).item()\n",
    "                predict_temp = logits_temp.argmax().item()\n",
    "                i += 1\n",
    "                if scores_temp > max_score:\n",
    "                    max_score = scores_temp\n",
    "                    logits = logits_temp.clone()\n",
    "                    final_step = len(init_permutation_i) - r\n",
    "                if logits_temp.argmax().item() == batch[\"label\"].item():\n",
    "                    correct_scores[batch_idx].append(scores_temp)\n",
    "                    correct_steps[batch_idx].append(len(init_permutation_i) - r)\n",
    "                    \n",
    "        final_scores.append(max_score)\n",
    "        final_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "        final_steps.append(final_step)\n",
    "        labels_test.append(batch[\"label\"].cpu())\n",
    "        logits_test.append(logits.detach().cpu())\n",
    "    labels_test = torch.cat(labels_test, dim=0)\n",
    "    logits_test = torch.stack(logits_test, dim=0)\n",
    "    preds_test = torch.argmax(logits_test, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "ts_f1_full = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=None)\n",
    "# full_f1_init\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "\n",
    "final_correctness = torch.tensor(final_correctness)\n",
    "init_correctness = torch.tensor(init_correctness)\n",
    "init_scores = torch.tensor(init_scores)\n",
    "final_scores = torch.tensor(final_scores)\n",
    "final_steps = torch.tensor(final_steps)\n",
    "total_steps = torch.tensor(total_steps)\n",
    "final_scores = F.sigmoid(torch.tensor(final_scores))\n",
    "init_scores = F.sigmoid(torch.tensor(init_scores))\n",
    "num_cols = torch.tensor(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  101,  1015,  1025,  1016,  1025,  1017,  1025,  1018,  1025,  1019,\n",
       "         1025,  1020,  1025,  1021,  1025,  1022,  1025,  1023,  1025,  2184,\n",
       "         1025,  2340,  1025,  2260,  1025,  2410,  1025,  2403,  1025,  2321,\n",
       "         1025,  2385,  1025,  2459,  1025,  2324,  1025,  2539,  1025,  2322,\n",
       "         1025,  2538,  1025,  2570,  1025,  2603,  1025,  2484,  1025,  2423,\n",
       "         1025,  2656,  1025,  2676,  1025,  2654,  1025,  2756,  1025,  2382,\n",
       "         1025,  2861,  1025,  3590,   101,  1015,  1025,  1015,  1025,  1015,\n",
       "         1025,  1015,  1025,  1015,  1025,  1015,  1025,  1015,  1025,  1015,\n",
       "         1025,  1015,  1025,  1015,  1025,  1015,  1025,  1015,  1025,  1015,\n",
       "         1025,  1015,  1025,  1017,  1025,  1017,  1025,  1017,  1025,  1017,\n",
       "         1025,  1017,  1025,  1017,  1025,  1017,  1025,  1017,  1025,  1017,\n",
       "         1025,  1017,  1025,  1017,  1025,  1017,  1025,  1017,  1025,  1017,\n",
       "         1025,  1017,  1025,  1017,  1025,  1017,  1025,  1017,   101,  9402,\n",
       "         1025,  9800,  1025,  9645,  1025,  8746,  1025, 10114,  1025, 10550,\n",
       "         1025, 10715,  1025, 11518,  1025,  7287,  1025, 11118,  1025, 11176,\n",
       "         1025, 12104,  1025, 12457,  1025, 10630,  1025,  1015,  1025,  1016,\n",
       "         1025,  1017,  1025,  1018,  1025,  1019,  1025,  1020,  1025,  1021,\n",
       "         1025,  1022,  1025,  1023,  1025,  2184,  1025,  2340,  1025,  2260,\n",
       "         1025,  2410,  1025,  2403,  1025,  2321,  1025,  2385,  1025,  2459,\n",
       "         1025,  2324], device='cuda:0')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1015,  1025,  1016,  1025,  1017,  1025,  1018,  1025,  1019,  1025,\n",
       "         1020,  1025,  1021,  1025,  1022,  1025,  1023,  1025,  2184,  1025,\n",
       "         2340,  1025,  2260,  1025,  2410,  1025,  2403,  1025,  2321,  1025,\n",
       "         2385,  1025,  2459,  1025,  2324,  1025,  2539,  1025,  2322,  1025,\n",
       "         2538,  1025,  2570,  1025,  2603,  1025,  2484,  1025,  2423,  1025,\n",
       "         2656,  1025,  2676,  1025,  2654,  1025,  2756,  1025,  2382,  1025,\n",
       "         2861,  1025,  3590,   101,  1015,  1025,  1015,  1025,  1015,  1025,\n",
       "         1015,  1025,  1015,  1025,  1015,  1025,  1015,  1025,  1015,  1025,\n",
       "         1015,  1025,  1015,  1025,  1015,  1025,  1015,  1025,  1015,  1025,\n",
       "         1015,  1025,  1017,  1025,  1017,  1025,  1017,  1025,  1017,  1025,\n",
       "         1017,  1025,  1017,  1025,  1017,  1025,  1017,  1025,  1017,  1025,\n",
       "         1017,  1025,  1017,  1025,  1017,  1025,  1017,  1025,  1017,  1025,\n",
       "         1017,  1025,  1017,  1025,  1017,  1025,  1017,   101,  9402,  1025,\n",
       "         9800,  1025,  9645,  1025,  8746,  1025, 10114,  1025, 10550,  1025,\n",
       "        10715,  1025, 11518,  1025,  7287,  1025, 11118,  1025, 11176,  1025,\n",
       "        12104,  1025, 12457,  1025, 10630,  1025,  1015,  1025,  1016,  1025,\n",
       "         1017,  1025,  1018,  1025,  1019,  1025,  1020,  1025,  1021,  1025,\n",
       "         1022,  1025,  1023,  1025,  2184,  1025,  2340,  1025,  2260,  1025,\n",
       "         2410,  1025,  2403,  1025,  2321,  1025,  2385,  1025,  2459,  1025,\n",
       "         2324], device='cuda:0')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"data\"].T[0][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[\"data\"].T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 ; 2 ; 3 ; 4 ; 5 ; 6 ; 7 ; 8 ; 9 ; 10 ; 11 ; 12 ; 13 ; 14 ; 15 ; 16 ; 17 ; 18 ; 19 ; 20 ; 21 ; 22 ; 23 ; 24 ; 25 ; 26 ; 27 ; 28 ; 29 ; 30 ; 31 ; 32'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(batch[\"data\"].T[target_col_mask==0][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 768)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "sb_model = SentenceTransformer(\"all-mpnet-base-v2\", cache_folder=\"/data/zhihao/TU/Watchog/sentence_transformers_cache\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_aug_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_aug_embs_sb[0].device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "res0 = tokenizer.decode(batch[\"data\"].T[target_col_mask==0][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'male ; male ; male ; male ; female ; female ; female ; male ; male ; male ; female ; female ; female ; female ; female ; female ; male ; male ; male ; female ; female ; female ; female ; female ; female ; male ; male ; male ; male ; male ; male ;'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "';male;female'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\";\".join(set([i.strip() for i in res0.split(\";\")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'male ; male ; male ; male ; female ; female ; female ; male ; male ; male ; female ; female ; female ; female ; female ; female ; male ; male ; male ; female ; female ; female ; female ; female ; female ; male ; male ; male ; male ; male ; male ;'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_sb = torch.tensor(sb_model.encode([res0, \n",
    "                                       res0.replace(\";\", \",\"),\n",
    "                                       res0.replace(\"female\", \"male\"), \n",
    "                                       \";\".join(set([i.strip() for i in res0.split(\";\")])), \n",
    "                                       res0.replace(\"female\", \"F\").replace(\"male\", \"M\"),\n",
    "                                       \"gender; gender; gender;\",\n",
    "                                       \"1997;2005\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 768])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_sb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 0.8899, 0.9620, 0.4504, 0.4522, 0.5468, 0.0903])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cosine_similarity(res_sb[0], res_sb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_sb = torch.tensor(sb_model.encode([\"2017; 2022; 1997\", \n",
    "                                       \"2007-11-04; 2007-11-04; 2007-11-04\",\n",
    "                                       \"100; 200; 300\",\n",
    "                                       \"23; 52; 48; 11\", \n",
    "                                       \"2017.11; 2022.54; 1997.54\", \n",
    "                                       \"11.11; 12.11; 0.124\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_data = [\"2017; 2022; 1997\", \n",
    "                                       \"2007-11-04; 2007-11-04; 2007-11-04\",\n",
    "                                       \"100; 200; 300\",\n",
    "                                       \"23; 52; 48; 11\", \n",
    "                                       \"2017.11; 2022.54; 1997.54\", \n",
    "                                       \"11.11; 12.11; 0.124\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 0.7579, 0.1219, 0.1400, 0.4983, 0.1521],\n",
       "       grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cosine_similarity(res_embs[0], res_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids_list = [tokenizer.encode(\n",
    "    i, add_special_tokens=True) for i in res_data]\n",
    "\n",
    "\n",
    "# group_df[\"data\"].apply(lambda x: tokenizer.encode(\n",
    "#     tokenizer.cls_token + \" \" + x, add_special_tokens=False, max_length=cur_maxlen, truncation=True)).tolist(\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_embs = []\n",
    "for i in range(len(res_data)):\n",
    "    logits, embs = model(torch.tensor(token_ids_list[i]).reshape(1, -1).to(device), cls_indexes=torch.LongTensor([[0, 0]]).to(device), get_enc=True)\n",
    "    res_embs.append(embs.cpu())\n",
    "res_embs = torch.stack(res_embs, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 0.7579, 0.1219, 0.1400, 0.4983, 0.1521],\n",
       "       grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 0.3938, 0.2782, 0.2382, 0.7235, 0.1998])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cosine_similarity(res_sb[0], res_sb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, batch in enumerate(train_dataloader_iter):\n",
    "    break\n",
    "cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "target_col_mask = batch[\"target_col_mask\"].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save good context\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "sb_model = SentenceTransformer(\"all-mpnet-base-v2\", cache_folder=\"/data/zhihao/TU/Watchog/sentence_transformers_cache\")\n",
    "\n",
    "\n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "num_single_fail = 0\n",
    "num_good_context = 0\n",
    "class_context = defaultdict(list)\n",
    "training_aug_embs = []\n",
    "training_aug_embs_target = []\n",
    "training_aug_embs_sb = []\n",
    "training_aug_labels = []\n",
    "training_aug_col_num = []\n",
    "training_aug_data = []\n",
    "training_aug_col_mask = []\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in enumerate(train_dataloader_iter):\n",
    "        cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "        target_col_mask = batch[\"target_col_mask\"].T\n",
    "        if 1 not in target_col_mask:\n",
    "            continue\n",
    "        init_permutation_i = get_permutation(target_col_mask)\n",
    "        training_aug_col_num.append(len(init_permutation_i))\n",
    "        \n",
    "        label_i = batch[\"label\"].item()\n",
    "        training_aug_labels.append(label_i)\n",
    "        \n",
    "        logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "        training_aug_embs.append(embs.detach().cpu())\n",
    "        \n",
    "        logits, embs = model(batch[\"data\"].T[target_col_mask==0].reshape(1, -1), cls_indexes=torch.LongTensor([[0, 0]]).to(device), get_enc=True)\n",
    "        training_aug_embs_target.append(embs.detach().cpu())\n",
    "        \n",
    "        string_data = tokenizer.decode(batch[\"data\"].T[target_col_mask==0][1:]).split(\";\")\n",
    "        string_data = \";\".join(set([i.strip() for i in string_data]))\n",
    "        sb_embs = torch.tensor(sb_model.encode([string_data]))\n",
    "        training_aug_embs_sb.append(sb_embs)\n",
    "        \n",
    "        training_aug_data.append(batch[\"data\"].T[target_col_mask!=0])\n",
    "        training_aug_col_mask.append(target_col_mask[target_col_mask!=0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_aug_embs = torch.stack(training_aug_embs, dim=0)\n",
    "training_aug_embs_sb = torch.stack(training_aug_embs_sb, dim=0).squeeze()\n",
    "training_aug_embs_target = torch.stack(training_aug_embs_target, dim=0)\n",
    "training_aug_labels = torch.tensor(training_aug_labels)\n",
    "training_aug_col_num = torch.tensor(training_aug_col_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "        for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "            target_col_mask = batch[\"target_col_mask\"].T\n",
    "            embs = test_embs[batch_idx][0].reshape(1,-1).to(device)\n",
    "            logits = test_logits[batch_idx][0].reshape(-1).to(device)\n",
    "            scores_init = verifier(embs)\n",
    "            max_score = -float(\"inf\")\n",
    "\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, indices = F.cosine_similarity(test_aug_embs_sb[batch_idx], training_aug_embs_sb).topk(K)\n",
    "for aug_idx in indices:\n",
    "    aug_data = training_aug_data[aug_idx]\n",
    "    aug_col_mask = training_aug_col_mask[aug_idx]\n",
    "    \n",
    "    aug_permutation_i = torch.tensor(get_permutation(aug_col_mask)) + len(init_permutation_i) -1\n",
    "    permutation_i = init_permutation_i + aug_permutation_i.tolist()\n",
    "    max_num_cols_i = min(len(permutation_i), args.max_num_col)\n",
    "    aug_data = torch.cat([batch[\"data\"].T, aug_data.reshape(1, -1)], dim=-1)\n",
    "    aug_target_col_mask = torch.cat([target_col_mask, aug_col_mask.reshape(1, -1)], dim=-1)\n",
    "    for r in range(max_num_cols_i, max(max_num_cols_i//2, max_num_cols_i-3), -1): # not \n",
    "        for x in itertools.combinations(permutation_i, r):\n",
    "            if 0 not in x:\n",
    "                continue\n",
    "\n",
    "            \n",
    "            new_batch_data = []\n",
    "            for col_i in x:\n",
    "                if col_i == 0:\n",
    "                    if len(new_batch_data) == 0:\n",
    "                        cls_indexes_value = 0\n",
    "                    else:\n",
    "                        cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                new_batch_data.append(aug_data[aug_target_col_mask==col_i])\n",
    "            new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "            cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "            logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "            ood_score_temp = F.softmax(logits_temp.detach()).max().item()\n",
    "            score_permutation[batch_idx].append(ood_score_temp)\n",
    "            predict_temp = logits_temp.argmax().item()\n",
    "            permutation_correctness[batch_idx].append(predict_temp == label_i)\n",
    "            num_permutations[batch_idx] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([117])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ".shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 184])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_col_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([117])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_col_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [82]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtraining_aug_embs_sb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "values, indices = F.cosine_similarity(test_aug_embs_sb[batch_idx], training_aug_embs_sb).topk(K)\n",
    "for aug_idx in indices:\n",
    "    aug_data = training_aug_data[aug_idx]\n",
    "    aug_col_mask = training_aug_col_mask[aug_idx]\n",
    "    \n",
    "    aug_permutation_i = torch.tensor(get_permutation(aug_col_mask)) + len(init_permutation_i) -1\n",
    "    permutation_i = init_permutation_i + aug_permutation_i.tolist()\n",
    "    max_num_cols_i = min(len(permutation_i), args.max_num_col)\n",
    "    aug_data = torch.cat([batch[\"data\"].T, aug_data.reshape(1, -1)], dim=-1)\n",
    "    aug_target_col_mask = torch.cat([target_col_mask, aug_col_mask.reshape(1, -1)], dim=-1)\n",
    "    for r in range(max_num_cols_i, max(max_num_cols_i//2, max_num_cols_i-3), -1): # not \n",
    "        for x in itertools.combinations(permutation_i, r):\n",
    "            if 0 not in x:\n",
    "                continue\n",
    "\n",
    "            \n",
    "            new_batch_data = []\n",
    "            for col_i in x:\n",
    "                if col_i == 0:\n",
    "                    if len(new_batch_data) == 0:\n",
    "                        cls_indexes_value = 0\n",
    "                    else:\n",
    "                        cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                new_batch_data.append(aug_data[aug_target_col_mask==col_i])\n",
    "            new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "            cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "            logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "            scores_temp = verifier(embs_temp).item()\n",
    "            predict_temp = logits_temp.argmax().item()\n",
    "            num_permutations[batch_idx] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save good context\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "sb_model = SentenceTransformer(\"all-mpnet-base-v2\", cache_folder=\"/data/zhihao/TU/Watchog/sentence_transformers_cache\")\n",
    "\n",
    "\n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "num_single_fail = 0\n",
    "num_good_context = 0\n",
    "class_context = defaultdict(list)\n",
    "test_aug_embs = []\n",
    "test_aug_embs_target = []\n",
    "test_aug_embs_sb = []\n",
    "test_aug_labels = []\n",
    "test_aug_col_num = []\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "        cls_indexes = torch.LongTensor([[0, batch[\"cls_indexes\"].cpu().item()]]).to(device)\n",
    "        target_col_mask = batch[\"target_col_mask\"].T\n",
    "\n",
    "        init_permutation_i = get_permutation(target_col_mask)\n",
    "        test_aug_col_num.append(len(init_permutation_i))\n",
    "        \n",
    "        label_i = batch[\"label\"].item()\n",
    "        test_aug_labels.append(label_i)\n",
    "        \n",
    "        logits, embs = model(batch[\"data\"].T, cls_indexes=cls_indexes, get_enc=True)\n",
    "        test_aug_embs.append(embs.detach().cpu())\n",
    "        \n",
    "        logits, embs = model(batch[\"data\"].T[target_col_mask==0].reshape(1, -1), cls_indexes=torch.LongTensor([[0, 0]]).to(device), get_enc=True)\n",
    "        test_aug_embs_target.append(embs.detach().cpu())\n",
    "        \n",
    "        string_data = tokenizer.decode(batch[\"data\"].T[target_col_mask==0][1:]).split(\";\")\n",
    "        string_data = \";\".join(set([i.strip() for i in string_data]))\n",
    "        sb_embs = torch.tensor(sb_model.encode([string_data]))\n",
    "        test_aug_embs_sb.append(sb_embs)\n",
    "        \n",
    "test_aug_embs = torch.stack(test_aug_embs, dim=0)\n",
    "test_aug_embs_sb = torch.stack(test_aug_embs_sb, dim=0)\n",
    "test_aug_embs_target = torch.stack(test_aug_embs_target, dim=0)\n",
    "test_aug_labels = torch.tensor(test_aug_labels)\n",
    "test_aug_col_num = torch.tensor(test_aug_col_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs_correctness = []\n",
    "embs_sim_scores = []\n",
    "embs_sb_correctness = []\n",
    "embs_sb_sim_scores = []\n",
    "embs_target_correctness = []\n",
    "embs_target_sim_scores = []\n",
    "for idx in (test_aug_col_num<8).nonzero().reshape(-1):\n",
    "    embs_correctness.append(training_aug_labels[F.cosine_similarity(test_aug_embs[idx], training_aug_embs).argmax()] == test_aug_labels[idx])\n",
    "    embs_sim_scores.append(F.cosine_similarity(test_aug_embs[idx], training_aug_embs).max().item())\n",
    "    embs_sb_correctness.append(training_aug_labels[F.cosine_similarity(test_aug_embs_sb[idx], training_aug_embs_sb).argmax()] == test_aug_labels[idx])\n",
    "    embs_sb_sim_scores.append(F.cosine_similarity(test_aug_embs_sb[idx], training_aug_embs_sb).max().item())\n",
    "    embs_target_correctness.append(training_aug_labels[F.cosine_similarity(test_aug_embs_target[idx], training_aug_embs_target).argmax()] == test_aug_labels[idx])\n",
    "    embs_target_sim_scores.append(F.cosine_similarity(test_aug_embs_target[idx], training_aug_embs_target).max().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1085"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_correctness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs_correctness = torch.tensor(embs_correctness).reshape(-1)\n",
    "embs_sb_correctness = torch.tensor(embs_sb_correctness).reshape(-1)\n",
    "embs_target_correctness = torch.tensor(embs_target_correctness).reshape(-1)\n",
    "embs_sim_scores = torch.tensor(embs_sim_scores).reshape(-1)\n",
    "embs_sb_sim_scores = torch.tensor(embs_sb_sim_scores).reshape(-1)\n",
    "embs_target_sim_scores = torch.tensor(embs_target_sim_scores).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(219) 401 tensor(0.5461) tensor(0.9671) tensor(0.7996)\n",
      "tensor(191) 401 tensor(0.4763) tensor(0.8770) tensor(0.7033)\n",
      "tensor(190) 401 tensor(0.4738) tensor(0.9776) tensor(0.9293)\n"
     ]
    }
   ],
   "source": [
    "print(embs_correctness.sum(), embs_correctness.shape[0], embs_correctness.sum()/embs_correctness.shape[0], embs_sim_scores[embs_correctness].mean(), embs_sim_scores[~embs_correctness].mean())\n",
    "print(embs_sb_correctness.sum(), embs_sb_correctness.shape[0], embs_sb_correctness.sum()/embs_sb_correctness.shape[0], embs_sb_sim_scores[embs_sb_correctness].mean(), embs_sb_sim_scores[~embs_sb_correctness].mean())\n",
    "print(embs_target_correctness.sum(), embs_target_correctness.shape[0], embs_target_correctness.sum()/embs_target_correctness.shape[0], embs_target_sim_scores[embs_target_correctness].mean(), embs_target_sim_scores[~embs_target_correctness].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_correctness_tocheck = final_correctness[test_aug_col_num<8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(219) tensor(235) tensor(211) tensor(0.5262)\n"
     ]
    }
   ],
   "source": [
    "print(embs_correctness.sum(), final_correctness_tocheck.sum(), (embs_correctness&final_correctness_tocheck).sum(), (embs_correctness&final_correctness_tocheck).sum()/len(embs_correctness))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs_correctness = []\n",
    "embs_sim_scores = []\n",
    "embs_sb_correctness = []\n",
    "embs_sb_sim_scores = []\n",
    "embs_target_correctness = []\n",
    "embs_target_sim_scores = []\n",
    "K = 10\n",
    "for idx in (test_aug_col_num<8).nonzero().reshape(-1):\n",
    "    values, indices = F.cosine_similarity(test_aug_embs[idx], training_aug_embs).topk(K)\n",
    "    if test_aug_labels[idx].item() in training_aug_labels[indices]:\n",
    "        embs_correctness.append(True)\n",
    "    else:\n",
    "        embs_correctness.append(False)\n",
    "    values, indices = F.cosine_similarity(test_aug_embs_sb[idx], training_aug_embs_sb).topk(K)\n",
    "    if test_aug_labels[idx].item() in training_aug_labels[indices]:\n",
    "        embs_sb_correctness.append(True)\n",
    "    else:\n",
    "        embs_sb_correctness.append(False)\n",
    "    values, indices = F.cosine_similarity(test_aug_embs_target[idx], training_aug_embs_target).topk(K)\n",
    "    if test_aug_labels[idx].item() in training_aug_labels[indices]:\n",
    "        embs_target_correctness.append(True)\n",
    "    else:\n",
    "        embs_target_correctness.append(False)\n",
    "embs_correctness = torch.tensor(embs_correctness).reshape(-1)\n",
    "embs_sb_correctness = torch.tensor(embs_sb_correctness).reshape(-1)\n",
    "embs_target_correctness = torch.tensor(embs_target_correctness).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(236) 401 tensor(0.5885)\n",
      "tensor(257) 401 tensor(0.6409)\n",
      "tensor(237) 401 tensor(0.5910)\n"
     ]
    }
   ],
   "source": [
    "# K = 3\n",
    "print(embs_correctness.sum(), embs_correctness.shape[0], embs_correctness.sum()/embs_correctness.shape[0],)\n",
    "print(embs_sb_correctness.sum(), embs_sb_correctness.shape[0], embs_sb_correctness.sum()/embs_sb_correctness.shape[0])\n",
    "print(embs_target_correctness.sum(), embs_target_correctness.shape[0], embs_target_correctness.sum()/embs_target_correctness.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(243) 401 tensor(0.6060)\n",
      "tensor(283) 401 tensor(0.7057)\n",
      "tensor(253) 401 tensor(0.6309)\n"
     ]
    }
   ],
   "source": [
    "# K = 5\n",
    "print(embs_correctness.sum(), embs_correctness.shape[0], embs_correctness.sum()/embs_correctness.shape[0],)\n",
    "print(embs_sb_correctness.sum(), embs_sb_correctness.shape[0], embs_sb_correctness.sum()/embs_sb_correctness.shape[0])\n",
    "print(embs_target_correctness.sum(), embs_target_correctness.shape[0], embs_target_correctness.sum()/embs_target_correctness.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(251) 401 tensor(0.6259)\n",
      "tensor(307) 401 tensor(0.7656)\n",
      "tensor(271) 401 tensor(0.6758)\n"
     ]
    }
   ],
   "source": [
    "# K = 10\n",
    "print(embs_correctness.sum(), embs_correctness.shape[0], embs_correctness.sum()/embs_correctness.shape[0],)\n",
    "print(embs_sb_correctness.sum(), embs_sb_correctness.shape[0], embs_sb_correctness.sum()/embs_sb_correctness.shape[0])\n",
    "print(embs_target_correctness.sum(), embs_target_correctness.shape[0], embs_target_correctness.sum()/embs_target_correctness.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================K=1=============================\n",
      "ts_micro_f1=0.5567, ts_macro_f1=0.2950\n",
      "============================K=3=============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1276939/1482598903.py:150: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  final_scores = F.sigmoid(torch.tensor(final_scores))\n",
      "/tmp/ipykernel_1276939/1482598903.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  init_scores = F.sigmoid(torch.tensor(init_scores))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_micro_f1=0.5539, ts_macro_f1=0.2920\n",
      "============================K=5=============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1276939/1482598903.py:150: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  final_scores = F.sigmoid(torch.tensor(final_scores))\n",
      "/tmp/ipykernel_1276939/1482598903.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  init_scores = F.sigmoid(torch.tensor(init_scores))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [127]\u001b[0m, in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    103\u001b[0m new_batch_data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(new_batch_data, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    104\u001b[0m cls_indexes \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m0\u001b[39m, cls_indexes_value])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 105\u001b[0m logits_temp, embs_temp \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_batch_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcls_indexes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcls_indexes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_enc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m scores_temp \u001b[38;5;241m=\u001b[39m verifier(embs_temp\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    107\u001b[0m predict_temp \u001b[38;5;241m=\u001b[39m logits_temp\u001b[38;5;241m.\u001b[39margmax()\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/jupyterprojects/jupyter/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/jupyterprojects/jupyter/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/jupyterprojects/TU/watchog/watchog/model.py:571\u001b[0m, in \u001b[0;36mBertForMultiOutputClassification.forward\u001b[0;34m(self, input_ids, get_enc, cls_indexes, token_type_ids)\u001b[0m\n\u001b[1;32m    569\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    570\u001b[0m \u001b[38;5;66;03m# BertModelMultiOutput\u001b[39;00m\n\u001b[0;32m--> 571\u001b[0m bert_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    572\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    573\u001b[0m table_length \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mlen\u001b[39m(input_ids[i]\u001b[38;5;241m.\u001b[39mnonzero()) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(input_ids))]\n\u001b[1;32m    574\u001b[0m \u001b[38;5;66;03m# Note: returned tensor contains pooled_output of all tokens (to make the tensor size consistent)\u001b[39;00m\n",
      "File \u001b[0;32m~/jupyterprojects/jupyter/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/jupyterprojects/jupyter/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/jupyterprojects/jupyter/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:1141\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1134\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m-> 1141\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1142\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1153\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1154\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/jupyterprojects/jupyter/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/jupyterprojects/jupyter/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/jupyterprojects/jupyter/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:694\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    683\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    684\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    685\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    691\u001b[0m         output_attentions,\n\u001b[1;32m    692\u001b[0m     )\n\u001b[1;32m    693\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 694\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    704\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/jupyterprojects/jupyter/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/jupyterprojects/jupyter/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/jupyterprojects/jupyter/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:626\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    623\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    624\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 626\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[1;32m    631\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[0;32m~/jupyterprojects/jupyter/lib/python3.8/site-packages/transformers/pytorch_utils.py:238\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/jupyterprojects/jupyter/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:638\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[0;32m--> 638\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    639\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[1;32m    640\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m~/jupyterprojects/jupyter/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/jupyterprojects/jupyter/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/jupyterprojects/jupyter/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:538\u001b[0m, in \u001b[0;36mBertIntermediate.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 538\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    539\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate_act_fn(hidden_states)\n\u001b[1;32m    540\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/jupyterprojects/jupyter/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/jupyterprojects/jupyter/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/jupyterprojects/jupyter/lib/python3.8/site-packages/torch/nn/modules/linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "max_tokens_per_col = 512//args.max_num_col\n",
    "\n",
    "for K in [1, 3, 5, 10]:\n",
    "    print(f\"============================K={K}=============================\")\n",
    "    model.load_state_dict(best_state_dict, strict=False)\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    verifier.load_state_dict(veri_state_dict)\n",
    "    verifier.eval()\n",
    "    verifier = verifier.to(device)\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    init_scores = []\n",
    "    init_correctness = []\n",
    "    final_scores = []\n",
    "    final_correctness = []\n",
    "    num_cols = []\n",
    "    total_steps = []\n",
    "    final_steps = []\n",
    "    correct_scores = defaultdict(list)\n",
    "    correct_steps = defaultdict(list)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(test_dataloader_iter):\n",
    "            target_col_mask = batch[\"target_col_mask\"].T\n",
    "            embs = test_embs[batch_idx][0].reshape(1,-1).to(device)\n",
    "            logits = test_logits[batch_idx][0].reshape(-1).to(device)\n",
    "            scores_init = verifier(embs)\n",
    "            max_score = -float(\"inf\")\n",
    "\n",
    "            init_scores.append(scores_init.item())\n",
    "            init_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            \n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            early_stop = False\n",
    "            i = 0\n",
    "            final_step = 0\n",
    "            total_steps.append(len(init_permutation_i) - max(len(init_permutation_i)//2, len(init_permutation_i)-3) -1)\n",
    "            num_cols.append(len(init_permutation_i))\n",
    "\n",
    "            for r in range(len(init_permutation_i), max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "                for x in itertools.combinations(init_permutation_i, r):\n",
    "                    if 0 not in x:\n",
    "                        continue\n",
    "                    logits_temp = test_logits[batch_idx][i].reshape(-1).to(device)\n",
    "                    embs_temp = test_embs[batch_idx][i].reshape(1,-1).to(device)\n",
    "                    scores_temp = verifier(embs_temp).item()\n",
    "                    predict_temp = logits_temp.argmax().item()\n",
    "                    i += 1\n",
    "                    if scores_temp > max_score:\n",
    "                        max_score = scores_temp\n",
    "                        logits = logits_temp.clone()\n",
    "                        final_step = len(init_permutation_i) - r\n",
    "                    if logits_temp.argmax().item() == batch[\"label\"].item():\n",
    "                        correct_scores[batch_idx].append(scores_temp)\n",
    "                        correct_steps[batch_idx].append(len(init_permutation_i) - r)\n",
    "            \n",
    "            # extra columns for those with less than max_num_col columns\n",
    "            if len(init_permutation_i) < args.max_num_col:\n",
    "                values, indices = F.cosine_similarity(test_aug_embs_sb[batch_idx], training_aug_embs_sb).topk(K)\n",
    "                for aug_idx in indices:\n",
    "                    aug_data = training_aug_data[aug_idx]\n",
    "                    aug_col_mask = training_aug_col_mask[aug_idx]\n",
    "                    aug_permutation_i = get_permutation(aug_col_mask)[: args.max_num_col - len(init_permutation_i)]\n",
    "                    aug_col_mask, aug_data = aug_col_mask[aug_col_mask<=max(aug_permutation_i)], aug_data[aug_col_mask<=max(aug_permutation_i)]\n",
    "                    assert len(aug_col_mask.unique()) == len(aug_permutation_i) and len(aug_col_mask) == len(aug_data)\n",
    "                    \n",
    "                    \n",
    "                    aug_permutation_i = torch.tensor(get_permutation(aug_col_mask)) + len(init_permutation_i) -1\n",
    "                    permutation_i = init_permutation_i + aug_permutation_i.tolist()\n",
    "                    max_num_cols_i = min(len(permutation_i), args.max_num_col)\n",
    "                    aug_data = torch.cat([batch[\"data\"].T, aug_data.reshape(1, -1)], dim=-1)\n",
    "                    aug_target_col_mask = torch.cat([target_col_mask, aug_col_mask.reshape(1, -1)], dim=-1)\n",
    "                    for r in range(max_num_cols_i, max(max_num_cols_i//2, max_num_cols_i-3), -1): # not \n",
    "                        for x in itertools.combinations(permutation_i, r):\n",
    "                            if 0 not in x:\n",
    "                                continue\n",
    "\n",
    "                            \n",
    "                            new_batch_data = []\n",
    "                            for col_i in x:\n",
    "                                if col_i == 0:\n",
    "                                    if len(new_batch_data) == 0:\n",
    "                                        cls_indexes_value = 0\n",
    "                                    else:\n",
    "                                        cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                                new_batch_data.append(aug_data[aug_target_col_mask==col_i][:max_tokens_per_col])\n",
    "                            new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                            cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                            logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                            scores_temp = verifier(embs_temp.reshape(1,-1)).item()\n",
    "                            predict_temp = logits_temp.argmax().item()\n",
    "                            if scores_temp > max_score:\n",
    "                                max_score = scores_temp\n",
    "                                logits = logits_temp.clone()\n",
    "                                final_step = len(init_permutation_i) - r\n",
    "                            # if logits_temp.argmax().item() == batch[\"label\"].item():\n",
    "                            #     correct_scores[batch_idx].append(scores_temp)\n",
    "                            #     correct_steps[batch_idx].append(len(init_permutation_i) - r)\n",
    "\n",
    "\n",
    "            final_scores.append(max_score)\n",
    "            final_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "            final_steps.append(final_step)\n",
    "            labels_test.append(batch[\"label\"].cpu())\n",
    "            logits_test.append(logits.detach().cpu())\n",
    "        labels_test = torch.cat(labels_test, dim=0)\n",
    "        logits_test = torch.stack(logits_test, dim=0)\n",
    "        preds_test = torch.argmax(logits_test, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix, f1_score\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach().numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    ts_f1_full = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=None)\n",
    "    # full_f1_init\n",
    "    print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "\n",
    "    final_correctness = torch.tensor(final_correctness)\n",
    "    init_correctness = torch.tensor(init_correctness)\n",
    "    init_scores = torch.tensor(init_scores)\n",
    "    final_scores = torch.tensor(final_scores)\n",
    "    final_steps = torch.tensor(final_steps)\n",
    "    total_steps = torch.tensor(total_steps)\n",
    "    final_scores = F.sigmoid(torch.tensor(final_scores))\n",
    "    init_scores = F.sigmoid(torch.tensor(init_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_permutation_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4], device='cuda:0')"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_col_mask.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_permutation_i[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permutation_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_cols=0 ts_micro_f1=1.0000, ts_macro_f1=1.0000\n",
    "# num_cols=2 ts_micro_f1=0.6364, ts_macro_f1=0.3241\n",
    "# num_cols=3 ts_micro_f1=0.5181, ts_macro_f1=0.1611\n",
    "# num_cols=4 ts_micro_f1=0.5909, ts_macro_f1=0.2328\n",
    "# num_cols=5 ts_micro_f1=0.5455, ts_macro_f1=0.2550\n",
    "# num_cols=6 ts_micro_f1=0.5733, ts_macro_f1=0.2734\n",
    "# num_cols=7 ts_micro_f1=0.5146, ts_macro_f1=0.2800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_cols=1 ts_micro_f1=1.0000, ts_macro_f1=1.0000, average_final_score=0.1843\n",
      "num_cols=3 ts_micro_f1=0.6515, ts_macro_f1=0.3413, average_final_score=0.7548\n",
      "num_cols=4 ts_micro_f1=0.5542, ts_macro_f1=0.1692, average_final_score=0.8554\n",
      "num_cols=5 ts_micro_f1=0.6023, ts_macro_f1=0.2481, average_final_score=0.8843\n",
      "num_cols=6 ts_micro_f1=0.5455, ts_macro_f1=0.2771, average_final_score=0.9279\n",
      "num_cols=7 ts_micro_f1=0.5867, ts_macro_f1=0.3150, average_final_score=0.8783\n",
      "num_cols=8 ts_micro_f1=0.5439, ts_macro_f1=0.2998, average_final_score=0.9014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55079/1335470484.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  num_cols = torch.tensor(num_cols)\n"
     ]
    }
   ],
   "source": [
    "num_cols = torch.tensor(num_cols)\n",
    "for n_col in num_cols.unique().tolist():\n",
    "    mask = num_cols == n_col\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach()[mask].numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1)[mask].numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    \n",
    "    print(\"num_cols={} ts_micro_f1={:.4f}, ts_macro_f1={:.4f}, average_final_score={:.4f}\".format(n_col, ts_micro_f1, ts_macro_f1, final_scores[mask].mean().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_check_idx = []\n",
    "for i in (torch.tensor(final_correctness) == False).nonzero().reshape(-1).tolist():\n",
    "    if len(correct_scores[i])>0:\n",
    "        to_check_idx.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[28, 34, 41, 52, 53, 58, 64, 87, 96, 98]"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_check_idx[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_check_idx_init = []\n",
    "for i in (torch.tensor(final_correctness) == False).nonzero().reshape(-1).tolist():\n",
    "    if init_correctness[i] == True:\n",
    "        to_check_idx_init.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[34, 52, 53, 87, 96]"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_check_idx_init[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[34, 52] in to_check_idx_init[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([34, 52]).issubset(set(to_check_idx_init[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(to_check_idx_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7311) False True tensor(0.9998) 6 2 2 tensor(14) tensor(96)\n"
     ]
    }
   ],
   "source": [
    "target_idx = 53\n",
    "print(final_scores[target_idx], final_correctness[target_idx], init_correctness[target_idx], init_scores[target_idx], num_cols[target_idx], \n",
    "      final_steps[target_idx], total_steps[target_idx], labels_test[target_idx], preds_test[target_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.4617e-04, 8.8781e-05, 5.6317e-05, 4.9926e-05, 4.8902e-04, 1.9130e-07,\n",
       "        1.9499e-05, 6.4935e-05, 1.2679e-04, 3.9128e-04, 1.1793e-03, 7.3363e-06,\n",
       "        3.3061e-06, 5.4222e-06, 6.2757e-06, 2.7384e-04, 7.6965e-05, 5.2322e-05,\n",
       "        1.9385e-03, 6.7124e-09, 7.2464e-06])"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.sigmoid(torch.tensor(correct_scores[target_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 8, ..., 8, 8, 3])"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, ..., 2, 2, 1])"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(final_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, ..., 2, 2, 1])"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4044608/241628995.py:1: RuntimeWarning: invalid value encountered in true_divide\n",
      "  sns.histplot(np.array(final_steps)/np.array(total_steps))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(np.array(final_steps)/np.array(total_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "719 1085\n"
     ]
    }
   ],
   "source": [
    "print(len(correct_scores), len(test_dataloader_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(torch.tensor(final_steps)[final_correctness==True]/torch.tensor(total_steps)[final_correctness==True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(torch.tensor(num_cols)[final_scores>0.999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = torch.tensor(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1) tensor(0.)\n",
      "tensor(3) tensor(0.4394)\n",
      "tensor(4) tensor(0.4940)\n",
      "tensor(5) tensor(0.6023)\n",
      "tensor(6) tensor(0.6136)\n",
      "tensor(7) tensor(0.6000)\n",
      "tensor(8) tensor(0.6374)\n"
     ]
    }
   ],
   "source": [
    "for num_col in num_cols.unique():\n",
    "    print(num_col, ((final_scores>0.999)&(num_cols==num_col)).sum()/(num_cols==num_col).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(torch.tensor(num_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3696)"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.tensor(num_cols)<8).sum()/len(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4044608/2626332357.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sns.histplot(torch.tensor(final_steps)[final_scores>0.999]/torch.tensor(total_steps)[final_scores>0.999])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(torch.tensor(final_steps)[final_scores>0.999]/torch.tensor(total_steps)[final_scores>0.999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(final_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(F.sigmoid(final_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03246206, -0.04829908,  0.086727  ,  0.04106206, -0.01851852,\n",
       "       -0.03611111, -0.05656566,  0.02      , -0.18245614, -0.04158004,\n",
       "        0.10636443,  0.0872211 , -0.01515152,  0.24728261,  0.00579151,\n",
       "        0.02988506,  0.07655502,  0.03333333,  0.07142857,  0.07692308,\n",
       "        0.07179487,  0.03259259,  0.03428571,  0.1122807 ,  0.160401  ,\n",
       "       -0.02564103,  0.16190476,  0.        ,  0.01098901,  0.1       ,\n",
       "        0.        ,  0.        ,  0.        , -0.22794118, -0.14444444,\n",
       "        0.07142857, -0.26666667,  0.02222222,  0.08333333, -0.2       ,\n",
       "        0.        ,  0.        , -0.02197802,  0.14141414,  0.        ,\n",
       "        0.        ,  0.        ,  0.4       ,  0.23809524,  0.0952381 ,\n",
       "        0.28571429,  0.66666667,  0.16666667,  0.03571429, -0.66666667,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.06060606,  0.        ,\n",
       "        0.        ,  0.        ,  0.16666667, -0.33333333,  0.16666667,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "       -0.06349206, -0.33333333,  0.        , -0.28571429,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.06349206,\n",
       "        0.        ,  0.        , -0.5       ,  0.        ,  0.        ,\n",
       "        0.        ,  0.16666667,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_f1_full - full_f1_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Threshold: 0.9****************************\n",
      "Init\n",
      "443 603 0.7346600331674958\n",
      "138 482 0.2863070539419087\n",
      "MSP\n",
      "447 603 0.7412935323383084\n",
      "157 482 0.3257261410788382\n",
      "MSP & Init\n",
      "438\n",
      "452 603 0.7495854063018242\n",
      "186 482 0.38589211618257263\n",
      "*********************Threshold: 0.99****************************\n",
      "Init\n",
      "407 515 0.7902912621359224\n",
      "174 570 0.30526315789473685\n",
      "MSP\n",
      "408 515 0.7922330097087379\n",
      "196 570 0.34385964912280703\n",
      "MSP & Init\n",
      "404\n",
      "411 515 0.7980582524271844\n",
      "227 570 0.39824561403508774\n",
      "*********************Threshold: 0.999****************************\n",
      "Init\n",
      "353 421 0.838479809976247\n",
      "228 664 0.3433734939759036\n",
      "MSP\n",
      "352 421 0.836104513064133\n",
      "252 664 0.3795180722891566\n",
      "MSP & Init\n",
      "351\n",
      "354 421 0.8408551068883611\n",
      "284 664 0.42771084337349397\n",
      "*********************Threshold: 0.9999****************************\n",
      "Init\n",
      "281 319 0.8808777429467085\n",
      "300 766 0.391644908616188\n",
      "MSP\n",
      "281 319 0.8808777429467085\n",
      "323 766 0.4216710182767624\n",
      "MSP & Init\n",
      "281\n",
      "281 319 0.8808777429467085\n",
      "357 766 0.4660574412532637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4044608/1018509068.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  init_scores = torch.tensor(init_scores)\n",
      "/tmp/ipykernel_4044608/1018509068.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  final_scores = torch.tensor(final_scores)\n"
     ]
    }
   ],
   "source": [
    "correct_init_mask = torch.tensor(init_correctness)\n",
    "correct_msp_mask = torch.tensor(final_correctness)\n",
    "init_scores = torch.tensor(init_scores)\n",
    "final_scores = torch.tensor(final_scores)\n",
    "for threshold in [0.9, 0.99, 0.999, 0.9999]:\n",
    "    uncertain_init_mask = init_scores < threshold\n",
    "    condition_mask = ~uncertain_init_mask\n",
    "    print(f\"*********************Threshold: {threshold}****************************\")\n",
    "    print(\"Init\")\n",
    "    # init prediction\n",
    "    print((condition_mask&correct_init_mask).sum().item(), \n",
    "        (condition_mask).sum().item(), \n",
    "        (condition_mask&correct_init_mask).sum().item()/(condition_mask).sum().item())\n",
    "    # init prediction\n",
    "    print((~condition_mask&correct_init_mask).sum().item(), \n",
    "        (~condition_mask).sum().item(), \n",
    "       (~condition_mask&correct_init_mask).sum().item()/(~condition_mask).sum().item())\n",
    "    print(\"MSP\")\n",
    "    # msp prediction\n",
    "    print((condition_mask&correct_msp_mask).sum().item(), \n",
    "        (condition_mask).sum().item(), \n",
    "        (condition_mask&correct_msp_mask).sum().item()/(condition_mask).sum().item())\n",
    "    # msp prediction\n",
    "    print((~condition_mask&correct_msp_mask).sum().item(), \n",
    "        (~condition_mask).sum().item(), \n",
    "        (~condition_mask&correct_msp_mask).sum().item()/(~condition_mask).sum().item())\n",
    "    print(\"MSP & Init\")\n",
    "    print(((condition_mask&correct_init_mask)&(condition_mask&correct_msp_mask)).sum().item())\n",
    "    # print(((~(init_target_mask&(~uncertain_init_mask & ~uncertain_target_mask))& correct_msp_mask)&(~(init_target_mask&(~uncertain_init_mask & ~uncertain_target_mask))& correct_init_mask)).sum().item())\n",
    "    print(((condition_mask&correct_init_mask)|(condition_mask&correct_msp_mask)).sum().item(),\n",
    "          (condition_mask).sum().item(), \n",
    "          ((condition_mask&correct_init_mask)|(condition_mask&correct_msp_mask)).sum().item()/(condition_mask).sum().item())\n",
    "    print(((~condition_mask&correct_init_mask)|(~condition_mask&correct_msp_mask)).sum().item(),\n",
    "          (~condition_mask).sum().item(), \n",
    "          ((~condition_mask&correct_init_mask)|(~condition_mask&correct_msp_mask)).sum().item()/(~condition_mask).sum().item())\n",
    "    # print(\"Permutation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(658) tensor(0.6065)\n"
     ]
    }
   ],
   "source": [
    "print((final_scores>0.999).sum(), (final_scores>0.999).sum()/len(final_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999863862991333"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(754) 1085 tensor(0.6949)\n"
     ]
    }
   ],
   "source": [
    "print((final_scores>0.999).sum(), len(final_scores), (final_scores>0.999).sum()/len(final_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "test 1085\n"
     ]
    }
   ],
   "source": [
    "src = None\n",
    "init_max_col_length = 8\n",
    "test_dataset_iter_extra = GittablesTablewiseIterateDataset(cv=cv,\n",
    "                            split=\"test\", src=src,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length,\n",
    "                            gt_only='all' not in task,\n",
    "                            device=device,\n",
    "                            base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                            small_tag=\"semi1\",\n",
    "                            max_unlabeled=16,\n",
    "                            adaptive_max_length=False,)\n",
    "padder = collate_fn(tokenizer.pad_token_id)\n",
    "# test_dataloader_iter_extra = DataLoader(test_dataset_iter_extra,\n",
    "#                                 batch_size=1,\n",
    "#                             #   collate_fn=collate_fn)\n",
    "#                             collate_fn=padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_iter_extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols_extra = []\n",
    "for i in range(len(test_dataset_iter_extra)):\n",
    "    init_permutation_i = get_permutation(test_dataset_iter_extra[i][\"target_col_mask\"].T)\n",
    "    num_cols_extra.append(len(init_permutation_i))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_permutation_i, init_permutation_i_extra = init_permutation_i[:8], init_permutation_i[8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(num_cols_extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_micro_f1=0.5576, ts_macro_f1=0.3024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4044608/1708860331.py:143: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  final_scores = F.sigmoid(torch.tensor(final_scores))\n",
      "/tmp/ipykernel_4044608/1708860331.py:144: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  init_scores = F.sigmoid(torch.tensor(init_scores))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "\n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "verifier.load_state_dict(veri_state_dict)\n",
    "verifier.eval()\n",
    "verifier = verifier.to(device)\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "init_scores = []\n",
    "init_correctness = []\n",
    "final_scores = []\n",
    "final_correctness = []\n",
    "num_cols = []\n",
    "total_steps = []\n",
    "final_steps = []\n",
    "correct_scores = defaultdict(list)\n",
    "correct_steps = defaultdict(list)\n",
    "init_max_col_length = 8\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in enumerate(test_dataset_iter_extra):\n",
    "        target_col_mask = batch[\"target_col_mask\"].T\n",
    "        embs = test_embs[batch_idx][0].reshape(1,-1).to(device)\n",
    "        logits = test_logits[batch_idx][0].reshape(-1).to(device)\n",
    "        scores_init = verifier(embs)\n",
    "        max_score = -float(\"inf\")\n",
    "\n",
    "        init_scores.append(scores_init.item())\n",
    "        init_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "        init_permutation_i = get_permutation(target_col_mask)\n",
    "        init_permutation_i, init_permutation_i_extra = init_permutation_i[:init_max_col_length], init_permutation_i[init_max_col_length:]\n",
    "        \n",
    "        col_idx_set = target_col_mask.unique().tolist()\n",
    "        early_stop = False\n",
    "        i = 0\n",
    "        final_step = 0\n",
    "        total_steps.append(len(init_permutation_i) - max(len(init_permutation_i)//2, len(init_permutation_i)-3) -1)\n",
    "        num_cols.append(len(init_permutation_i))\n",
    "        enough = False\n",
    "        for r in range(len(init_permutation_i),  max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "            for x in itertools.combinations(init_permutation_i, r):\n",
    "                if 0 not in x:\n",
    "                    continue\n",
    "                logits_temp = test_logits[batch_idx][i].reshape(-1).to(device)\n",
    "                embs_temp = test_embs[batch_idx][i].reshape(1,-1).to(device)\n",
    "                scores_temp = verifier(embs_temp).item()\n",
    "                predict_temp = logits_temp.argmax().item()\n",
    "                i += 1\n",
    "                if scores_temp > max_score:\n",
    "                    max_score = scores_temp\n",
    "                    logits = logits_temp.clone()\n",
    "                    final_step = len(init_permutation_i) - r\n",
    "                if logits_temp.argmax().item() == batch[\"label\"].item():\n",
    "                    correct_scores[batch_idx].append(scores_temp)\n",
    "                    correct_steps[batch_idx].append(len(init_permutation_i) - r)\n",
    "                if F.sigmoid(torch.tensor(max_score)).item() > 0.999:\n",
    "                    enough = True\n",
    "            if enough:\n",
    "                break  \n",
    "        if not enough and len(init_permutation_i_extra)>0:\n",
    "            for new_col_idx in init_permutation_i_extra:\n",
    "                init_permutation_i_new = init_permutation_i + [new_col_idx]\n",
    "                for r in range(len(init_permutation_i),  max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "                    for x in itertools.combinations(init_permutation_i_new, r):\n",
    "                        if 0 not in x or new_col_idx not in x:\n",
    "                            continue\n",
    "                        new_batch_data = []\n",
    "                        for col_i in x:\n",
    "                            if col_i == 0:\n",
    "                                if len(new_batch_data) == 0:\n",
    "                                    cls_indexes_value = 0\n",
    "                                else:\n",
    "                                    cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                            new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                        new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                        cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                        logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                        scores_temp = verifier(embs_temp.reshape(1,-1)).item()\n",
    "                        predict_temp = logits_temp.argmax().item()\n",
    "                        \n",
    "                        if scores_temp > max_score:\n",
    "                            max_score = scores_temp\n",
    "                            logits = logits_temp.clone()\n",
    "                            final_step = len(init_permutation_i) - r\n",
    "                        if logits_temp.argmax().item() == batch[\"label\"].item():\n",
    "                            correct_scores[batch_idx].append(scores_temp)\n",
    "                            correct_steps[batch_idx].append(len(init_permutation_i) - r)\n",
    "                        if F.sigmoid(torch.tensor(max_score)).item() > 0.999:\n",
    "                            enough = True\n",
    "                    if enough:\n",
    "                        break\n",
    "                if enough:\n",
    "                    break\n",
    "                \n",
    "                \n",
    "        final_scores.append(max_score)\n",
    "        final_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "        final_steps.append(final_step)\n",
    "        labels_test.append(batch[\"label\"].cpu())\n",
    "        logits_test.append(logits.detach().cpu())\n",
    "    labels_test = torch.cat(labels_test, dim=0)\n",
    "    logits_test = torch.stack(logits_test, dim=0)\n",
    "    preds_test = torch.argmax(logits_test, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "ts_f1_full = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=None)\n",
    "# full_f1_init\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "final_correctness = torch.tensor(final_correctness)\n",
    "init_correctness = torch.tensor(init_correctness)\n",
    "init_scores = torch.tensor(init_scores)\n",
    "final_scores = torch.tensor(final_scores)\n",
    "final_steps = torch.tensor(final_steps)\n",
    "total_steps = torch.tensor(total_steps)\n",
    "final_scores = F.sigmoid(torch.tensor(final_scores))\n",
    "init_scores = F.sigmoid(torch.tensor(init_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_micro_f1=0.5567, ts_macro_f1=0.3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4044608/1939833176.py:135: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  final_scores = F.sigmoid(torch.tensor(final_scores))\n",
      "/tmp/ipykernel_4044608/1939833176.py:136: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  init_scores = F.sigmoid(torch.tensor(init_scores))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "\n",
    "model.load_state_dict(best_state_dict, strict=False)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "verifier.load_state_dict(veri_state_dict)\n",
    "verifier.eval()\n",
    "verifier = verifier.to(device)\n",
    "labels_test = []\n",
    "logits_test = []\n",
    "init_scores = []\n",
    "init_correctness = []\n",
    "final_scores = []\n",
    "final_correctness = []\n",
    "num_cols = []\n",
    "total_steps = []\n",
    "final_steps = []\n",
    "correct_scores = defaultdict(list)\n",
    "correct_steps = defaultdict(list)\n",
    "init_max_col_length = 8\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in enumerate(test_dataset_iter_extra):\n",
    "        target_col_mask = batch[\"target_col_mask\"].T\n",
    "        embs = test_embs[batch_idx][0].reshape(1,-1).to(device)\n",
    "        logits = test_logits[batch_idx][0].reshape(-1).to(device)\n",
    "        scores_init = verifier(embs)\n",
    "        max_score = -float(\"inf\")\n",
    "\n",
    "        init_scores.append(scores_init.item())\n",
    "        init_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "        init_permutation_i = get_permutation(target_col_mask)\n",
    "        init_permutation_i, init_permutation_i_extra = init_permutation_i[:init_max_col_length], init_permutation_i[init_max_col_length:]\n",
    "        \n",
    "        col_idx_set = target_col_mask.unique().tolist()\n",
    "        early_stop = False\n",
    "        i = 0\n",
    "        final_step = 0\n",
    "        total_steps.append(len(init_permutation_i) - max(len(init_permutation_i)//2, len(init_permutation_i)-3) -1)\n",
    "        num_cols.append(len(init_permutation_i))\n",
    "        enough = False\n",
    "        for r in range(len(init_permutation_i),  max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "            for x in itertools.combinations(init_permutation_i, r):\n",
    "                if 0 not in x:\n",
    "                    continue\n",
    "                logits_temp = test_logits[batch_idx][i].reshape(-1).to(device)\n",
    "                embs_temp = test_embs[batch_idx][i].reshape(1,-1).to(device)\n",
    "                scores_temp = verifier(embs_temp).item()\n",
    "                predict_temp = logits_temp.argmax().item()\n",
    "                i += 1\n",
    "                if scores_temp > max_score:\n",
    "                    max_score = scores_temp\n",
    "                    logits = logits_temp.clone()\n",
    "                    final_step = len(init_permutation_i) - r\n",
    "                if logits_temp.argmax().item() == batch[\"label\"].item():\n",
    "                    correct_scores[batch_idx].append(scores_temp)\n",
    "                    correct_steps[batch_idx].append(len(init_permutation_i) - r)\n",
    "\n",
    "        if len(init_permutation_i_extra)>0:\n",
    "            for new_col_idx in init_permutation_i_extra:\n",
    "                init_permutation_i_new = init_permutation_i + [new_col_idx]\n",
    "                for r in range(len(init_permutation_i),  max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "                    for x in itertools.combinations(init_permutation_i_new, r):\n",
    "                        if 0 not in x or new_col_idx not in x:\n",
    "                            continue\n",
    "                        new_batch_data = []\n",
    "                        for col_i in x:\n",
    "                            if col_i == 0:\n",
    "                                if len(new_batch_data) == 0:\n",
    "                                    cls_indexes_value = 0\n",
    "                                else:\n",
    "                                    cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                            new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                        new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                        cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                        logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                        scores_temp = verifier(embs_temp.reshape(1,-1)).item()\n",
    "                        predict_temp = logits_temp.argmax().item()\n",
    "                        \n",
    "                        if scores_temp > max_score:\n",
    "                            max_score = scores_temp\n",
    "                            logits = logits_temp.clone()\n",
    "                            final_step = len(init_permutation_i) - r\n",
    "                        if logits_temp.argmax().item() == batch[\"label\"].item():\n",
    "                            correct_scores[batch_idx].append(scores_temp)\n",
    "                            correct_steps[batch_idx].append(len(init_permutation_i) - r)\n",
    "\n",
    "                \n",
    "                \n",
    "        final_scores.append(max_score)\n",
    "        final_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "        final_steps.append(final_step)\n",
    "        labels_test.append(batch[\"label\"].cpu())\n",
    "        logits_test.append(logits.detach().cpu())\n",
    "    labels_test = torch.cat(labels_test, dim=0)\n",
    "    logits_test = torch.stack(logits_test, dim=0)\n",
    "    preds_test = torch.argmax(logits_test, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "ts_pred_list = logits_test.argmax(\n",
    "                            1).cpu().detach().numpy().tolist()\n",
    "ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"micro\")\n",
    "ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=\"macro\")\n",
    "ts_f1_full = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                    ts_pred_list,\n",
    "                    average=None)\n",
    "# full_f1_init\n",
    "print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "final_correctness = torch.tensor(final_correctness)\n",
    "init_correctness = torch.tensor(init_correctness)\n",
    "init_scores = torch.tensor(init_scores)\n",
    "final_scores = torch.tensor(final_scores)\n",
    "final_steps = torch.tensor(final_steps)\n",
    "total_steps = torch.tensor(total_steps)\n",
    "final_scores = F.sigmoid(torch.tensor(final_scores))\n",
    "init_scores = F.sigmoid(torch.tensor(init_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================max_unlabeled=16===============================\n",
      "test\n",
      "test 1085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9311/2742996530.py:48: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3697.)\n",
      "  target_col_mask = batch[\"target_col_mask\"].T\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "for max_unlabeled in [16, 32, 64, 128]:\n",
    "    print(f\"============================max_unlabeled={max_unlabeled}===============================\")\n",
    "    test_dataset_iter_extra = GittablesTablewiseIterateDataset(cv=cv,\n",
    "                                split=\"test\", src=src,\n",
    "                                tokenizer=tokenizer,\n",
    "                                max_length=max_length,\n",
    "                                gt_only='all' not in task,\n",
    "                                device=device,\n",
    "                                base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                                small_tag=\"semi1\",\n",
    "                                max_unlabeled=max_unlabeled,\n",
    "                                adaptive_max_length=False,)\n",
    "    model.load_state_dict(best_state_dict, strict=False)\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    verifier.load_state_dict(veri_state_dict)\n",
    "    verifier.eval()\n",
    "    verifier = verifier.to(device)\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    init_scores = []\n",
    "    init_correctness = []\n",
    "    final_scores = []\n",
    "    final_correctness = []\n",
    "    num_cols = []\n",
    "    total_steps = []\n",
    "    final_steps = []\n",
    "    correct_scores = defaultdict(list)\n",
    "    correct_steps = defaultdict(list)\n",
    "    init_max_col_length = 8\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(test_dataset_iter_extra):\n",
    "            target_col_mask = batch[\"target_col_mask\"].T\n",
    "            embs = test_embs[batch_idx][0].reshape(1,-1).to(device)\n",
    "            logits = test_logits[batch_idx][0].reshape(-1).to(device)\n",
    "            scores_init = verifier(embs)\n",
    "            max_score = -float(\"inf\")\n",
    "\n",
    "            init_scores.append(scores_init.item())\n",
    "            init_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            init_permutation_i, init_permutation_i_extra = init_permutation_i[:init_max_col_length], init_permutation_i[init_max_col_length:]\n",
    "            \n",
    "            if 0 not in init_permutation_i:\n",
    "                col_to_exclude = init_permutation_i[-1]\n",
    "                init_permutation_i = init_permutation_i[:-1] + [0]\n",
    "                init_permutation_i_extra.remove(0)\n",
    "                init_permutation_i_extra = [col_to_exclude] + init_permutation_i_extra\n",
    "                assert 0 in init_permutation_i and 0 not in init_permutation_i_extra\n",
    "            \n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            early_stop = False\n",
    "            i = 0\n",
    "            final_step = 0\n",
    "            total_steps.append(len(init_permutation_i) - max(len(init_permutation_i)//2, len(init_permutation_i)-3) -1)\n",
    "            num_cols.append(len(init_permutation_i))\n",
    "            enough = False\n",
    "            for r in range(len(init_permutation_i),  max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "                for x in itertools.combinations(init_permutation_i, r):\n",
    "                    if 0 not in x:\n",
    "                        continue\n",
    "                    logits_temp = test_logits[batch_idx][i].reshape(-1).to(device)\n",
    "                    embs_temp = test_embs[batch_idx][i].reshape(1,-1).to(device)\n",
    "                    scores_temp = verifier(embs_temp).item()\n",
    "                    predict_temp = logits_temp.argmax().item()\n",
    "                    i += 1\n",
    "                    if scores_temp > max_score:\n",
    "                        max_score = scores_temp\n",
    "                        logits = logits_temp.clone()\n",
    "                        final_step = len(init_permutation_i) - r\n",
    "                    if logits_temp.argmax().item() == batch[\"label\"].item():\n",
    "                        correct_scores[batch_idx].append(scores_temp)\n",
    "                        correct_steps[batch_idx].append(len(init_permutation_i) - r)\n",
    "                    if F.sigmoid(torch.tensor(max_score)).item() > 0.999:\n",
    "                        enough = True\n",
    "                if enough:\n",
    "                    break  \n",
    "            if not enough and len(init_permutation_i_extra)>0:\n",
    "                for new_col_idx in init_permutation_i_extra:\n",
    "                    init_permutation_i_new = init_permutation_i + [new_col_idx]\n",
    "                    for r in range(len(init_permutation_i),  max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "                        for x in itertools.combinations(init_permutation_i_new, r):\n",
    "                            if 0 not in x or new_col_idx not in x:\n",
    "                                continue\n",
    "                            new_batch_data = []\n",
    "                            for col_i in x:\n",
    "                                if col_i == 0:\n",
    "                                    if len(new_batch_data) == 0:\n",
    "                                        cls_indexes_value = 0\n",
    "                                    else:\n",
    "                                        cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                                new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                            new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                            cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                            logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                            scores_temp = verifier(embs_temp.reshape(1,-1)).item()\n",
    "                            predict_temp = logits_temp.argmax().item()\n",
    "                            \n",
    "                            if scores_temp > max_score:\n",
    "                                max_score = scores_temp\n",
    "                                logits = logits_temp.clone()\n",
    "                                final_step = len(init_permutation_i) - r\n",
    "                            if logits_temp.argmax().item() == batch[\"label\"].item():\n",
    "                                correct_scores[batch_idx].append(scores_temp)\n",
    "                                correct_steps[batch_idx].append(len(init_permutation_i) - r)\n",
    "                            if F.sigmoid(torch.tensor(max_score)).item() > 0.999:\n",
    "                                enough = True\n",
    "                        if enough:\n",
    "                            break\n",
    "                    if enough:\n",
    "                        break\n",
    "                    \n",
    "                    \n",
    "            final_scores.append(max_score)\n",
    "            final_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "            final_steps.append(final_step)\n",
    "            labels_test.append(batch[\"label\"].cpu())\n",
    "            logits_test.append(logits.detach().cpu())\n",
    "        labels_test = torch.cat(labels_test, dim=0)\n",
    "        logits_test = torch.stack(logits_test, dim=0)\n",
    "        preds_test = torch.argmax(logits_test, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix, f1_score\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach().numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    ts_f1_full = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=None)\n",
    "    # full_f1_init\n",
    "    print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "    final_correctness = torch.tensor(final_correctness)\n",
    "    init_correctness = torch.tensor(init_correctness)\n",
    "    init_scores = torch.tensor(init_scores)\n",
    "    final_scores = torch.tensor(final_scores)\n",
    "    final_steps = torch.tensor(final_steps)\n",
    "    total_steps = torch.tensor(total_steps)\n",
    "    final_scores = F.sigmoid(torch.tensor(final_scores))\n",
    "    init_scores = F.sigmoid(torch.tensor(init_scores))\n",
    "    print((final_scores>0.999).sum(), len(final_scores), (final_scores>0.999).sum()/len(final_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_micro_f1=0.5567, ts_macro_f1=0.2983"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================max_unlabeled=32===============================\n",
      "test\n",
      "test 1085\n",
      "ts_micro_f1=0.5594, ts_macro_f1=0.3043\n",
      "tensor(731) 1085 tensor(0.6737)\n",
      "============================max_unlabeled=64===============================\n",
      "test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4044608/3498873978.py:154: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  final_scores = F.sigmoid(torch.tensor(final_scores))\n",
      "/tmp/ipykernel_4044608/3498873978.py:155: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  init_scores = F.sigmoid(torch.tensor(init_scores))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 1085\n",
      "ts_micro_f1=0.5594, ts_macro_f1=0.3043\n",
      "tensor(732) 1085 tensor(0.6747)\n",
      "============================max_unlabeled=128===============================\n",
      "test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4044608/3498873978.py:154: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  final_scores = F.sigmoid(torch.tensor(final_scores))\n",
      "/tmp/ipykernel_4044608/3498873978.py:155: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  init_scores = F.sigmoid(torch.tensor(init_scores))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 1085\n",
      "ts_micro_f1=0.5594, ts_macro_f1=0.3043\n",
      "tensor(732) 1085 tensor(0.6747)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4044608/3498873978.py:154: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  final_scores = F.sigmoid(torch.tensor(final_scores))\n",
      "/tmp/ipykernel_4044608/3498873978.py:155: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  init_scores = F.sigmoid(torch.tensor(init_scores))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "for max_unlabeled in [32, 64, 128]:\n",
    "    print(f\"============================max_unlabeled={max_unlabeled}===============================\")\n",
    "    test_dataset_iter_extra = GittablesTablewiseIterateDataset(cv=cv,\n",
    "                                split=\"test\", src=src,\n",
    "                                tokenizer=tokenizer,\n",
    "                                max_length=max_length,\n",
    "                                gt_only='all' not in task,\n",
    "                                device=device,\n",
    "                                base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                                small_tag=\"semi1\",\n",
    "                                max_unlabeled=max_unlabeled,\n",
    "                                adaptive_max_length=False,)\n",
    "    model.load_state_dict(best_state_dict, strict=False)\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    verifier.load_state_dict(veri_state_dict)\n",
    "    verifier.eval()\n",
    "    verifier = verifier.to(device)\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    init_scores = []\n",
    "    init_correctness = []\n",
    "    final_scores = []\n",
    "    final_correctness = []\n",
    "    num_cols = []\n",
    "    total_steps = []\n",
    "    final_steps = []\n",
    "    correct_scores = defaultdict(list)\n",
    "    correct_steps = defaultdict(list)\n",
    "    init_max_col_length = 8\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(test_dataset_iter_extra):\n",
    "            target_col_mask = batch[\"target_col_mask\"].T\n",
    "            embs = test_embs[batch_idx][0].reshape(1,-1).to(device)\n",
    "            logits = test_logits[batch_idx][0].reshape(-1).to(device)\n",
    "            scores_init = verifier(embs)\n",
    "            max_score = -float(\"inf\")\n",
    "\n",
    "            init_scores.append(scores_init.item())\n",
    "            init_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            init_permutation_i, init_permutation_i_extra = init_permutation_i[:init_max_col_length], init_permutation_i[init_max_col_length:]\n",
    "            \n",
    "            if 0 not in init_permutation_i:\n",
    "                col_to_exclude = init_permutation_i[-1]\n",
    "                init_permutation_i = init_permutation_i[:-1] + [0]\n",
    "                init_permutation_i_extra.remove(0)\n",
    "                init_permutation_i_extra = [col_to_exclude] + init_permutation_i_extra\n",
    "                assert 0 in init_permutation_i and 0 not in init_permutation_i_extra\n",
    "            \n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            early_stop = False\n",
    "            i = 0\n",
    "            final_step = 0\n",
    "            total_steps.append(len(init_permutation_i) - max(len(init_permutation_i)//2, len(init_permutation_i)-3) -1)\n",
    "            num_cols.append(len(init_permutation_i))\n",
    "            enough = False\n",
    "            for r in range(len(init_permutation_i),  max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "                for x in itertools.combinations(init_permutation_i, r):\n",
    "                    if 0 not in x:\n",
    "                        continue\n",
    "                    logits_temp = test_logits[batch_idx][i].reshape(-1).to(device)\n",
    "                    embs_temp = test_embs[batch_idx][i].reshape(1,-1).to(device)\n",
    "                    scores_temp = verifier(embs_temp).item()\n",
    "                    predict_temp = logits_temp.argmax().item()\n",
    "                    i += 1\n",
    "                    if scores_temp > max_score:\n",
    "                        max_score = scores_temp\n",
    "                        logits = logits_temp.clone()\n",
    "                        final_step = len(init_permutation_i) - r\n",
    "                    if logits_temp.argmax().item() == batch[\"label\"].item():\n",
    "                        correct_scores[batch_idx].append(scores_temp)\n",
    "                        correct_steps[batch_idx].append(len(init_permutation_i) - r)\n",
    "                    if F.sigmoid(torch.tensor(max_score)).item() > 0.999:\n",
    "                        enough = True\n",
    "                if enough:\n",
    "                    break  \n",
    "            if not enough and len(init_permutation_i_extra)>0:\n",
    "                for new_col_idx in init_permutation_i_extra:\n",
    "                    init_permutation_i_new = init_permutation_i + [new_col_idx]\n",
    "                    for r in range(len(init_permutation_i),  max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "                        for x in itertools.combinations(init_permutation_i_new, r):\n",
    "                            if 0 not in x or new_col_idx not in x:\n",
    "                                continue\n",
    "                            new_batch_data = []\n",
    "                            for col_i in x:\n",
    "                                if col_i == 0:\n",
    "                                    if len(new_batch_data) == 0:\n",
    "                                        cls_indexes_value = 0\n",
    "                                    else:\n",
    "                                        cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                                new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                            new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                            cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                            logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                            scores_temp = verifier(embs_temp.reshape(1,-1)).item()\n",
    "                            predict_temp = logits_temp.argmax().item()\n",
    "                            \n",
    "                            if scores_temp > max_score:\n",
    "                                max_score = scores_temp\n",
    "                                logits = logits_temp.clone()\n",
    "                                final_step = len(init_permutation_i) - r\n",
    "                            if logits_temp.argmax().item() == batch[\"label\"].item():\n",
    "                                correct_scores[batch_idx].append(scores_temp)\n",
    "                                correct_steps[batch_idx].append(len(init_permutation_i) - r)\n",
    "                            if F.sigmoid(torch.tensor(max_score)).item() > 0.999:\n",
    "                                enough = True\n",
    "                        if enough:\n",
    "                            break\n",
    "                    if enough:\n",
    "                        break\n",
    "                    \n",
    "                    \n",
    "            final_scores.append(max_score)\n",
    "            final_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "            final_steps.append(final_step)\n",
    "            labels_test.append(batch[\"label\"].cpu())\n",
    "            logits_test.append(logits.detach().cpu())\n",
    "        labels_test = torch.cat(labels_test, dim=0)\n",
    "        logits_test = torch.stack(logits_test, dim=0)\n",
    "        preds_test = torch.argmax(logits_test, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix, f1_score\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach().numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    ts_f1_full = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=None)\n",
    "    # full_f1_init\n",
    "    print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "    final_correctness = torch.tensor(final_correctness)\n",
    "    init_correctness = torch.tensor(init_correctness)\n",
    "    init_scores = torch.tensor(init_scores)\n",
    "    final_scores = torch.tensor(final_scores)\n",
    "    final_steps = torch.tensor(final_steps)\n",
    "    total_steps = torch.tensor(total_steps)\n",
    "    final_scores = F.sigmoid(torch.tensor(final_scores))\n",
    "    init_scores = F.sigmoid(torch.tensor(init_scores))\n",
    "    print((final_scores>0.999).sum(), len(final_scores), (final_scores>0.999).sum()/len(final_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================max_unlabeled=16===============================\n",
      "test\n",
      "test 1085\n",
      "ts_micro_f1=0.5604, ts_macro_f1=0.2952\n",
      "tensor(824) 1085 tensor(0.7594)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55079/3884267276.py:156: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  final_scores = F.sigmoid(torch.tensor(final_scores))\n",
      "/tmp/ipykernel_55079/3884267276.py:157: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  init_scores = F.sigmoid(torch.tensor(init_scores))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import itertools\n",
    "\n",
    "def is_sublist(A, B):\n",
    "    it = iter(B)\n",
    "    return all(x in it for x in A)\n",
    "def get_permutation(x):\n",
    "    new = []\n",
    "    x = x.tolist()\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    for k in x:\n",
    "        if k not in new:\n",
    "            new.append(k)\n",
    "    return new\n",
    "\n",
    "for max_unlabeled in [16]:\n",
    "    print(f\"============================max_unlabeled={max_unlabeled}===============================\")\n",
    "    test_dataset_iter_extra = GittablesTablewiseIterateDataset(cv=cv,\n",
    "                                split=\"test\", src=src,\n",
    "                                tokenizer=tokenizer,\n",
    "                                max_length=max_length,\n",
    "                                gt_only='all' not in task,\n",
    "                                device=device,\n",
    "                                base_dirpath=os.path.join(args.data_path, \"GitTables/semtab_gittables/2022\"),\n",
    "                                small_tag=\"semi1\",\n",
    "                                max_unlabeled=max_unlabeled,\n",
    "                                adaptive_max_length=False,)\n",
    "    model.load_state_dict(best_state_dict, strict=False)\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    verifier.load_state_dict(veri_state_dict)\n",
    "    verifier.eval()\n",
    "    verifier = verifier.to(device)\n",
    "    labels_test = []\n",
    "    logits_test = []\n",
    "    init_scores = []\n",
    "    init_correctness = []\n",
    "    final_scores = []\n",
    "    final_correctness = []\n",
    "    num_cols = []\n",
    "    total_steps = []\n",
    "    final_steps = []\n",
    "    correct_scores = defaultdict(list)\n",
    "    correct_steps = defaultdict(list)\n",
    "    init_max_col_length = 8\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(test_dataset_iter_extra):\n",
    "            target_col_mask = batch[\"target_col_mask\"].T\n",
    "            embs = test_embs[batch_idx][0].reshape(1,-1).to(device)\n",
    "            logits = test_logits[batch_idx][0].reshape(-1).to(device)\n",
    "            scores_init = verifier(embs)\n",
    "            max_score = -float(\"inf\")\n",
    "\n",
    "            init_scores.append(scores_init.item())\n",
    "            init_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            init_permutation_i, init_permutation_i_extra = init_permutation_i[:init_max_col_length], init_permutation_i[init_max_col_length:]\n",
    "            \n",
    "            col_idx_set = target_col_mask.unique().tolist()\n",
    "            early_stop = False\n",
    "            i = 0\n",
    "            final_step = 0\n",
    "            total_steps.append(len(init_permutation_i) - max(len(init_permutation_i)//2, len(init_permutation_i)-3) -1)\n",
    "            num_cols.append(len(init_permutation_i))\n",
    "            enough = False\n",
    "            for r in range(len(init_permutation_i),  max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1): # not \n",
    "                for x in itertools.combinations(init_permutation_i, r):\n",
    "                    if 0 not in x:\n",
    "                        continue\n",
    "                    logits_temp = test_logits[batch_idx][i].reshape(-1).to(device)\n",
    "                    embs_temp = test_embs[batch_idx][i].reshape(1,-1).to(device)\n",
    "                    scores_temp = verifier(embs_temp).item()\n",
    "                    predict_temp = logits_temp.argmax().item()\n",
    "                    i += 1\n",
    "                    if scores_temp > max_score:\n",
    "                        max_score = scores_temp\n",
    "                        logits = logits_temp.clone()\n",
    "                        final_step = len(init_permutation_i) - r\n",
    "                    if logits_temp.argmax().item() == batch[\"label\"].item():\n",
    "                        correct_scores[batch_idx].append(scores_temp)\n",
    "                        correct_steps[batch_idx].append(len(init_permutation_i) - r)\n",
    "                    if F.sigmoid(torch.tensor(max_score)).item() > 0.999:\n",
    "                        enough = True\n",
    "                if enough:\n",
    "                    break  \n",
    "                \n",
    "            if not enough and len(init_permutation_i_extra)>0:\n",
    "                for z in range(1, len(init_permutation_i_extra)+1):\n",
    "                    for new_col_idx in itertools.combinations(init_permutation_i_extra, z):\n",
    "                        init_permutation_i_new = init_permutation_i + list(new_col_idx)\n",
    "                        for r in range(len(init_permutation_i),  max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1):\n",
    "                            for x in itertools.combinations(init_permutation_i_new, r):\n",
    "                                if not set(list(new_col_idx)+[0]).issubset(set(x)):\n",
    "                                    continue\n",
    "                                new_batch_data = []\n",
    "                                for col_i in x:\n",
    "                                    if col_i == 0:\n",
    "                                        if len(new_batch_data) == 0:\n",
    "                                            cls_indexes_value = 0\n",
    "                                        else:\n",
    "                                            cls_indexes_value = sum([len(new_batch_data[i]) for i in range(len(new_batch_data))])\n",
    "                                    new_batch_data.append(batch[\"data\"].T[target_col_mask==col_i])\n",
    "                                new_batch_data = torch.cat(new_batch_data, dim=-1).reshape(1, -1)\n",
    "                                cls_indexes = torch.tensor([0, cls_indexes_value]).reshape(1, -1).to(device)\n",
    "                                logits_temp, embs_temp = model(new_batch_data, cls_indexes=cls_indexes, get_enc=True)\n",
    "                                scores_temp = verifier(embs_temp.reshape(1,-1)).item()\n",
    "                                predict_temp = logits_temp.argmax().item()\n",
    "                                \n",
    "                                if scores_temp > max_score:\n",
    "                                    max_score = scores_temp\n",
    "                                    logits = logits_temp.clone()\n",
    "                                    final_step = len(init_permutation_i) - r\n",
    "                                if logits_temp.argmax().item() == batch[\"label\"].item():\n",
    "                                    correct_scores[batch_idx].append(scores_temp)\n",
    "                                    correct_steps[batch_idx].append(len(init_permutation_i) - r)\n",
    "                                if F.sigmoid(torch.tensor(max_score)).item() > 0.999:\n",
    "                                    enough = True\n",
    "                            if enough:\n",
    "                                break\n",
    "                        if enough:\n",
    "                            break\n",
    "                        \n",
    "                    \n",
    "            final_scores.append(max_score)\n",
    "            final_correctness.append(logits.argmax().item() == batch[\"label\"].item())\n",
    "            final_steps.append(final_step)\n",
    "            labels_test.append(batch[\"label\"].cpu())\n",
    "            logits_test.append(logits.detach().cpu())\n",
    "        labels_test = torch.cat(labels_test, dim=0)\n",
    "        logits_test = torch.stack(logits_test, dim=0)\n",
    "        preds_test = torch.argmax(logits_test, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix, f1_score\n",
    "    ts_pred_list = logits_test.argmax(\n",
    "                                1).cpu().detach().numpy().tolist()\n",
    "    ts_micro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"micro\")\n",
    "    ts_macro_f1 = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=\"macro\")\n",
    "    ts_f1_full = f1_score(labels_test.reshape(-1).numpy().tolist(),\n",
    "                        ts_pred_list,\n",
    "                        average=None)\n",
    "    # full_f1_init\n",
    "    print(\"ts_micro_f1={:.4f}, ts_macro_f1={:.4f}\".format(ts_micro_f1, ts_macro_f1))\n",
    "    final_correctness = torch.tensor(final_correctness)\n",
    "    init_correctness = torch.tensor(init_correctness)\n",
    "    init_scores = torch.tensor(init_scores)\n",
    "    final_scores = torch.tensor(final_scores)\n",
    "    final_steps = torch.tensor(final_steps)\n",
    "    total_steps = torch.tensor(total_steps)\n",
    "    final_scores = F.sigmoid(torch.tensor(final_scores))\n",
    "    init_scores = F.sigmoid(torch.tensor(init_scores))\n",
    "    print((final_scores>0.999).sum(), len(final_scores), (final_scores>0.999).sum()/len(final_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "        for batch_idx, batch in enumerate(test_dataset_iter_extra):\n",
    "            target_col_mask = batch[\"target_col_mask\"].T\n",
    "            embs = test_embs[batch_idx][0].reshape(1,-1).to(device)\n",
    "            logits = test_logits[batch_idx][0].reshape(-1).to(device)\n",
    "            scores_init = verifier(embs)\n",
    "            max_score = -float(\"inf\")\n",
    "\n",
    "            init_permutation_i = get_permutation(target_col_mask)\n",
    "            init_permutation_i, init_permutation_i_extra = init_permutation_i[:init_max_col_length], init_permutation_i[init_max_col_length:]\n",
    "            \n",
    "            if 0 not in init_permutation_i:\n",
    "                col_to_exclude = init_permutation_i[-1]\n",
    "                init_permutation_i = init_permutation_i[:-1] + [0]\n",
    "                init_permutation_i_extra.remove(0)\n",
    "                init_permutation_i_extra = [col_to_exclude] + init_permutation_i_extra\n",
    "                assert 0 in init_permutation_i and 0 not in init_permutation_i_extra\n",
    "            if len(init_permutation_i_extra) == 2:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 0]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_permutation_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 9]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_permutation_i_extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 0, 8, 9]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_permutation_i_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 9, 0]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(new_col_idx)+[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 3, 4, 5, 6, 0, 8)\n",
      "(1, 2, 3, 4, 5, 7, 0, 8)\n",
      "(1, 2, 3, 4, 6, 7, 0, 8)\n",
      "(1, 2, 3, 5, 6, 7, 0, 8)\n",
      "(1, 2, 4, 5, 6, 7, 0, 8)\n",
      "(1, 3, 4, 5, 6, 7, 0, 8)\n",
      "(2, 3, 4, 5, 6, 7, 0, 8)\n",
      "(1, 2, 3, 4, 5, 0, 8)\n",
      "(1, 2, 3, 4, 6, 0, 8)\n",
      "(1, 2, 3, 4, 7, 0, 8)\n",
      "(1, 2, 3, 5, 6, 0, 8)\n",
      "(1, 2, 3, 5, 7, 0, 8)\n",
      "(1, 2, 3, 6, 7, 0, 8)\n",
      "(1, 2, 4, 5, 6, 0, 8)\n",
      "(1, 2, 4, 5, 7, 0, 8)\n",
      "(1, 2, 4, 6, 7, 0, 8)\n",
      "(1, 2, 5, 6, 7, 0, 8)\n",
      "(1, 3, 4, 5, 6, 0, 8)\n",
      "(1, 3, 4, 5, 7, 0, 8)\n",
      "(1, 3, 4, 6, 7, 0, 8)\n",
      "(1, 3, 5, 6, 7, 0, 8)\n",
      "(1, 4, 5, 6, 7, 0, 8)\n",
      "(2, 3, 4, 5, 6, 0, 8)\n",
      "(2, 3, 4, 5, 7, 0, 8)\n",
      "(2, 3, 4, 6, 7, 0, 8)\n",
      "(2, 3, 5, 6, 7, 0, 8)\n",
      "(2, 4, 5, 6, 7, 0, 8)\n",
      "(3, 4, 5, 6, 7, 0, 8)\n",
      "(1, 2, 3, 4, 0, 8)\n",
      "(1, 2, 3, 5, 0, 8)\n",
      "(1, 2, 3, 6, 0, 8)\n",
      "(1, 2, 3, 7, 0, 8)\n",
      "(1, 2, 4, 5, 0, 8)\n",
      "(1, 2, 4, 6, 0, 8)\n",
      "(1, 2, 4, 7, 0, 8)\n",
      "(1, 2, 5, 6, 0, 8)\n",
      "(1, 2, 5, 7, 0, 8)\n",
      "(1, 2, 6, 7, 0, 8)\n",
      "(1, 3, 4, 5, 0, 8)\n",
      "(1, 3, 4, 6, 0, 8)\n",
      "(1, 3, 4, 7, 0, 8)\n",
      "(1, 3, 5, 6, 0, 8)\n",
      "(1, 3, 5, 7, 0, 8)\n",
      "(1, 3, 6, 7, 0, 8)\n",
      "(1, 4, 5, 6, 0, 8)\n",
      "(1, 4, 5, 7, 0, 8)\n",
      "(1, 4, 6, 7, 0, 8)\n",
      "(1, 5, 6, 7, 0, 8)\n",
      "(2, 3, 4, 5, 0, 8)\n",
      "(2, 3, 4, 6, 0, 8)\n",
      "(2, 3, 4, 7, 0, 8)\n",
      "(2, 3, 5, 6, 0, 8)\n",
      "(2, 3, 5, 7, 0, 8)\n",
      "(2, 3, 6, 7, 0, 8)\n",
      "(2, 4, 5, 6, 0, 8)\n",
      "(2, 4, 5, 7, 0, 8)\n",
      "(2, 4, 6, 7, 0, 8)\n",
      "(2, 5, 6, 7, 0, 8)\n",
      "(3, 4, 5, 6, 0, 8)\n",
      "(3, 4, 5, 7, 0, 8)\n",
      "(3, 4, 6, 7, 0, 8)\n",
      "(3, 5, 6, 7, 0, 8)\n",
      "(4, 5, 6, 7, 0, 8)\n",
      "(1, 2, 3, 4, 5, 6, 0, 9)\n",
      "(1, 2, 3, 4, 5, 7, 0, 9)\n",
      "(1, 2, 3, 4, 6, 7, 0, 9)\n",
      "(1, 2, 3, 5, 6, 7, 0, 9)\n",
      "(1, 2, 4, 5, 6, 7, 0, 9)\n",
      "(1, 3, 4, 5, 6, 7, 0, 9)\n",
      "(2, 3, 4, 5, 6, 7, 0, 9)\n",
      "(1, 2, 3, 4, 5, 0, 9)\n",
      "(1, 2, 3, 4, 6, 0, 9)\n",
      "(1, 2, 3, 4, 7, 0, 9)\n",
      "(1, 2, 3, 5, 6, 0, 9)\n",
      "(1, 2, 3, 5, 7, 0, 9)\n",
      "(1, 2, 3, 6, 7, 0, 9)\n",
      "(1, 2, 4, 5, 6, 0, 9)\n",
      "(1, 2, 4, 5, 7, 0, 9)\n",
      "(1, 2, 4, 6, 7, 0, 9)\n",
      "(1, 2, 5, 6, 7, 0, 9)\n",
      "(1, 3, 4, 5, 6, 0, 9)\n",
      "(1, 3, 4, 5, 7, 0, 9)\n",
      "(1, 3, 4, 6, 7, 0, 9)\n",
      "(1, 3, 5, 6, 7, 0, 9)\n",
      "(1, 4, 5, 6, 7, 0, 9)\n",
      "(2, 3, 4, 5, 6, 0, 9)\n",
      "(2, 3, 4, 5, 7, 0, 9)\n",
      "(2, 3, 4, 6, 7, 0, 9)\n",
      "(2, 3, 5, 6, 7, 0, 9)\n",
      "(2, 4, 5, 6, 7, 0, 9)\n",
      "(3, 4, 5, 6, 7, 0, 9)\n",
      "(1, 2, 3, 4, 0, 9)\n",
      "(1, 2, 3, 5, 0, 9)\n",
      "(1, 2, 3, 6, 0, 9)\n",
      "(1, 2, 3, 7, 0, 9)\n",
      "(1, 2, 4, 5, 0, 9)\n",
      "(1, 2, 4, 6, 0, 9)\n",
      "(1, 2, 4, 7, 0, 9)\n",
      "(1, 2, 5, 6, 0, 9)\n",
      "(1, 2, 5, 7, 0, 9)\n",
      "(1, 2, 6, 7, 0, 9)\n",
      "(1, 3, 4, 5, 0, 9)\n",
      "(1, 3, 4, 6, 0, 9)\n",
      "(1, 3, 4, 7, 0, 9)\n",
      "(1, 3, 5, 6, 0, 9)\n",
      "(1, 3, 5, 7, 0, 9)\n",
      "(1, 3, 6, 7, 0, 9)\n",
      "(1, 4, 5, 6, 0, 9)\n",
      "(1, 4, 5, 7, 0, 9)\n",
      "(1, 4, 6, 7, 0, 9)\n",
      "(1, 5, 6, 7, 0, 9)\n",
      "(2, 3, 4, 5, 0, 9)\n",
      "(2, 3, 4, 6, 0, 9)\n",
      "(2, 3, 4, 7, 0, 9)\n",
      "(2, 3, 5, 6, 0, 9)\n",
      "(2, 3, 5, 7, 0, 9)\n",
      "(2, 3, 6, 7, 0, 9)\n",
      "(2, 4, 5, 6, 0, 9)\n",
      "(2, 4, 5, 7, 0, 9)\n",
      "(2, 4, 6, 7, 0, 9)\n",
      "(2, 5, 6, 7, 0, 9)\n",
      "(3, 4, 5, 6, 0, 9)\n",
      "(3, 4, 5, 7, 0, 9)\n",
      "(3, 4, 6, 7, 0, 9)\n",
      "(3, 5, 6, 7, 0, 9)\n",
      "(4, 5, 6, 7, 0, 9)\n",
      "(1, 2, 3, 4, 5, 0, 8, 9)\n",
      "(1, 2, 3, 4, 6, 0, 8, 9)\n",
      "(1, 2, 3, 4, 7, 0, 8, 9)\n",
      "(1, 2, 3, 5, 6, 0, 8, 9)\n",
      "(1, 2, 3, 5, 7, 0, 8, 9)\n",
      "(1, 2, 3, 6, 7, 0, 8, 9)\n",
      "(1, 2, 4, 5, 6, 0, 8, 9)\n",
      "(1, 2, 4, 5, 7, 0, 8, 9)\n",
      "(1, 2, 4, 6, 7, 0, 8, 9)\n",
      "(1, 2, 5, 6, 7, 0, 8, 9)\n",
      "(1, 3, 4, 5, 6, 0, 8, 9)\n",
      "(1, 3, 4, 5, 7, 0, 8, 9)\n",
      "(1, 3, 4, 6, 7, 0, 8, 9)\n",
      "(1, 3, 5, 6, 7, 0, 8, 9)\n",
      "(1, 4, 5, 6, 7, 0, 8, 9)\n",
      "(2, 3, 4, 5, 6, 0, 8, 9)\n",
      "(2, 3, 4, 5, 7, 0, 8, 9)\n",
      "(2, 3, 4, 6, 7, 0, 8, 9)\n",
      "(2, 3, 5, 6, 7, 0, 8, 9)\n",
      "(2, 4, 5, 6, 7, 0, 8, 9)\n",
      "(3, 4, 5, 6, 7, 0, 8, 9)\n",
      "(1, 2, 3, 4, 0, 8, 9)\n",
      "(1, 2, 3, 5, 0, 8, 9)\n",
      "(1, 2, 3, 6, 0, 8, 9)\n",
      "(1, 2, 3, 7, 0, 8, 9)\n",
      "(1, 2, 4, 5, 0, 8, 9)\n",
      "(1, 2, 4, 6, 0, 8, 9)\n",
      "(1, 2, 4, 7, 0, 8, 9)\n",
      "(1, 2, 5, 6, 0, 8, 9)\n",
      "(1, 2, 5, 7, 0, 8, 9)\n",
      "(1, 2, 6, 7, 0, 8, 9)\n",
      "(1, 3, 4, 5, 0, 8, 9)\n",
      "(1, 3, 4, 6, 0, 8, 9)\n",
      "(1, 3, 4, 7, 0, 8, 9)\n",
      "(1, 3, 5, 6, 0, 8, 9)\n",
      "(1, 3, 5, 7, 0, 8, 9)\n",
      "(1, 3, 6, 7, 0, 8, 9)\n",
      "(1, 4, 5, 6, 0, 8, 9)\n",
      "(1, 4, 5, 7, 0, 8, 9)\n",
      "(1, 4, 6, 7, 0, 8, 9)\n",
      "(1, 5, 6, 7, 0, 8, 9)\n",
      "(2, 3, 4, 5, 0, 8, 9)\n",
      "(2, 3, 4, 6, 0, 8, 9)\n",
      "(2, 3, 4, 7, 0, 8, 9)\n",
      "(2, 3, 5, 6, 0, 8, 9)\n",
      "(2, 3, 5, 7, 0, 8, 9)\n",
      "(2, 3, 6, 7, 0, 8, 9)\n",
      "(2, 4, 5, 6, 0, 8, 9)\n",
      "(2, 4, 5, 7, 0, 8, 9)\n",
      "(2, 4, 6, 7, 0, 8, 9)\n",
      "(2, 5, 6, 7, 0, 8, 9)\n",
      "(3, 4, 5, 6, 0, 8, 9)\n",
      "(3, 4, 5, 7, 0, 8, 9)\n",
      "(3, 4, 6, 7, 0, 8, 9)\n",
      "(3, 5, 6, 7, 0, 8, 9)\n",
      "(4, 5, 6, 7, 0, 8, 9)\n",
      "(1, 2, 3, 0, 8, 9)\n",
      "(1, 2, 4, 0, 8, 9)\n",
      "(1, 2, 5, 0, 8, 9)\n",
      "(1, 2, 6, 0, 8, 9)\n",
      "(1, 2, 7, 0, 8, 9)\n",
      "(1, 3, 4, 0, 8, 9)\n",
      "(1, 3, 5, 0, 8, 9)\n",
      "(1, 3, 6, 0, 8, 9)\n",
      "(1, 3, 7, 0, 8, 9)\n",
      "(1, 4, 5, 0, 8, 9)\n",
      "(1, 4, 6, 0, 8, 9)\n",
      "(1, 4, 7, 0, 8, 9)\n",
      "(1, 5, 6, 0, 8, 9)\n",
      "(1, 5, 7, 0, 8, 9)\n",
      "(1, 6, 7, 0, 8, 9)\n",
      "(2, 3, 4, 0, 8, 9)\n",
      "(2, 3, 5, 0, 8, 9)\n",
      "(2, 3, 6, 0, 8, 9)\n",
      "(2, 3, 7, 0, 8, 9)\n",
      "(2, 4, 5, 0, 8, 9)\n",
      "(2, 4, 6, 0, 8, 9)\n",
      "(2, 4, 7, 0, 8, 9)\n",
      "(2, 5, 6, 0, 8, 9)\n",
      "(2, 5, 7, 0, 8, 9)\n",
      "(2, 6, 7, 0, 8, 9)\n",
      "(3, 4, 5, 0, 8, 9)\n",
      "(3, 4, 6, 0, 8, 9)\n",
      "(3, 4, 7, 0, 8, 9)\n",
      "(3, 5, 6, 0, 8, 9)\n",
      "(3, 5, 7, 0, 8, 9)\n",
      "(3, 6, 7, 0, 8, 9)\n",
      "(4, 5, 6, 0, 8, 9)\n",
      "(4, 5, 7, 0, 8, 9)\n",
      "(4, 6, 7, 0, 8, 9)\n",
      "(5, 6, 7, 0, 8, 9)\n"
     ]
    }
   ],
   "source": [
    "for z in range(1, len(init_permutation_i_extra)+1):\n",
    "    for new_col_idx in itertools.combinations(init_permutation_i_extra, z):\n",
    "        init_permutation_i_new = init_permutation_i + list(new_col_idx)\n",
    "        for r in range(len(init_permutation_i),  max(len(init_permutation_i)//2, len(init_permutation_i)-3), -1):\n",
    "            for x in itertools.combinations(init_permutation_i_new, r):\n",
    "                if not set(list(new_col_idx)+[0]).issubset(set(x)):\n",
    "                    continue\n",
    "                if 0 not in x:\n",
    "                    break\n",
    "                print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 0, 8, 9]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_permutation_i_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 8, 9}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(list(new_col_idx)+[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_permutation_i_extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = []\n",
    "for batch_idx, batch in enumerate(test_dataset_iter_extra):\n",
    "        target_col_mask = batch[\"target_col_mask\"].T\n",
    "        init_permutation_i = get_permutation(target_col_mask)\n",
    "        num_cols.append(len(init_permutation_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# table search STARMIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list_1 = [\n",
    "    \"Name: Philip Duffy; Jeremy Oppenheim; Mark Sedwill;\",\n",
    "    \"Mode of Travel: Air; Taxi; Air;\",\n",
    "    \"Purpose: Regional Meeting; Exchange Visit; Evening Meal;\",\n",
    "    \"Destination: London; Ottawa; Bristol;\",\n",
    "    \"Day: 10; 30; 02;\",\n",
    "    \"Month: April; July; September;\",\n",
    "    \"Year: 2019; 2019; 2019;\",\n",
    "    \"Expense: 189.06; 8.08; 50.00;\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cur_maxlen = min(max_length, 512 // len(column_list_1) - 1)\n",
    "\n",
    "# print(tokenizer.cls_token)\n",
    "# print(group_df[\"data\"])\n",
    "token_ids_list = [tokenizer.encode(\n",
    "                tokenizer.cls_token + \" \" + str(x), add_special_tokens=False, max_length=cur_maxlen, truncation=True) for x in column_list_1]\n",
    "token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                    token_ids_list)).to(device)\n",
    "cls_index_list = [0] + np.cumsum(\n",
    "    np.array([len(x) for x in token_ids_list])).tolist()[:-1]\n",
    "cls_indexes = torch.LongTensor(cls_index_list).to(device).reshape(-1, 1)\n",
    "cls_indexes = torch.hstack([torch.zeros_like(cls_indexes), cls_indexes])\n",
    "logits, embs_1 = model(token_ids.reshape(1, -1), cls_indexes=cls_indexes, get_enc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "cur_maxlen = min(max_length, 512 // len(column_list_1) - 1)\n",
    "\n",
    "# print(tokenizer.cls_token)\n",
    "# print(group_df[\"data\"])\n",
    "token_ids_list = [tokenizer.encode(\n",
    "                tokenizer.cls_token + \" \" + str(x), add_special_tokens=False, max_length=cur_maxlen, truncation=True) for x in column_list_1]\n",
    "token_ids = nn.utils.rnn.pad_sequence(\n",
    "      [torch.tensor(x) for x in token_ids_list], padding_value=tokenizer.pad_token_id).to(device)\n",
    "cls_indexes = torch.nonzero(\n",
    "                token_ids == tokenizer.cls_token_id)\n",
    "logits, embs_1_seperate = model(token_ids, cls_indexes=cls_indexes, get_enc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list_2 = [\n",
    "    \"Name: Clark; Gyimah; Harrington;\",\n",
    "    \"Date: 23/07; 03/09; 05/08;\",\n",
    "    \"Destination: France; Belgium; China;\",\n",
    "    \"Purpose: Discuss EU; Build Relations; Discuss Productivity;\",\n",
    "]\n",
    "cur_maxlen = min(max_length, 512 // len(column_list_2) - 1)\n",
    "\n",
    "# print(tokenizer.cls_token)\n",
    "# print(group_df[\"data\"])\n",
    "token_ids_list = [tokenizer.encode(\n",
    "                tokenizer.cls_token + \" \" + str(x), add_special_tokens=False, max_length=cur_maxlen, truncation=True) \n",
    "                  for x in column_list_2]\n",
    "token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                    token_ids_list)).to(device)\n",
    "cls_index_list = [0] + np.cumsum(\n",
    "    np.array([len(x) for x in token_ids_list])).tolist()[:-1]\n",
    "cls_indexes = torch.LongTensor(cls_index_list).to(device).reshape(-1, 1)\n",
    "cls_indexes = torch.hstack([torch.zeros_like(cls_indexes), cls_indexes])\n",
    "logits, embs_2 = model(token_ids.reshape(1, -1), cls_indexes=cls_indexes, get_enc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertSdpaSelfAttention is used but `torch.nn.functional.scaled_dot_product_attention` does not support non-absolute `position_embedding_type` or `output_attentions=True` or `head_mask`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n"
     ]
    }
   ],
   "source": [
    "token_ids = token_ids.reshape(1, -1)\n",
    "attention_mask = token_ids != 0\n",
    "res = model.bert(token_ids, attention_mask=attention_mask, return_dict=True, output_attentions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res['attentions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 47, 47])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['attentions'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([47, 47])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['attentions'][0].squeeze().mean(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1229, 0.2070, 0.1410, 0.1387],\n",
       "        [0.0706, 0.2805, 0.1124, 0.0850],\n",
       "        [0.0726, 0.1788, 0.2063, 0.1059],\n",
       "        [0.0787, 0.1273, 0.1170, 0.2293]], device='cuda:0',\n",
       "       grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['attentions'][0].squeeze().mean(0)[cls_mask][:, cls_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0862, 0.1984, 0.1442, 0.1397], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.1911, 0.1100, 0.1367, 0.1355], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.3175, 0.0678, 0.1071, 0.0799], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.2838, 0.0439, 0.0646, 0.0359], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.0532, 0.0339, 0.0359, 0.0215], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.0197, 0.0310, 0.0400, 0.0251], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.0175, 0.0553, 0.0463, 0.0215], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.0207, 0.0101, 0.0224, 0.0223], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.0221, 0.0504, 0.0575, 0.0379], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.0858, 0.0916, 0.1262, 0.0552], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.0429, 0.0663, 0.1021, 0.0942], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.0207, 0.0475, 0.0998, 0.0851], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "*********************************************\n",
      "tensor([0.0968, 0.0672, 0.0819, 0.0628], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "cls_mask = (token_ids==tokenizer.cls_token_id).reshape(-1)\n",
    "acc_attention = []\n",
    "for i in range(len(res['attentions'])):\n",
    "    attn_i = res['attentions'][i].squeeze().mean(0)[cls_mask][:, cls_mask].mean(0)\n",
    "    acc_attention.append(attn_i)\n",
    "    print(attn_i)\n",
    "acc_attention = torch.stack(acc_attention, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0207, 0.0475, 0.0998, 0.0851], device='cuda:0',\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([0.0009, 0.0032, 0.0102, 0.0080], device='cuda:0',\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([7.6240e-05, 2.8848e-04, 1.2860e-03, 4.4200e-04], device='cuda:0',\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([1.6872e-06, 1.4552e-05, 7.4002e-05, 1.6757e-05], device='cuda:0',\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([3.4952e-08, 1.4639e-07, 1.6596e-06, 3.7438e-07], device='cuda:0',\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([6.1142e-10, 8.0929e-09, 7.6920e-08, 8.0513e-09], device='cuda:0',\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([1.2015e-11, 2.5077e-10, 3.0805e-09, 2.0201e-10], device='cuda:0',\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([6.3881e-13, 8.5117e-12, 1.1060e-10, 4.3394e-12], device='cuda:0',\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([1.8127e-13, 3.7366e-13, 7.1448e-12, 1.5571e-13], device='cuda:0',\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([5.7560e-14, 2.5345e-14, 7.6492e-13, 1.2436e-14], device='cuda:0',\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([1.1001e-14, 2.7890e-15, 1.0458e-13, 1.6845e-15], device='cuda:0',\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([9.4820e-16, 5.5333e-16, 1.5076e-14, 2.3538e-16], device='cuda:0',\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "cls_mask = (token_ids==tokenizer.cls_token_id).reshape(-1)\n",
    "acc_attention = torch.ones_like(res['attentions'][0].squeeze().mean(0)[cls_mask][:, cls_mask].mean(0))\n",
    "for i in range(len(res['attentions'])-1, -1, -1):\n",
    "    attn_i = res['attentions'][i].squeeze().mean(0)[cls_mask][:, cls_mask].mean(0)\n",
    "    acc_attention = acc_attention * attn_i\n",
    "    print(acc_attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0555, 0.1283, 0.0926, 0.0824], device='cuda:0',\n",
       "       grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['attentions'][0].squeeze().mean(0)[cls_mask][:, cls_mask].fill_diagonal_(0).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "cur_maxlen = min(max_length, 512 // len(column_list_2) - 1)\n",
    "\n",
    "# print(tokenizer.cls_token)\n",
    "# print(group_df[\"data\"])\n",
    "token_ids_list = [tokenizer.encode(\n",
    "                tokenizer.cls_token + \" \" + str(x), add_special_tokens=False, max_length=cur_maxlen, truncation=True) \n",
    "                  for x in column_list_2]\n",
    "token_ids = nn.utils.rnn.pad_sequence(\n",
    "      [torch.tensor(x) for x in token_ids_list], padding_value=tokenizer.pad_token_id).to(device)\n",
    "cls_indexes = torch.nonzero(\n",
    "                token_ids == tokenizer.cls_token_id)\n",
    "logits, embs_2_seperate = model(token_ids, cls_indexes=cls_indexes, get_enc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list_3 = [\n",
    "    'Bird Name: Pine Siskin; American Robin; Northern Flicker;',\n",
    "    'Scientific Name: Carduelis Pinus; Turdus migratorius; Colaptes auratus;',\n",
    "    'Date: 2019; 2019; 2019;',\n",
    "    'Location: Ottawa; Ottawa; London;'\n",
    "]\n",
    "\n",
    "cur_maxlen = min(max_length, 512 // len(column_list_3) - 1)\n",
    "\n",
    "# print(tokenizer.cls_token)\n",
    "# print(group_df[\"data\"])\n",
    "token_ids_list = [tokenizer.encode(\n",
    "                tokenizer.cls_token + \" \" + str(x), add_special_tokens=False, max_length=cur_maxlen, truncation=True) \n",
    "                  for x in column_list_3]\n",
    "token_ids = torch.LongTensor(reduce(operator.add,\n",
    "                                    token_ids_list)).to(device)\n",
    "cls_index_list = [0] + np.cumsum(\n",
    "    np.array([len(x) for x in token_ids_list])).tolist()[:-1]\n",
    "cls_indexes = torch.LongTensor(cls_index_list).to(device).reshape(-1, 1)\n",
    "cls_indexes = torch.hstack([torch.zeros_like(cls_indexes), cls_indexes])\n",
    "logits, embs_3 = model(token_ids.reshape(1, -1), cls_indexes=cls_indexes, get_enc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "cur_maxlen = min(max_length, 512 // len(column_list_3) - 1)\n",
    "\n",
    "# print(tokenizer.cls_token)\n",
    "# print(group_df[\"data\"])\n",
    "token_ids_list = [tokenizer.encode(\n",
    "                tokenizer.cls_token + \" \" + str(x), add_special_tokens=False, max_length=cur_maxlen, truncation=True) \n",
    "                  for x in column_list_3]\n",
    "token_ids = nn.utils.rnn.pad_sequence(\n",
    "      [torch.tensor(x) for x in token_ids_list], padding_value=tokenizer.pad_token_id).to(device)\n",
    "cls_indexes = torch.nonzero(\n",
    "                token_ids == tokenizer.cls_token_id)\n",
    "logits, embs_3_seperate = model(token_ids, cls_indexes=cls_indexes, get_enc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 768])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.8207278 ,  0.19450662,  0.20627114,  0.27426058],\n",
       "       [ 0.3452878 ,  0.23242974,  0.5336273 ,  0.64597607],\n",
       "       [ 0.33870924,  0.39381886,  0.5873476 ,  0.6411325 ],\n",
       "       [ 0.34317726,  0.29647005,  0.68273383,  0.58981204],\n",
       "       [ 0.12590188,  0.57557684,  0.12846455,  0.02838844],\n",
       "       [ 0.08469278,  0.53540766,  0.01483871, -0.0364889 ],\n",
       "       [ 0.11339067,  0.5485551 , -0.00187877, -0.03961209],\n",
       "       [ 0.16596259,  0.13950422,  0.3106986 ,  0.34296668]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_similarity(embs_1.detach().cpu().numpy(), embs_2.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8207278  0.57557684 0.68273383 0.64597607]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.7250144"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(cosine_similarity(embs_1.detach().cpu().numpy(), embs_2.detach().cpu().numpy()).max(0))\n",
    "cosine_similarity(embs_1.detach().cpu().numpy(), embs_2.detach().cpu().numpy()).max(0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96244603 0.963094   0.96277654 0.9627989 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.8511155"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(cosine_similarity(embs_1_seperate.detach().cpu().numpy(), embs_2_seperate.detach().cpu().numpy()).max(0))\n",
    "cosine_similarity(embs_1_seperate.detach().cpu().numpy(), embs_2_seperate.detach().cpu().numpy()).max(0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(732) 1085 tensor(0.6747)\n"
     ]
    }
   ],
   "source": [
    "print((final_scores>0.999).sum(), len(final_scores), (final_scores>0.999).sum()/len(final_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
