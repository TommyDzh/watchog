/home/zhihao/jupyterprojects/jupyter/lib/python3.8/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.
Epoch 0 starts
Epoch 0 (sato0): tr_loss=0.7158466 tr_macro_f1=0.5301 tr_micro_f1=0.8366  vl_loss=0.4194832 vl_macro_f1=0.6333 vl_micro_f1=0.9000 (372.77 sec.)
Epoch 1 starts
Epoch 1 (sato0): tr_loss=0.3069985 tr_macro_f1=0.7151 tr_micro_f1=0.9257  vl_loss=0.3601162 vl_macro_f1=0.7248 vl_micro_f1=0.9156 (375.15 sec.)
Epoch 2 starts
Epoch 2 (sato0): tr_loss=0.2095977 tr_macro_f1=0.7894 tr_micro_f1=0.9483  vl_loss=0.3730152 vl_macro_f1=0.7410 vl_micro_f1=0.9192 (374.43 sec.)
Epoch 3 starts
Epoch 3 (sato0): tr_loss=0.1517188 tr_macro_f1=0.8413 tr_micro_f1=0.9620  vl_loss=0.3722886 vl_macro_f1=0.7776 vl_micro_f1=0.9230 (372.93 sec.)
Epoch 4 starts
Epoch 4 (sato0): tr_loss=0.1205729 tr_macro_f1=0.8707 tr_micro_f1=0.9691  vl_loss=0.3581155 vl_macro_f1=0.7776 vl_micro_f1=0.9283 (375.32 sec.)
Epoch 5 starts
Epoch 5 (sato0): tr_loss=0.0921137 tr_macro_f1=0.9034 tr_micro_f1=0.9759  vl_loss=0.3922993 vl_macro_f1=0.7880 vl_micro_f1=0.9266 (376.89 sec.)
Epoch 6 starts
Epoch 6 (sato0): tr_loss=0.0799503 tr_macro_f1=0.9150 tr_micro_f1=0.9786  vl_loss=0.3862190 vl_macro_f1=0.8043 vl_micro_f1=0.9284 (376.05 sec.)
Epoch 7 starts
Epoch 7 (sato0): tr_loss=0.0643889 tr_macro_f1=0.9281 tr_micro_f1=0.9828  vl_loss=0.4043845 vl_macro_f1=0.8005 vl_micro_f1=0.9284 (377.08 sec.)
Epoch 8 starts
Epoch 8 (sato0): tr_loss=0.0547048 tr_macro_f1=0.9451 tr_micro_f1=0.9858  vl_loss=0.4151911 vl_macro_f1=0.8043 vl_micro_f1=0.9275 (377.40 sec.)
Epoch 9 starts
Epoch 9 (sato0): tr_loss=0.0489363 tr_macro_f1=0.9505 tr_micro_f1=0.9872  vl_loss=0.4211811 vl_macro_f1=0.8097 vl_micro_f1=0.9311 (376.16 sec.)
Epoch 10 starts
Epoch 10 (sato0): tr_loss=0.0418486 tr_macro_f1=0.9571 tr_micro_f1=0.9888  vl_loss=0.4245658 vl_macro_f1=0.8048 vl_micro_f1=0.9297 (375.12 sec.)
Epoch 11 starts
Epoch 11 (sato0): tr_loss=0.0387865 tr_macro_f1=0.9622 tr_micro_f1=0.9895  vl_loss=0.4364407 vl_macro_f1=0.8150 vl_micro_f1=0.9320 (376.53 sec.)
Epoch 12 starts
Epoch 12 (sato0): tr_loss=0.0344045 tr_macro_f1=0.9680 tr_micro_f1=0.9908  vl_loss=0.4456819 vl_macro_f1=0.8145 vl_micro_f1=0.9335 (376.13 sec.)
Epoch 13 starts
Epoch 13 (sato0): tr_loss=0.0284549 tr_macro_f1=0.9715 tr_micro_f1=0.9924  vl_loss=0.4281310 vl_macro_f1=0.8120 vl_micro_f1=0.9339 (377.07 sec.)
Epoch 14 starts
Epoch 14 (sato0): tr_loss=0.0280643 tr_macro_f1=0.9741 tr_micro_f1=0.9929  vl_loss=0.4585595 vl_macro_f1=0.8135 vl_micro_f1=0.9329 (373.44 sec.)
Epoch 15 starts
Epoch 15 (sato0): tr_loss=0.0268683 tr_macro_f1=0.9735 tr_micro_f1=0.9930  vl_loss=0.4505116 vl_macro_f1=0.8158 vl_micro_f1=0.9326 (375.48 sec.)
Epoch 16 starts
Epoch 16 (sato0): tr_loss=0.0220467 tr_macro_f1=0.9836 tr_micro_f1=0.9941  vl_loss=0.4624274 vl_macro_f1=0.8266 vl_micro_f1=0.9346 (371.85 sec.)
Epoch 17 starts
Epoch 17 (sato0): tr_loss=0.0186848 tr_macro_f1=0.9840 tr_micro_f1=0.9951  vl_loss=0.4757182 vl_macro_f1=0.8193 vl_micro_f1=0.9342 (373.35 sec.)
Epoch 18 starts
Epoch 18 (sato0): tr_loss=0.0190258 tr_macro_f1=0.9863 tr_micro_f1=0.9953  vl_loss=0.4554117 vl_macro_f1=0.8062 vl_micro_f1=0.9329 (372.63 sec.)
Epoch 19 starts
Epoch 19 (sato0): tr_loss=0.0159967 tr_macro_f1=0.9868 tr_micro_f1=0.9955  vl_loss=0.4854684 vl_macro_f1=0.8294 vl_micro_f1=0.9347 (372.79 sec.)
Epoch 20 starts
Epoch 20 (sato0): tr_loss=0.0132736 tr_macro_f1=0.9895 tr_micro_f1=0.9963  vl_loss=0.4987817 vl_macro_f1=0.8229 vl_micro_f1=0.9344 (370.52 sec.)
Epoch 21 starts
Epoch 21 (sato0): tr_loss=0.0113914 tr_macro_f1=0.9917 tr_micro_f1=0.9969  vl_loss=0.4883609 vl_macro_f1=0.8136 vl_micro_f1=0.9359 (372.39 sec.)
Epoch 22 starts
Epoch 22 (sato0): tr_loss=0.0111640 tr_macro_f1=0.9914 tr_micro_f1=0.9969  vl_loss=0.5072088 vl_macro_f1=0.8236 vl_micro_f1=0.9346 (374.40 sec.)
Epoch 23 starts
Epoch 23 (sato0): tr_loss=0.0096887 tr_macro_f1=0.9934 tr_micro_f1=0.9973  vl_loss=0.5144758 vl_macro_f1=0.8203 vl_micro_f1=0.9349 (374.88 sec.)
Epoch 24 starts
Epoch 24 (sato0): tr_loss=0.0090786 tr_macro_f1=0.9934 tr_micro_f1=0.9974  vl_loss=0.4989566 vl_macro_f1=0.8266 vl_micro_f1=0.9381 (374.41 sec.)
Epoch 25 starts
Epoch 25 (sato0): tr_loss=0.0087088 tr_macro_f1=0.9935 tr_micro_f1=0.9974  vl_loss=0.5064213 vl_macro_f1=0.8234 vl_micro_f1=0.9366 (372.94 sec.)
Epoch 26 starts
Epoch 26 (sato0): tr_loss=0.0080425 tr_macro_f1=0.9948 tr_micro_f1=0.9975  vl_loss=0.5048146 vl_macro_f1=0.8288 vl_micro_f1=0.9381 (375.02 sec.)
Epoch 27 starts
Epoch 27 (sato0): tr_loss=0.0072535 tr_macro_f1=0.9952 tr_micro_f1=0.9979  vl_loss=0.5189218 vl_macro_f1=0.8316 vl_micro_f1=0.9383 (373.28 sec.)
Epoch 28 starts
Epoch 28 (sato0): tr_loss=0.0068014 tr_macro_f1=0.9952 tr_micro_f1=0.9979  vl_loss=0.5252385 vl_macro_f1=0.8343 vl_micro_f1=0.9385 (374.67 sec.)
Epoch 29 starts
Epoch 29 (sato0): tr_loss=0.0064917 tr_macro_f1=0.9951 tr_micro_f1=0.9980  vl_loss=0.5270076 vl_macro_f1=0.8326 vl_micro_f1=0.9384 (372.27 sec.)