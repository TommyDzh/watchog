/home/zhihao/jupyterprojects/jupyter/lib/python3.8/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.
Epoch 0 starts
Epoch 0 (sato0): tr_loss=0.7684405 tr_macro_f1=0.5222 tr_micro_f1=0.8085  vl_loss=0.4491175 vl_macro_f1=0.6327 vl_micro_f1=0.8925 (208.42 sec.)
Epoch 1 starts
Epoch 1 (sato0): tr_loss=0.3109556 tr_macro_f1=0.7208 tr_micro_f1=0.9224  vl_loss=0.3868914 vl_macro_f1=0.7061 vl_micro_f1=0.9077 (210.70 sec.)
Epoch 2 starts
Epoch 2 (sato0): tr_loss=0.2117461 tr_macro_f1=0.7946 tr_micro_f1=0.9464  vl_loss=0.3753561 vl_macro_f1=0.7548 vl_micro_f1=0.9153 (209.50 sec.)
Epoch 3 starts
Epoch 3 (sato0): tr_loss=0.1574047 tr_macro_f1=0.8367 tr_micro_f1=0.9594  vl_loss=0.3487047 vl_macro_f1=0.7712 vl_micro_f1=0.9264 (208.48 sec.)
Epoch 4 starts
Epoch 4 (sato0): tr_loss=0.1244996 tr_macro_f1=0.8756 tr_micro_f1=0.9678  vl_loss=0.4296960 vl_macro_f1=0.7758 vl_micro_f1=0.9093 (211.87 sec.)
Epoch 5 starts
Epoch 5 (sato0): tr_loss=0.1037088 tr_macro_f1=0.8950 tr_micro_f1=0.9726  vl_loss=0.3915564 vl_macro_f1=0.7966 vl_micro_f1=0.9274 (210.66 sec.)
Epoch 6 starts
Epoch 6 (sato0): tr_loss=0.0873286 tr_macro_f1=0.9194 tr_micro_f1=0.9776  vl_loss=0.3686079 vl_macro_f1=0.7868 vl_micro_f1=0.9294 (209.13 sec.)
Epoch 7 starts
Epoch 7 (sato0): tr_loss=0.0711237 tr_macro_f1=0.9246 tr_micro_f1=0.9810  vl_loss=0.3935494 vl_macro_f1=0.8122 vl_micro_f1=0.9304 (210.81 sec.)
Epoch 8 starts
Epoch 8 (sato0): tr_loss=0.0572189 tr_macro_f1=0.9437 tr_micro_f1=0.9851  vl_loss=0.4146278 vl_macro_f1=0.8030 vl_micro_f1=0.9297 (210.80 sec.)
Epoch 9 starts
Epoch 9 (sato0): tr_loss=0.0543548 tr_macro_f1=0.9525 tr_micro_f1=0.9859  vl_loss=0.4178750 vl_macro_f1=0.8100 vl_micro_f1=0.9287 (210.72 sec.)
Epoch 10 starts
Epoch 10 (sato0): tr_loss=0.0479540 tr_macro_f1=0.9539 tr_micro_f1=0.9872  vl_loss=0.4072618 vl_macro_f1=0.8169 vl_micro_f1=0.9311 (208.05 sec.)
Epoch 11 starts
Epoch 11 (sato0): tr_loss=0.0421009 tr_macro_f1=0.9588 tr_micro_f1=0.9893  vl_loss=0.4444762 vl_macro_f1=0.8020 vl_micro_f1=0.9302 (209.99 sec.)
Epoch 12 starts
Epoch 12 (sato0): tr_loss=0.0353419 tr_macro_f1=0.9717 tr_micro_f1=0.9910  vl_loss=0.4089689 vl_macro_f1=0.8202 vl_micro_f1=0.9334 (210.44 sec.)
Epoch 13 starts
Epoch 13 (sato0): tr_loss=0.0330577 tr_macro_f1=0.9712 tr_micro_f1=0.9916  vl_loss=0.4367373 vl_macro_f1=0.8113 vl_micro_f1=0.9330 (208.89 sec.)
Epoch 14 starts
Epoch 14 (sato0): tr_loss=0.0314774 tr_macro_f1=0.9694 tr_micro_f1=0.9909  vl_loss=0.4630017 vl_macro_f1=0.7921 vl_micro_f1=0.9318 (209.93 sec.)
Epoch 15 starts
Epoch 15 (sato0): tr_loss=0.0281377 tr_macro_f1=0.9663 tr_micro_f1=0.9913  vl_loss=0.4552779 vl_macro_f1=0.8137 vl_micro_f1=0.9342 (209.60 sec.)
Epoch 16 starts
Epoch 16 (sato0): tr_loss=0.0256755 tr_macro_f1=0.9744 tr_micro_f1=0.9931  vl_loss=0.4490370 vl_macro_f1=0.8060 vl_micro_f1=0.9346 (208.69 sec.)
Epoch 17 starts
Epoch 17 (sato0): tr_loss=0.0216520 tr_macro_f1=0.9824 tr_micro_f1=0.9945  vl_loss=0.4747449 vl_macro_f1=0.8206 vl_micro_f1=0.9311 (198.42 sec.)
Epoch 18 starts
Epoch 18 (sato0): tr_loss=0.0191361 tr_macro_f1=0.9850 tr_micro_f1=0.9947  vl_loss=0.4555353 vl_macro_f1=0.8237 vl_micro_f1=0.9344 (203.21 sec.)
Epoch 19 starts
Epoch 19 (sato0): tr_loss=0.0153157 tr_macro_f1=0.9882 tr_micro_f1=0.9956  vl_loss=0.4694290 vl_macro_f1=0.8198 vl_micro_f1=0.9359 (193.94 sec.)
Epoch 20 starts
Epoch 20 (sato0): tr_loss=0.0154742 tr_macro_f1=0.9883 tr_micro_f1=0.9956  vl_loss=0.4873678 vl_macro_f1=0.8216 vl_micro_f1=0.9314 (191.59 sec.)
Epoch 21 starts
Epoch 21 (sato0): tr_loss=0.0121515 tr_macro_f1=0.9900 tr_micro_f1=0.9967  vl_loss=0.5063760 vl_macro_f1=0.8183 vl_micro_f1=0.9339 (207.82 sec.)
Epoch 22 starts
Epoch 22 (sato0): tr_loss=0.0129511 tr_macro_f1=0.9921 tr_micro_f1=0.9966  vl_loss=0.5006686 vl_macro_f1=0.8120 vl_micro_f1=0.9348 (204.89 sec.)
Epoch 23 starts
Epoch 23 (sato0): tr_loss=0.0112572 tr_macro_f1=0.9907 tr_micro_f1=0.9966  vl_loss=0.5266641 vl_macro_f1=0.8146 vl_micro_f1=0.9334 (211.91 sec.)
Epoch 24 starts
Epoch 24 (sato0): tr_loss=0.0090189 tr_macro_f1=0.9929 tr_micro_f1=0.9973  vl_loss=0.5267637 vl_macro_f1=0.8157 vl_micro_f1=0.9346 (191.35 sec.)
Epoch 25 starts
Epoch 25 (sato0): tr_loss=0.0091011 tr_macro_f1=0.9934 tr_micro_f1=0.9974  vl_loss=0.5245894 vl_macro_f1=0.8164 vl_micro_f1=0.9353 (191.19 sec.)
Epoch 26 starts
Epoch 26 (sato0): tr_loss=0.0077784 tr_macro_f1=0.9941 tr_micro_f1=0.9975  vl_loss=0.5366602 vl_macro_f1=0.8229 vl_micro_f1=0.9340 (192.05 sec.)
Epoch 27 starts
Epoch 27 (sato0): tr_loss=0.0072341 tr_macro_f1=0.9948 tr_micro_f1=0.9978  vl_loss=0.5323349 vl_macro_f1=0.8272 vl_micro_f1=0.9341 (213.53 sec.)
Epoch 28 starts
Epoch 28 (sato0): tr_loss=0.0065305 tr_macro_f1=0.9948 tr_micro_f1=0.9979  vl_loss=0.5391967 vl_macro_f1=0.8262 vl_micro_f1=0.9352 (220.58 sec.)
Epoch 29 starts
Epoch 29 (sato0): tr_loss=0.0062943 tr_macro_f1=0.9954 tr_micro_f1=0.9980  vl_loss=0.5418274 vl_macro_f1=0.8270 vl_micro_f1=0.9349 (229.62 sec.)