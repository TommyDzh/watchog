/home/zhihao/jupyterprojects/jupyter/lib/python3.8/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.
Epoch 0 starts
Epoch 0 (sato0): tr_loss=0.8341091 tr_macro_f1=0.4620 tr_micro_f1=0.7921  vl_loss=0.4437001 vl_macro_f1=0.6035 vl_micro_f1=0.8959 (198.61 sec.)
Epoch 1 starts
Epoch 1 (sato0): tr_loss=0.3120283 tr_macro_f1=0.6780 tr_micro_f1=0.9225  vl_loss=0.4004693 vl_macro_f1=0.6979 vl_micro_f1=0.9076 (199.36 sec.)
Epoch 2 starts
Epoch 2 (sato0): tr_loss=0.2211893 tr_macro_f1=0.7646 tr_micro_f1=0.9439  vl_loss=0.3491084 vl_macro_f1=0.7455 vl_micro_f1=0.9202 (198.82 sec.)
Epoch 3 starts
Epoch 3 (sato0): tr_loss=0.1663441 tr_macro_f1=0.8147 tr_micro_f1=0.9573  vl_loss=0.3515630 vl_macro_f1=0.7627 vl_micro_f1=0.9277 (198.50 sec.)
Epoch 4 starts
Epoch 4 (sato0): tr_loss=0.1251266 tr_macro_f1=0.8565 tr_micro_f1=0.9673  vl_loss=0.3741964 vl_macro_f1=0.7618 vl_micro_f1=0.9253 (199.17 sec.)
Epoch 5 starts
Epoch 5 (sato0): tr_loss=0.1002088 tr_macro_f1=0.8829 tr_micro_f1=0.9739  vl_loss=0.4011508 vl_macro_f1=0.7771 vl_micro_f1=0.9243 (191.48 sec.)
Epoch 6 starts
Epoch 6 (sato0): tr_loss=0.0933855 tr_macro_f1=0.8977 tr_micro_f1=0.9753  vl_loss=0.3763882 vl_macro_f1=0.7900 vl_micro_f1=0.9293 (191.26 sec.)
Epoch 7 starts
Epoch 7 (sato0): tr_loss=0.0635793 tr_macro_f1=0.9317 tr_micro_f1=0.9833  vl_loss=0.4463592 vl_macro_f1=0.8039 vl_micro_f1=0.9255 (200.05 sec.)
Epoch 8 starts
Epoch 8 (sato0): tr_loss=0.0627551 tr_macro_f1=0.9364 tr_micro_f1=0.9843  vl_loss=0.3913742 vl_macro_f1=0.7963 vl_micro_f1=0.9311 (198.69 sec.)
Epoch 9 starts
Epoch 9 (sato0): tr_loss=0.0588297 tr_macro_f1=0.9372 tr_micro_f1=0.9850  vl_loss=0.4138699 vl_macro_f1=0.7917 vl_micro_f1=0.9284 (202.24 sec.)
Epoch 10 starts
Epoch 10 (sato0): tr_loss=0.0482768 tr_macro_f1=0.9472 tr_micro_f1=0.9872  vl_loss=0.4148424 vl_macro_f1=0.8148 vl_micro_f1=0.9326 (191.91 sec.)
Epoch 11 starts
Epoch 11 (sato0): tr_loss=0.0434913 tr_macro_f1=0.9591 tr_micro_f1=0.9886  vl_loss=0.4089727 vl_macro_f1=0.8011 vl_micro_f1=0.9304 (198.44 sec.)
Epoch 12 starts
Epoch 12 (sato0): tr_loss=0.0411546 tr_macro_f1=0.9627 tr_micro_f1=0.9895  vl_loss=0.4199693 vl_macro_f1=0.8158 vl_micro_f1=0.9304 (199.93 sec.)
Epoch 13 starts
Epoch 13 (sato0): tr_loss=0.0355444 tr_macro_f1=0.9701 tr_micro_f1=0.9910  vl_loss=0.4069942 vl_macro_f1=0.8017 vl_micro_f1=0.9337 (204.96 sec.)
Epoch 14 starts
Epoch 14 (sato0): tr_loss=0.0301299 tr_macro_f1=0.9682 tr_micro_f1=0.9920  vl_loss=0.4529905 vl_macro_f1=0.7954 vl_micro_f1=0.9304 (199.60 sec.)
Epoch 15 starts
Epoch 15 (sato0): tr_loss=0.0270589 tr_macro_f1=0.9759 tr_micro_f1=0.9930  vl_loss=0.4465365 vl_macro_f1=0.8107 vl_micro_f1=0.9338 (204.36 sec.)
Epoch 16 starts
Epoch 16 (sato0): tr_loss=0.0271921 tr_macro_f1=0.9758 tr_micro_f1=0.9930  vl_loss=0.4347808 vl_macro_f1=0.8140 vl_micro_f1=0.9337 (224.90 sec.)
Epoch 17 starts
Epoch 17 (sato0): tr_loss=0.0191124 tr_macro_f1=0.9839 tr_micro_f1=0.9950  vl_loss=0.4686713 vl_macro_f1=0.8138 vl_micro_f1=0.9331 (202.92 sec.)
Epoch 18 starts
Epoch 18 (sato0): tr_loss=0.0184358 tr_macro_f1=0.9841 tr_micro_f1=0.9948  vl_loss=0.4650541 vl_macro_f1=0.8082 vl_micro_f1=0.9321 (195.52 sec.)
Epoch 19 starts
Epoch 19 (sato0): tr_loss=0.0157392 tr_macro_f1=0.9881 tr_micro_f1=0.9955  vl_loss=0.4716171 vl_macro_f1=0.8237 vl_micro_f1=0.9344 (210.48 sec.)
Epoch 20 starts
Epoch 20 (sato0): tr_loss=0.0146858 tr_macro_f1=0.9894 tr_micro_f1=0.9959  vl_loss=0.4763040 vl_macro_f1=0.8213 vl_micro_f1=0.9359 (210.59 sec.)
Epoch 21 starts
Epoch 21 (sato0): tr_loss=0.0145335 tr_macro_f1=0.9900 tr_micro_f1=0.9960  vl_loss=0.4988956 vl_macro_f1=0.8083 vl_micro_f1=0.9350 (198.83 sec.)
Epoch 22 starts
Epoch 22 (sato0): tr_loss=0.0115057 tr_macro_f1=0.9931 tr_micro_f1=0.9966  vl_loss=0.5081660 vl_macro_f1=0.8187 vl_micro_f1=0.9340 (193.56 sec.)
Epoch 23 starts
Epoch 23 (sato0): tr_loss=0.0109603 tr_macro_f1=0.9929 tr_micro_f1=0.9970  vl_loss=0.5073939 vl_macro_f1=0.8146 vl_micro_f1=0.9333 (198.08 sec.)
Epoch 24 starts
Epoch 24 (sato0): tr_loss=0.0092793 tr_macro_f1=0.9940 tr_micro_f1=0.9974  vl_loss=0.5268011 vl_macro_f1=0.8142 vl_micro_f1=0.9351 (186.16 sec.)
Epoch 25 starts
Epoch 25 (sato0): tr_loss=0.0093888 tr_macro_f1=0.9927 tr_micro_f1=0.9971  vl_loss=0.5131980 vl_macro_f1=0.8069 vl_micro_f1=0.9358 (196.74 sec.)
Epoch 26 starts
Epoch 26 (sato0): tr_loss=0.0077732 tr_macro_f1=0.9947 tr_micro_f1=0.9978  vl_loss=0.5443667 vl_macro_f1=0.8078 vl_micro_f1=0.9342 (194.52 sec.)
Epoch 27 starts
Epoch 27 (sato0): tr_loss=0.0074380 tr_macro_f1=0.9942 tr_micro_f1=0.9978  vl_loss=0.5355549 vl_macro_f1=0.8146 vl_micro_f1=0.9360 (190.48 sec.)
Epoch 28 starts
Epoch 28 (sato0): tr_loss=0.0068717 tr_macro_f1=0.9943 tr_micro_f1=0.9977  vl_loss=0.5467901 vl_macro_f1=0.8111 vl_micro_f1=0.9351 (189.25 sec.)
Epoch 29 starts
Epoch 29 (sato0): tr_loss=0.0065204 tr_macro_f1=0.9953 tr_micro_f1=0.9980  vl_loss=0.5469991 vl_macro_f1=0.8100 vl_micro_f1=0.9352 (197.39 sec.)