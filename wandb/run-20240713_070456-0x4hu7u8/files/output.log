/home/zhihao/jupyterprojects/jupyter/lib/python3.8/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.
Epoch 0 starts
Epoch 0 (sato0): tr_loss=1.0989504 tr_macro_f1=0.3749 tr_micro_f1=0.6954  vl_loss=0.5244053 vl_macro_f1=0.5227 vl_micro_f1=0.8656 (213.22 sec.)
Epoch 1 starts
Epoch 1 (sato0): tr_loss=0.3879450 tr_macro_f1=0.6278 tr_micro_f1=0.9022  vl_loss=0.4822299 vl_macro_f1=0.6218 vl_micro_f1=0.8772 (213.12 sec.)
Epoch 2 starts
Epoch 2 (sato0): tr_loss=0.2485981 tr_macro_f1=0.7337 tr_micro_f1=0.9369  vl_loss=0.3796062 vl_macro_f1=0.7297 vl_micro_f1=0.9131 (214.67 sec.)
Epoch 3 starts
Epoch 3 (sato0): tr_loss=0.1858898 tr_macro_f1=0.7923 tr_micro_f1=0.9531  vl_loss=0.3794170 vl_macro_f1=0.7496 vl_micro_f1=0.9177 (213.13 sec.)
Epoch 4 starts
Epoch 4 (sato0): tr_loss=0.1597822 tr_macro_f1=0.8279 tr_micro_f1=0.9583  vl_loss=0.3948660 vl_macro_f1=0.7359 vl_micro_f1=0.9215 (214.82 sec.)
Epoch 5 starts
Epoch 5 (sato0): tr_loss=0.1322186 tr_macro_f1=0.8494 tr_micro_f1=0.9649  vl_loss=0.3823622 vl_macro_f1=0.7760 vl_micro_f1=0.9263 (213.18 sec.)
Epoch 6 starts
Epoch 6 (sato0): tr_loss=0.0964239 tr_macro_f1=0.8902 tr_micro_f1=0.9750  vl_loss=0.4008003 vl_macro_f1=0.7572 vl_micro_f1=0.9220 (214.12 sec.)
Epoch 7 starts
Epoch 7 (sato0): tr_loss=0.0923712 tr_macro_f1=0.8994 tr_micro_f1=0.9755  vl_loss=0.4080807 vl_macro_f1=0.7884 vl_micro_f1=0.9281 (213.66 sec.)
Epoch 8 starts
Epoch 8 (sato0): tr_loss=0.0761145 tr_macro_f1=0.9230 tr_micro_f1=0.9797  vl_loss=0.4169798 vl_macro_f1=0.8007 vl_micro_f1=0.9278 (214.43 sec.)
Epoch 9 starts
Epoch 9 (sato0): tr_loss=0.0665524 tr_macro_f1=0.9313 tr_micro_f1=0.9827  vl_loss=0.4136770 vl_macro_f1=0.7882 vl_micro_f1=0.9262 (212.54 sec.)
Epoch 10 starts
Epoch 10 (sato0): tr_loss=0.0617889 tr_macro_f1=0.9403 tr_micro_f1=0.9836  vl_loss=0.4179050 vl_macro_f1=0.7999 vl_micro_f1=0.9271 (213.75 sec.)
Epoch 11 starts
Epoch 11 (sato0): tr_loss=0.0500633 tr_macro_f1=0.9486 tr_micro_f1=0.9871  vl_loss=0.4444420 vl_macro_f1=0.7928 vl_micro_f1=0.9269 (214.04 sec.)
Epoch 12 starts
Epoch 12 (sato0): tr_loss=0.0476665 tr_macro_f1=0.9529 tr_micro_f1=0.9876  vl_loss=0.4463820 vl_macro_f1=0.8094 vl_micro_f1=0.9292 (212.23 sec.)
Epoch 13 starts
Epoch 13 (sato0): tr_loss=0.0386738 tr_macro_f1=0.9633 tr_micro_f1=0.9898  vl_loss=0.4094887 vl_macro_f1=0.8152 vl_micro_f1=0.9343 (220.53 sec.)
Epoch 14 starts
Epoch 14 (sato0): tr_loss=0.0350030 tr_macro_f1=0.9632 tr_micro_f1=0.9907  vl_loss=0.4454235 vl_macro_f1=0.7916 vl_micro_f1=0.9297 (214.50 sec.)
Epoch 15 starts
Epoch 15 (sato0): tr_loss=0.0293501 tr_macro_f1=0.9699 tr_micro_f1=0.9923  vl_loss=0.4559137 vl_macro_f1=0.8092 vl_micro_f1=0.9314 (203.14 sec.)
Epoch 16 starts
Epoch 16 (sato0): tr_loss=0.0284305 tr_macro_f1=0.9773 tr_micro_f1=0.9925  vl_loss=0.4392418 vl_macro_f1=0.8146 vl_micro_f1=0.9307 (200.95 sec.)
Epoch 17 starts
Epoch 17 (sato0): tr_loss=0.0216120 tr_macro_f1=0.9821 tr_micro_f1=0.9943  vl_loss=0.4600014 vl_macro_f1=0.8184 vl_micro_f1=0.9322 (201.21 sec.)
Epoch 18 starts
Epoch 18 (sato0): tr_loss=0.0199174 tr_macro_f1=0.9853 tr_micro_f1=0.9947  vl_loss=0.4579811 vl_macro_f1=0.8154 vl_micro_f1=0.9318 (215.85 sec.)
Epoch 19 starts
Epoch 19 (sato0): tr_loss=0.0164016 tr_macro_f1=0.9868 tr_micro_f1=0.9955  vl_loss=0.4706350 vl_macro_f1=0.8147 vl_micro_f1=0.9350 (208.00 sec.)
Epoch 20 starts
Epoch 20 (sato0): tr_loss=0.0176131 tr_macro_f1=0.9866 tr_micro_f1=0.9954  vl_loss=0.4951842 vl_macro_f1=0.8027 vl_micro_f1=0.9319 (200.89 sec.)
Epoch 21 starts
Epoch 21 (sato0): tr_loss=0.0146921 tr_macro_f1=0.9902 tr_micro_f1=0.9960  vl_loss=0.5086113 vl_macro_f1=0.8127 vl_micro_f1=0.9345 (200.07 sec.)
Epoch 22 starts
Epoch 22 (sato0): tr_loss=0.0142931 tr_macro_f1=0.9900 tr_micro_f1=0.9963  vl_loss=0.5233493 vl_macro_f1=0.8239 vl_micro_f1=0.9324 (201.69 sec.)
Epoch 23 starts
Epoch 23 (sato0): tr_loss=0.0126379 tr_macro_f1=0.9910 tr_micro_f1=0.9965  vl_loss=0.4948016 vl_macro_f1=0.8255 vl_micro_f1=0.9362 (209.80 sec.)
Epoch 24 starts
Epoch 24 (sato0): tr_loss=0.0100249 tr_macro_f1=0.9929 tr_micro_f1=0.9971  vl_loss=0.5220717 vl_macro_f1=0.8180 vl_micro_f1=0.9329 (210.07 sec.)
Epoch 25 starts
Epoch 25 (sato0): tr_loss=0.0099607 tr_macro_f1=0.9931 tr_micro_f1=0.9971  vl_loss=0.5044695 vl_macro_f1=0.8147 vl_micro_f1=0.9361 (211.87 sec.)
Epoch 26 starts
Epoch 26 (sato0): tr_loss=0.0090388 tr_macro_f1=0.9934 tr_micro_f1=0.9974  vl_loss=0.5008113 vl_macro_f1=0.8191 vl_micro_f1=0.9359 (201.62 sec.)
Epoch 27 starts
Epoch 27 (sato0): tr_loss=0.0082769 tr_macro_f1=0.9938 tr_micro_f1=0.9975  vl_loss=0.5130007 vl_macro_f1=0.8183 vl_micro_f1=0.9362 (199.41 sec.)
Epoch 28 starts
Epoch 28 (sato0): tr_loss=0.0073194 tr_macro_f1=0.9941 tr_micro_f1=0.9977  vl_loss=0.5128311 vl_macro_f1=0.8224 vl_micro_f1=0.9357 (197.89 sec.)
Epoch 29 starts
Epoch 29 (sato0): tr_loss=0.0069227 tr_macro_f1=0.9947 tr_micro_f1=0.9978  vl_loss=0.5175826 vl_macro_f1=0.8174 vl_micro_f1=0.9358 (208.44 sec.)